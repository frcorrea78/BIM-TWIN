Authors,Title,Year,Source title,Cited by,Link,Abstract,Document Type,Publication Stage,Source,EID
"Redmon J., Divvala S., Girshick R., Farhadi A.","You only look once: Unified, real-time object detection",2016,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",13086,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986308404&doi=10.1109%2fCVPR.2016.91&partnerID=40&md5=79a23b9cc271b6f314eea447fb88cc7d","We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork. © 2016 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84986308404
"Becerik-Gerber B., Jazizadeh F., Li N., Calis G.","Application areas and data requirements for BIM-enabled facilities management",2012,"Journal of Construction Engineering and Management",504,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859575621&doi=10.1061%2f%28ASCE%29CO.1943-7862.0000433&partnerID=40&md5=ff02cb8ce9e1f4735b345031c839e3e4","Facilities management (FM) encompasses and requires multidisciplinary activities, and thus has extensive information requirements. While some of these needs are addressed by several existing FM information systems, building information modeling (BIM), which is becoming widely adopted by the construction industry, holds undeveloped possibilities for providing and supporting FM practices with its functionalities of visualization, analysis, control, and so on. This paper explores how BIM can be a beneficial platform for supplementing FM practices. An online survey and face-to-face interviews were conducted to assess the current status of BIM implementations in FM, potential applications, and the level of interest in the utilization of BIM. Interactions between BIM and FM are defined by illustrating application areas and data requirements for BIM-enabled FM practices. Highlighting the synergy between the two, this paper can help professionals recognize potential areas in which BIM can be useful in FM practices. © 2012 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84859575621
"Gallaher M.P., O'Connor A.C., Dettbarn J.L., Gilday L.T.","Cost Analysis of Inadequate Inoperability in the Capital Facilities Industry",2004,"Cost Analysis of Inadequate Interoperability in the U.S. Capital Facilities Industry",500,,[No abstract available],,"Final",Scopus,2-s2.0-27144449547
"Shinde S., Kothari A., Gupta V.","YOLO based Human Action Recognition and Localization",2018,"Procedia Computer Science",47,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051357145&doi=10.1016%2fj.procs.2018.07.112&partnerID=40&md5=9023b3018d06d32ce7434b0dde392807","Human action recognition in video analytics has been widely studied in recent years. Yet, most of these methods assign a single action label to video after either analyzing a complete video or using classifier for each frame. But when compared to human vision strategy, it can be deduced that we (human) require just an instance of visual data for recognition of scene. It turns out that small group of frames or even single frame from the video are enough for precise recognition. In this paper, we present an approach to detect, localize and recognize actions of interest in almost real-time from frames obtained by a continuous stream of video data that can be captured from a surveillance camera. The model takes input frames after a specified period and is able to give action label based on a single frame. Combining results over specific time we predicted the action label for the stream of video. We demonstrate that YOLO is effective method and comparatively fast for recognition and localization in Liris Human Activities dataset. © 2018 The Authors. Published by Elsevier Ltd.",Conference Paper,"Final",Scopus,2-s2.0-85051357145
"Montserrat D.M., Lin Q., Allebach J., Delp E.J.","Training object detection and recognition CNN models using data augmentation",2017,"IS and T International Symposium on Electronic Imaging Science and Technology",42,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030256427&doi=10.2352%2fISSN.2470-1173.2017.10.IMAWM-163&partnerID=40&md5=1b55d7b5a6e89d01e20b047a40345711","Recent progress in deep learning methods has shown that key steps in object detection and recognition, including feature extraction, region proposals, and classification, can be done using Convolutional Neural Networks (CNN) with high accuracy. However, the use of CNNs for object detection and recognition has significant technical challenges that still need to be addressed. One of the most daunting problems is the very large number of training images required for each class/label. One way to address this problem is through the use of data augmentation methods where linear and nonlinear transforms are done on the training data to create ""new"" training images. Typical transformations include spatial flipping, warping and other deformations. An important concept of data augmentation is that the deformations applied to the labeled training images do not change the semantic meaning of the classes/labels. In this paper we investigate several approaches to data augmentation. First, several data augmentation techniques are used to increase the size of the training dataset. Then, a Faster R-CNN is trained with the augmented dataset for detect and recognize objects. Our work is focused on two different scenarios: detecting objects in the wild (i.e. commercial logos) and detecting objects captured using a camera mounted on a computer system (i.e. toy animals). © 2017, Society for Imaging Science and Technology.",Conference Paper,"Final",Scopus,2-s2.0-85030256427
"Quintana B., Prieto S.A., Adán A., Bosché F.","Door detection in 3D coloured point clouds of indoor environments",2018,"Automation in Construction",41,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032223417&doi=10.1016%2fj.autcon.2017.10.016&partnerID=40&md5=58468221e12ccbaa0f99c6c300729873","Door detection is becoming an increasingly important subject in building indoor modelling owing to its value in scan-to-BIM processes. This paper presents an original approach that detects open, semi-open and closed doors in 3D laser scanned data of indoor environments. The proposed technique is unique in that it integrates the information regarding both the geometry (i.e. XYZ coordinates) and colour (i.e. RGB or HSV) provided by a calibrated set of 3D laser scanner and a colour camera. In other words, our technique is developed in a 6D-space framework. The geometry-colour integration and other characteristics of our method make it robust to occlusion and variations in colours resulting from varying lighting conditions at each scanning location (e.g. specular highlights) and from different scanning locations. In addition to this paper, the authors also contribute a public dataset of real scenes along with an annotated ground truth. The dataset has varying levels of challenges and will help to assess the performance of new and existing contributions in the field. The approach proposed in this paper is tested against that dataset, yielding encouraging results. © 2017 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85032223417
"East W.E., Brodt W.","BIM for construction handover",2007,"Journal of Building Information Modeling",35,,[No abstract available],,"Final",Scopus,2-s2.0-70350211289
"Baek F., Ha I., Kim H.","Augmented reality system for facility management using image-based indoor localization",2019,"Automation in Construction",33,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057751858&doi=10.1016%2fj.autcon.2018.11.034&partnerID=40&md5=5427dd4df541b6fbf1d4fddc5117c689","Image-based localization has provided opportunities for efficient facility management. Combined with augmented reality (AR), automated localization can offer visually assistive information in facility management. However, implementing an AR-based facility management system with image-based localization is difficult. Device-intensive methods or markers were prerequisites for facility information display. Localization accuracy and information readability and accessibility were some of the issues to be resolved for a successful representation of facility information. This paper presents an AR system for facility management using an image-based indoor localization method that estimates the user's indoor position and orientation by comparing the user's perspective to building information modeling (BIM) based on a deep learning computation. A graphics processing unit (GPU)-enabled server is used for the deep learning computation, and the resultant information is wirelessly transferred to the mobile AR device through transmission control protocol/Internet protocol (TCP/IP). Thereafter, spatial mapping visually fits the object of interest (e.g. pipes) onto the AR image using three-dimensional (3D) sensing capability of AR device. Experts evaluated that the proposed system has potential for improved facility management and identified future research direction, such as integrated information presentation and effective reflection of rehabilitation efforts on the drawings. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85057751858
"Lu Q., Lee S., Chen L.","Image-driven fuzzy-based system to construct as-is IFC BIM objects",2018,"Automation in Construction",31,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053428303&doi=10.1016%2fj.autcon.2018.03.034&partnerID=40&md5=35364aa88676d152b91a2cd7236c267f","Various new data capturing technologies and object recognition systems have been developed to construct as-is building information models (BIMs) for operations and maintenance (O&M) management of existing buildings. However, a crucial challenge occurs in existing systems when semantic building information is captured under uncontrolled environmental conditions, especially in complex environments with poorly textured features (e.g., no obvious characteristics, edges, points, or lines). This study presents a semiautomatic image-driven system to recognize building objects and their materials and reviews the state-of-the-art object and material recognition methods and systems. A novel semiautomatic image-driven system was developed according to the new neuro-fuzzy framework for recognition of building objects and based on material classification procedures supported by an extensible texture library constructed to recognize their surface materials. More than 600 images were collected for the training process to develop this system, and more than 200 images were used for system verification. The results of the verification experiments show that the developed system can successfully recognize five kinds of building objects (i.e., beams, columns, windows, doors, and walls) and their corresponding surface materials from a single image taken by a handheld digital camera. Furthermore, the recognized building objects are automatically represented in industry foundation classes (IFC), a standard data schema for BIMs. The developed system is highly accurate, robust, and time-efficient for constructing as-is BIM objects in IFC and can help both BIM researchers and practitioners to develop information-rich BIMs in the O&M phase. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85053428303
"Lee S.-K., An H.-K., Yu J.-H.","An extension of the technology acceptance model for BIM-based FM",2012,"Construction Research Congress 2012: Construction Challenges in a Flat World, Proceedings of the 2012 Construction Research Congress",30,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866248429&doi=10.1061%2f9780784412329.061&partnerID=40&md5=bc82d689e7cc19c2f19e416bdbd8a2dc","BIM in the FM industry has significant impact on the acceleration of design and construction phases of equal importance. However, most of the facility managers are still managing the maintenance and operations of facilities by using paper-based processes that include drawings and spreadsheets. Therefore, we propose the conceptual BIM acceptance model in FM for understanding why people accept or reject BIM. The objective is to understand the key factors affecting the acceptance of BIM by facility managers. The external and internal variables identified through a literature review with respect to understanding the acceptance of new information technologies, and then to select external variables to increase BIM acceptance in FM. And the interview refines the constructs of a conceptual BIM acceptance model in FM based on the knowledge of experts and their experience with the topic. The proposed model combines the TAM2 and the PBC. The model consists of thirteen factors that are hypothesized to have direct or indirect effects on BIM acceptance. The primary contribution of this paper is to propose the foundation of research on the BIM challenge for FM as a guide for future research. © 2012 ASCE.",Conference Paper,"Final",Scopus,2-s2.0-84866248429
"Ammari K.E., Hammad A.","Collaborative BIM-based markerless mixed reality framework for facilities maintenance",2014,"Computing in Civil and Building Engineering - Proceedings of the 2014 International Conference on Computing in Civil and Building Engineering",25,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929332861&doi=10.1061%2f9780784413616.082&partnerID=40&md5=603e13f0cc1527a37d4d7b93d115f4a6","Facilities maintenance tasks require gathering and sharing large amounts of information related to facilities components. This information covers historical inspection data and operation information. Despite the availability of sophisticated Computerized Maintenance Management Systems (CMMSs), these systems focus on the data management aspects (i.e. work orders, resource management and asset inventory) and lack the functions required to facilitate data collection and data entry, as well as data retrieval and visualization when and where needed. Building Information Modeling (BIM) provides opportunities to improve the efficiency of CMMSs by sharing building information between different applications/users throughout the lifecycle of the facility. This paper proposes a framework for a collaborative BIM-based Markerless Mixed Reality (BIM3R). The framework integrates CMMS, BIM, and video-based tracking in a BIM3R setting to retrieve information based on time (e.g. inspection schedule) and the location of the user, visualize maintenance operations, and support collaboration between the field and the office to enhance decision making. Finally, a prototype system is implemented and a case study is applied to demonstrate the feasibility of the proposed approach. © ASCE 2014.",Conference Paper,"Final",Scopus,2-s2.0-84929332861
"Fonnet A., Alves N., Sousa N., Guevara M., Magalhães L.","Heritage BIM integration with mixed reality for building preventive maintenance",2017,"EPCGI 2017 - 24th Encontro Portugues de Computacao Grafica e Interacao",18,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043490986&doi=10.1109%2fEPCGI.2017.8124304&partnerID=40&md5=3bae999aeacf98c1078a96c62f60d2f4","Historical and cultural building conservation is nowadays limited to high value buildings and only receive financial support when serious issues arise. HeritageCARE project is willing to shift this mentality, towards ""prevention is better than the cure"". New technologies are able to support such motivation by improving building inspector work during their inspection routine. In that regard, mixed reality will be explored to offer easy and efficient interaction while remaining focused on the task at hand. Moreover, integration with historical building information model will ensure capture of localized data and easier exchange with stakeholders in case of renovation projects. This paper presents an architecture for a mixed reality application working towards this goal and a first prototype. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85043490986
"Riexinger G., Kluth A., Olbrich M., Braun J.-D., Bauernhansl T.","Mixed Reality for On-Site Self-Instruction and Self-Inspection with Building Information Models",2018,"Procedia CIRP",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049569632&doi=10.1016%2fj.procir.2018.03.160&partnerID=40&md5=358da2e0465b06004acda8015e67e972","Mixed Reality (MR) solutions for the manufacturing domain aim to support the construction, production and maintenance processes of factories, its equipment and products. Within the European project ""INSITER"", Fraunhofer developed visualization solutions and MR prototypes aiming to provide relevant data for different stakeholders using Building Information Modeling (BIM)-based information. Planning data of production environments or construction sites is made available on site via MR. The main objective of the work presented in this paper, is to support planning processes as well as production and construction workflows with in-situ visualization of digital planning or process data in MR. © 2018 The Authors. Published by Elsevier B.V.",Conference Paper,"Final",Scopus,2-s2.0-85049569632
"Bonanni T.M., Pennisi A., Bloisi D., Iocchi L., Nardi D.","Human-robot collaboration for semantic labeling of the environment",2013,"Proceedings of the 3rd Workshop on Semantic Perception, Mapping and Exploration",12,,[No abstract available],,"Final",Scopus,2-s2.0-85039989711
"Kopsida M., Brilakis I.","BIM registration methods for mobile augmented reality-based inspection",2016,"eWork and eBusiness in Architecture, Engineering and Construction - Proceedings of the 11th European Conference on Product and Process Modelling, ECPPM 2016",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016585286&partnerID=40&md5=b0b0940b3127226a6e14250c1edb7b12","On-site construction inspection for progress monitoring is a manual, time consuming and labour intensive process consumed by exhaustive manual extraction of data from drawings and databases. Efforts have been made to facilitate the inspection process by using emerging technologies such as Augmented Reality (AR). AR based systems can simplify and reduce the time of inspection by providing the inspector with instantaneous access to the information stored in the Building Information Modelling (BIM). However, precise alignment between the BIM model and the real world scene is still a challenge. For estimating the position and orientation of the user, methods have been proposed that either use markers or confine the user to a specific location, or use Global Positioning System (GPS) which cannot operate efficiently in an indoor environment. This paper presents an evaluation of different methods that could potentially be used for a marker-less BIM registration in AR. We implemented and tested line, edge, and contour detection algorithms using images, data from LSD and ORB Simultaneous Localisation And Mapping (SLAM) methods and 3D and positioning data from Kinect sensor and Google Project Tango. The results indicate that sparse 3D data is the input dataset that leads to the most robust results when combined with XYZ method. © 2016 Taylor & Francis Group.",Conference Paper,"Final",Scopus,2-s2.0-85016585286
"Silva H., Resende R., Breternitz M.","Mixed reality application to support infrastructure maintenance",2018,"Proceedings - 2018 International Young Engineers Forum, YEF-ECE 2018",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048887936&doi=10.1109%2fYEF-ECE.2018.8368938&partnerID=40&md5=3a3999d40d704edb1e1fa6fd31c225c2","This paper presents a mixed reality (MR) application developed for the head-mounted display Microsoft HoloLens that supports infrastructure maintenance works in buildings with complex infrastructure. The solution is intended to help maintenance workers when they need to track and fix part of the infrastructure by revealing hidden infrastructure, displaying additional information and guiding workers in complex tasks. The application has the potential to improve maintenance worker's tasks as it can help them perform faster and with more accuracy. The work explores the creation of the application and discusses the methodologies used to build an optimal and user-friendly tool. The methodology is based on design science research: an improvement need, and not necessarily a problem, was identified, and from there a solution was conceived. MR has proven to be a major tool for helping in several areas, and this paper can give insights for many future solutions with mixed reality or HoloLens and help them build new and better applications to improve tasks at a job or at home. © 2018 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85048887936
"Quintana B., Prieto S.A., Adán A., Bosché F.","Scan-to-BIM for small BIM components",2017,"Proc., Joint Conference on Computing in Construction (JC3)",2,,[No abstract available],,"Final",Scopus,2-s2.0-85048684100
"Keady R.A.","Financial impact and analysis of equipment inventories",2013,"Facilities Engineering Journal",2,,[No abstract available],,"Final",Scopus,2-s2.0-85071487536
"Arayici Y.","The use of the 3D laser scanner in the built environment",2010,"Built Environment: Design, Management and Applications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892136276&partnerID=40&md5=7a4e9d9a0b0fbbb543c12d2baa7099b8","Capturing and modelling 3D information of the built environment is a big challenge. Anumber of techniques and technologies are now in use. These include EDM (ElectronicDistance Measurement), GPS (Global Positioning System), and photogrammetric application,remote sensing and traditional building surveying applications. However, the use of thesetechnologies cannot be practical and efficient in regard to time, cost and accuracy.Furthermore, a multi disciplinary knowledge base, created from the studies and researchabout the regeneration aspects is fundamental: historical, architectural, archeologically,environmental, social, economic, etc. In order to have an adequate diagnosis of regeneration,it is necessary to describe buildings and surroundings by means of documentation and plans.However, at this point in time the foregoing is considerably far removed from the realsituation, since more often than not it is extremely difficult to obtain full documentation andcartography, of an acceptable quality, since the material, constructive pathologies and systemsare often insufficient or deficient (flat that simply reflects levels, isolated photographs,..).Sometimes the information in reality exists, but this fact is not known, or it is not easilyaccessible, leading to the unnecessary duplication of efforts and resources.Systems that measure range from the time-of-flight of a laser pulse have been availablefor about 25 years, so this does not constitute new technology. However, the development offast measurement (up to 10000 measurements per second) and a scanning mechanism (usingrotating mirrors) has only occurred in this decade or so. Packaging these components into arobust and reliable instrument has resulted in the innovation of a 3D laser scanner.In this chapter, we discussed 3D laser scanning technology, which can acquire highdensity point data in an accurate, fast way. Besides, the scanner can digitize all the 3Dinformation concerned with a real world object such as buildings, trees and terrain down tomillimetre detail Therefore, it can provide benefits for refurbishment process in regenerationin the Built Environment and it can be the potential solution to overcome the challengesabove. The chapter introduces an approach for scanning buildings, processing the point cloudraw data, and a modelling approach for CAD extraction and building objects classification inIFC (Industry Foundation Classes) format. The approach presented in this section can lead toparametric design and Building Information Modelling (BIM) for existing structures. In thischapter, while use of laser scanners are explained, the integration of it with varioustechnologies and systems are also explored for professionals in the Built Environment. © 2010 Nova Science Publishers, Inc. All rights reserved.",Book Chapter,"Final",Scopus,2-s2.0-84892136276
