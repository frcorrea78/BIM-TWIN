Authors,Title,Year,Source title,Cited by,Link,Abstract,Document Type,Publication Stage,Source,EID
"Nelder J.A., Mead R.","A simplex method for function minimization",1965,"Comput. J.",20543,,[No abstract available],,,Scopus,2-s2.0-0000238336
"Besl P.J., McKay N.D.","A Method for Registration of 3-D Shapes",1992,"IEEE Transactions on Pattern Analysis and Machine Intelligence",12199,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026821209&doi=10.1109%2f34.121791&partnerID=40&md5=ee06231fbe1dba306ad906353ec3701d","This paper describes a general-purpose, representation-independent method for the accurate and computationally efficient registration of 3-D shapes including free-form curves and surfaces. The method handles the full six degrees of freedom and is based on the iterative closest point (ICP) algorithm, which requires only a procedure to find the closest point on a geometric entity to a given point. The ICP algorithm always converges monotonically to the nearest local minimum of a mean-square distance metric, and experience shows that the rate of convergence is rapid during the first few iterations. Therefore, given an adequate set of initial rotations and translations for a particular class of objects with a certain level of “shape complexity,” one can globally minimize the mean-square distance metric over all six degrees of freedom by testing each initial registration. For example, a given “model” shape and a sensed “data” shape that represents a major portion of the model shape can be registered in minutes by testing one initial translation and a relatively small set of rotations to allow for the given level of model complexity. One important application of this method is to register sensed data from unfixtured rigid objects with an ideal geometric model prior to shape inspection. The described method is also useful for deciding fundamental issues such as the congruence (shape equivalence) of different geometric representations as well as for estimating the motion between point sets where the correspondences are not known. Experimental results show the capabilities of the registration algorithm on point sets, curves, and surfaces. © 1992 IEEE",Article,"Final",Scopus,2-s2.0-0026821209
"Rusinkiewicz S., Levoy M.","Efficient variants of the ICP algorithm",2001,"Proceedings of International Conference on 3-D Digital Imaging and Modeling, 3DIM",2978,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949236475&doi=10.1109%2fIM.2001.924423&partnerID=40&md5=8ce35ec134f1ca6df34433ed583897fd","The ICP (Iterative Closest Point) algorithm is widely used for geometric alignment of three-dimensional models when an initial estimate of the relative pose is known. Many variants of ICP have been proposed, affecting all phases of the algorithm from the selection and matching of points to the minimization strategy. We enumerate and classify many of these variants, and evaluate their effect on the speed with which the correct alignment is reached. In order to improve convergence for nearly-flat meshes with small features, such as inscribed surfaces, we introduce a new variant based on uniform sampling of the space of normals. We conclude by proposing a combination of ICP variants optimized for high speed. We demonstrate an implementation that is able to align two range images in a few tens of milliseconds, assuming a good initial guess. This capability has potential application to real-time 3D model acquisition and model-based tracking.",Article,"Final",Scopus,2-s2.0-84949236475
"Adams R., Bischof L.","Seeded Region Growing",1994,"IEEE Transactions on Pattern Analysis and Machine Intelligence",2348,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028444401&doi=10.1109%2f34.295913&partnerID=40&md5=ee60756feb6d1292182e347f8517b760","We present here a new algorithm for segmentation of intensity images which is robust, rapid, and free of tuning parameters. The method, however, requires the input of a number of seeds, either individual pixels or regions, which will control the formation of regions into which the image will be segmented. In this correspondence, we present the algorithm, discuss briefly its properties, and suggest two ways in which it can be employed, namely, by using manual seed selection or by automated procedures. © 1994 IEEE.",Article,"Final",Scopus,2-s2.0-0028444401
"Yang C., Medioni G.","Object modelling by registration of multiple range images",1992,"Image and Vision Computing",1991,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-44049122968&doi=10.1016%2f0262-8856%2892%2990066-C&partnerID=40&md5=61be7968c009cd57950b74296200b88a","We study the problem of creating a complete model of a physical object. Although this may be possible using intensity images, we here use images which directly provide access to three dimensional information. The first problem that we need to solve is to find the transformation between the different views. Previous approaches either assume this transformation to be known (which is extremely difficult for a complete model), or compute it with feature matching (which is not accurate enough for integration). In this paper, we propose a new approach which works on range data directly and registers successive views with enough overlapping area to get an accurate transformation between views. This is performed by minimizing a functional which does not require point-to-point matches. We give the details of the registration method and modelling procedure and illustrate them on real range images of complex objects. © 1992.",Article,"Final",Scopus,2-s2.0-44049122968
"Rusu R.B., Blodow N., Beetz M.","Fast Point Feature Histograms (FPFH) for 3D Registration",2009,"Proceedings - IEEE International Conference on Robotics and Automation",1882,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111089218&doi=10.1109%2fROBOT.2009.5152473&partnerID=40&md5=d2055d64075f0ef3e4a96d163d2cc611","In our recent work [1], [2], we proposed Point Feature Histograms (PFH) as robust multi-dimensional features which describe the local geometry around a point p for 3D point cloud datasets. In this paper, we modify their mathematical expressions and perform a rigorous analysis on their robustness and complexity for the problem of 3D registration for overlapping point cloud views. More concretely, we present several optimizations that reduce their computation times drastically by either caching previously computed values or by revising their theoretical formulations. The latter results in a new type of local features, called Fast Point Feature Histograms (FPFH), which retain most of the discriminative power of the PFH. Moreover, we propose an algorithm for the online computation of FPFH features for realtime applications. To validate our results we demonstrate their efficiency for 3D registration and propose a new sample consensus based method for bringing two datasets into the convergence basin of a local non-linear optimizer: SAC-IA (SAmple Consensus Initial Alignment). © 2009 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85111089218
"Myronenko A., Song X.","Point set registration: Coherent point drifts",2010,"IEEE Transactions on Pattern Analysis and Machine Intelligence",1626,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049528457&doi=10.1109%2fTPAMI.2010.46&partnerID=40&md5=a488a7494ac14cb5be07ea844d6e1d7d","Point set registration is a key component in many computer vision tasks. The goal of point set registration is to assign correspondences between two sets of points and to recover the transformation that maps one point set to the other. Multiple factors, including an unknown nonrigid spatial transformation, large dimensionality of point set, noise, and outliers, make the point set registration a challenging problem. We introduce a probabilistic method, called the Coherent Point Drift (CPD) algorithm, for both rigid and nonrigid point set registration. We consider the alignment of two point sets as a probability density estimation problem. We fit the Gaussian mixture model (GMM) centroids (representing the first point set) to the data (the second point set) by maximizing the likelihood. We force the GMM centroids to move coherently as a group to preserve the topological structure of the point sets. In the rigid case, we impose the coherence constraint by reparameterization of GMM centroid locations with rigid parameters and derive a closed form solution of the maximization step of the EM algorithm in arbitrary dimensions. In the nonrigid case, we impose the coherence constraint by regularizing the displacement field and using the variational calculus to derive the optimal transformation. We also introduce a fast algorithm that reduces the method computation complexity to linear. We test the CPD algorithm for both rigid and nonrigid transformations in the presence of noise, outliers, and missing points, where CPD shows accurate results and outperforms current state-of-the-art methods. © 2010 IEEE.",Article,"Final",Scopus,2-s2.0-78049528457
"Jones D.R., Perttunen C.D., Stuckman B.E.","Lipschitzian optimization without the Lipschitz constant",1993,"Journal of Optimization Theory and Applications",1353,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027678534&doi=10.1007%2fBF00941892&partnerID=40&md5=15ffbf3fd412e5b4baa0b4ac3a0630eb","We present a new algorithm for finding the global minimum of a multivariate function subject to simple bounds. The algorithm is a modification of the standard Lipschitzian approach that eliminates the need to specify a Lipschitz constant. This is done by carrying out simultaneous searches using all possible constants from zero to infinity. On nine standard test functions, the new algorithm converges in fewer function evaluations than most competing methods. The motivation for the new algorithm stems from a different way of looking at the Lipschitz constant. In particular, the Lipschitz constant is viewed as a weighting parameter that indicates how much emphasis to place on global versus local search. In standard Lipschitzian methods, this constant is usually large because it must equal or exceed the maximum rate of change of the objective function. As a result, these methods place a high emphasis on global search and exhibit slow convergence. In contrast, the new algorithm carries out simultaneous searches using all possible constants, and therefore operates at both the global and local level. Once the global part of the algorithm finds the basin of convergence of the optimum, the local part of the algorithm quickly and automatically exploits it. This accounts for the fast convergence of the new algorithm on the test functions. © 1993 Plenum Publishing Corporation.",Article,"Final",Scopus,2-s2.0-0027678534
"Hansen N., Müller S.D., Koumoutsakos P.","Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES)",2003,"Evolutionary Computation",1306,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042879997&doi=10.1162%2f106365603321828970&partnerID=40&md5=d08226fde6ff1c87de8e61187aae1511","This paper presents a novel evolutionary optimization strategy based on the deran-domized evolution strategy with covariance matrix adaptation (CMA-ES). This new approach is intended to reduce the number of generations required for convergence to the optimum. Reducing the number of generations, i.e., the time complexity of the algorithm, is important if a large population size is desired: (1) to reduce the effect of noise; (2) to improve global search properties; and (3) to implement the algorithm on (highly) parallel machines. Our method results in a highly parallel algorithm which scales favorably with large numbers of processors. This is accomplished by efficiently incorporating the available information from a large population, thus significantly reducing the number of generations needed to adapt the covariance matrix. The original version of the CMA-ES was designed to reliably adapt the covariance matrix in small populations but it cannot exploit large populations efficiently. Our modifications scale up the efficiency to population sizes of up to 10n, where n is the problem dimension. This method has been applied to a large number of test problems, demonstrating that in many cases the CMA-ES can be advanced from quadratic to linear time complexity.",Article,"Final",Scopus,2-s2.0-0042879997
"Telea A.","An image inpainting technique based on the fast marching method",2004,"Journal of Graphics Tools",861,,[No abstract available],,"Final",Scopus,2-s2.0-24644514008
"Endres F., Hess J., Sturm J., Cremers D., Burgard W.","3-D Mapping with an RGB-D camera",2014,"IEEE Transactions on Robotics",585,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894554423&doi=10.1109%2fTRO.2013.2279412&partnerID=40&md5=97ed6562f2972dcca1c95d86f8644644","In this paper, we present a novel mapping system that robustly generates highly accurate 3-D maps using an RGB-D camera. Our approach requires no further sensors or odometry. With the availability of low-cost and light-weight RGB-D sensors such as the Microsoft Kinect, our approach applies to small domestic robots such as vacuum cleaners, as well as flying robots such as quadrocopters. Furthermore, our system can also be used for free-hand reconstruction of detailed 3-D models. In addition to the system itself, we present a thorough experimental evaluation on a publicly available benchmark dataset. We analyze and discuss the influence of several parameters such as the choice of the feature descriptor, the number of visual features, and validation methods. The results of the experiments demonstrate that our system can robustly deal with challenging scenarios such as fast camera motions and feature-poor environments while being fast enough for online operation. Our system is fully available as open source and has already been widely adopted by the robotics community. © 2013 IEEE.",Article,"Final",Scopus,2-s2.0-84894554423
"Chua C.S., Jarvis R.","Point Signatures: A New Representation for 3D Object Recognition",1997,"International Journal of Computer Vision",477,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031246477&doi=10.1023%2fA%3a1007981719186&partnerID=40&md5=6d5995a0337db4a7f7b90b25d59e5d73","Few systems capable of recognizing complex objects with free-form (sculptured) surfaces have been developed. The apparent lack of success is mainly due to the lack of a competent modelling scheme for representing such complex objects. In this paper, a new form of point representation for describing 3D free-form surfaces is proposed. This representation, which we call the point signature, serves to describe the structural neighbourhood of a point in a more complete manner than just using the 3D coordinates of the point. Being invariant to rotation and translation, the point signature can be used directly to hypothesize the correspondence to model points with similar signatures. Recognition is achieved by matching the signatures of data points representing the sensed surface to the signatures of data points representing the model surface. The use of point signatures is not restricted to the recognition of a single-object scene to a small library of models. Instead, it can be extended naturally to the recognition of scenes containing multiple partially-overlapping objects (which may also be juxtaposed with each other) against a large model library. No preliminary phase of segmenting the scene into the component objects is required. In searching for the appropriate candidate model, recognition need not proceed in a linear order which can become prohibitive for a large model library. For a given scene, signatures are extracted at arbitrarily spaced seed points. Each of these signatures is used to vote for models that contain points having similar signatures. Inappropriate models with low votes can be rejected while the remaining candidate models are ordered according to the votes they received. In this way, efficient verification of the hypothesized candidates can proceed by testing the most likely model first. Experiments using real data obtained from a range finder have shown fast recognition from a library of fifteen models whose complexities vary from that of simple piecewise quadric shapes to complicated face masks. Results from the recognition of both single-object and multiple-object scenes are presented.",Article,"Final",Scopus,2-s2.0-0031246477
"Tam G.K.L., Cheng Z.-Q., Lai Y.-K., Langbein F.C., Liu Y., Marshall D., Martin R.R., Sun X.-F., Rosin P.L.","Registration of 3d point clouds and meshes: A survey from rigid to Nonrigid",2013,"IEEE Transactions on Visualization and Computer Graphics",417,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877879387&doi=10.1109%2fTVCG.2012.310&partnerID=40&md5=2418a3042e3b9a9bac26922fd9c83a10","Three-dimensional surface registration transforms multiple three-dimensional data sets into the same coordinate system so as to align overlapping components of these sets. Recent surveys have covered different aspects of either rigid or nonrigid registration, but seldom discuss them as a whole. Our study serves two purposes: 1) To give a comprehensive survey of both types of registration, focusing on three-dimensional point clouds and meshes and 2) to provide a better understanding of registration from the perspective of data fitting. Registration is closely related to data fitting in which it comprises three core interwoven components: model selection, correspondences and constraints, and optimization. Study of these components 1) provides a basis for comparison of the novelties of different techniques, 2) reveals the similarity of rigid and nonrigid registration in terms of problem representations, and 3) shows how overfitting arises in nonrigid registration and the reasons for increasing interest in intrinsic techniques. We further summarize some practical issues of registration which include initializations and evaluations, and discuss some of our own observations, insights and foreseeable research trends. © 2012 IEEE.",Review,"Final",Scopus,2-s2.0-84877879387
"Yang J., Li H., Campbell D., Jia Y.","Go-ICP: A Globally Optimal Solution to 3D ICP Point-Set Registration",2016,"IEEE Transactions on Pattern Analysis and Machine Intelligence",365,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991746810&doi=10.1109%2fTPAMI.2015.2513405&partnerID=40&md5=908266b3d24d75cea61f2493a38250e1","The Iterative Closest Point (ICP) algorithm is one of the most widely used methods for point-set registration. However, being based on local iterative optimization, ICP is known to be susceptible to local minima. Its performance critically relies on the quality of the initialization and only local optimality is guaranteed. This paper presents the first globally optimal algorithm, named Go-ICP, for Euclidean (rigid) registration of two 3D point-sets under the L2 error metric defined in ICP. The Go-ICP method is based on a branch-and-bound scheme that searches the entire 3D motion space SE(3). By exploiting the special structure of SE(3) geometry, we derive novel upper and lower bounds for the registration error function. Local ICP is integrated into the BnB scheme, which speeds up the new method while guaranteeing global optimality. We also discuss extensions, addressing the issue of outlier robustness. The evaluation demonstrates that the proposed method is able to produce reliable registration results regardless of the initialization. Go-ICP can be applied in scenarios where an optimal solution is desirable or where a good initialization is not always available. © 2015 IEEE.",Article,"Final",Scopus,2-s2.0-84991746810
"Zeng A., Song S., Nießner M., Fisher M., Xiao J., Funkhouser T.","3DMatch: Learning local geometric descriptors from RGB-D reconstructions",2017,"Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017",284,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040244040&doi=10.1109%2fCVPR.2017.29&partnerID=40&md5=9b22e54a749e1cf80206613f98ddd3e0","Matching local geometric features on real-world depth images is a challenging task due to the noisy, low-resolution, and incomplete nature of 3D scan data. These difficulties limit the performance of current state-of-art methods, which are typically based on histograms over geometric properties. In this paper, we present 3DMatch, a data-driven model that learns a local volumetric patch descriptor for establishing correspondences between partial 3D data. To amass training data for our model, we propose a self-supervised feature learning method that leverages the millions of correspondence labels found in existing RGB-D reconstructions. Experiments show that our descriptor is not only able to match local geometry in new scenes for reconstruction, but also generalize to different tasks and spatial scales (e.g. instance-level object model alignment for the Amazon Picking Challenge, and mesh surface correspondence). Results show that 3DMatch consistently outperforms other state-of-the-art approaches by a significant margin. Code, data, benchmarks, and pre-trained models are available online at http://3dmatch.cs.princeton.edu. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85040244040
"Rowan T.","Functional stability analysis of numerical algorithms",1990,"Functional Stability Analysis of Numerical Algorithms",251,,[No abstract available],,"Final",Scopus,2-s2.0-0003725380
"Sun C., Sherrah J.","3D symmetry detection using the extended gaussian image",1997,"IEEE Transactions on Pattern Analysis and Machine Intelligence",189,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031076506&doi=10.1109%2f34.574800&partnerID=40&md5=dc8d025c1acda558cf74ba10c18e34f2","Symmetry detection is important in the area of computer vision. A 3D symmetry detection algorithm is presented in this correspondence. The symmetry detection problem is converted to the correlation of the Gaussian image. Once the Gaussian image of the object has been obtained, the algorithm is independent of the input format. The algorithm can handle different kinds of images or objects. Simulated and real images have been tested in a variety of formats, and the results show that the symmetry can be determined using the Gaussian image. © 1997 IEEE.",Article,"Final",Scopus,2-s2.0-0031076506
"Deng H., Birdal T., Ilic S.","PPFNet: Global Context Aware Local Features for Robust 3D Point Matching",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",147,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055098583&doi=10.1109%2fCVPR.2018.00028&partnerID=40&md5=8ac93a8a166aa69cae4cf57ff9f864f7","We present PPFNet - Point Pair Feature NETwork for deeply learning a globally informed 3D local feature descriptor to find correspondences in unorganized point clouds. PPFNet learns local descriptors on pure geometry and is highly aware of the global context, an important cue in deep learning. Our 3D representation is computed as a collection of point-pair-features combined with the points and normals within a local vicinity. Our permutation invariant network design is inspired by PointNet and sets PPFNet to be ordering-free. As opposed to voxelization, our method is able to consume raw point clouds to exploit the full sparsity. PPFNet uses a novel N-tuple loss and architecture injecting the global information naturally into the local descriptor. It shows that context awareness also boosts the local feature representation. Qualitative and quantitative evaluations of our network suggest increased recall, improved robustness and invariance as well as a vital step in the 3D descriptor extraction performance. © 2018 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85055098583
"Wang Y., Solomon J.","Deep closest point: Learning representations for point cloud registration",2019,"Proceedings of the IEEE International Conference on Computer Vision",134,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081692730&doi=10.1109%2fICCV.2019.00362&partnerID=40&md5=93efa9441b6af6303b65d867e931ec25","Point cloud registration is a key problem for computer vision applied to robotics, medical imaging, and other applications. This problem involves finding a rigid transformation from one point cloud into another so that they align. Iterative Closest Point (ICP) and its variants provide simple and easily-implemented iterative methods for this task, but these algorithms can converge to spurious local optima. To address local optima and other difficulties in the ICP pipeline, we propose a learning-based method, titled Deep Closest Point (DCP), inspired by recent techniques in computer vision and natural language processing. Our model consists of three parts: A point cloud embedding network, an attention-based module combined with a pointer generation layer to approximate combinatorial matching, and a differentiable singular value decomposition (SVD) layer to extract the final rigid transformation. We train our model end-to-end on the ModelNet40 dataset and show in several settings that it performs better than ICP, its variants (e.g., Go-ICP, FGR), and the recently-proposed learning-based method PointNetLK. Beyond providing a state-of-the-art registration technique, we evaluate the suitability of our learned features transferred to unseen objects. We also provide preliminary analysis of our learned model to help understand whether domain-specific and/or global features facilitate rigid registration. © 2019 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85081692730
"Boje C., Guerriero A., Kubicki S., Rezgui Y.","Towards a semantic Construction Digital Twin: Directions for future research",2020,"Automation in Construction",113,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082386834&doi=10.1016%2fj.autcon.2020.103179&partnerID=40&md5=914efcd6c064d6a97299f00d812bb8fc","As the Architecture, Engineering and Construction sector is embracing the digital age, the processes involved in the design, construction and operation of built assets are more and more influenced by technologies dealing with value-added monitoring of data from sensor networks, management of this data in secure and resilient storage systems underpinned by semantic models, as well as the simulation and optimisation of engineering systems. Aside from enhancing the efficiency of the value chain, such information-intensive models and associated technologies play a decisive role in minimising the lifecycle impacts of our buildings. While Building Information Modelling provides procedures, technologies and data schemas enabling a standardised semantic representation of building components and systems, the concept of a Digital Twin conveys a more holistic socio-technical and process-oriented characterisation of the complex artefacts involved by leveraging the synchronicity of the cyber-physical bi-directional data flows. Moreover, BIM lacks semantic completeness in areas such as control systems, including sensor networks, social systems, and urban artefacts beyond the scope of buildings, thus requiring a holistic, scalable semantic approach that factors in dynamic data at different levels. The paper reviews the multi-faceted applications of BIM during the construction stage and highlights limits and requirements, paving the way to the concept of a Construction Digital Twin. A definition of such a concept is then given, described in terms of underpinning research themes, while elaborating on areas for future research. © 2020 The Authors",Review,"Final",Scopus,2-s2.0-85082386834
"Lim K.Y.H., Zheng P., Chen C.-H.","A state-of-the-art survey of Digital Twin: techniques, engineering product lifecycle management and business innovation perspectives",2020,"Journal of Intelligent Manufacturing",93,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075384583&doi=10.1007%2fs10845-019-01512-w&partnerID=40&md5=31f4ad1b53bf5c177725cfd1fb6a27c4","With the rapid advancement of cyber-physical systems, Digital Twin (DT) is gaining ever-increasing attention owing to its great capabilities to realize Industry 4.0. Enterprises from different fields are taking advantage of its ability to simulate real-time working conditions and perform intelligent decision-making, where a cost-effective solution can be readily delivered to meet individual stakeholder demands. As a hot topic, many approaches have been designed and implemented to date. However, most approaches today lack a comprehensive review to examine DT benefits by considering both engineering product lifecycle management and business innovation as a whole. To fill this gap, this work conducts a state-of-the art survey of DT by selecting 123 representative items together with 22 supplementary works to address those two perspectives, while considering technical aspects as a fundamental. The systematic review further identifies eight future perspectives for DT, including modular DT, modeling consistency and accuracy, incorporation of Big Data analytics in DT models, DT simulation improvements, VR integration into DT, expansion of DT domains, efficient mapping of cyber-physical data and cloud/edge computing integration. This work sets out to be a guide to the status of DT development and application in today’s academic and industrial environment. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.",Review,"Final",Scopus,2-s2.0-85075384583
"Khajavi S.H., Motlagh N.H., Jaribion A., Werner L.C., Holmstrom J.","Digital Twin: Vision, benefits, boundaries, and creation for buildings",2019,"IEEE Access",76,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077738936&doi=10.1109%2fACCESS.2019.2946515&partnerID=40&md5=a69e0011a75fe6a60823f59b9a66bba6","The concept of a digital twin has been used in some industries where an accurate digital model of the equipment can be used for predictive maintenance. The use of a digital twin for performance is critical, and for capital-intensive equipment such as jet engines it proved to be successful in terms of cost savings and reliability improvements. In this paper, we aim to study the expansion of the digital twin in including building life cycle management and explore the benefits and shortcomings of such implementation. In four rounds of experimentation, more than 25,000 sensor reading instances were collected, analyzed, and utilized to create and test a limited digital twin of an office building facade element. This is performed to point out the method of implementation, highlight the benefits gained from digital twin, and to uncover some of the technical shortcomings of the current Internet of Things systems for this purpose. © 2013 IEEE.",Article,"Final",Scopus,2-s2.0-85077738936
"Choy C., Park J., Koltun V.","Fully convolutional geometric features",2019,"Proceedings of the IEEE International Conference on Computer Vision",72,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081916833&doi=10.1109%2fICCV.2019.00905&partnerID=40&md5=d88dd2bb23f2fbb25e937eae6145c073","Extracting geometric features from 3D scans or point clouds is the first step in applications such as registration, reconstruction, and tracking. State-of-the-art methods require computing low-level features as input or extracting patch-based features with limited receptive field. In this work, we present fully-convolutional geometric features, computed in a single pass by a 3D fully-convolutional network. We also present new metric learning losses that dramatically improve performance. Fully-convolutional geometric features are compact, capture broad spatial context, and scale to large scenes. We experimentally validate our approach on both indoor and outdoor datasets. Fully-convolutional geometric features achieve state-of-the-art accuracy without requiring prepossessing, are compact (32 dimensions), and are 290 times faster than the most accurate prior method. © 2019 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85081916833
"Ochmann S., Vock R., Klein R.","Automatic reconstruction of fully volumetric 3D building models from oriented point clouds",2019,"ISPRS Journal of Photogrammetry and Remote Sensing",72,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063442343&doi=10.1016%2fj.isprsjprs.2019.03.017&partnerID=40&md5=5cf9d1476f8ef76576bea4b3e2454e39","We present a novel method for reconstructing parametric, volumetric, multi-story building models from unstructured, unfiltered indoor point clouds with oriented normals by means of solving an integer linear optimization problem. Our approach overcomes limitations of previous methods in several ways: First, we drop assumptions about the input data such as the availability of separate scans as an initial room segmentation. Instead, a fully automatic room segmentation and outlier removal is performed on the unstructured point clouds. Second, restricting the solution space of our optimization approach to arrangements of volumetric wall entities representing the structure of a building enforces a consistent model of volumetric, interconnected walls fitted to the observed data instead of unconnected, paper-thin surfaces. Third, we formulate the optimization as an integer linear programming problem which allows for an exact solution instead of the approximations achieved with most previous techniques. Lastly, our optimization approach is designed to incorporate hard constraints which were difficult or even impossible to integrate before. We evaluate and demonstrate the capabilities of our proposed approach on a variety of complex real-world point clouds. © 2019",Article,"Final",Scopus,2-s2.0-85063442343
"Liu C., Wu J., Kohli P., Furukawa Y.","Raster-to-Vector: Revisiting Floorplan Transformation",2017,"Proceedings of the IEEE International Conference on Computer Vision",68,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041927829&doi=10.1109%2fICCV.2017.241&partnerID=40&md5=b230abcaeb1e298da2cd59e47357e8ce","This paper addresses the problem of converting a rasterized floorplan image into a vector-graphics representation. Unlike existing approaches that rely on a sequence of lowlevel image processing heuristics, we adopt a learning-based approach. A neural architecture first transforms a rasterized image to a set of junctions that represent low-level geometric and semantic information (e.g., wall corners or door end-points). Integer programming is then formulated to aggregate junctions into a set of simple primitives (e.g., wall lines, door lines, or icon boxes) to produce a vectorized floorplan, while ensuring a topologically and geometrically consistent result. Our algorithm significantly outperforms existing methods and achieves around 90% precision and recall, getting to the range of production-ready performance. The vector representation allows 3D model popup for better indoor scene visualization, direct model manipulation for architectural remodeling, and further computational applications such as data analysis. Our system is efficient: we have converted hundred thousand production-level floorplan images into the vector representation and generated 3D popup models. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85041927829
"Kazhdan M.","An approximate and efficient method for optimal rotation alignment of 3D models",2007,"IEEE Transactions on Pattern Analysis and Machine Intelligence",61,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249685005&doi=10.1109%2fTPAMI.2007.1032&partnerID=40&md5=32dabe4091527df61c901775c067031d","In many shape analysis applications, the ability to find the best rotation that aligns two models is an essential first step in the analysis process. In the past, methods for model alignment have either used normalization techniques, such as PCA alignment, or have performed an exhaustive search over the space of rotation to find the best optimal alignment. While normalization techniques have the advantage of efficiency, providing a quick method for registering two shapes, they are often imprecise and can give rise to poor alignments. Conversely, exhaustive search is guaranteed to provide the correct answer, but, even using efficient signal processing techniques, this type of approach can be prohibitively slow. In this paper, we present a new method for aligning two 3D shapes. We show that the method is markedly faster than existing approaches based on efficient signal processing and we provide registration results demonstrating that the alignments obtained using our method have a high degree of precision and are markedly better than those obtained using normalization. © 2007 IEEE.",Article,"Final",Scopus,2-s2.0-34249685005
"Yew Z.J., Lee G.H.","3DFeat-net: Weakly supervised local 3D features for point cloud registration",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",59,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055452309&doi=10.1007%2f978-3-030-01267-0_37&partnerID=40&md5=aa5a38ad61f7bde00bb94db68e8804fc","In this paper, we propose the 3DFeat-Net which learns both 3D feature detector and descriptor for point cloud matching using weak supervision. Unlike many existing works, we do not require manual annotation of matching point clusters. Instead, we leverage on alignment and attention mechanisms to learn feature correspondences from GPS/INS tagged 3D point clouds without explicitly specifying them. We create training and benchmark outdoor Lidar datasets, and experiments show that 3DFeat-Net obtains state-of-the-art performance on these gravity-aligned datasets. © Springer Nature Switzerland AG 2018.",Conference Paper,"Final",Scopus,2-s2.0-85055452309
"Gimenez L., Robert S., Suard F., Zreik K.","Automatic reconstruction of 3D building models from scanned 2D floor plans",2016,"Automation in Construction",54,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951336284&doi=10.1016%2fj.autcon.2015.12.008&partnerID=40&md5=d216033a94481f7218cbca4d33cff522","The overall energy efficiency of existing buildings has to be significantly improved to comply with emerging regulations and to contribute to overcoming current environmental challenges. Many policies aim at accelerating the renovation rate. The effectiveness of renovation actions could be significantly improved through the systematic use of Information and Communication Technologies (ICT) tools and Building Information Modeling (BIM). But these solutions rely on full-fledged digital models, which, for most buildings, are not available. The present article introduces a research work aiming at the development of methods for the generation of 3D building models from 2D plans. The developed prototype is able to extract information from 2D plans and to generate IFC (Industry Foundation Classes)-compliant 3D models that include the main components of the building: walls, openings, and spaces. The article also presents the results of a quantitative assessment of the platform capabilities and performances, relying on a database of 90 real architectural floor plans. The results are very promising and show that such solutions could be key components of future digital toolkits for renovation design. © 2015 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84951336284
"Wang C., Hou S., Wen C., Gong Z., Li Q., Sun X., Li J.","Semantic line framework-based indoor building modeling using backpacked laser scanning point cloud",2018,"ISPRS Journal of Photogrammetry and Remote Sensing",49,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046133599&doi=10.1016%2fj.isprsjprs.2018.03.025&partnerID=40&md5=32fef0620bb54395c0dd88a693a852a5","Indoor building models are essential in many indoor applications. These models are composed of the primitives of the buildings, such as the ceilings, floors, walls, windows, and doors, but not the movable objects in the indoor spaces, such as furniture. This paper presents, for indoor environments, a novel semantic line framework-based modeling building method using backpacked laser scanning point cloud data. The proposed method first semantically labels the raw point clouds into the walls, ceiling, floor, and other objects. Then line structures are extracted from the labeled points to achieve an initial description of the building line framework. To optimize the detected line structures caused by furniture occlusion, a conditional Generative Adversarial Nets (cGAN) deep learning model is constructed. The line framework optimization model includes structure completion, extrusion removal, and regularization. The result of optimization is also derived from a quality evaluation of the point cloud. Thus, the data collection and building model representation become a united task-driven loop. The proposed method eventually outputs a semantic line framework model and provides a layout for the interior of the building. Experiments show that the proposed method effectively extracts the line framework from different indoor scenes. © 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Article,"Final",Scopus,2-s2.0-85046133599
"Choy C., Dong W., Koltun V.","Deep global registration",2020,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",46,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089579667&doi=10.1109%2fCVPR42600.2020.00259&partnerID=40&md5=bd9df9b8a12099fae623b8a35b96ad70","We present Deep Global Registration, a differentiable framework for pairwise registration of real-world 3D scans. Deep global registration is based on three modules: a 6-dimensional convolutional network for correspondence confidence prediction, a differentiable Weighted Procrustes algorithm for closed-form pose estimation, and a robust gradient-based SE(3) optimizer for pose refinement. Experiments demonstrate that our approach outperforms state-of-the-art methods, both learning-based and classical, on real-world data. © 2020 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85089579667
"Ceylan D., Mitra N.J., Zheng Y., Pauly M.","Coupled structure-from-motion and 3D symmetry detection for urban facades",2014,"ACM Transactions on Graphics",46,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893297783&doi=10.1145%2f2517348&partnerID=40&md5=ff0f773438e51a726973577f4c7ea9bf","Repeated structures are ubiquitous in urban facades. Such repetitions lead to ambiguity in establishing correspondences across sets of unordered images. A decoupled structure-from-motion reconstruction followed by symmetry detection often produces errors: outputs are either noisy and incomplete, or even worse, appear to be valid but actually have a wrong number of repeated elements.We present an optimization framework for extracting repeated elements in images of urban facades, while simultaneously calibrating the input images and recovering the 3D scene geometry using a graph-based global analysis. We evaluate the robustness of the proposed scheme on a range of challenging examples containing widespread repetitions and nondistinctive features. These image sets are common but cannot be handled well with state-of-the-art methods. We show that the recovered symmetry information along with the 3D geometry enables a range of novel image editing operations that maintain consistency across the images. © 2014 ACM 0730-0301/2014/01-ART3 15.00.",Article,"Final",Scopus,2-s2.0-84893297783
"Xu Y., Boerner R., Yao W., Hoegner L., Stilla U.","Pairwise coarse registration of point clouds in urban scenes using voxel-based 4-planes congruent sets",2019,"ISPRS Journal of Photogrammetry and Remote Sensing",41,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062937996&doi=10.1016%2fj.isprsjprs.2019.02.015&partnerID=40&md5=2a874aae03450371288bfa118b47bbf1","To ensure complete coverage when measuring a large-scale urban area, pairwise registration between point clouds acquired via terrestrial laser scanning or stereo image matching is usually necessary when there is insufficient georeferencing information from additional GNSS and INS sensors. In this paper, we propose a semi-automatic and target-less method for coarse registration of point clouds using geometric constraints of voxel-based 4-plane congruent sets (V4PCS). The planar patches are firstly extracted from voxelized point clouds. Then, the transformation invariant, 4-plane congruent sets are constructed from extracted planar surfaces in each point cloud. Initial transformation parameters between point clouds are estimated via corresponding congruent sets having the highest registration scores in the RANSAC process. Finally, a closed-form solution is performed to achieve optimized transformation parameters by finding all corresponding planar patches using the initial transformation parameters. Experimental results reveal that our proposed method can be effective for registering point clouds acquired from various scenes. A success rate of better than 80% was achieved, with average rotation errors of about 0.5 degrees and average translation errors less than approximately 0.6 m. In addition, our proposed method is more efficient than other baseline methods when using the same hardware and software configuration conditions. © 2019 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Article,"Final",Scopus,2-s2.0-85062937996
"Nikoohemat S., Diakité A.A., Zlatanova S., Vosselman G.","Indoor 3D reconstruction from point clouds for optimal routing in complex buildings to support disaster management",2020,"Automation in Construction",38,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079243663&doi=10.1016%2fj.autcon.2020.103109&partnerID=40&md5=5329e32d0719b3d0479af644cf437251","During an emergency inside large buildings such as hospitals and shopping malls, the availability of up-to-date information is critical. One common source of information is the 2D layout of buildings and emergency exits. For most buildings, this information is represented as tangled floor plans, which in most cases are outdated. One solution to update the data of buildings after each renovation is to recreate 3D models of buildings in a quick and automatic approach. These 3D models provide proactively crucial building information in a digital format for first responders to be used in emergency cases. Thanks to advances in remote sensing, laser scanners can be used to generate an accurate spatial representation of buildings quickly. However, such devices provide point clouds, which are unstructured data. In this paper, we introduce a complete workflow that allows to generate 3D models from point clouds of buildings and extract fine-grained indoor navigation networks from those models, to support advanced path planning for disaster management and navigation of different types of agents. The process extracts structural elements of buildings such as walls, slabs, ceiling and openings, and reconstruct their volumetric shapes. Additionally, the furnishing elements in the input point clouds are identified and reconstructed as the obstacles. Stairs are also reconstructed to allow multistory navigation path planning. Our algorithm is fully 3D and can handle vertical and slanted structures. We test it on several real datasets, compared it to the state-of-the-art approaches and provide a process to check the consistency of the reconstruction, which allows in return to further improve its result. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85079243663
"Bueno M., Bosché F., González-Jorge H., Martínez-Sánchez J., Arias P.","4-Plane congruent sets for automatic registration of as-is 3D point clouds with 3D BIM models",2018,"Automation in Construction",38,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041457887&doi=10.1016%2fj.autcon.2018.01.014&partnerID=40&md5=59d9e6d92291f219034d03c86f03ffd8","Construction quality and progress control are demanding, yet critical construction activities. Building Information Models and as-built scanned data can be used in Scan-vs-BIM processes to effectively and comprehensively support these activities. This however requires accurate registration of scanned point clouds with 3D (BIM) models. Automating such registration remains a challenge in the context of the built environment, because as-built can be incomplete and/or contain data from non-model objects, and construction buildings and other structures often present symmetries and self-similarities that are very challenging to registration. In this paper, we present a novel automatic coarse registration method that is an adaptation of the ‘4 Points Congruent Set’ algorithm to the use of planes; we call it the ‘4-Plane Congruent Set’ (4-PlCS) algorithm. The approach is further integrated in a software system that delivers not one but a ranked list of the most likely transformations, so to allow the user to quickly select the correct transformation, if need be. Two variants of the method are also considered, in particular one in the case when the vertical axis is known a priori; we call that method the 4.5-PlCS method. The proposed algorithm is tested using five different datasets, including three simulated and two real-life ones. The results show the effectiveness of the proposed method, where the correct transformation always ranks very high (in our experiments, first or second), and is extremely close to the ground-truth transformation. Experimental comparison of the proposed approach with a standard, more intuitive approach based on finding 3-plane congruent sets shows the discriminatory power of 4-plane bases over 3-plane bases, albeit at no clear benefits in terms of computational time. The experimental results for the 4.5-PlCS method show that it delivers a non-negligible reduction in computational time (approx. 20%), but at no additional benefit in terms of effectiveness in finding the correct transformation. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85041457887
"Linowes J., Babilinski K.","Augmented reality for developers: Build practical augmented reality applications with Unity, ARCore, ARKit, and Vuforia",2017,"Augmented Reality for Developers",38,,[No abstract available],,"Final",Scopus,2-s2.0-85068417979
"Johnson Andrew Edie, Hebert Martial","Efficient multiple model recognition in cluttered 3-D scenes",1998,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",38,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032304285&doi=10.1109%2fCVPR.1998.698676&partnerID=40&md5=f5c2610f23b6c8ec1dec34de272cdb07","We present a 3-D shape-based object recognition system for simultaneous recognition of multiple objects in scenes containing clutter and occlusion. Recognition is based on matching surfaces by matching points using the spin-image representation. The spin-image is a data level shape descriptor that is used to match surfaces represented as surface meshes. We present a compression scheme for spin-images that results in efficient multiple object recognition which we verify with results showing the simultaneous recognition of multiple objects from a library of 20 models. Furthermore, we demonstrate the robust performance of recognition in the presence of clutter and occlusion through analysis of recognition trials on 100 scenes.",Conference Paper,"Final",Scopus,2-s2.0-0032304285
"Chen K., Lu W., Xue F., Tang P., Li L.H.","Automatic building information model reconstruction in high-density urban areas: Augmenting multi-source data with architectural knowledge",2018,"Automation in Construction",36,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046795435&doi=10.1016%2fj.autcon.2018.05.009&partnerID=40&md5=7e0752978e6e12936c9d0dd8d3e6da4a","Many studies have been conducted to create building information models (BIMs) or city information models (CIMs) as the digital infrastructure to support various smart city programs. However, automatic generation of such models for high-density (HD) urban areas remains a challenge owing to (a) complex topographic conditions and noisy data irrelevant to the buildings, and (b) exponentially growing computational complexity when the task is reconstructing hundreds of buildings at an urban scale. This paper develops a method - multi-Source recTification of gEometric Primitives (mSTEP) - for automatic reconstruction of BIMs in HD urban areas. By retrieving building base, height, and footprint geodata from topographic maps, level of detail 1 (LoD1) BIMs representing buildings with flat roof configuration were first constructed. Geometric primitives were then detected from LiDAR point clouds and rectified using architectural knowledge about building geometries (e.g. a rooftop object would normally be in parallel with the outer edge of the roof). Finally, the rectified primitives were used to refine the LoD1 BIMs to LoD2, which show detailed geometric features of roofs and rooftop objects. A total of 1361 buildings located in a four square kilometer area of Hong Kong Island were selected as the subjects for this study. The evaluation results show that mSTEP is an efficient BIM reconstruction method that can significantly improve the level of automation and decrease the computation time. mSTEP is also well applicable to point clouds of various densities. The research is thus of profound significance; other cities and districts around the world can easily adopt mSTEP to reconstruct their own BIMs/CIMs to support their smart city programs. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85046795435
"Murali S., Speciale P., Oswald M.R., Pollefeys M.","Indoor Scan2BIM: Building information models of house interiors",2017,"IEEE International Conference on Intelligent Robots and Systems",36,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041955434&doi=10.1109%2fIROS.2017.8206513&partnerID=40&md5=56457c4c0ef9332f7b60b303b48bcbc8","We present a system to generate building information models (BIMs) of house interiors from 3D scans. The strength of our approach is its simplicity and low runtime which allows for mobile processing applications. We consider scans of single floor, Manhattan-like indoor scenes for which our method creates metric room layouts by detecting walls and performing a subsequent reasoning about their neighborhood relations. The output of our method is a 3D BIM with hierarchical semantic annotations for individual rooms being refined by walls, ceilings, floors and doors. A variety of experiments demonstrate the effectiveness of our approach. Our reconstruction results compare well to other state-of-art methods in both reconstruction quality as well as runtime. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85041955434
"Jung J., Stachniss C., Ju S., Heo J.","Automated 3D volumetric reconstruction of multiple-room building interiors for as-built BIM",2018,"Advanced Engineering Informatics",34,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055862180&doi=10.1016%2fj.aei.2018.10.007&partnerID=40&md5=8dcf678f78595a3887e30b874a0e26b3","Currently, fully automated as-built modeling of building interiors using point-cloud data still remains an open challenge, due to several problems that repeatedly arise: (1) complex indoor environments containing multiple rooms; (2) time-consuming and labor-intensive noise filtering; (3) difficulties of representation of volumetric and detail-rich objects such as windows and doors. This study aimed to overcome such limitations while improving the amount of details reproduced within the model for further utilization in BIM. First, we input just the registered three-dimensional (3D) point-cloud data and segmented the point cloud into separate rooms for more effective performance of the later modeling phases for each room. For noise filtering, an offset space from the ceiling height was used to determine whether the scan points belonged to clutter or architectural components. The filtered points were projected onto a binary map in order to trace the floor-wall boundary, which was further refined through subsequent segmentation and regularization procedures. Then, the wall volumes were estimated in two ways: inside- and outside-wall-component modeling. Finally, the wall points were segmented and projected onto an inverse binary map, thereby enabling detection and modeling of the hollow areas as windows or doors. The experimental results on two real-world data sets demonstrated, through comparison with manually-generated models, the effectiveness of our approach: the calculated RMSEs of the two resulting models were 0.089 m and 0.074 m, respectively. © 2018 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85055862180
"National Infrastructure Commission (NIC)","Data for the Public Good",2017,"Data for the Public Good",34,,[No abstract available],,"Final",Scopus,2-s2.0-85048399318
"Zolanvari S.M.I., Laefer D.F., Natanzi A.S.","Three-dimensional building façade segmentation and opening area detection from point clouds",2018,"ISPRS Journal of Photogrammetry and Remote Sensing",33,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046760564&doi=10.1016%2fj.isprsjprs.2018.04.004&partnerID=40&md5=a1cf41c93eadfd54fdc86e5a94794472","Laser scanning generates a point cloud from which geometries can be extracted, but most methods struggle to do this automatically, especially for the entirety of an architecturally complex building (as opposed to that of a single façade). To address this issue, this paper introduces the Improved Slicing Method (ISM), an innovative and computationally-efficient method for three-dimensional building segmentation. The method is also able to detect opening boundaries even on roofs (e.g. chimneys), as well as a building's overall outer boundaries using a local density analysis technique. The proposed procedure is validated by its application to two architecturally complex, historic brick buildings. Accuracies of at least 86% were achieved, with computational times as little as 0.53 s for detecting features from a data set of 5.0 million points. The accuracy more than rivalled the current state of the art, while being up to six times faster and with the further advantage of requiring no manual intervention or reliance on a priori information. © 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Article,"Final",Scopus,2-s2.0-85046760564
"Wen C., Pan S., Wang C., Li J.","An Indoor Backpack System for 2-D and 3-D Mapping of Building Interiors",2016,"IEEE Geoscience and Remote Sensing Letters",31,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968719046&doi=10.1109%2fLGRS.2016.2558486&partnerID=40&md5=8f477257d3bd210d7ba13d53f52f52ff","This letter presents a backpack mapping system for creating indoor 2-D and 3-D maps of building interiors. For many applications, indoor mobile mapping provides a 3-D structure via an indoor map. Because there are significant roll and pitch motions of the indoor mobile mapping system, the need arises for a moving mobile system with 6 degrees of freedom (DOFs) ( $x$, $y$, and $z$ positions and roll, yaw, and pitch angles). First, we present a 6-DOF pose estimation algorithm by fusing 2-D laser scanner data with inertial sensor data using an extended Kalman filter-based method. The estimated 6-DOF pose is used as the initialized transformation for consecutive map alignment in 3-D map building. The 6-DOF pose gives a full 3-D estimation of the system pose and is used to accelerate the map alignment process and also align the two maps directly when there are few or no overlapping areas between the maps. Our results show that the proposed system effectively builds a consistent 2-D grid map and a 3-D point cloud map of an indoor environment. © 2016 IEEE.",Article,"Final",Scopus,2-s2.0-84968719046
"Yang H., Shi J., Carlone L.","Teaser: Fast and certifiable point cloud registration",2021,"IEEE Transactions on Robotics",30,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097843755&doi=10.1109%2fTRO.2020.3033695&partnerID=40&md5=afa7da2d2b0baab8f0b8a37e0dcfdf0f","We propose the first fast and certifiable algorithm for the registration of two sets of three-dimensional (3-D) points in the presence of large amounts of outlier correspondences. A certifiable algorithm is one that attempts to solve an intractable optimization problem (e.g., robust estimation with outliers) and provides readily checkable conditions to verify if the returned solution is optimal (e.g., if the algorithm produced the most accurate estimate in the face of outliers) or bound its suboptimality or accuracy. Toward this goal, we first reformulate the registration problem using a truncated least squares (TLS) cost that makes the estimation insensitive to a large fraction of spurious correspondences. Then, we provide a general graph-theoretic framework to decouple scale, rotation, and translation estimation, which allows solving in cascade for the three transformations. Despite the fact that each subproblem (scale, rotation, and translation estimation) is still nonconvex and combinatorial in nature, we show that 1) TLS scale and (component-wise) translation estimation can be solved in polynomial time via an adaptive voting scheme, 2) TLS rotation estimation can be relaxed to a semidefinite program (SDP) and the relaxation is tight, even in the presence of extreme outlier rates, and 3) the graph-theoretic framework allows drastic pruning of outliers by finding the maximum clique. We name the resulting algorithm TEASER (Truncated least squares Estimation And SEmidefinite Relaxation). While solving large SDP relaxations is typically slow, we develop a second fast and certifiable algorithm, named TEASER++, that uses graduated nonconvexity to solve the rotation subproblem and leverages Douglas-Rachford Splitting to efficiently certify global optimality. For both algorithms, we provide theoretical bounds on the estimation errors, which are the first of their kind for robust registration problems. Moreover, we test their performance on standard benchmarks, object detection datasets, and the 3DMatch scan matching dataset, and show that 1) both algorithms dominate the state-of-the-art (e.g., RANSAC, branch-&-bound, heuristics) and are robust to more than 99% outliers when the scale is known, 2) TEASER++ can run in milliseconds and it is currently the fastest robust registration algorithm, and 3) TEASER++ is so robust it can also solve problems without correspondences (e.g., hypothesizing all-to-all correspondences), where it largely outperforms ICP and it is more accurate than Go-ICP while being orders of magnitude faster. We release a fast open-source C++ implementation of TEASER++. © 2020 IEEE.",Article,"Final",Scopus,2-s2.0-85097843755
"Wang H., Zhang W., Chen Y., Chen M., Yan K.","Semantic decomposition and reconstruction of compound buildings with symmetric roofs from LiDAR data and aerial imagery",2015,"Remote Sensing",29,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945932890&doi=10.3390%2frs71013945&partnerID=40&md5=cf8359ee2c2aa7d772ae8deb6e3d5b0c","3D building models are important for many applications related to human activities in urban environments. However, due to the high complexity of the building structures, it is still difficult to automatically reconstruct building models with accurate geometric description and semantic information. To simplify this problem, this article proposes a novel approach to automatically decompose the compound buildings with symmetric roofs into semantic primitives by exploiting local symmetry contained in the building structure. In this approach, the proposed decomposition allows the overlapping of neighbor primitives and each decomposed primitive can be represented as a parametric form, which simplify the complexity of the building reconstruction and facilitate the integration of LiDAR data and aerial imagery into a parameters optimization process. The proposed method starts by extracting isolated building regions from the LiDAR point clouds. Next, point clouds belonging to each compound building are segmented into planar patches to construct an attributed graph, and then the local symmetries contained in the attributed graph are exploited to automatically decompose the compound buildings into different semantic primitives. In the final step, 2D image features are extracted depending on the initial 3D primitives generated from LiDAR data, and then the compound building is reconstructed using constraints from LiDAR data and aerial imagery by a nonlinear least squares optimization. The proposed method is applied to two datasets with different point densities to show that the complexity of building reconstruction can be reduced considerably by decomposing the compound buildings into semantic primitives. The experimental results also demonstrate that the traditional model driven methods can be further extended to the automated reconstruction of compound buildings by using the proposed semantic decomposition method. © 2015 by the authors.",Article,"Final",Scopus,2-s2.0-84945932890
"Han J., Yin P., He Y., Gu F.","Enhanced ICP for the registration of large-scale 3D environment models: An experimental study",2016,"Sensors (Switzerland)",28,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958528915&doi=10.3390%2fs16020228&partnerID=40&md5=76b3b809373ab275a7338c6d91497e35","One of the main applications of mobile robots is the large-scale perception of the outdoor environment. One of the main challenges of this application is fusing environmental data obtained by multiple robots, especially heterogeneous robots. This paper proposes an enhanced iterative closest point (ICP) method for the fast and accurate registration of 3D environmental models. First, a hierarchical searching scheme is combined with the octree-based ICP algorithm. Second, an early-warning mechanism is used to perceive the local minimum problem. Third, a heuristic escape scheme based on sampled potential transformation vectors is used to avoid local minima and achieve optimal registration. Experiments involving one unmanned aerial vehicle and one unmanned surface vehicle were conducted to verify the proposed technique. The experimental results were compared with those of normal ICP registration algorithms to demonstrate the superior performance of the proposed method. © 2016 by the authors; licensee MDPI, Basel, Switzerland.",Article,"Final",Scopus,2-s2.0-84958528915
"Turner E., Zakhor A.","Watertight as-built architectural floor plans generated from laser range data",2012,"Proceedings - 2nd Joint 3DIM/3DPVT Conference: 3D Imaging, Modeling, Processing, Visualization and Transmission, 3DIMPVT 2012",27,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872016143&doi=10.1109%2f3DIMPVT.2012.80&partnerID=40&md5=0edd3a77b8abc406e46d7c144328a8fe","In this paper we describe an approach to automatically generate a floor plan for the interior environment of a building using laser scan data. This floor plan is meant to accurately indicate the positions of walls within an area of interest in the building. This proposed algorithm separates the floors of a building scan, selects a representative sampling of wall scans for each floor, and triangulates these samples to develop a watertight representation of the walls for each of the scanned areas. Curves and straight line segments are fit to these walls, in order to mitigate any registration errors from the original scans. This method is not dependent on the scanning system and can successfully process noisy scans with non-zero registration error. Most of the processing is performed after a dramatic dimensionality reduction, yielding a scalable approach. We demonstrate the effectiveness of our approach on a three-story point cloud from a commercial building as well as on the lobby and hallways of a hotel. © 2012 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84872016143
"Eckart B., Kim K., Kautz J.","Hgmr: Hierarchical Gaussian mixtures for adaptive 3d registration",2018,"ECCV",25,,[No abstract available],,"Final",Scopus,2-s2.0-85070973424
"Lin W.-Y., Liu S., Jiang N., Do M.N., Tan P., Lu J.","Repmatch: Robust feature matching and pose for reconstructing modern cities",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",24,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990040847&doi=10.1007%2f978-3-319-46448-0_34&partnerID=40&md5=0dd2126a796859b19b9d1e52d2157d1a","A perennial problem in recovering 3-D models from images is repeated structures common in modern cities. The problem can be traced to the feature matcher which needs to match less distinctive features (permitting wide-baselines and avoiding broken sequences), while simultaneously avoiding incorrect matching of ambiguous repeated features. To meet this need, we develop RepMatch, an epipolar guided (assumes predominately camera motion) feature matcher that accommodates both wide-baselines and repeated structures. RepMatch is based on using RANSAC to guide the training of match consistency curves for differentiating true and false matches. By considering the set of all nearest-neighbor matches, RepMatch can procure very large numbers of matches over wide baselines. This in turn lends stability to pose estimation. RepMatch’s performance compares favorably on standard datasets and enables more complete reconstructions of modern architectures. © Springer International Publishing AG 2016.",Conference Paper,"Final",Scopus,2-s2.0-84990040847
"Lu Q., Chen L., Li S., Pitt M.","Semi-automatic geometric digital twinning for existing buildings based on images and CAD drawings",2020,"Automation in Construction",22,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082486835&doi=10.1016%2fj.autcon.2020.103183&partnerID=40&md5=8940c891ecdf5aaa634ff403282d13d6","Despite the emerging new data capturing technologies and advanced modelling systems, the process of geometric digital twin modelling for existing buildings still lacks a systematic and completed framework to streamline. As-is Building Information Model (BIM) is one of the commonly used geometric digital twin modelling approaches. However, the process of as-is BIM construction is time-consuming and needed to improve. To address this challenge, in this paper, a semi-automatic approach is developed to establish a systematic, accurate and convenient digital twinning system based on images and CAD drawings. With this ultimate goal, this paper summarises the state-of-the-art geometric digital twinning methods and elaborates on the methodological framework of this semi-automatic geometric digital twinning approach. The framework consists of three modules. The Building Framework Construction and Geometry Information Extraction (Module 1) defines the locations of each structural component through recognising special symbols in a floor plan and then extracting data from CAD drawings using the Optical Character Recognition (OCR) technology. Meaningful text information is further filtered based on predefined rules. In order to integrate with completed building information, the Building Information Complementary (Module 2) is developed based on neuro-fuzzy system (NFS) and the image processing procedure to supplement additional building components. Finally, the Information Integration and IFC Creation (Module 3) integrates information from Module 1 and 2 and creates as-is Industry Foundation Classes (IFC) BIM based on IFC schema. A case study using part of an office building and the results of its analysis are provided and discussed from the perspectives of applicability and accuracy. Future works and limitations are also addressed. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85082486835
"Chen S., Nan L., Xia R., Zhao J., Wonka P.","PLADE: A Plane-Based Descriptor for Point Cloud Registration with Small Overlap",2020,"IEEE Transactions on Geoscience and Remote Sensing",21,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082883490&doi=10.1109%2fTGRS.2019.2952086&partnerID=40&md5=e36577b7a515fdef8585e7914949e129","Traditional point cloud registration methods require large overlap between scans, which imposes strict constraints on data acquisition. To facilitate registration, users have to carefully position scanners to ensure sufficient overlap. In this article, we propose to use high-level structural information (i.e., plane/line features and their interrelationship) for registration, which is capable of registering point clouds with small overlap, allowing more freedom in data acquisition. We design a novel plane-/line-based descriptor dedicated to establishing structure-level correspondences between point clouds. Based on this descriptor, we propose a simple but effective registration algorithm. We also provide a data set of real-world scenes containing a larger number of scans with a wide range of overlap. Experiments and comparisons with state-of-the-art methods on various data sets reveal that our method is superior to existing techniques. Though the proposed algorithm outperforms state-of-the-art methods on the most challenging data set, the point cloud registration problem is still far from being solved, leaving significant room for improvement and future work. © 2019 IEEE.",Article,"Final",Scopus,2-s2.0-85082883490
"Xue F., Lu W., Chen Z., Webster C.J.","From LiDAR point cloud towards digital twin city: Clustering city objects based on Gestalt principles",2020,"ISPRS Journal of Photogrammetry and Remote Sensing",19,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088925897&doi=10.1016%2fj.isprsjprs.2020.07.020&partnerID=40&md5=234e1972f8e73c8588e0ac8badcdaf9a","Recent advancement of remote sensing technologies has brought in accurate, dense, and inexpensive city-scale Light Detection And Ranging (LiDAR) point clouds, which can be utilized to model city objects (e.g., buildings, roads, and automobiles) for creating Digital Twin Cities (DTCs). However, processing such unstructured point clouds is very challenging, epitomized by high cost, movable objects, limited object classes, and high information inadequacy/redundancy. We noticed that many city objects are not in random shapes; rather, they have invariant cross-sections following the Gestalt design principles, including proximity, connectivity, symmetry, and similarity. In this paper, we present a novel unsupervised method, called Clustering Of Symmetric Cross-sections of Objects (COSCO), to process urban LiDAR point clouds to a hierarchy of objects based on their characteristic cross-sections. First, city objects are segmented as connected patches of proximate 3D points. Then, symmetric cross-sections are detected for symmetric city objects. Finally, the taxonomy and groups of city objects are recognized from a hierarchical clustering analysis of the dissimilarity matrix. Experimental results showed that COSCO detected the correct taxonomy and types of 12 cars from 24,126 LiDAR points in 8.28 s. Based on the cross-sections and taxonomy, a digital twin was created by registering online free 3D car models in 29.58 s. The contribution of this paper is twofold. First, it presents an effective unsupervised method for understanding and developing DTC objects in LiDAR point clouds by harnessing innate Gestalt design principles. Secondly, COSCO can be an efficient LiDAR pre-processing tool for recognizing symmetric city objects’ cross-sections, positions, heading directions, dimensions, and possible types for smart city applications in GIScience, Architecture, Engineering, Construction and Operation (AECO), and autonomous vehicles. © 2020 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Article,"Final",Scopus,2-s2.0-85088925897
"Xu H., Yu L., Fei S.","Hand-Held 3-D Reconstruction of Large-Scale Scene with Kinect Sensors Based on Surfel and Video Sequences",2018,"IEEE Geoscience and Remote Sensing Letters",16,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053116846&doi=10.1109%2fLGRS.2018.2866280&partnerID=40&md5=c41a9386c8c5f2dbff691976aaae5af6","This letter presents a hand-held complex large-scale scene reconstruction method with Kinect sensors based on surfel and video sequences. The feature point method simultaneous localization and mapping (SLAM) is employed to estimate the pose of the camera, and then bundle adjustment by combining 2-D and 3-D feature points is used to optimize camera pose. Also, the surfel model is employed to construct deformation maps for the fusion and optimization of point clouds, and finally, an accurate precise 3-D map can be obtained. The main contribution of this letter is that: 1) by using the SLAM method to obtain camera pose as the initial value of optimization, the problem of insufficient memory and low efficiency of the structure form motion method can be well solved; 2) sparsely textured regions can be reconstructed better by using bundle adjustment by combining 2-D and 3-D feature points; and 3) dense 3-D reconstruction of large scenes can be achieved, and the reconstructed 3-D models are more elaborate. Finally, experimental results show that this proposed method can be applied to a variety of complex large-scale scenes, and can obtain accurate precise 3-D model. This presented 3-D reconstruction method can be widely used in the fields of human-computer interaction, consumer electronics, and virtual reality. © 2004-2012 IEEE.",Article,"Final",Scopus,2-s2.0-85053116846
"Cheng L., Wu Y., Chen S., Zong W., Yuan Y., Sun Y., Zhuang Q., Li M.","A symmetry-based method for LiDAR point registration",2018,"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",16,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031808929&doi=10.1109%2fJSTARS.2017.2752765&partnerID=40&md5=48805fd2d59df7053a03332cf22b6cb7","LiDAR point registration is a key procedure for the acquisition of complete point cloud datasets. It has great significance for the fusion of multisource LiDAR data. In general, the widely used methods for LiDAR point registration can be categorized into three types: Auxiliary methods, direct methods, and feature methods. However, for the registration of complex objects (e.g., stadium and tower), such methods may face varying degrees of technical problems owing to the unavailability of auxiliary data or targets, requirement of sufficient overlapping areas, and difficulty in feature extraction and matching. In the real world, numerous objects with extremely complicated geometric shapes have the characteristic of symmetry. This study focuses on complex objects with symmetry and tries to exploit their intrinsic symmetry characteristic in order to facilitate their point cloud registration. A symmetry-based method for LiDAR point registration is proposed, in which the general idea is to derive 3-D central axes from multisource point clouds, based on the symmetry of objects. The proposed method consists of six main steps: Detection of rotational symmetry, adaptive point cloud slicing, central point extraction, central axis fitting, central axis matching, and orientation and positioning. Comparative experiments and quantitative evaluations are conducted. The experimental results indicate that the proposed framework can achieve satisfactory registration of objects with rotational symmetry. © 2008-2012 IEEE.",Article,"Final",Scopus,2-s2.0-85031808929
"Xue F., Lu W., Chen K., Webster C.J.","BIM reconstruction from 3D point clouds: A semantic registration approach based on multimodal optimization and architectural design knowledge",2019,"Advanced Engineering Informatics",15,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073651417&doi=10.1016%2fj.aei.2019.100965&partnerID=40&md5=b98ee88336262347b3f92a5f111710c9","Reconstructing semantically rich building information model (BIM) from 2D images or 3D point clouds represents a research realm that is gaining increasing popularity in architecture, engineering, and construction. Researchers have found that architectural design knowledge, such as symmetry, planarity, parallelism, and orthogonality, can be utilized to improve the effectiveness of such BIM reconstruction. Following this line of enquiry, this paper aims to develop a novel semantic registration approach for complicated scenes with repetitive, irregular-shaped objects. The approach first formulates the architectural repetition as the multimodality in mathematics. Thus, the reconstruction of repetitive objects becomes a multimodal optimization (MMO) problem of registering BIM components which have accurate geometries and rich semantics. Then, the topological information about repetition and symmetry in the reconstructed BIM is recognized and regularized for BIM semantic enrichment. A university lecture hall case, consisting of 1.9 million noisy points of 293 chairs, was selected for an experiment to validate the proposed approach. Experimental results showed that a BIM was satisfactorily created (achieving about 90% precision and recall) automatically in 926.6 s; and an even more satisfactory BIM achieved 99.3% precision and 98.0% recall with detected semantic and topological information under the minimal effort of human intervention in 228.4 s. The multimodality model of repetitive objects, the repetition detection and regularization for BIM, and satisfactory reconstruction results in the presented approach can contribute to methodologies and practices in multiple disciplines related to BIM and smart city. © 2019 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85073651417
"Xue F., Lu W., Chen K., Zetkulic A.","From Semantic Segmentation to Semantic Registration: Derivative-Free Optimization-Based Approach for Automatic Generation of Semantically Rich As-Built Building Information Models from 3D Point Clouds",2019,"Journal of Computing in Civil Engineering",14,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058550468&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000839&partnerID=40&md5=e25e0d7a6315e4c2d83516db3ac67e6f","Development of semantically rich as-built building information models (BIMs) presents an ongoing challenge for the global BIM and computing engineering communities. A plethora of approaches have been developed that, however, possess several common weaknesses: (1) heavy reliance on laborious manual or semiautomatic segmentation of raw data [e.g., two-dimensional (2D) images or three-dimensional (3D) point clouds]; (2) unsatisfactory results for complex scenes (e.g., furniture or nonstandard indoor settings); and (3) failure to use existing resources for modeling and semantic enrichment. This paper aims to advance a novel, derivative-free optimization (DFO)-based approach that can automatically generate semantically rich as-built BIMs of complex scenes from 3D point clouds. In layman's terms, the proposed approach recognizes candidate BIM components from 3D point clouds, reassembles the components into a BIM, and registers them with semantic information from credible sources. The approach was prototyped in Autodesk Revit and tested on a noisy point cloud of office furniture scanned via a Google Tango smartphone. The results revealed that the semantically rich as-built BIM was automatically and correctly generated with a root-mean-square error (RMSE) of 3.87 cm in 6.44 s, which outperformed the well-known iterative closest point (ICP) algorithm. The approach was then scaled up to a large auditorium scene consisting of 293 chairs to generate a satisfactory output BIM with a precision of 81.9% and a recall of 80.5%. The semantic registration approach also proved superior to existing segmentation approaches in that it is segmentation-free and capable of processing complex scenes and reusing known information. In addition to these methodological contributions, this approach, properly scaled up, will open new avenues for creation of building/city information models from inexpensive data sources and support profound value-added applications such as smart building or smart city developments. © 2019 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85058550468
"Wijmans E., Furukawa Y.","Exploiting 2D floorplan for building-scale panorama RGBD alignment",2017,"Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017",13,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044253861&doi=10.1109%2fCVPR.2017.156&partnerID=40&md5=97af1e66f4517e6a951e777b64510c7c","This paper presents a novel algorithm that utilizes a 2D floorplan to align panorama RGBD scans. While effective panorama RGBD alignment techniques exist, such a system requires extremely dense RGBD image sampling. Our approach can significantly reduce the number of necessary scans with the aid of a floorplan image. We formulate a novel Markov Random Field inference problem as a scan placement over the floorplan, as opposed to the conventional scan-to-scan alignment. The technical contributions lie in multi-modal image correspondence cues (between scans and schematic floorplan) as well as a novel coverage potential avoiding an inherent stacking bias. The proposed approach has been evaluated on five challenging large indoor spaces. To the best of our knowledge, we present the first effective system that utilizes a 2D floorplan image for building-scale 3D pointcloud alignment. The source code and the data are shared with the community to further enhance indoor mapping research. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85044253861
"Xue F., Wu L., Lu W.","Semantic enrichment of building and city information models: A ten-year review",2021,"Advanced Engineering Informatics",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100100019&doi=10.1016%2fj.aei.2020.101245&partnerID=40&md5=8a6623677696616e57978623280dfba2","Building Information Models (BIMs) and City Information Models (CIMs) have flourished in building and urban studies independently over the past decade. Semantic enrichment is an indispensable process that adds new semantics such as geometric, non-geometric, and topological information into existing BIMs or CIMs to enable multidisciplinary applications in fields such as construction management, geoinformatics, and urban planning. These two paths are now coming to a juncture for integration and juxtaposition. However, a critical review of the semantic enrichment of BIM and CIM is missing in the literature. This research aims to probe into semantic enrichment by comparing its similarities and differences between BIM and CIM over a ten-year time span. The research methods include establishing a uniform conceptual model, and sourcing and analyzing 44 pertinent cases in the literature. The findings plot the terminologies, methods, scopes, and trends for the semantic enrichment approaches in the two domains. With the increasing availability of data sources, algorithms, and computing power, they cross the border to enter each other's domain. Future research will likely gain new momentums from the demands of value-added applications, development of remote sensing devices, intelligent data processing algorithms, interoperability between BIM and CIM software platforms, and emerging technologies such as big data analytics. © 2021 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85100100019
"Xue F., Lu W., Webster C.J., Chen K.","A derivative-free optimization-based approach for detecting architectural symmetries from 3D point clouds",2019,"ISPRS Journal of Photogrammetry and Remote Sensing",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058571840&doi=10.1016%2fj.isprsjprs.2018.12.005&partnerID=40&md5=591e789fbaa89a511c01f2b6e45a53ea","Symmetry is ubiquitous in architecture, across both time and place. Automated architectural symmetry detection (ASD) from a data source is not only an intriguing inquiry in its own right, but also a step towards creation of semantically rich building and city information models with applications in architectural design, construction management, heritage conservation, and smart city development. While recent advances in sensing technologies provide inexpensive yet high-quality architectural 3D point clouds, existing methods of ASD from these data sources suffer several weaknesses including noise sensitivity, inaccuracy, and high computational loads. This paper aims to develop a novel derivative-free optimization (DFO)-based approach for effective ASD. It does so by firstly transforming ASD into a nonlinear optimization problem involving architectural regularity and topology. An in-house ODAS (Optimization-based Detection of Architectural Symmetries) approach is then developed to solve the formulated problem using a set of state-of-the-art DFO algorithms. Efficiency, accuracy, and robustness of ODAS are gauged from the experimental results on nine sets of real-life architectural 3D point clouds, with the computational time for ASD from 1.4 million points only 3.7 s and increasing in a sheer logarithmic order against the number of points. The contributions of this paper are threefold. Firstly, formulating ASD as a nonlinear optimization problem constitutes a methodological innovation. Secondly, the provision of up-to-date, open source DFO algorithms allows benchmarking in the future development of free, fast, accurate, and robust approaches for ASD. Thirdly, the ODAS approach can be directly used to develop building and city information models for various value-added applications. © 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Article,"Final",Scopus,2-s2.0-85058571840
"Attenni M.","Informative models for architectural heritage",2019,"Heritage",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083745070&doi=10.3390%2fheritage2030125&partnerID=40&md5=531c8b813e4f73e1c478106fbb5162f5","BIM (Building Information Modeling) processes are the most effective way to know existing architectural structures, integrating the most advanced potentials of 3D modeling and the structured storage of heterogeneous information. Many HBIM (Heritage Building Information Modeling) applications lead to the systematization of survey data, even though a univocal working method is not yet clearly defined. This research considers the decomposition of architecture, based on structured criteria, and its reconstruction, through ideal models, as the main moments of the HBIM process. This hypothesis is verified through a procedure that links the survey 3D data with the characteristics of the ideal HBIM model, which allows a continuous comparison between the project model and as-built. The research provides for the setting up of a general methodology that, according to a growing approach to the complexity of the analyzed buildings, compares the process followed on two architectural structures. The study analyzes some important HBIM issues: The relationship between the semantic modeling and the surfaces’ continuity of architectural heritage; the relationship between the elements standardization, geometric irregularities, and material heterogeneity; the reliability of the built models; and the evaluation of the gap between an ideal model and the objective accuracy of surveying. © 2019 by the author. Licensee MDPI, Basel, Switzerland.",Article,"Final",Scopus,2-s2.0-85083745070
"Bassier M., Vergauwen M.","Unsupervised reconstruction of Building Information Modeling wall objects from point cloud data",2020,"Automation in Construction",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091337373&doi=10.1016%2fj.autcon.2020.103338&partnerID=40&md5=8f920467f04bcea25d0de5470665210a","Scan-to-BIM of existing buildings is in high demand by the construction industry. However, these models are costly and time-consuming to create. The automation of this process is still subject of ongoing research. Current obstacles include the interpretation and reconstruction of raw point cloud data, which is complicated by the complexity of built structures, the vast amount of data to be processed and the variety of objects in the built environment. This research aims to overcome the current obstacles and reconstruct the structure of buildings in an unsupervised manner. More specifically, a novel method is presented to automatically reconstruct BIM wall objects and their topology. Key contributions of the method are the ability to reconstruct different wall axis and connection types and the simultaneous processing of entire multi-story structures. The method is validated with the Stanford 2D–3D-Semantics Dataset (2D–3D-S). © 2020 Elsevier B.V.",Review,"Final",Scopus,2-s2.0-85091337373
"Polewski P., Yao W.","Scale invariant line-based co-registration of multimodal aerial data using L1 minimization of spatial and angular deviations",2019,"ISPRS Journal of Photogrammetry and Remote Sensing",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064429131&doi=10.1016%2fj.isprsjprs.2019.04.004&partnerID=40&md5=0baa14df600fc2517b96d1c1a226761c","In this work, we investigate the coregistration of multimodal data, such as photogrammetric/LiDAR point clouds, digital surface models, orthoimages, or 3D CAD city models, using corresponding line segments. The lines are analytically derived as intersections of adjacent planar surfaces, which can be determined more robustly and are deemed more accurate compared to single point based features. We propose a two-stage approach, which first focuses on finding optimal line correspondences between the datasets using a scale-invariant graph matching method, and then utilizes the found matching as a basis for calculating the optimal coregistration transform. By decoupling the correspondence search from the transform calculation, our approach can use more line pairs for determining the optimal transform than would be practicable with a combined, sampling-style approach. As opposed to competing methods, our transform computation is based on explicitly minimizing the average L1 distance on the matched line set. The assumed model accounts for an isotropic scaling factor, three translations and three rotation angles. We conducted experiments on two publicly available ISPRS datasets: Vaihingen and Dortmund, and compared the performance of several variations of our approach with three competing methods. The results indicate that the L1 methods decreased the median matched line distance by up to one third in case of pre-aligned Z axes. Moreover, when coregistering two photogrammetric datasets acquired from distinct viewing perspectives, our method was able to triple the number of matched lines (under a strict proximity-based criterion) compared to its competitor. Our results show that it is worthwhile to base the transform calculation on significantly more line pairs than is customary for sample consensus-based approaches. Our established validation dataset for line-based coregistration has been published and made available online (https://doi.org/10.17632/dmp7tkn8kc.2). © 2019 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Article,"Final",Scopus,2-s2.0-85064429131
"Taberna G.A., Guarnieri R., Mantini D.","SPOT3D: Spatial positioning toolbox for head markers using 3D scans",2019,"Scientific Reports",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071751106&doi=10.1038%2fs41598-019-49256-0&partnerID=40&md5=ab715a4652a27928dcd88822d635edd0","Recent studies have highlighted the importance of an accurate individual head model for reliably using high-density electroencephalography (hdEEG) as a brain imaging technique. Correct identification of sensor positions is fundamental for accurately estimating neural activity from hdEEG recordings. We previously introduced a method of automated localization and labelling of hdEEG sensors using an infrared colour-enhanced 3D scanner. Here, we describe an extension of this method, the spatial positioning toolbox for head markers using 3D scans (SPOT3D), which integrates a graphical user interface (GUI). This enables the correction of imprecisions in EEG sensor positioning and the inclusion of additional head markers. The toolbox was validated using 3D scan data collected in four participants wearing a 256-channel hdEEG cap. We quantified the misalignment between the 3D scan and the head shape, and errors in EEG sensor locations. We assessed these parameters after using the automated approach and after manually adjusting its results by means of the GUI. The GUI overcomes the main limitations of the automated method, yielding enhanced precision and reliability of head marker positioning. © 2019, The Author(s).",Article,"Final",Scopus,2-s2.0-85071751106
"Wu Y., Shang J., Chen P., Zlatanova S., Hu X., Zhou Z.","Indoor mapping and modeling by parsing floor plan images",2020,"International Journal of Geographical Information Science",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087656408&doi=10.1080%2f13658816.2020.1781130&partnerID=40&md5=97dc84a67f2e2da11850900e65af6829","A large proportion of indoor spatial data is generated by parsing floor plans. However, a mature and automatic solution for generating high-quality building elements (e.g., walls and doors) and space partitions (e.g., rooms) is still lacking. In this study, we present a two-stage approach to indoor mapping and modeling (IMM) from floor plan images. The first stage vectorizes the building elements on the floor plan images and the second stage repairs the topological inconsistencies between the building elements, separates indoor spaces, and generates indoor maps and models. To reduce the shape complexity of indoor boundary elements, i.e., walls and openings, we harness the regularity of the boundary elements and extract them as rectangles in the first stage. Furthermore, to resolve the overlaps and gaps of the vectorized results, we propose an optimization model that adjusts the rectangle vertex coordinates to conform to the topological constraints. Experiments demonstrate that our approach achieves a considerable improvement in room detection without conforming to Manhattan World Assumption. Our approach also outputs instance-separate walls with consistent topology, which enables direct modeling into Industry Foundation Classes (IFC) or City Geography Markup Language (CityGML). © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.",Article,"Final",Scopus,2-s2.0-85087656408
"Xu J., Xue F., Chiaradia A., Lu W., Cao J.","Indoor-outdoor navigation without beacons: Compensating smartphone AR positioning errors with 3D pedestrian network",2020,"Construction Research Congress 2020: Infrastructure Systems and Sustainability - Selected Papers from the Construction Research Congress 2020",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096943524&doi=10.1061%2f9780784482858.049&partnerID=40&md5=8dd36531c80131354c0baf565ffdae46","Despite the extensive use of positioning and navigation in outdoor space, indoor positioning and navigation systems, essential for intelligent building and smart city services, are unsatisfactory in either performance or price, sometimes in both. This paper analyzes and compares the performances and prices of existing indoor positioning technologies that are categorized into a few classes according to their spatial sensing and referencing methods. Based on the previous work in walkability, this paper proposes a novel walkability network-based augmented reality (WaNAR) method using smartphones with AR positioning function for positioning and navigation. In WaNAR, drifting of the AR positioning signals are corrected continuously by the ground-truth 3D indoor/outdoor walkability network (e.g., nobody is supposed to walk through a wall) in a 3D model. The error at the vertical axis of the walking direction is corrected continuously and that of the walking direction is compensated at every turn. WaNAR can be used in both indoor and outdoor navigation, its performance and price are proved to be largely improved compared to existing technologies. The only investment for a typical building is a 3D drawing of indoor walkable space in a few staff-hours. WaNAR has broad application prospects at various positioning and navigation scenarios. © 2020 American Society of Civil Engineers.",Conference Paper,"Final",Scopus,2-s2.0-85096943524
"Xue F., Chiaradia A.J.F., Webster C.J., Liu D., Xu J., Lu W.","Personalized walkability assessment for pedestrian paths: An as-built BIM approach using ubiquitous augmented reality (ar) smartphone and deep transfer learning",2018,"Proceedings of the 23rd International Symposium on the Advancement of Construction Management and Real Estate",2,,[No abstract available],,"Final",Scopus,2-s2.0-85096936694
"Bianchini C., Nicastro S.","From BIM to H-BIM",2018,"Proceedings of the 2018 3rd Digital Heritage International Congress, Digital Heritage 2018 - Held jointly with the 2018 24th International Conference on Virtual Systems and Multimedia, VSMM 2018",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072397980&doi=10.1109%2fDigitalHeritage.2018.8810087&partnerID=40&md5=7ad8830e40dae38a5aaa9f1ff73d04b2","This paper discusses the potentialities and critical aspects resulting from the integration of BIM systems in the processes dealing with the Built Heritage (BH). It focuses on the conceptual extension of virtual model triggered by BIM approach and its possibilities of stratifying knowledge.The potential of BH-oriented BIM systems (the so-called Heritage-BIM or H-BIM) is undeniable. However, there remain operational and theoretical issues related to the unsolved aporia between the rigidity of modelling tools and the high flexibility needed when BH elements are involved.The outcomes of our research, tested on case studies belonging to Sapienza Main Campus, led to a clearer understanding of the inner features of the H-BIM model, its structuring in Level of Evolution Models and the adoption of an additional parameter, the Level of Reliability for digital objects. © 2018 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85072397980
"Benazera E.",[No title available],2020,"Libcmaes: A Multithreaded C++11 Library with Python Bindings for High Performance Blackbox Stochastic Optimization Using the CMA-ES Algorithm for Covariance Matrix Adaptation Evolution Strategy",1,,[No abstract available],,"Final",Scopus,2-s2.0-85106534523
"Steven J.",[No title available],2020,"NLopt: A Free/Open-Source Library for Nonlinear Optimization",1,,[No abstract available],,"Final",Scopus,2-s2.0-85106519379
"Tanaka K., Schmitz P., Ciganovic M., Kumar P.",[No title available],2020,"Probreg: Probablistic Point Cloud Registration Library",1,,[No abstract available],,"Final",Scopus,2-s2.0-85106501196
"Srinivasan R.",[No title available],0000,"Go-icp_cython: A Cython Version of the Original Go-ICP",1,,[No abstract available],,"Final",Scopus,2-s2.0-85106528812
"Xue F., Guo H., Lu W.","Digital twinning of construction objects: Lessons learned from pose estimation methods",0000,"Proceedings of the 37th Information Technology for Construction Conference (CIB W78)",1,,[No abstract available],,"Final",Scopus,2-s2.0-85106508070
