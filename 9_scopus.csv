Authors,Title,Year,Source title,Cited by,Link,Abstract,Document Type,Publication Stage,Source,EID
"Box G.E.P., Jenkins G.M.",[No title available],1976,"Time Series Analysis: Forecasting and Control",20358,,[No abstract available],,,Scopus,2-s2.0-0004311217
"Hevner A.R., March S.T., Park J., Ram S.","Design science in information systems research",2004,"MIS Quarterly: Management Information Systems",7819,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242652022&doi=10.2307%2f25148625&partnerID=40&md5=fb1dde6271e2c2d4d646405dcddea0d1","Two paradigms characterize much of the research in the Information Systems discipline: behavioral science and design science. The behavioral-science paradigm seeks to develop and verify theories that explain or predict human or organizational behavior. The design-science paradigm seeks to extend the boundaries of human and organizational capabilities by creating new and innovative artifacts. Both paradigms are foundational to the IS discipline, positioned as it is at the confluence of people, organizations, and technology. Our objective is to describe the performance of design-science research in Information Systems via a concise conceptual framework and clear guidelines for understanding, executing, and evaluating the research. In the design-science paradigm, knowledge and understanding of a problem domain and its solution are achieved in the building and application of the designed artifact. Three recent exemplars in the research literature are used to demonstrate the application of these guidelines. We conclude with an analysis of the challenges of performing high-quality design-science research in the context of the broader IS community.",Article,"Final",Scopus,2-s2.0-0242652022
"Van der Aalst W.","Process mining: Data science in action",2016,"Process Mining: Data Science in Action",1144,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979530122&doi=10.1007%2f978-3-662-49851-4&partnerID=40&md5=2c9677c2cfe2b253453b40c50e86ebb3","This is the second edition of Wil van der Aalst’s seminal book on process mining, which now discusses the field also in the broader context of data science and big data approaches. It includes several additions and updates, e.g. on inductive mining techniques, the notion of alignments, a considerably expanded section on software tools and a completely new chapter of process mining in the large. It is self-contained, while at the same time covering the entire process-mining spectrum from process discovery to predictive analytics. After a general introduction to data science and process mining in Part I, Part II provides the basics of business process modeling and data mining necessary to understand the remainder of the book. Next, Part III focuses on process discovery as the most important process mining task, while Part IV moves beyond discovering the control flow of processes, highlighting conformance checking, and organizational and time perspectives. Part V offers a guide to successfully applying process mining in practice, including an introduction to the widely used open-source tool ProM and several commercial products. Lastly, Part VI takes a step back, reflecting on the material presented and the key open challenges. Overall, this book provides a comprehensive overview of the state of the art in process mining. It is intended for business process analysts, business consultants, process managers, graduate students, and BPM researchers. © Springer-Verlag Berlin Heidelberg 2011, 2016.",Book,"Final",Scopus,2-s2.0-84979530122
"Günther C.W., Van Der Aalst W.M.P.","Fuzzy mining - Adaptive process simplification based on multi-perspective metrics",2007,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",591,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-38049156249&doi=10.1007%2f978-3-540-75183-0_24&partnerID=40&md5=a8035428ca9ad8f15a5151a0273117cf","Process Mining is a technique for extracting process models from execution logs. This is particularly useful in situations where people have an idealized view of reality. Real-life processes turn out to be less structured than people tend to believe. Unfortunately, traditional process mining approaches have problems dealing with unstructured processes. The discovered models are often ""spaghetti-like"", showing all details without distinguishing what is important and what is not. This paper proposes a new process mining approach to overcome this problem. The approach is configurable and allows for different faithfully simplified views of a particular process. To do this, the concept of a roadmap is used as a metaphor. Just like different roadmaps provide suitable abstractions of reality, process models should provide meaningful abstractions of operational processes encountered in domains ranging from healthcare and logistics to web services and public administration. © Springer-Verlag Berlin Heidelberg 2007.",Conference Paper,"Final",Scopus,2-s2.0-38049156249
"Schleich B., Anwer N., Mathieu L., Wartzack S.","Shaping the digital twin for design and production engineering",2017,"CIRP Annals - Manufacturing Technology",508,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018723536&doi=10.1016%2fj.cirp.2017.04.040&partnerID=40&md5=ba7049ec32c79b6298cc70581af3c133","The digitalization of manufacturing fuels the application of sophisticated virtual product models, which are referred to as digital twins, throughout all stages of product realization. Particularly, more realistic virtual models of manufactured products are essential to bridge the gap between design and manufacturing and to mirror the real and virtual worlds. In this paper, we propose a comprehensive reference model based on the concept of Skin Model Shapes, which serves as a digital twin of the physical product in design and manufacturing. In this regard, model conceptualization, representation, and implementation as well as applications along the product life-cycle are addressed. © 2017",Article,"Final",Scopus,2-s2.0-85018723536
"Qi Q., Tao F.","Digital Twin and Big Data Towards Smart Manufacturing and Industry 4.0: 360 Degree Comparison",2018,"IEEE Access",488,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041173790&doi=10.1109%2fACCESS.2018.2793265&partnerID=40&md5=421f931c692160832c81d6535ddfea0a","With the advances in new-generation information technologies, especially big data and digital twin, smart manufacturing is becoming the focus of global manufacturing transformation and upgrading. Intelligence comes from data. Integrated analysis for the manufacturing big data is beneficial to all aspects of manufacturing. Besides, the digital twin paves a way for the cyber-physical integration of manufacturing, which is an important bottleneck to achieve smart manufacturing. In this paper, the big data and digital twin in manufacturing are reviewed, including their concept as well as their applications in product design, production planning, manufacturing, and predictive maintenance. On this basis, the similarities and differences between big data and digital twin are compared from the general and data perspectives. Since the big data and digital twin can be complementary, how they can be integrated to promote smart manufacturing are discussed. © 2013 IEEE.",Article,"Final",Scopus,2-s2.0-85041173790
"Tao F., Zhang H., Liu A., Nee A.Y.C.","Digital Twin in Industry: State-of-the-Art",2019,"IEEE Transactions on Industrial Informatics",484,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054374767&doi=10.1109%2fTII.2018.2873186&partnerID=40&md5=2fd1fcedbc08dff8d43df76d7de1d53f","Digital twin (DT) is one of the most promising enabling technologies for realizing smart manufacturing and Industry 4.0. DTs are characterized by the seamless integration between the cyber and physical spaces. The importance of DTs is increasingly recognized by both academia and industry. It has been almost 15 years since the concept of the DT was initially proposed. To date, many DT applications have been successfully implemented in different industries, including product design, production, prognostics and health management, and some other fields. However, at present, no paper has focused on the review of DT applications in industry. In an effort to understand the development and application of DTs in industry, this paper thoroughly reviews the state-of-the-art of the DT research concerning the key components of DTs, the current development of DTs, and the major DT applications in industry. This paper also outlines the current challenges and some possible directions for future work. © 2005-2012 IEEE.",Article,"Final",Scopus,2-s2.0-85054374767
"Tao F., Zhang M.","Digital Twin Shop-Floor: A New Shop-Floor Paradigm Towards Smart Manufacturing",2017,"IEEE Access",450,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030752762&doi=10.1109%2fACCESS.2017.2756069&partnerID=40&md5=ec2b49226948f1c7116612c0f78f846e","With the developments and applications of the new information technologies, such as cloud computing, Internet of Things, big data, and artificial intelligence, a smart manufacturing era is coming. At the same time, various national manufacturing development strategies have been put forward, such as Industry 4.0, Industrial Internet, manufacturing based on Cyber-Physical System, and Made in China 2025. However, one of specific challenges to achieve smart manufacturing with these strategies is how to converge the manufacturing physical world and the virtual world, so as to realize a series of smart operations in the manufacturing process, including smart interconnection, smart interaction, smart control and management, etc. In this context, as a basic unit of manufacturing, shop-floor is required to reach the interaction and convergence between physical and virtual spaces, which is not only the imperative demand of smart manufacturing, but also the evolving trend of itself. Accordingly, a novel concept of digital twin shop-floor (DTS) based on digital twin is explored and its four key components are discussed, including physical shop-floor, virtual shop-floor, shop-floor service system, and shop-floor digital twin data. What is more, the operation mechanisms and implementing methods for DTS are studied and key technologies as well as challenges ahead are investigated, respectively. © 2013 IEEE.",Article,"Final",Scopus,2-s2.0-85030752762
"Deb C., Zhang F., Yang J., Lee S.E., Shah K.W.","A review on time series forecasting techniques for building energy consumption",2017,"Renewable and Sustainable Energy Reviews",365,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015085852&doi=10.1016%2fj.rser.2017.02.085&partnerID=40&md5=626c23f1474b8b76416c0413c27c464a","Energy consumption forecasting for buildings has immense value in energy efficiency and sustainability research. Accurate energy forecasting models have numerous implications in planning and energy optimization of buildings and campuses. For new buildings, where past recorded data is unavailable, computer simulation methods are used for energy analysis and forecasting future scenarios. However, for existing buildings with historically recorded time series energy data, statistical and machine learning techniques have proved to be more accurate and quick. This study presents a comprehensive review of the existing machine learning techniques for forecasting time series energy consumption. Although the emphasis is given to a single time series data analysis, the review is not just limited to it since energy data is often co-analyzed with other time series variables like outdoor weather and indoor environmental conditions. The nine most popular forecasting techniques that are based on the machine learning platform are analyzed. An in-depth review and analysis of the ‘hybrid model’, that combines two or more forecasting techniques is also presented. The various combinations of the hybrid model are found to be the most effective in time series energy forecasting for building. © 2017 Elsevier Ltd",Review,"Final",Scopus,2-s2.0-85015085852
"Leemans S.J.J., Fahland D., Van Der Aalst W.M.P.","Discovering block-structured process models from event logs - A constructive approach",2013,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",307,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879641701&doi=10.1007%2f978-3-642-38697-8_17&partnerID=40&md5=496b0c935efa1a9d200a05b6b6f92e4a","Process discovery is the problem of, given a log of observed behaviour, finding a process model that 'best' describes this behaviour. A large variety of process discovery algorithms has been proposed. However, no existing algorithm guarantees to return a fitting model (i.e., able to reproduce all observed behaviour) that is sound (free of deadlocks and other anomalies) in finite time. We present an extensible framework to discover from any given log a set of block-structured process models that are sound and fit the observed behaviour. In addition we characterise the minimal information required in the log to rediscover a particular process model. We then provide a polynomial-time algorithm for discovering a sound, fitting, block-structured model from any given log; we give sufficient conditions on the log for which our algorithm returns a model that is language-equivalent to the process model underlying the log, including unseen behaviour. The technique is implemented in a prototypical tool. © 2013 Springer-Verlag.",Conference Paper,"Final",Scopus,2-s2.0-84879641701
"March S.T., Storey V.C.","Design science in the information systems discipline: An introduction to the special issue on design science research",2008,"MIS Quarterly: Management Information Systems",284,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-55949085529&doi=10.2307%2f25148869&partnerID=40&md5=e75ba461135100fa8e7b016fccbccfc9",[No abstract available],Article,"Final",Scopus,2-s2.0-55949085529
"Mani G.-F., Feniosky P.-M., Savarese S.","D4AR-A 4-dimensional augmented reality model for automating construction progress monitoring data collection, processing and communication",2009,"Electronic Journal of Information Technology in Construction",282,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350154917&partnerID=40&md5=48ea864eb64c180144062cb127f90c1b","Early detection of actual or potential schedule delay in field construction activities is vital to project management. This entails project managers to design, implement, and maintain a systematic approach for construction progress monitoring to promptly identify, process and communicate discrepancies between actual and as-planned performances. To achieve this goal, this research focuses on exploring application of unsorted daily progress photograph logs available on any construction site as a data collection technique. Our approach is based on computing-from the images themselves-the photographer's locations and orientations, along with a sparse 3D geometric representation of the as-built site using daily progress photographs and superimposition of the reconstructed scene over as-planned 4D models. Within such an environment, progress photographs are registered in the virtual as-planned environment and this allows a large unstructured collection of daily construction images to be sorted, interactively browsed and explored. In addition, sparse reconstructed scenes superimposed over 4D models allow site images to be geo-registered with the as-planned components and consequently, location-based image processing technique to be implemented and progress data to be extracted automatically. The results of progress comparison between as-planned and as-built performances are visualized in the D4AR (4D Augmented Reality) environment using a traffic light metaphor. We present our preliminary results on three ongoing construction projects and discuss implementation, perceived benefits and future potential enhancement of this new technology in construction, in all fronts of automatic data collection, processing and communication. © 2009 The authors.",Article,"Final",Scopus,2-s2.0-70350154917
"Tao F., Sui F., Liu A., Qi Q., Zhang M., Song B., Guo Z., Lu S.C.-Y., Nee A.Y.C.","Digital twin-driven product design framework",2019,"International Journal of Production Research",271,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042921933&doi=10.1080%2f00207543.2018.1443229&partnerID=40&md5=ba290742598bd6b1307f8743ec098fc4","With the advent of new generation information technologies in industry and product design, the big data-driven product design era has arrived. However, the big data-driven product design mainly places emphasis on the analysis of physical data rather than the virtual models, in other words, the convergence between product physical and virtual space is usually absent. Digital twin, a new emerging and fast growing technology which connects the physical and virtual world, has attracted much attention worldwide recently. This paper presents a new method for product design based on the digital twin approach. The development of product design is briefly introduced first. The framework of digital twin-driven product design (DTPD) is then proposed and analysed. A case is presented to illustrate the application of the proposed DTPD method. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.",Article,"Final",Scopus,2-s2.0-85042921933
"Glaessgen E.H., Stargel D.S.","The digital twin paradigm for future NASA and U.S. Air force vehicles",2012,"Collection of Technical Papers - AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics and Materials Conference",263,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881426231&partnerID=40&md5=cd8379d4891f2ddab1a2bacad8bed2ba","Future generations of NASA and U.S. Air Force vehicles will require lighter mass while being subjected to higher loads and more extreme service conditions over longer time periods than the present generation. Current approaches for certification, fleet management and sustainment are largely based on statistical distributions of material properties, heuristic design philosophies, physical testing and assumed similitude between testing and operational conditions and will likely be unable to address these extreme requirements. To address the shortcomings of conventional approaches, a fundamental paradigm shift is needed. This paradigm shift, the Digital Twin, integrates ultra-high fidelity simulation with the vehicle's on-board integrated vehicle health management system, maintenance history and all available historical and fleet data to mirror the life of its flying twin and enable unprecedented levels of safety and reliability. © 2012 AIAA.",Conference Paper,"Final",Scopus,2-s2.0-84881426231
"Sacks R., Eastman C., Lee G., Teicholz P.","BIM Handbook: A Guide to Building Information Modeling for Owners, Designers, Engineers, Contractors, and Facility Managers",2018,"BIM Handbook: A Guide to Building Information Modeling for Owners, Designers, Engineers, Contractors, and Facility Managers",224,,[No abstract available],,"Final",Scopus,2-s2.0-85054559327
"Ding L., Zhou Y., Akinci B.","Building Information Modeling (BIM) application framework: The process of expanding from 3D to computable nD",2014,"Automation in Construction",191,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907426904&doi=10.1016%2fj.autcon.2014.04.009&partnerID=40&md5=ba44e7517229a7099122070dd2f68c28","The utilization of Building Information Modeling (BIM) has been growing significantly and translating into the support of various tasks within the construction industry. In relation to such a growth, many approaches that leverage dimensions of information stored in BIM model are being developed. Through this, it is possible to allow all stakeholders to retrieve and generate information from the same model, enabling them to work cohesively. To identify gaps of existing work and evaluate new studies in this area, a BIM application framework is developed and discussed in this paper. Such a framework gives an overview of BIM applications in the construction industry. A literature review, within this framework, has been conducted and the result reveals a research gap for BIM applications in the project domains of quality, safety and environmental management. A computable multi-dimensional (nD) model is difficult to establish in these areas because with continuously changing conditions, the decision making rules for evaluating whether an individual component is considered good quality, or whether a construction site is safe, also vary as the construction progresses. A process of expanding from 3D to computable nD models, specifically, a possible way to integrate safety, quality and carbon emission variables into BIM during the construction phase of a project is explained in this paper. As examples, the processes of utilizing nD models on real construction sites are described. It is believed to benefit the industry by providing a computable BIM and enabling all project participants to extract any information required for decision making. Finally, the framework is used to identify areas to extend BIM research. © 2014 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84907426904
"Buijs J.C.A.M., Van Dongen B.F., Van Der Aalst W.M.P.","On the role of fitness, precision, generalization and simplicity in process discovery",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",181,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872786846&doi=10.1007%2f978-3-642-33606-5_19&partnerID=40&md5=9545edb55f0a2cdfc8bb7ca02be23eaf","Process discovery algorithms typically aim at discovering process models from event logs that best describe the recorded behavior. Often, the quality of a process discovery algorithm is measured by quantifying to what extent the resulting model can reproduce the behavior in the log, i.e. replay fitness. At the same time, there are many other metrics that compare a model with recorded behavior in terms of the precision of the model and the extent to which the model generalizes the behavior in the log. Furthermore, several metrics exist to measure the complexity of a model irrespective of the log. In this paper, we show that existing process discovery algorithms typically consider at most two out of the four main quality dimensions: replay fitness, precision, generalization and simplicity. Moreover, existing approaches can not steer the discovery process based on user-defined weights for the four quality dimensions. This paper also presents the ETM algorithm which allows the user to seamlessly steer the discovery process based on preferences with respect to the four quality dimensions. We show that all dimensions are important for process discovery. However, it only makes sense to consider precision, generalization and simplicity if the replay fitness is acceptable. © 2012 Springer-Verlag.",Conference Paper,"Final",Scopus,2-s2.0-84872786846
"Tang S., Shelden D.R., Eastman C.M., Pishdad-Bozorgi P., Gao X.","A review of building information modeling (BIM) and the internet of things (IoT) devices integration: Present status and future trends",2019,"Automation in Construction",180,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060885881&doi=10.1016%2fj.autcon.2019.01.020&partnerID=40&md5=7f882d4aa0b2c069887a02c5094892d6","The integration of Building Information Modeling (BIM) with real-time data from the Internet of Things (IoT) devices presents a powerful paradigm for applications to improve construction and operational efficiencies. Connecting real-time data streams from the rapidly expanding set of IoT sensor networks to the high-fidelity BIM models provides numerous applications. However, BIM and IoT integration research are still in nascent stages, there is a need to understand the current situation of BIM and IoT device integration. This paper conducts a comprehensive review with the intent to identify common emerging areas of application and common design patterns in the approach to tackling BIM-IoT device integration along with an examination of current limitations and predictions of future research directions. Altogether, 97 papers from 14 AEC related journals and databases in other industry over the last decade were reviewed. Several prevalent domains of application namely Construction Operation and Monitoring, Health & Safety Management, Construction Logistic & Management, and Facility Management were identified. The authors summarized 5 integration methods with description, examples, and discussion. These integration methods are utilizing BIM tools’ APIs and relational database, transform BIM data into a relational database using new data schema, create new query language, using semantic web technologies and hybrid approach. Based on the observed limitations, prominent future research directions are suggested, focusing on service-oriented architecture (SOA) patterns and web services-based strategies for BIM and IoT integration, establishing information integration & management standards, solving interoperability issue, and cloud computing. © 2019 Elsevier B.V.",Review,"Final",Scopus,2-s2.0-85060885881
"Vachalek J., Bartalsky L., Rovny O., Sismisova D., Morhac M., Loksik M.","The digital twin of an industrial production line within the industry 4.0 concept",2017,"Proceedings of the 2017 21st International Conference on Process Control, PC 2017",138,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027512911&doi=10.1109%2fPC.2017.7976223&partnerID=40&md5=31bb2e758a775ddea30b1d66b905d3b7","This article presents the digital twin concept, which is an augmented manufacturing project created in close collaboration by SOVA Digital and the Institute of Automation, Measurement and Applied Informatics (ÚAMAI), of the Faculty of Mechanical Engineering, Slovak University of Technology in Bratislava with the support of SIEMENS. The project is a technological concept focusing on the continuous optimization of production processes, proactive maintenance, and continuous processing of process data. This project is the basis for further work to promote the concept of Industry 4.0. for the needs of the industry subjects within Slovakia. Its basic goal is to support the existing production structures within the automotive industry and the most efficient use of resources by augmented production and planning strategies, such as the digital twin presented here. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85027512911
"Dave B., Kubler S., Främling K., Koskela L.","Opportunities for enhanced lean construction management using Internet of Things standards",2016,"Automation in Construction",129,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949680819&doi=10.1016%2fj.autcon.2015.10.009&partnerID=40&md5=6099e707710515adcda41748e118ab66","Traditionally, production control on construction sites has been challenging, and still remains challenging. The ad-hoc production control methods that are usually used, most of which are informal, foster uncertainty that prevents smooth production flow. Lean construction methods such as the Last Planner System have partially tackled this problem by involving site teams into the decision making process and having them report back to the production management system. However, such systems have relatively long ""lookahead"" planning cycles to respond to the dynamic production requirements of construction, where daily, if not hourly control is needed. New solutions have been proposed such as VisiLean, KanBIM, etc., but again these types of construction management systems require the proximity and availability of computer devices to workers. Through this paper, the authors investigate how the communication framework underlying such construction management systems can be further improved so as to fully or partially automate various communication functions across the construction project lifecycle (e.g., to enable lean and close to real-time reporting of production control information). To this end, the present paper provides evidences of how the Internet of Things (IoT) and related standards can contribute to such an improvement. The paper then provides first insights - through various construction scenarios - into how the proposed communication framework can be beneficial for various actors and core business perspectives, from lean construction management to the management of the entire building lifecycle. © 2015 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84949680819
"Dimitrov A., Golparvar-Fard M.","Vision-based material recognition for automated monitoring of construction progress and generating building information modeling from unordered site image collections",2014,"Advanced Engineering Informatics",126,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893782757&doi=10.1016%2fj.aei.2013.11.002&partnerID=40&md5=6a9cfdda6d3fc66981eb614098cfc619","Automatically monitoring construction progress or generating Building Information Models using site images collections - beyond point cloud data - requires semantic information such as construction materials and inter-connectivity to be recognized for building elements. In the case of materials such information can only be derived from appearance-based data contained in 2D imagery. Currently, the state-of-the-art texture recognition algorithms which are often used for recognizing materials are very promising (reaching over 95% average accuracy), yet they have mainly been tested in strictly controlled conditions and often do not perform well with images collected from construction sites (dropping to 70% accuracy and lower). In addition, there is no benchmark that validates their performance under real-world construction site conditions. To overcome these limitations, we propose a new vision-based method for material classification from single images taken under unknown viewpoint and site illumination conditions. In the proposed algorithm, material appearance is modeled by a joint probability distribution of responses from a filter bank and principal Hue-Saturation-Value color values and classified using a multiple one-vs.-all χ2 kernel Support Vector Machine classifier. Classification performance is compared with the state-of-the-art algorithms both in computer vision and AEC communities. For experimental studies, a new database containing 20 typical construction materials with more than 150 images per category is assembled and used for validation. Overall, for material classification an average accuracy of 97.1% for 200×200 pixel image patches are reported. In cases where image patches are smaller, our method can synthetically generate additional pixels and maintain a competitive accuracy to those reported above (90.8% for 30×30 pixel patches). The results show the promise of the applicability of the proposed method and expose the limitations of the state-of-the-art classification algorithms under real world conditions. It further defines a new benchmark that could be used to measure the performance of future algorithms. © 2013 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84893782757
"Boje C., Guerriero A., Kubicki S., Rezgui Y.","Towards a semantic Construction Digital Twin: Directions for future research",2020,"Automation in Construction",113,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082386834&doi=10.1016%2fj.autcon.2020.103179&partnerID=40&md5=914efcd6c064d6a97299f00d812bb8fc","As the Architecture, Engineering and Construction sector is embracing the digital age, the processes involved in the design, construction and operation of built assets are more and more influenced by technologies dealing with value-added monitoring of data from sensor networks, management of this data in secure and resilient storage systems underpinned by semantic models, as well as the simulation and optimisation of engineering systems. Aside from enhancing the efficiency of the value chain, such information-intensive models and associated technologies play a decisive role in minimising the lifecycle impacts of our buildings. While Building Information Modelling provides procedures, technologies and data schemas enabling a standardised semantic representation of building components and systems, the concept of a Digital Twin conveys a more holistic socio-technical and process-oriented characterisation of the complex artefacts involved by leveraging the synchronicity of the cyber-physical bi-directional data flows. Moreover, BIM lacks semantic completeness in areas such as control systems, including sensor networks, social systems, and urban artefacts beyond the scope of buildings, thus requiring a holistic, scalable semantic approach that factors in dynamic data at different levels. The paper reviews the multi-faceted applications of BIM during the construction stage and highlights limits and requirements, paving the way to the concept of a Construction Digital Twin. A definition of such a concept is then given, described in terms of underpinning research themes, while elaborating on areas for future research. © 2020 The Authors",Review,"Final",Scopus,2-s2.0-85082386834
"Dave B., Buda A., Nurminen A., Främling K.","A framework for integrating BIM and IoT through open standards",2018,"Automation in Construction",104,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051379498&doi=10.1016%2fj.autcon.2018.07.022&partnerID=40&md5=9daa502dc1dc7080a41fcd01842cb455","The built environment provides significant opportunities for IoT (Internet of Things) deployment, and can be singled out as one of the most important aspects for IoT related research. While the IoT deployment in the built environment is growing exponentially, there exists a gap in integrating these two in a systematic way through open standards and systems. From technological perspective, there is a need for convergence of diverse fields ranging from Building Information Systems and Building Services to Building Automation Systems, and IoT devices and finally the end user services to develop smart, user oriented applications. This paper outlines the efforts to develop a platform that integrates the built environment data with IoT sensors in a campus wide, web based system called Otaniemi3D that provides information about energy usage, occupancy and user comfort by integrating Building Information Models and IoT devices through open messaging standards (O-MI and O-DF) and IFC models. The paper describes the design criteria, the system architecture, the workflow and a proof of concept with potential use cases that integrate IoT with the built environment. Initial results show that both the end users and other research groups can benefit from such platforms by either consuming the data in their daily life or using the data for more advance research. © 2018 The Authors",Article,"Final",Scopus,2-s2.0-85051379498
"Jans M., Van Der Werf J.M., Lybaert N., Vanhoof K.","A business process mining application for internal transaction fraud mitigation",2011,"Expert Systems with Applications",102,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957986425&doi=10.1016%2fj.eswa.2011.04.159&partnerID=40&md5=7e128549930c4b96dab26b2c26894247","Corporate fraud these days represents a huge cost to our economy. In the paper we address one specific type of corporate fraud, internal transaction fraud. Given the omnipresence of stored history logs, the field of process mining rises as an adequate answer to mitigating internal transaction fraud. Process mining diagnoses processes by mining event logs. This way we can expose opportunities to commit fraud in the followed process. In this paper we report on an application of process mining at a case company. The procurement process was selected as example for internal transaction fraud mitigation. The results confirm the contribution process mining can provide to business practice. © 2010 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-79957986425
"Buijs J.C.A.M., Van Dongen B.F., Van Der Aalst W.M.P.","Quality dimensions in process discovery: The importance of fitness, precision, generalization and simplicity",2014,"International Journal of Cooperative Information Systems",95,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900485338&doi=10.1142%2fS0218843014400012&partnerID=40&md5=950af524fbd22bc95cf0310ec2e47534","Process discovery algorithms typically aim at discovering process models from event logs that best describe the recorded behavior. Often, the quality of a process discovery algorithm is measured by quantifying to what extent the resulting model can reproduce the behavior in the log, i.e. replay fitness. At the same time, there are other measures that compare a model with recorded behavior in terms of the precision of the model and the extent to which the model generalizes the behavior in the log. Furthermore, many measures exist to express the complexity of a model irrespective of the log. In this paper, we first discuss several quality dimensions related to process discovery. We further show that existing process discovery algorithms typically consider at most two out of the four main quality dimensions: replay fitness, precision, generalization and simplicity. Moreover, existing approaches cannot steer the discovery process based on user-defined weights for the four quality dimensions. This paper presents the ETM algorithm which allows the user to seamlessly steer the discovery process based on preferences with respect to the four quality dimensions. We show that all dimensions are important for process discovery. However, it only makes sense to consider precision, generalization and simplicity if the replay fitness is acceptable. © 2014 World Scientific Publishing Company.",Article,"Final",Scopus,2-s2.0-84900485338
"Min Q., Lu Y., Liu Z., Su C., Wang B.","Machine Learning based Digital Twin Framework for Production Optimization in Petrochemical Industry",2019,"International Journal of Information Management",90,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066307148&doi=10.1016%2fj.ijinfomgt.2019.05.020&partnerID=40&md5=5cc95ab869c2986f2aa7c98a092105ff","Digital twins, along with the internet of things (IoT), data mining, and machine learning technologies, offer great potential in the transformation of today's manufacturing paradigm toward intelligent manufacturing. Production control in petrochemical industry involves complex circumstances and a high demand for timeliness; therefore, agile and smart controls are important components of intelligent manufacturing in the petrochemical industry. This paper proposes a framework and approaches for constructing a digital twin based on the petrochemical industrial IoT, machine learning and a practice loop for information exchange between the physical factory and a virtual digital twin model to realize production control optimization. Unlike traditional production control approaches, this novel approach integrates machine learning and real-time industrial big data to train and optimize digital twin models. It can support petrochemical and other process manufacturing industries to dynamically adapt to the changing environment, respond in a timely manner to changes in the market due to production optimization, and improve economic benefits. Accounting for environmental characteristics, this paper provides concrete solutions for machine learning difficulties in the petrochemical industry, e.g., high data dimensions, time lags and alignment between time series data, and high demand for immediacy. The approaches were evaluated by applying them in the production unit of a petrochemical factory, and a model was trained via industrial IoT data and used to realize intelligent production control based on real-time data. A case study shows the effectiveness of this approach in the petrochemical industry. © 2019 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85066307148
"Cheng J.C.P., Chen W., Chen K., Wang Q.","Data-driven predictive maintenance planning framework for MEP components based on BIM and IoT using machine learning algorithms",2020,"Automation in Construction",74,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078707972&doi=10.1016%2fj.autcon.2020.103087&partnerID=40&md5=064c227f5e3c92afbeb91ad35da0096e","Facility managers usually conduct reactive maintenance or preventive maintenance strategies in building maintenance management. However, there are some limitations that reactive maintenance cannot prevent failure, and preventive maintenance cannot predict the future condition of MEP components and repair in advance to extend the lifetime of facilities. Therefore, this study aims to apply a predictive maintenance strategy with advanced technologies to overcome these limitations. Building information modeling (BIM) and Internet of Things (IoT) have the potential to improve the efficiency of facility maintenance management (FMM). Despite the significant efforts that have been made to apply BIM and IoT to the architecture, engineering, construction, and facility management (AEC/FM) industry, BIM and IoT integration for FMM is still at an initial stage. In order to provide a better maintenance strategy for building facilities, a data-driven predictive maintenance planning framework based on BIM and IoT technologies for FMM was developed, consisting of an information layer and an application layer. Data collection and data integration among the BIM models, FM system, and IoT network are undertaken in the information layer, while the application layer contains four modules to achieve predictive maintenance, namely: (1) condition monitoring and fault alarming module, (2) condition assessment module, (3) condition prediction module, and (4) maintenance planning module. Machine learning algorithms, ANN and SVM, are used to predict the future condition of MEP components. Furthermore, the developed framework was applied in an illustrative example to validate the feasibility of the approach. The results show that the constantly updated data obtained from the information layer together with the machine learning algorithms in the application layer can efficiently predict the future condition of MEP components for maintenance planning. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85078707972
"Yuan X., Anumba C.J., Parfitt M.K.","Cyber-physical systems for temporary structure monitoring",2016,"Automation in Construction",71,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961217447&doi=10.1016%2fj.autcon.2016.02.005&partnerID=40&md5=86f1228b6b88ebd2b78d0e9765238e86","Information technology-based methods, such as Cyber-Physical Systems (CPS), play an important role in industrial transformation and evolution. However, while significant efforts have been made towards CPS application in several other industry sectors, the exploration of CPS benefits and applicability to the construction industry is at the initial stage. While CPS has been identified as a promising solution to address problems in the construction industry, few explorations have been made on CPS application to temporary structures, which have significant safety issues that urgently need to be addressed. With a focus on the enhanced monitoring of temporary structures to prevent potential structural failures, this study proposed a CPS-based temporary structures monitoring (TSM) system that integrates the virtual model of a temporary structure and the physical structure on the construction jobsite. In doing this, the applicability of CPS to temporary structures monitoring is investigated, and end user requirements and system requirements are identified for system design. In addition, a system architecture and a description of the issues surrounding the choice of a system development environment are presented. For better understanding of how the TSM works, aspects of the developed CPS-based TSM are presented with system workflow and simulated examples of the structural monitoring of a scaffolding system. The potential benefits and barriers to CPS implementation in temporary structures, along with future research based on this study, are highlighted. © 2016 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84961217447
"Pan Y., Zhang L., Wu X., Skibniewski M.J.","Multi-classifier information fusion in risk analysis",2020,"Information Fusion",70,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081156314&doi=10.1016%2fj.inffus.2020.02.003&partnerID=40&md5=0f05307cf8a05f2efc44ef0038fded6f","This paper develops a novel multi-classifier information fusion approach that integrates the probabilistic support vector machine (SVM) and the improved Dempster-Shafer (D-S) evidence theory to support risk analysis under uncertainty. Safety levels for various risk factors can be classified separately using the probabilistic SVM. Then, these multiple classification results will be fused at the decision level to achieve an overall risk evaluation by an improved D-S evidence theory with the integration of the Dempster’ rule and the weighted average rule. The Monte Carlo simulation approach is employed to model the randomness and uncertainty underlying limited observations. A global sensitivity analysis is performed to identify the most significant factors contributing to the risk event. A realistic operational tunnel case in China is used to demonstrate the feasibility and effectiveness of the developed approach, aiming to assess the magnitude of the structural health risk. Results indicate the developed SVM-DS approach is capable of (1) Fusing multi-classifier information effectively from different SVM models with a high classification accuracy of 97.14%; (2) Performing a strong robustness to bias, which can achieve acceptable classification accuracy even under a 20% bias; and (3) Exhibiting a more outstanding classification performance (87.99% accuracy) than the single SVM model (63.84% accuracy) under a high bias (20%). Since the proposed reliable risk analysis method can efficiently fuse multi-sensory information with ubiquitous uncertainties, conflicts, and bias, it provides in-depth analysis for structural health status together with the most critical risk factors, and then proper remedial actions can be taken at an early stage. © 2020",Article,"Final",Scopus,2-s2.0-85081156314
"Lagkas T., Argyriou V., Bibi S., Sarigiannidis P.","UAV IoT framework views and challenges: Towards protecting drones as “things”",2018,"Sensors (Switzerland)",70,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056725891&doi=10.3390%2fs18114015&partnerID=40&md5=8262678779844d4d14830e46deff2866","Unmanned aerial vehicles (UAVs) have enormous potential in enabling new applications in various areas, ranging from military, security, medicine, and surveillance to traffic-monitoring applications. Lately, there has been heavy investment in the development of UAVs and multi-UAVs systems that can collaborate and complete missions more efficiently and economically. Emerging technologies such as 4G/5G networks have significant potential on UAVs equipped with cameras, sensors, and GPS receivers in delivering Internet of Things (IoT) services from great heights, creating an airborne domain of the IoT. However, there are many issues to be resolved before the effective use of UAVs can be made, including security, privacy, and management. As such, in this paper we review new UAV application areas enabled by the IoT and 5G technologies, analyze the sensor requirements, and overview solutions for fleet management over aerial-networking, privacy, and security challenges. Finally, we propose a framework that supports and enables these technologies on UAVs. The introduced framework provisions a holistic IoT architecture that enables the protection of UAVs as “flying” things in a collaborative networked environment. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.",Review,"Final",Scopus,2-s2.0-85056725891
"Raedts I., Petković M., Usenko Y.S., Van Der Werf J.M., Groote J.F., Somers L.","Transformation of BPMN models for behaviour analysis",2007,"Proceedings of the 5th International Workshop on Modelling, Simulation, Verification and Validation of Enterprise Information Systems - MSVVEIS 2007; In Conjunction with ICEIS 2007",69,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-58149112794&partnerID=40&md5=b7cdd14cbeca1f52f9c8a2e2ae1f489a","In industry, many business processes are modelled and stored in Enterprise Information Systems (EIS). Tools supporting the verification and validation of business processes can help to improve the quality of these business processes. However, existing tools can not directly be applied to models used in industry. In this paper, we present our approach for model verification and validation: translating industrial models to Petri nets and mCRL2, and subsequently applying existing tools on the models derived from the initial industrial models. The following translations are described: BPMN models to Petri nets and Petri nets to mCRL2. It is shown what the analysis on the derived models can reveal about the original models.",Conference Paper,"Final",Scopus,2-s2.0-58149112794
"Lin J.-R., Hu Z.-Z., Zhang J.-P., Yu F.-Q.","A Natural-Language-Based Approach to Intelligent Data Retrieval and Representation for Cloud BIM",2016,"Computer-Aided Civil and Infrastructure Engineering",67,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954563556&doi=10.1111%2fmice.12151&partnerID=40&md5=c52b5e310eb1c2c61d59a5dcb63ccaec","As the information from diverse disciplines continues to integrate during the whole life cycle of an Architecture, Engineering, and Construction (AEC) project, the BIM (Building Information Model/Modeling) becomes increasingly large. This condition will cause users difficulty in acquiring the information they truly desire on a mobile device with limited space for interaction. The situation will be even worse for personnel without extensive knowledge of Industry Foundation Classes (IFC) or for nonexperts of the BIM software. To improve the value of the big data of BIM, an approach to intelligent data retrieval and representation for cloud BIM applications based on natural language processing was proposed. First, strategies for data storage and query acceleration based on the popular cloud-based database were explored to handle the large amount of BIM data. Then, the concepts ""keyword"" and ""constraint"" were proposed to capture the key objects and their specifications in a natural-language-based sentence that expresses the requirements of the user. Keywords and constraints can be mapped to IFC entities or properties through the International Framework for Dictionaries (IFD). The relationship between the user's requirement and the IFC-based data model was established by path finding in a graph generated from the IFC schema, enabling data retrieval and analysis. Finally, the analyzed and summarized results of BIM data were represented based on the structure of the retrieved data. A prototype application was developed to validate the proposed approach on the data collected during the construction of the terminal of Kunming Airport, the largest single building in China. The case study illustrated the following: (1) relationships between the user requirements and the data users concerned are established, (2) user-concerned data can be automatically retrieved and aggregated based on the cloud for BIM, and (3) the data are represented in a proper form for a visual view and a comprehensive report. With this approach, users can significantly benefit from requesting for information and the value of BIM will be enhanced. ©2015 Computer-Aided Civil and Infrastructure Engineering.",Article,"Final",Scopus,2-s2.0-84954563556
"Pan Y., Zhang L.","Roles of artificial intelligence in construction engineering and management: A critical review and future trends",2021,"Automation in Construction",66,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097906264&doi=10.1016%2fj.autcon.2020.103517&partnerID=40&md5=cc017f83fa385de8f603657789a90cc0","With the extensive adoption of artificial intelligence (AI), construction engineering and management (CEM) is experiencing a rapid digital transformation. Since AI-based solutions in CEM has become the current research focus, it needs to be comprehensively understood. In this regard, this paper presents a systematic review under both scientometric and qualitative analysis to present the current state of AI adoption in the context of CEM and discuss its future research trends. To begin with, a scientometric review is performed to explore the characteristics of keywords, journals, and clusters based on 4,473 journal articles published in 1997–2020. It is found that there has been an explosion of relevant papers especially in the past 10 years along with the change in keyword popularity from expert systems to building information modeling (BIM), digital twins, and others. Then, a brief understanding of CEM is provided, which can be benefited from the emerging trend of AI in terms of automation, risk mitigation, high efficiency, digitalization, and computer vision. Special concerns have been put on six hot research topics that amply the advantage of AI in CEM, including (1) knowledge representation and reasoning, (2) information fusion, (3) computer vision, (4) natural language processing, (5) intelligence optimization, and (6) process mining. The goal of these topics is to model, predict, and optimize issues in a data-driven manner throughout the whole lifecycle of the actual complex project. To further narrow the gap between AI and CEM, six key directions of future researches, such as smart robotics, cloud virtual and augmented reality (cloud VR/AR), Artificial Intelligence of Things (AIoT), digital twins, 4D printing, and blockchains, are highlighted to constantly facilitate the automation and intelligence in CEM. © 2020 Elsevier B.V.",Review,"Final",Scopus,2-s2.0-85097906264
"Peng Y., Lin J.-R., Zhang J.-P., Hu Z.-Z.","A hybrid data mining approach on BIM-based building operation and maintenance",2017,"Building and Environment",57,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033726504&doi=10.1016%2fj.buildenv.2017.09.030&partnerID=40&md5=acadb156e52adbe2fad8bbcb0b735013","Huge amounts of data are generated daily during the operation and maintenance (O&M) phase of buildings. These accumulated data have the potential to provide deep information that can help improve facility management. Building Information Model/Modeling (BIM) technology has proven potential in O&M management in some studies, making it possible to store massive data. However, the complex and non-intuitive data records, as well as inaccurate manual inputs, raise difficulties in making full use of information in current O&M activities. This paper aims to address these problems by proposing a BIM-based Data Mining (DM) approach for extracting meaningful laws and patterns, as well as detecting improper records. In this approach, the BIM database is first transformed into a data warehouse. After that, three DM methods are combined to find useful information from the BIM. Specifically, the cluster analysis can find relationships of similarity among records, the outlier detection detects manually input improper data and keeps the database fresh, and the improved pattern mining algorithm finds deeper logic links among records. Particular emphasis is put on introducing the algorithms and how they should be used by building managers. Hence, the value of BIM is increased based on rules, extracted from data of O&M phase that appear irregular and disordered. Validated by an integrated on-site practice in an airport terminal, the proposed DM methods are helpful in prediction, early warning, and decision making, leading to the improvements of resource usage and maintenance efficiency during the O&M phase. © 2017 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85033726504
"Lu R., Brilakis I.","Digital twinning of existing reinforced concrete bridges from labelled point clusters",2019,"Automation in Construction",48,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065641838&doi=10.1016%2fj.autcon.2019.102837&partnerID=40&md5=eb8619b2d5d7a3d5ac059918869928f6","The automation of digital twinning for existing reinforced concrete bridges from point clouds remains an unresolved problem. Whilst current methods can automatically detect bridge objects in point clouds in the form of labelled point clusters, the fitting of accurate 3D shapes to point clusters remains largely human dependent largely. 95% of the total manual modelling time is spent on customizing shapes and fitting them correctly. The challenges exhibited in the fitting step are due to the irregular geometries of existing bridges. Existing methods can fit geometric primitives such as cuboids and cylinders to point clusters, assuming bridges are comprised of generic shapes. However, the produced geometric digital twins are too ideal to depict the real geometry of bridges. In addition, none of the existing methods have explicitly demonstrated how to evaluate the resulting Industry Foundation Classes bridge data models in terms of spatial accuracy using quantitative measurements. In this article, we tackle these challenges by delivering a slicing-based object fitting method that can generate the geometric digital twin of an existing reinforced concrete bridge from four types of labelled point cluster. The quality of the generated models is gauged using cloud-to-cloud distance-based metrics. Experiments on ten bridge point cloud datasets indicate that the method achieves an average modelling distance of 7.05 cm (while the manual method achieves 7.69 cm), and an average modelling time of 37.8 s. This is a huge leap over the current practice of digital twinning performed manually. © 2019 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85065641838
"Park J., Lee D., Zhu J.","An integrated approach for ship block manufacturing process performance evaluation: Case from a Korean shipbuilding company",2014,"International Journal of Production Economics",47,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905966034&doi=10.1016%2fj.ijpe.2014.06.012&partnerID=40&md5=5f938ddb5a16c4518360063f63cdbd5c","For effective ship manufacturing, a ship is divided into hundreds of properly sized blocks in the design stage. Each block is produced in its own manufacturing process, and subsequently the blocks are assembled into the body of a ship. Performance evaluation of the block manufacturing process (BMP) has been an important issue in the shipbuilding industry, since the BMP is related to overall shipbuilding productivity. However, performance evaluation of BMP entails many difficulties due to the many block types and many differences between actual and planned operations. To address this issue, this paper proposes a systematic approach to evaluate the performance of BMPs by integrating process mining (PM) and data envelopment analysis (DEA). The approach evaluates performance based on actual work data, which are saved in the databases of production information systems, and provides guidelines for the improvement of underperforming BMPs in relation to the manufacturing processes. For demonstrative purpose, the proposed approach is applied to a Korean shipbuilding company. © 2014 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84905966034
"Teizer J., Wolf M., Golovina O., Perschewski M., Propach M., Neges M., König M.","Internet of Things (IoT) for integrating environmental and localization data in Building Information Modeling (BIM)",2017,"ISARC 2017 - Proceedings of the 34th International Symposium on Automation and Robotics in Construction",44,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032347335&doi=10.22260%2fisarc2017%2f0084&partnerID=40&md5=678561fff35eb9290350168e52b80b1e","Digital transformation is an ongoing challenge in construction. Whereas central storage and planning with Building Information Modeling (BIM) can be considered state-of-the-art, the integration of realtime data like environmental and localization data of workers in indoor work environments can provide further benefits for operations management in construction and facility management. This paper introduces the concept of permanent availability of up-to-date actual performance data sets through an Internet-of-Things (IoT) approach that integrates environmental and localization data in a cloud-based BIM platform. In this paper, we reflect on the usage of Internet of Things (IoT) technology and the lean and injury-free (LIFE) construction management approach, create a concept to implement the topics in existing systems, design and create a prototypical application, validate the prototype in field-typical work settings, and critically review the results.",Conference Paper,"Final",Scopus,2-s2.0-85032347335
"Premchaiswadi W., Porouhan P.","Process modeling and bottleneck mining in online peer-review systems",2015,"SpringerPlus",44,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940206911&doi=10.1186%2fs40064-015-1183-4&partnerID=40&md5=a031f4070bd168d20bc3b0232c0d9380","This paper is divided into three main parts. In the first part of the study, we captured, collected and formatted an event log describing the handling of reviews for proceedings of an international conference in Thailand. In the second part, we used several process mining techniques in order to discover process models, social, organizational, and hierarchical structures from the proceeding’s event log. In the third part, we detected the deviations and bottlenecks of the peer review process by comparing the observed events (i.e., authentic dataset) with a pre-defined model (i.e., master map). Finally, we investigated the performance information as well as the total waiting time in order to improve the effectiveness and efficiency of the online submission and peer review system for the prospective conferences and seminars. Consequently, the main goals of the study were as follows: (1) to convert the collected event log into the appropriate format supported by process mining analysis tools, (2) to discover process models and to construct social networks based on the collected event log, and (3) to find deviations, discrepancies and bottlenecks between the collected event log and the master pre-defined model. The results showed that although each paper was initially sent to three different reviewers; it was not always possible to make a decision after the first round of reviewing; therefore, additional reviewers were invited. In total, all the accepted and rejected manuscripts were reviewed by an average of 3.9 and 3.2 expert reviewers, respectively. Moreover, obvious violations of the rules and regulations relating to careless or inappropriate peer review of a manuscript—committed by the editorial board and other staff—were identified. Nine blocks of activity in the authentic dataset were not completely compatible with the activities defined in the master model. Also, five of the activity traces were not correctly enabled, and seven activities were missed within the online submission system. On the other hand, dealing with the feedback (comments) received from the first and the third reviewers; the conference committee members and the organizers did not attend to those feedback/comments in a timely manner. © 2015, Premchaiswadi and Porouhan.",Article,"Final",Scopus,2-s2.0-84940206911
"Lu Q., Parlikad A.K., Woodall P., Don Ranasinghe G., Xie X., Liang Z., Konstantinou E., Heaton J., Schooling J.","Developing a Digital Twin at Building and City Levels: Case Study of West Cambridge Campus",2020,"Journal of Management in Engineering",39,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081580153&doi=10.1061%2f%28ASCE%29ME.1943-5479.0000763&partnerID=40&md5=80fae89f7ab8ce83fa81ca1fb8ba1ed8","A digital twin (DT) refers to a digital replica of physical assets, processes, and systems. DTs integrate artificial intelligence, machine learning, and data analytics to create living digital simulation models that are able to learn and update from multiple sources as well as represent and predict the current and future conditions of physical counterparts. However, current activities related to DTs are still at an early stage with respect to buildings and other infrastructure assets from an architectural and engineering/construction point of view. Less attention has been paid to the operation and maintenance (O&M) phase, which is the longest time span in the asset life cycle. A systematic and clear architecture verified with practical use cases for constructing a DT would be the foremost step for effective operation and maintenance of buildings and cities. According to current research about multitier architectures, this paper presents a system architecture for DTs that is specifically designed at both the building and city levels. Based on this architecture, a DT demonstrator of the West Cambridge site of the University of Cambridge in the UK was developed that integrates heterogeneous data sources, supports effective data querying and analysis, supports decision-making processes in O&M management, and further bridges the gap between human relationships with buildings/cities. This paper aims at going through the whole process of developing DTs in building and city levels from the technical perspective and sharing lessons learned and challenges involved in developing DTs in real practices. Through developing this DT demonstrator, the results provide a clear roadmap and present particular DT research efforts for asset management practitioners, policymakers, and researchers to promote the implementation and development of DT at the building and city levels. © 2020 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85081580153
"Shim C.-S., Dang N.-S., Lon S., Jeon C.-H.","Development of a bridge maintenance system for prestressed concrete bridges using 3D digital twin model",2019,"Structure and Infrastructure Engineering",39,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066812168&doi=10.1080%2f15732479.2019.1620789&partnerID=40&md5=9ba1b50226ea35f615b5482a8a41562b","Preventive maintenance is increasingly becoming an essential strategy in the bridge industry owing to its proactive advantage of maintaining the structural sustainability during its entire service life. Several in-use bridges lack an appropriate regular maintenance solution, leading to extra cost during the operation stage. This paper proposes a new generation of the bridge maintenance system by using a digital twin model concept for more reliable decision-making. A detailed solution is proposed in this work to enhance the bridge maintenance process using a parallel solution: a maintenance information management system based on a 3D information model in conjunction with a digital inspection system using image processing. Three-dimensional digital models are required to utilise information from the entire lifecycle of a project, including design and construction, operation, and maintenance, by continuously exchanging and updating data from each stakeholder. For the maintenance of prestressed concrete bridges, the twin models are defined and their uses are presented. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.",Article,"Final",Scopus,2-s2.0-85066812168
"Lu Q., Xie X., Parlikad A.K., Schooling J.M.","Digital twin-enabled anomaly detection for built asset monitoring in operation and maintenance",2020,"Automation in Construction",38,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085247924&doi=10.1016%2fj.autcon.2020.103277&partnerID=40&md5=1f0230cdbd9e34660593d42dc02c0c7d","Effective asset management plays a significant role in delivering the functionality and serviceability of buildings. However, there is a lack of efficient strategies and comprehensive approaches for managing assets and their associated data that can help to monitor, detect, record, and communicate operation and maintenance (O&M) issues. With the importance of Digital Twin (DT) concepts being proven in the architecture, engineering, construction and facility management (AEC/FM) sectors, a DT-enabled anomaly detection system for asset monitoring and its data integration method based on extended industry foundation classes (IFC) in daily O&M management are provided in this study. This paper presents a novel IFC-based data structure, using which a set of monitoring data that carries diagnostic information on the operational condition of assets is extracted from building DTs. Considering that assets run under changing loads determined by human demands, a Bayesian change point detection methodology that handles the contextual features of operational data is adopted to identify and filter contextual anomalies through cross-referencing with external operation information. Using the centrifugal pumps in the heating, ventilation and air-cooling (HVAC) system as a case study, the results indicate and prove that the novel DT-based anomaly detection process flow realizes a continuous anomaly detection of pumps, which contributes to efficient and automated asset monitoring in O&M. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85085247924
"Flath C.M., Stein N.","Towards a data science toolbox for industrial analytics applications",2018,"Computers in Industry",37,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029686258&doi=10.1016%2fj.compind.2017.09.003&partnerID=40&md5=26b352d1c51e409dacc55194364f5426","Manufacturing companies today have access to a vast number of data sources providing gigantic amounts of process and status data. Consequently, the need for analytical information systems is ever-growing to guide corporate decision-making. However, decision-makers in production environments are still very much focused on static, explanatory modeling provided by business intelligence suites instead of embracing the opportunities offered by predictive analytics. We develop a data science toolbox for manufacturing prediction tasks to bridge the gap between machine learning research and concrete practical needs. We provide guidelines and best practices for modeling, feature engineering and interpretation. To this end, we leverage tools from business information systems as well as machine learning. We illustrate the usage of this toolbox by means of a real-world manufacturing defect prediction case study. Thereby, we seek to enhance the understanding of predictive modeling. In particular, we want to emphasize that simply dumping data into “smart” algorithms is not the silver bullet. Instead, constant refinement and consolidation are required to improve the predictive power of a business analytics solution. © 2017 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85029686258
"Hwang I., Jang Y.J.","Process Mining to Discover Shoppers' Pathways at a Fashion Retail Store Using a WiFi-Base Indoor Positioning System",2017,"IEEE Transactions on Automation Science and Engineering",33,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018918153&doi=10.1109%2fTASE.2017.2692961&partnerID=40&md5=1b5c9ba8a1cb3af96e9252cabe2da354","We present a preliminary report of a customer pathway analysis in an off-line store. Smart phone WiFi-based positioning technology is used to identify each customer's pathway behavior. The log data containing the space-time information are analyzed using process mining, a tool that provides a comprehensive view of an entire process. The main benefit of process mining is that it provides the topological structure of the processes. We installed a WiFi signal-capturing device in a retail store of a fashion brand in South Korea and collected data over a two-month period. Halfway through the experimental period, we swapped a set of mannequins displayed at the entrance to the store with an item stand. We then compared the customers' pathway behavior before and after the change. Through an analysis based on process mining, we observed a change in the topological structure of the pathway behavior following the change in the display setting. This paper demonstrates the possibilities of analyzing customer behavior using WiFi-based technology and the process mining technique.Note to Practitioners - The main goal of this paper is to demonstrate the possibility of WiFi-based positioning technology and analytical methodology for analyzing indoor movement in the era of Big Data and the Internet of Things. Recently, with advances in communication, sensors, and wearable computing technologies, strong interest has been shown in marketing and retail behavior studies that can capture customer travel data in off-line stores to inform and improve sales and marketing. As the application of off-line store behavior analysis for behavior studies and marketing gains momentum, this paper can be used as a foundation for the development of sensor-based location analysis systems or devices for off-line stores. The focus of this paper is not to investigate customer behavior related to the display change nor the behavioral science related to retail. Rather, we experimentally demonstrate the value of the proposed technology and the process mining technique for future research. © 2004-2012 IEEE.",Article,"Final",Scopus,2-s2.0-85018918153
"Myers D., Suriadi S., Radke K., Foo E.","Anomaly detection for industrial control systems using process mining",2018,"Computers and Security",31,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049593755&doi=10.1016%2fj.cose.2018.06.002&partnerID=40&md5=c1c7caf75e59085c17f16cd03f13f6cb","Industrial control systems (ICS) are moving from dedicated communications to switched and routed corporate networks, exposing them to the Internet and placing them at risk of cyber-attacks. Existing methods of detecting cyber-attacks, such as intrusion detection systems (IDSs), are commonly implemented in ICS and SCADA networks. However, these devices do not detect more complex threats that manifest themselves gradually over a period of time through a combination of unusual sequencing of activities, such as process-related attacks. During the normal operation of ICSs, ICS devices record device logs, capturing their industrial processes over time. These logs are a rich source of information that should be analysed in order to detect such process-related attacks. In this paper, we present a novel process mining anomaly detection method for identifying anomalous behaviour and cyber-attacks using ICS data logs and the conformance checking analysis technique from the process mining discipline. A conformance checking analysis uses logs captured from production systems with a process model (which captures the expected behaviours of a system) to determine the extent to which real behaviours (captured in the logs) matches the expected behaviours (captured in the process model). The contributions of this paper include an experimentally derived recommendation for logging practices on ICS devices, for the purpose of process mining-based analysis; a formalised approach for pre-processing and transforming device logs from ICS systems into event logs suitable for process mining analysis; guidance on how to create a process model for ICSs and how to apply the created process model through a conformance checking analysis to identify anomalous behaviours. Our anomaly detection method has been successfully applied in detecting ICS cyber-attacks, which the widely used IDS Snort does not detect, using logs derived from industry standard ICS devices. © 2018 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85049593755
"Bose R.P.J.C., Verbeek E.H.M.W., Van Der Aalst W.M.P.","Discovering hierarchical process models using ProM",2012,"Lecture Notes in Business Information Processing",31,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861114192&doi=10.1007%2f978-3-642-29749-6_3&partnerID=40&md5=02b20735aebf2647d8dec50eb333c4d8","Process models can be seen as ""maps"" describing the operational processes of organizations. Traditional process discovery algorithms have problems dealing with fine-grained event logs and less-structured processes. The discovered models (i.e., ""maps"") are spaghetti-like and are difficult to comprehend or even misleading. One of the reasons for this can be attributed to the fact that the discovered models are flat (without any hierarchy). In this paper, we demonstrate the discovery of hierarchical process models using a set of interrelated plugins implemented in ProM. The hierarchy is enabled through the automated discovery of abstractions (of activities) with domain significance. © 2012 Springer-Verlag.",Conference Paper,"Final",Scopus,2-s2.0-84861114192
"Broniatowski D.A., Dredze M., Paul M.J., Dugas A.","Using social media to perform local influenza surveillance in an inner-city hospital: A retrospective observational study",2015,"JMIR Public Health and Surveillance",29,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014799325&doi=10.2196%2fpublichealth.4472&partnerID=40&md5=2adf7f88728f33d551e4f7156527b480","Background: Public health officials and policy makers in the United States expend significant resources at the national, state, county, and city levels to measure the rate of influenza infection. These individuals rely on influenza infection rate information to make important decisions during the course of an influenza season driving vaccination campaigns, clinical guidelines, and medical staffing. Web and social media data sources have emerged as attractive alternatives to supplement existing practices. While traditional surveillance methods take 1-2 weeks, and significant labor, to produce an infection estimate in each locale, web and social media data are available in near real-time for a broad range of locations. Objective: The objective of this study was to analyze the efficacy of flu surveillance from combining data from the websites Google Flu Trends and HealthTweets at the local level. We considered both emergency department influenza-like illness cases and laboratory-confirmed influenza cases for a single hospital in the City of Baltimore. Methods: This was a retrospective observational study comparing estimates of influenza activity of Google Flu Trends and Twitter to actual counts of individuals with laboratory-confirmed influenza, and counts of individuals presenting to the emergency department with influenza-like illness cases. Data were collected from November 20, 2011 through March 16, 2014. Each parameter was evaluated on the municipal, regional, and national scale. We examined the utility of social media data for tracking actual influenza infection at the municipal, state, and national levels. Specifically, we compared the efficacy of Twitter and Google Flu Trends data. Results: We found that municipal-level Twitter data was more effective than regional and national data when tracking actual influenza infection rates in a Baltimore inner-city hospital. When combined, national-level Twitter and Google Flu Trends data outperformed each data source individually. In addition, influenza-like illness data at all levels of geographic granularity were best predicted by national Google Flu Trends data. Conclusions: In order to overcome sensitivity to transient events, such as the news cycle, the best-fitting Google Flu Trends model relies on a 4-week moving average, suggesting that it may also be sacrificing sensitivity to transient fluctuations in influenza infection to achieve predictive power. Implications for influenza forecasting are discussed in this report. © JMIR Publications Inc. All rights reserved.",Article,"Final",Scopus,2-s2.0-85014799325
"Ma Z., Ren Y., Xiang X., Turk Z.","Data-driven decision-making for equipment maintenance",2020,"Automation in Construction",25,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078422258&doi=10.1016%2fj.autcon.2020.103103&partnerID=40&md5=b342f39dfafe0659f0b55d470f9a893e","Industrial parks, science parks, university campuses, tourist complexes are springing up greatly in developing countries. Decision-making on equipment maintenance of these areas where facilities intensively locate differs from that of industrial systems or plants in two features: 1) it needs regular repetition and update because equipment replacements, facility renovations and equipment condition changes often happen during the operation phase, 2) the accumulated maintenance data in these areas are large enough to be used for decision-making. However, existing approaches to decision-making on equipment maintenance have not considered such features. To fill this gap, this research aims to propose a data-driven approach for decision-making on equipment maintenance by integrating three technologies: Reliability Centered Maintenance (RCM), Building Information Modeling (BIM) and Geographic Information System (GIS). By implementing quantitative decision-making models and Monte-Carlo simulation, a data-driven RCM process is proposed. BIM and GIS are integrated to support the acquisition and update of data required for the proposed RCM process. Based on requirement analysis and architecture design, a prototype system is developed and verified by using a virtual campus. The results show that the proposed approach reduces labor cost and diminishes difficulties of decision-making on equipment maintenance. This paper contributes to the body of knowledge in that it provides an objective approach for the decision-making on equipment maintenance. For future improvements, the approach is compatible with the Internet of Things (IoT) technology to support more efficient data acquisition as a basis for decision-making on maintenance. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85078422258
"Erdogan T.G., Tarhan A.","A goal-driven evaluation method based on process mining for healthcare processes",2018,"Applied Sciences (Switzerland)",21,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047805465&doi=10.3390%2fapp8060894&partnerID=40&md5=2c248a9cee8a4ecd0067c3cb2e5164b2","As a business processes management technique, process mining (PM) has been applied in many domains in the last decade. In healthcare, where most processes are complex, variable, dynamic, and multi-disciplinary in nature, application of this technique is growing, yet challenging. Therefore, this study aims to introduce a goal-driven process evaluation method based on PM for healthcare processes. The proposed method comprises the following steps: defining goals and questions, data extraction, data preprocessing, log and pattern inspection, PM analysis and generating answers to questions, evaluating results, and initiating proposals for process improvements. The proposed method was applied in a case study on the surgery process of a university hospital in Turkey, which revealed for quantitative insights into the process. Bottlenecks and deviations that were crucial for determining measures (e.g., data and performance information) were identified to improve the efficiency of the surgery process. Our initial experience using the proposed method shows that it has potential for initiating process improvements by guiding the use of PM techniques in the healthcare domain. © 2018 by the authors.",Article,"Final",Scopus,2-s2.0-85047805465
"Pan Y., Zhang L.","BIM log mining: Learning and predicting design commands",2020,"Automation in Construction",20,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079126973&doi=10.1016%2fj.autcon.2020.103107&partnerID=40&md5=ad55b5c74c6a6a244f7172926a6ae9b1","This paper develops a framework to learn and predict design commands based upon building information modeling (BIM) event log data stored in Autodesk Revit journal files, which has the potential to improve the modeling efficiency. BIM design logs, which automatically keep detailed records on the modeling process, are the basis of data acquisition and data mining. Long Short-Term Memory Neural Network (LSTM NN), as a probabilistic deep learning model for learning sequential data with varying lengths from logs, is established to provide designers with predictions about the possible design command class in the next step. To demonstrate the feasibility of this method, a case study runs at large design logs over 4 GB from an international design firm for command class prediction. To begin with, useful data retrieved from logs is cleaned and saved in a 320 MB Comma Separated Values (CSV) file with totally 352,056 lines of commands over 289 projects. Subsequently, various design commands are categorized into 14 classes according to their effects and given numerical labels, which are then fed into LSTM NN for training and testing. As a result, the overall accuracy of this particular case study can reach 70.5% in the test set, which outperforms some classical machine learning methods, like k nearest neighbor, random forest and support vector machine. This research contributes to applying a probabilistic LSTM NN with optimal parameters to learn features from designers' subjective behaviors effectively and predict the next possible design command class intelligently towards automation of the design process. Moreover, the three most possible command classes will be offered as the recommendations under the assumption that the correct class tends to appear owning the top three highest probabilities, which can possibly enhance the reliability of predictions. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85079126973
"Stojanovic V., Trapp M., Richter R., Hagedorn B., Döllner J.","Towards the generation of digital twins for facility management based on 3D point clouds",2018,"Proceeding of the 34th Annual ARCOM Conference, ARCOM 2018",20,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054529484&partnerID=40&md5=362878d63e18bee90afc8761c9203163","Advances versus adaptation of Industry 4.0 practices in Facility Management (FM) have created usage demand for up-to-date digitized building assets. The use of Building Information Modelling (BIM) for FM in the Operation and Maintenance (O&M) stages of the building lifecycle is intended to bridge the gap between operations and digital data, but lacks the functionality of assessing and forecasting the state of the built environment in real-time. To accommodate this, BIM data needs to be constantly updated with the current state of the built environment. However, generation of as-is BIM data for a digital representation of a building is a labor intensive process. While some software applications offer a degree of automation for the generation of as-is BIM data, they can be impractical to use for routinely updating digital FM documentation. Current approaches for capturing the built environment using remote sensing and photometry-based methods allow for the creation of 3D point clouds that can be used as basis data for a Digital Twin (DT), along with existing BIM and FM documentation. 3D point clouds themselves do not contain any semantics or specific information about the building components they represent physically, but using machine learning methods they can be enhanced with semantics that would allow for reconstruction of as-is BIM and basis DT data. This paper presents current research and development progress of a service-oriented platform for generation of semantically rich 3D point cloud representations of indoor environments. A specific focus is placed on the reconstruction and visualization of the captured state of the built environment for increasing FM stakeholder engagement and facilitating collaboration. The preliminary results of a prototypical web-based application demonstrate the feasibility of such a platform for FM using a service-oriented paradigm. © Proceeding of the 34th Annual ARCOM Conference, ARCOM 2018.",Conference Paper,"Final",Scopus,2-s2.0-85054529484
"Ding L., Xu X.","Application of cloud storage on BIM life-cycle management",2014,"International Journal of Advanced Robotic Systems",20,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923317192&doi=10.5772%2f58443&partnerID=40&md5=006a236fbbdfe984665b099ac4d7a423","Because of its high information intensity, strong consistency and convenient visualization features, building information modelling (BIM) has received widespread attention in the fields of construction and project management. However, due to large amounts of information, high integration, the need for resource sharing between various departments, the long time-span of the BIM application, challenges relating to data interoperability, security and cost all slow down the adoption of BIM. This paper constructs a BIM cloud storage concept system using cloud storage, an advanced computer technology, to solve the problem of mass data processing, information security, and cost problems in the existing application of BIM to full life-cycle management. This system takes full advantage of the cloud storage technique. Achievements are reached in four areas of BIM information management, involving security and licensing management, file management, work process management and collaborative management. The system expands the time and space scales, improves the level of participation, and reduces the cost of BIM. The construction of the BIM cloud storage system is one of the most important directions of the development of BIM, which benefits the promotion and further development of BIM to better serve construction and engineering project management. © 2014 The Author(s).",Article,"Final",Scopus,2-s2.0-84923317192
"Yahya B.N., Song M., Bae H., Sul S.-O., Wu J.-Z.","Domain-driven actionable process model discovery",2016,"Computers and Industrial Engineering",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973597833&doi=10.1016%2fj.cie.2016.05.010&partnerID=40&md5=a6cd5b971d84e44cf801528d61cb423e","Process discovery is a type of process mining that constructs a process model from the event logs of an information system. The model discovered using process discovery techniques and the process as perceived by users will always differ in some ways and to some extents. In particular, less structured process, such as operational process in business and manufacturing, often result overly confusing, spaghetti-like, process models caused by the inherent complexity of the process. As a result, the mined model has many limitations for providing the users with explicit knowledge that can be directly used to influence behavior for the user's interest. Explicit knowledge, as later called by actionable knowledge, is an important representation on measuring the interestingness of mined patterns. This actionable knowledge, which is incorporated with users’ background knowledge and based on some notions of actionable rules, can result an actionable process model. Undoubtedly, domain experts, who know the process well, play a key role to enhance the mined model into an actionable model by their involvements during the discovery process. This paper presents a discovery method to obtain an actionable process model that is based on both the event relation in the log and users’ knowledge to improve the incompatibility of the traditional process mining approaches. Users can set their knowledge in terms of constraints. Unlike the existing approach, the proposed approach synthesizes the activity proximity and attempts to extract behavior satisfied by the constraints which may be hidden in the event logs for resulting an actionable process model. In addition, the proposed method is used in order to achieve a sound process model when the existence of the constraints does not satisfy the workflow soundness property. The method was implemented in the ProM framework and tested on a real process. © 2016 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-84973597833
"Pan Y., Zhang L.","BIM log mining: Exploring design productivity characteristics",2020,"Automation in Construction",15,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074657553&doi=10.1016%2fj.autcon.2019.102997&partnerID=40&md5=358c8c269860a09acc76a189078a1801","A clustering-based building information modeling (BIM) log mining method is developed in this research to provide a data-driven knowledge discovery about the design productivity characteristics from a huge amount of BIM design log data. Since design behaviors are non-deterministic and subjective, a novel clustering algorithm named efficient fuzzy Kohonen clustering network (EFKCN) is utilized to produce informative clusters of different features. First, datasets are pulled out from the raw design logs and transformed into understandable forms for computers. Then, EFKCN clustering algorithm is performed in datasets at both individual and team level. Finally, analysis and prediction methods, like time analysis, regression and others, will further investigate the extracted clusters, which help managers to figure out the design preference and productivity of different designers. A case study is conducted in the real BIM design logs from an international architecture design firm with 853,520 records to illustrate the effectiveness of the proposed method. From a view of individuals, the personal design behaviors hidden in different clusters are served to arrange proper design work rationally during particular time periods. From a team perspective, the design productivity of different designers can be approximately evaluated as high, medium, and low levels in an objective and efficient manner. In the comparison of EFKCN with other popular clustering methods, EFKCN takes less time and iterations to complete the clustering process, and its clustering results achieve great compactness and separation according to the value of cluster validity indices (CVIs). Hence, this research contributes to performing the novel clustering-based BIM log mining, which acts as a powerful decision-making tool in evaluating design productivity and drawing up personalized work arrangements for a more efficient modeling process. © 2019 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85074657553
"Kouhestani S., Nik-Bakht M.","IFC-based process mining for design authoring",2020,"Automation in Construction",13,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077803423&doi=10.1016%2fj.autcon.2019.103069&partnerID=40&md5=561947d0af20d909f1ad8be490f98844","Building Information Modelling (BIM) is defined as the process of creation and management of digital replica for building products in a collaborative design set-up. On this basis, BIM as a digital collaboration platform in AECO (Architecture, Engineering, Construction, and Operation) industry, can be upgraded to assist monitoring, control and improvement of the business processes related to planning, design, construction and operation of building facilities. The main problem in this regard, is the wastage of data related to activities completed by different actors during the project; and subsequently, the lack of analytics to discover latent patterns in collaboration and execution of such processes. The present study aims to enable BIM to capture digital footprints of project actors and create event logs for design authoring phase of building projects. This is done using files in IFC (Industry Foundation Classes) format, archived during the design process. We have developed algorithms to create event logs from such archives, and analyzed the event logs using process mining (i.e. process discovery, conformance checking and bottleneck analysis), to identify measures derived from as-happened processes. BIM managers can implement such measures in monitoring, controlling and re-engineering work processes related to design authoring. Two case studies were completed to validate and verify the products and findings of the research. Our results show that process models discovered/fine-tuned at various resolutions and from different perspectives (including ‘actor-centric’ and ‘phase-centric’ views) can provide a realistic view of the BIM project execution. This includes understanding the structure of collaboration and hand-over of work; evaluation of compliance with the BIM execution plan; and detection of bottlenecks and re-works. While the scope of the study has been limited to design authoring processes, this mindset can be extended to other BIM uses, and other phases (such as construction and operation) of building projects. Given the growing efforts on upgrading BIM to capture and formalize the lifecycle data on the products, processes and actors, this study can strongly support BIM managers with documentation and evaluation of the business processes and workflows in their project teams. © 2019",Article,"Final",Scopus,2-s2.0-85077803423
"Pan Y., Zhang L., Skibniewski M.J.","Clustering of designers based on building information modeling event logs",2020,"Computer-Aided Civil and Infrastructure Engineering",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083789150&doi=10.1111%2fmice.12551&partnerID=40&md5=d49e99f21ab8efcf8bb3542c0a7a22cb","A network-enabled event log mining approach is proposed for a deep understanding of the Building Information Modeling (BIM)-based collaborative design work. It proposes a novel algorithm termed node2vec-GMM combining a graph embedding algorithm named node2vec and a clustering method named Gaussian mixture model (GMM) to cluster designers within a network into several subgroups, and then makes cluster analysis. Its superiority lies in the efficient feature learning ability to preserve network structure and the powerful clustering ability to tackle uncertainty and visualize results, which can directly return the cluster embedding. As a case study, a directional network with 68 nodes (designers) and 436 ties (design task transmissions) is constructed based on retrieved data from 4GB real BIM event logs. The node2vec learns and projects the network feature representation into a 128-dimensional vector, which is learned by GMM to discover three possible clusters owning 15, 26, and 27 closely linked designers. Analysis of each cluster is performed from node importance measurement and link prediction to identify information spreading and designers’ roles within clusters. Our new algorithm node2vec-GMM is proven to better improve clustering quality than other state-of-the-art methods by at least 6.0% Adjusted Rand Index and 13.4% Adjusted Mutual Information. Overall, the designer clustering process provides managers with data-driven support in both monitoring the whole course of the BIM-based design and making reliable decisions to increase collaboration opportunities. © 2020 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85083789150
"Srewil Y., Scherer R.J.","Effective construction process monitoring and control through a collaborative cyber-physical approach",2013,"IFIP Advances in Information and Communication Technology",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897769715&doi=10.1007%2f978-3-642-40543-3_19&partnerID=40&md5=e66f667a5241d4a9d58a2c183ca9a6ef","The objectives of this research are: monitoring of project progress during execution, assessment project health on demand, to identify and make timely recommendations for corrective action in response to anticipated schedule delays. Implementation of this information in flexible process modeling approaches, like process configuration method enhances an alternative process planning. The paper proposes a solution in collaboration with cyber-physical system CPS based on RFID technology to minimize manual inputs and enhance data acquisition. Furthermore, it enables planers anticipating and identifying schedule delays and exceptions early or even before they happen. Analysis of the real-time data collected on site and actual vs. scheduled deviation will be transformed into a meaningful classification. This paper presents a comprehensive solution to integrate the outcomes of analysis real-time data into a knowledge base for updating the entire progress, handling exceptions and supporting efficient process alternative modeling. © IFIP International Federation for Information Processing 2013.",Conference Paper,"Final",Scopus,2-s2.0-84897769715
"Linares D.A., Anumba C., Roofigari-Esfahan N.","Overview of Supporting Technologies for Cyber-Physical Systems Implementation in the AEC Industry",2019,"Computing in Civil Engineering 2019: Data, Sensing, and Analytics - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2019",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087375813&partnerID=40&md5=11a256605147f7694b6ed676c1be3558","The development of cyber-physical systems (CPSs) is an essential milestone in advancing operations in many industries including the architecture, engineering, and construction (AEC). Its development is supported by technological advancements that align with the CPSs goals of automation and intelligent interaction between cyber and physical spaces. This study focuses on the evaluation of the supporting technologies for CPSs in AEC projects. To this end, a holistic review of industry and academic literature is carried out and then, the technologies are evaluated in terms of their level of implementation and application thorough the project lifecycle for horizontal and vertical project scenarios. Finally, a categorization was made to present the interrelations between the technologies to provide new insight into future research into CPS applications in the AEC industry. © 2019 American Society of Civil Engineers.",Conference Paper,"Final",Scopus,2-s2.0-85087375813
"Pan Y., Zhang L., Li Z.","Mining event logs for knowledge discovery based on adaptive efficient fuzzy Kohonen clustering network",2020,"Knowledge-Based Systems",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092044717&doi=10.1016%2fj.knosys.2020.106482&partnerID=40&md5=8be795b3d9777773e3e164a1e9aaf629","As a digital representation of building projects, Building Information Modeling (BIM) can accumulate large volumes of log data containing hidden knowledge for deep exploration. However, such ever-increasing logs are likely to suffer from high complexity, inaccuracy, and uncertainty, which will inevitably raise challenges in uncovering latent and meaningful patterns. In order to yield satisfactory clustering quality and efficiency for better design process management, a novel clustering-based BIM event log mining approach is put forward in this paper. For one thing, a hybrid clustering algorithm named adaptive efficient fuzzy Kohonen clustering network (AEFKCN) is developed with a modified learning rate to accelerate the convergence. For another, a new clustering validity index (CVI) only relying on boundary points is designed to reduce computational complexity. An experiment is conducted in a 4 GB realistic BIM design event log dataset to validate the effectiveness of the proposed method. It begins from extracting a set of features associated with designers’ engagement and efficiency and ends up retrieving inherent insights into the person's design behavioral patterns. Moreover, the cluster analysis can significantly distinguish the design productivity at different time periods into the high, medium, and low level, which presents a unique opportunity in understanding and assessing design productivity objectively. Practically, our method can support data-driven decision making for managers to strategically schedule personalized work for different designers, aiming to boost design efficiency and smooth the design process. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85092044717
"van Schaijk S.","Building Information Model (BIM) Based Process Mining Enabling Knowledge Reassurance and Fact-Based Problem Discovery within the Architecture, Engineering, Construction and Facility Management Industry, Master Construction Management and Engineering",2016,,2,,[No abstract available],,"Final",Scopus,2-s2.0-85100081529
