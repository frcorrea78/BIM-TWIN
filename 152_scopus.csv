Authors,Title,Year,Source title,Cited by,Link,Abstract,Document Type,Publication Stage,Source,EID
"Krizhevsky A., Sutskever I., Hinton G.E.","ImageNet classification with deep convolutional neural networks",2012,"Advances in Neural Information Processing Systems",57043,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876231242&partnerID=40&md5=621b2cd1757ccc77341281f8a2f2ecaf","We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called ""dropout"" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.",Conference Paper,"Final",Scopus,2-s2.0-84876231242
"Breiman L.","Random forests",2001,"Machine Learning",53290,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035478854&doi=10.1023%2fA%3a1010933404324&partnerID=40&md5=4b9f43897146098c0df3a2af232cf2f4","Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, * * *, 148-156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.",Article,"Final",Scopus,2-s2.0-0035478854
"Hastie T., Tibshirani R., Friedman J.",[No title available],2001,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction",34709,,[No abstract available],,,Scopus,2-s2.0-0003684449
"Cortes C., Vapnik V.","Support-Vector Networks",1995,"Machine Learning",31907,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249753618&doi=10.1023%2fA%3a1022627411411&partnerID=40&md5=97a8591c7d55575e8c48344379ee2796","The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data. High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition. © 1995, Kluwer Academic Publishers. All rights reserved.",Article,"Final",Scopus,2-s2.0-34249753618
"Bishop C.M.",[No title available],2006,"Pattern Recognition and Machine Learning",29014,,[No abstract available],,"Final",Scopus,2-s2.0-33846516584
"Srivastava N., Hinton G., Krizhevsky A., Sutskever I., Salakhutdinov R.","Dropout: A simple way to prevent neural networks from overfitting",2014,"Journal of Machine Learning Research",19075,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904163933&partnerID=40&md5=b865fd654b3befc5d829dbe5d42b80c3","Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different ""thinned"" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets. © 2014 Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever and Ruslan Salakhutdinov.",Article,"Final",Scopus,2-s2.0-84904163933
"Fischler M.A., Bolles R.C.","Random sample consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography",1981,"Communications of the ACM",16385,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0019574599&doi=10.1145%2f358669.358692&partnerID=40&md5=723688ad3a3685cd1b335a0ef3882605","A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing. © 1981, ACM. All rights reserved.",Article,"Final",Scopus,2-s2.0-0019574599
"Besl P.J., McKay N.D.","A Method for Registration of 3-D Shapes",1992,"IEEE Transactions on Pattern Analysis and Machine Intelligence",12199,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026821209&doi=10.1109%2f34.121791&partnerID=40&md5=ee06231fbe1dba306ad906353ec3701d","This paper describes a general-purpose, representation-independent method for the accurate and computationally efficient registration of 3-D shapes including free-form curves and surfaces. The method handles the full six degrees of freedom and is based on the iterative closest point (ICP) algorithm, which requires only a procedure to find the closest point on a geometric entity to a given point. The ICP algorithm always converges monotonically to the nearest local minimum of a mean-square distance metric, and experience shows that the rate of convergence is rapid during the first few iterations. Therefore, given an adequate set of initial rotations and translations for a particular class of objects with a certain level of “shape complexity,” one can globally minimize the mean-square distance metric over all six degrees of freedom by testing each initial registration. For example, a given “model” shape and a sensed “data” shape that represents a major portion of the model shape can be registered in minutes by testing one initial translation and a relatively small set of rotations to allow for the given level of model complexity. One important application of this method is to register sensed data from unfixtured rigid objects with an ideal geometric model prior to shape inspection. The described method is also useful for deciding fundamental issues such as the congruence (shape equivalence) of different geometric representations as well as for estimating the motion between point sets where the correspondences are not known. Experimental results show the capabilities of the registration algorithm on point sets, curves, and surfaces. © 1992 IEEE",Article,"Final",Scopus,2-s2.0-0026821209
"Freund Y., Schapire R.E.","A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting",1997,"Journal of Computer and System Sciences",9305,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031211090&doi=10.1006%2fjcss.1997.1504&partnerID=40&md5=996d0921b2d1f1002b5593aaee472b2e","In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone-Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in ℝn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line. © 1997 Academic Press.",Article,"Final",Scopus,2-s2.0-0031211090
"Lafferty J., McCallum A., Pereira F.","Conditional random fields: Probabilistic models for segmenting and labeling sequence data",2001,"Proc. 18th International Conf. on Machine Learning",8883,,[No abstract available],,,Scopus,2-s2.0-0142192295
"James G., Witten D., Hastie T., Tibshirani R.","An Introduction to Statistical Learning",2013,"An Introduction to Statistical Learning with Applications in R",6380,,[No abstract available],,"Final",Scopus,2-s2.0-84893874008
"Freund Y., Schapire R.E.","Experiments with a new boosting algorithm",1996,"Proceedings of the Thirteenth International Conference on Machine Learning",5835,,[No abstract available],,,Scopus,2-s2.0-0002978642
"Murphy K.P.",[No title available],2012,"Machine Learning: A Probabilistic Perspective",5357,,[No abstract available],,"Final",Scopus,2-s2.0-84857466151
"Zitová B., Flusser J.","Image registration methods: A survey",2003,"Image and Vision Computing",5246,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0043237770&doi=10.1016%2fS0262-8856%2803%2900137-9&partnerID=40&md5=1896e5bba2ee4fa60f306a2b30c77d97","This paper aims to present a review of recent as well as classic image registration methods. Image registration is the process of overlaying images (two or more) of the same scene taken at different times, from different viewpoints, and/or by different sensors. The registration geometrically align two images (the reference and sensed images). The reviewed approaches are classified according to their nature (area-based and feature-based) and according to four basic steps of image registration procedure: feature detection, feature matching, mapping function design, and image transformation and resampling. Main contributions, advantages, and drawbacks of the methods are mentioned in the paper. Problematic issues of image registration and outlook for the future research are discussed too. The major goal of the paper is to provide a comprehensive reference source for the researchers involved in image registration, regardless of particular application areas. © 2003 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-0043237770
"LeCun Y., Boser B., Denker J.S., Henderson D., Howard R.E., Hubbard W., Jackel L.D.","Backpropagation applied to handwritten zip code recognition",1989,"Neural Computation",5201,,[No abstract available],,,Scopus,2-s2.0-0000359337
"Sivic J., Zisserman A.","Video google: A text retrieval approach to object matching in videos",2003,"Proceedings of the IEEE International Conference on Computer Vision",5134,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0345414182&doi=10.1109%2ficcv.2003.1238663&partnerID=40&md5=7651e33e8959ec7e1d959362f33522cb","We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors. The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vector quantization), and inverted file systems and document rankings are used. The result is that retrieval is immediate, returning a ranked list of key frames/shots in the manner of Google. The method is illustrated for matching on two full length feature films.",Conference Paper,"Final",Scopus,2-s2.0-0345414182
"Hsu C.-W., Chang C.-C., Lin C.-J.","A practical guide to support vector classification",2003,"A Practical Guide to Support Vector Classification",4938,,[No abstract available],,,Scopus,2-s2.0-4944228528
"Duda R.O., Hart P.E.","Use of the Hough Transformation to Detect Lines and Curves in Pictures",1972,"Communications of the ACM",4709,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0015285440&doi=10.1145%2f361237.361242&partnerID=40&md5=0105a40397590837fe52eee4ac4a80fd","Hough has proposed an interesting and computationally efficient procedure for detecting lines in pictures. This paper points out that the use of angle-radius rather than slope-intercept parameters simplifies the computation further. It also shows how the method can be used for more general curve fitting, and gives alternative interpretations that explain the source of its efficiency. © 1972, ACM. All rights reserved.",Article,"Final",Scopus,2-s2.0-0015285440
"Hotelling H.","Analysis of a complex of statistical variables into principal components",1933,"Journal of Educational Psychology",4605,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-58149421595&doi=10.1037%2fh0071325&partnerID=40&md5=f86eda8f44cd231d65fd3f9d9c5a3ed8","The problem is stated in detail, a method of analysis is derived and its geometrical meaning shown, methods of solution are illustrated and certain derivative problems are discussed. (To be concluded in October issue.) (PsycINFO Database Record (c) 2006 APA, all rights reserved). © 1933 American Psychological Association.",Article,"Final",Scopus,2-s2.0-58149421595
"Bentley J.L.","Multidimensional Binary Search Trees Used for Associative Searching",1975,"Communications of the ACM",4278,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0016557674&doi=10.1145%2f361002.361007&partnerID=40&md5=53c42d0c268454a4eb75b99b632cddd5","This paper develops the multidimensional binary search tree (or k-d tree, where k is the dimensionality of the search space) as a data structure for storage of information to be retrieved by associative searches. The k-d tree is defined and examples are given. It is shown to be quite efficient in its storage requirements. A significant advantage of this structure is that a single data structure can handle many types of queries very efficiently. Various utility algorithms are developed; their proven average running times in an n record file are: insertion, O(log n); deletion of the root, O(n(k-1)/k); deletion of a random node, O(log n); and optimization (guarantees logarithmic performance of searches), O(n log n). Search algorithms are given for partial match queries with t keys specified [proven maximum running time of O(n(k-t)/k)] and for nearest neighbor queries [empirically observed average running time of O(log n).] These performances far surpass the best currently known algorithms for these tasks. An algorithm is presented to handle any general intersection query. The main focus of this paper is theoretical. It is felt, however, that k-d trees could be quite useful in many applications, and examples of potential uses are given. © 1975, ACM. All rights reserved.",Article,"Final",Scopus,2-s2.0-0016557674
"Qi C.R., Su H., Mo K., Guibas L.J.","PointNet: Deep learning on point sets for 3D classification and segmentation",2017,"Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017",3556,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043534104&doi=10.1109%2fCVPR.2017.16&partnerID=40&md5=e11897ee95a057bbc78aef23d420f926","Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85043534104
"Bates D.M., Watts D.G.",[No title available],1988,"Nonlinear Regression Analysis and Its Applications",3252,,[No abstract available],,"Final",Scopus,2-s2.0-0003456815
"Do Carmo M.P.",[No title available],1976,"Differential Geometry of Curves and Surfaces",3189,,[No abstract available],,,Scopus,2-s2.0-0003533718
"Powers D.M.W.","Evaluation: From precision, recall and F-measure to ROC, informedness, markedness & correlation",2011,"Journal of Machine Learning Technologies",3123,,[No abstract available],,"Final",Scopus,2-s2.0-84864758525
"Eastman C.M., Teicholz P., Sacks R., Liston K.",[No title available],2008,"BIM Handbook: A Guide to Building Information Modeling for Owners, Managers, Architects, Engineers, Contractors, and Fabricators",3033,,[No abstract available],,"Final",Scopus,2-s2.0-38649094993
"Rusinkiewicz S., Levoy M.","Efficient variants of the ICP algorithm",2001,"Proceedings of International Conference on 3-D Digital Imaging and Modeling, 3DIM",2978,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949236475&doi=10.1109%2fIM.2001.924423&partnerID=40&md5=8ce35ec134f1ca6df34433ed583897fd","The ICP (Iterative Closest Point) algorithm is widely used for geometric alignment of three-dimensional models when an initial estimate of the relative pose is known. Many variants of ICP have been proposed, affecting all phases of the algorithm from the selection and matching of points to the minimization strategy. We enumerate and classify many of these variants, and evaluate their effect on the speed with which the correct alignment is reached. In order to improve convergence for nearly-flat meshes with small features, such as inscribed surfaces, we introduce a new variant based on uniform sampling of the space of normals. We conclude by proposing a combination of ICP variants optimized for high speed. We demonstrate an implementation that is able to align two range images in a few tens of milliseconds, assuming a good initial guess. This capability has potential application to real-time 3D model acquisition and model-based tracking.",Article,"Final",Scopus,2-s2.0-84949236475
"Sokolova M., Lapalme G.","A systematic analysis of performance measures for classification tasks",2009,"Information Processing and Management",2554,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-65649138430&doi=10.1016%2fj.ipm.2009.03.002&partnerID=40&md5=3a9ff121deadfac8c95683fa0a8e179c","This paper presents a systematic analysis of twenty four performance measures used in the complete spectrum of Machine Learning classification tasks, i.e., binary, multi-class, multi-labelled, and hierarchical. For each classification task, the study relates a set of changes in a confusion matrix to specific characteristics of data. Then the analysis concentrates on the type of changes to a confusion matrix that do not change a measure, therefore, preserve a classifier's evaluation (measure invariance). The result is the measure invariance taxonomy with respect to all relevant label distribution changes in a classification problem. This formal analysis is supported by examples of applications where invariance properties of measures lead to a more reliable evaluation of classifiers. Text classification supplements the discussion with several case studies. © 2009 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-65649138430
"Penrose R.","A generalized inverse for matrices",1955,"Mathematical Proceedings of the Cambridge Philosophical Society",2537,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947145047&doi=10.1017%2fS0305004100030401&partnerID=40&md5=372ca7631b4522136ca565146d8e839e",[No abstract available],Article,"Final",Scopus,2-s2.0-84947145047
"Liu Z., Luo P., Wang X., Tang X.","Deep learning face attributes in the wild",2015,"Proceedings of the IEEE International Conference on Computer Vision",2499,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973917446&doi=10.1109%2fICCV.2015.425&partnerID=40&md5=1da67f13acf28106db916aa791f0012d","Predicting face attributes in the wild is challenging due to complex face variations. We propose a novel deep learning framework for attribute prediction in the wild. It cascades two CNNs, LNet and ANet, which are fine-tuned jointly with attribute tags, but pre-trained differently. LNet is pre-trained by massive general object categories for face localization, while ANet is pre-trained by massive face identities for attribute prediction. This framework not only outperforms the state-of-the-art with a large margin, but also reveals valuable facts on learning face representation. (1) It shows how the performances of face localization (LNet) and attribute prediction (ANet) can be improved by different pre-training strategies. (2) It reveals that although the filters of LNet are fine-tuned only with image-level attribute tags, their response maps over entire images have strong indication of face locations. This fact enables training LNet for face localization with only image-level annotations, but without face bounding boxes or landmarks, which are required by all attribute recognition works. (3) It also demonstrates that the high-level hidden neurons of ANet automatically discover semantic concepts after pre-training with massive face identities, and such concepts are significantly enriched after fine-tuning with attribute tags. Each attribute can be well explained with a sparse linear combination of these concepts. © 2015 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84973917446
"Wu Z., Song S., Khosla A., Yu F., Zhang L., Tang X., Xiao J.","3D ShapeNets: A deep representation for volumetric shapes",2015,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",2145,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949636429&doi=10.1109%2fCVPR.2015.7298801&partnerID=40&md5=f392b391514f80d1ea917474d1f68f5d","3D shape is a crucial but heavily underutilized cue in today's computer vision systems, mostly due to the lack of a good generic shape representation. With the recent availability of inexpensive 2.5D depth sensors (e.g. Microsoft Kinect), it is becoming increasingly important to have a powerful 3D shape representation in the loop. Apart from category recognition, recovering full 3D shapes from view-based 2.5D depth maps is also a critical part of visual understanding. To this end, we propose to represent a geometric 3D shape as a probability distribution of binary variables on a 3D voxel grid, using a Convolutional Deep Belief Network. Our model, 3D ShapeNets, learns the distribution of complex 3D shapes across different object categories and arbitrary poses from raw CAD data, and discovers hierarchical compositional part representation automatically. It naturally supports joint object recognition and shape completion from 2.5D depth maps, and it enables active object recognition through view planning. To train our 3D deep learning model, we construct ModelNet - a large-scale 3D CAD model dataset. Extensive experiments show that our 3D deep representation enables significant performance improvement over the-state-of-the-arts in a variety of tasks. © 2015 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84949636429
"Hoppe Hugues, DeRose Tony, Duchamp Tom, McDonald John, Stuetzle Werner","Surface reconstruction from unorganized points",1992,"Computer Graphics (ACM)",2068,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026888013&doi=10.1145%2f142920.134011&partnerID=40&md5=eb79072c6bfc5a01dd3221f17830486d","We describe and demonstrate an algorithm that takes as input an unorganized set of points {X1,...,nRTBC ⊂ IR3 on or near an unknown manifold M, and produces as output a simplicial surface that approximates M. Neither the topology, the presence of boundaries, nor the geometry of M are assumed to be known in advance - all are inferred automatically from the data. This problem naturally arises in a variety of practical situations such as range scanning an object from multiple view points, recovery of biological shapes from two-dimensional slices, and interactive surface sketching.",Article,"Final",Scopus,2-s2.0-0026888013
"Johnson A.E., Hebert M.","Using spin images for efficient object recognition in cluttered 3D scenes",1999,"IEEE Transactions on Pattern Analysis and Machine Intelligence",1999,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032685832&doi=10.1109%2f34.765655&partnerID=40&md5=acb786bc1f53799667a428a52d524052","We present a 3D shape-based object recognition system for simultaneous recognition of multiple objects in scenes containing clutter and occlusion. Recognition is based on matching surfaces by matching points using the spin image representation. The spin image is a data level shape descriptor that is used to match surfaces represented as surface meshes. We present a compression scheme for spin images that results in efficient multiple object recognition which we verify with results showing the simultaneous recognition of multiple objects from a library of 20 models. Furthermore, we demonstrate the robust performance of recognition in the presence of clutter and occlusion through analysis of recognition trials on 100 scenes.",Article,"Final",Scopus,2-s2.0-0032685832
"Yang C., Medioni G.","Object modelling by registration of multiple range images",1992,"Image and Vision Computing",1991,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-44049122968&doi=10.1016%2f0262-8856%2892%2990066-C&partnerID=40&md5=61be7968c009cd57950b74296200b88a","We study the problem of creating a complete model of a physical object. Although this may be possible using intensity images, we here use images which directly provide access to three dimensional information. The first problem that we need to solve is to find the transformation between the different views. Previous approaches either assume this transformation to be known (which is extremely difficult for a complete model), or compute it with feature matching (which is not accurate enough for integration). In this paper, we propose a new approach which works on range data directly and registers successive views with enough overlapping area to get an accurate transformation between views. This is performed by minimizing a functional which does not require point-to-point matches. We give the details of the registration method and modelling procedure and illustrate them on real range images of complex objects. © 1992.",Article,"Final",Scopus,2-s2.0-44049122968
"Silberman N., Hoiem D., Kohli P., Fergus R.","Indoor segmentation and support inference from RGBD images",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1613,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867713871&doi=10.1007%2f978-3-642-33715-4_54&partnerID=40&md5=0bb5f8e699a2e2b0f3e2564fe9ba1159","We present an approach to interpret the major surfaces, objects, and support relations of an indoor scene from an RGBD image. Most existing work ignores physical interactions or is applied only to tidy rooms and hallways. Our goal is to parse typical, often messy, indoor scenes into floor, walls, supporting surfaces, and object regions, and to recover support relationships. One of our main interests is to better understand how 3D cues can best inform a structured 3D interpretation. We also contribute a novel integer programming formulation to infer physical support relations. We offer a new dataset of 1449 RGBD images, capturing 464 diverse indoor scenes, with detailed annotations. Our experiments demonstrate our ability to infer support relations in complex scenes and verify that our 3D scene cues and inferred support lead to better object segmentation. © 2012 Springer-Verlag.",Conference Paper,"Final",Scopus,2-s2.0-84867713871
"Su H., Maji S., Kalogerakis E., Learned-Miller E.","Multi-view convolutional neural networks for 3D shape recognition",2015,"Proceedings of the IEEE International Conference on Computer Vision",1564,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973882748&doi=10.1109%2fICCV.2015.114&partnerID=40&md5=2d51348e0c4b74c3dd228cfb09a73e4a","A longstanding question in computer vision concerns the representation of 3D shapes for recognition: should 3D shapes be represented with descriptors operating on their native 3D formats, such as voxel grid or polygon mesh, or can they be effectively represented with view-based descriptors? We address this question in the context of learning to recognize 3D shapes from a collection of their rendered views on 2D images. We first present a standard CNN architecture trained to recognize the shapes' rendered views independently of each other, and show that a 3D shape can be recognized even from a single view at an accuracy far higher than using state-of-the-art 3D shape descriptors. Recognition rates further increase when multiple views of the shapes are provided. In addition, we present a novel CNN architecture that combines information from multiple views of a 3D shape into a single and compact shape descriptor offering even better recognition performance. The same architecture can be applied to accurately recognize human hand-drawn sketches of shapes. We conclude that a collection of 2D views can be highly informative for 3D shape recognition and is amenable to emerging CNN architectures and their derivatives. © 2015 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84973882748
"Schnabel R., Wahl R., Klein R.","Efficient RANSAC for point-cloud shape detection",2007,"Computer Graphics Forum",1351,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-34248995532&doi=10.1111%2fj.1467-8659.2007.01016.x&partnerID=40&md5=d9a07fd57c30ac18d12e991d6335b530","In this paper we present an automatic algorithm to detect basic shapes in unorganized point clouds. The algorithm decomposes the point cloud into a concise, hybrid structure of inherent shapes and a set of remaining points. Each detected shape serves as a proxy for a set of corresponding points. Our method is based on random sampling and detects planes, spheres, cylinders, cones and tori. For models with surfaces composed of these basic shapes only, for example, CAD models, we automatically obtain a representation solely consisting of shape proxies. We demonstrate that the algorithm is robust even in the presence of many outliers and a high degree of noise. The proposed method scales well with respect to the size of the input point cloud and the number and size of the shapes within the data. Even point sets with several millions of samples are robustly decomposed within less than a minute. Moreover, the algorithm is conceptually simple and easy to implement. Application areas include measurement of physical parameters, scan registration, surface compression, hybrid rendering, shape classification, meshing, simplification, approximation and reverse engineering. © 2007 The Eurographics Association and Blackwell Publishing Ltd.",Article,"Final",Scopus,2-s2.0-34248995532
"Shilane P., Min P., Kazhdan M., Funkhouser T.","The Princeton Shape Benchmark",2004,"Proceedings - Shape Modeling International SMI 2004",1241,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-6344252949&doi=10.1109%2fSMI.2004.1314504&partnerID=40&md5=f2258183d93608b663016bc3931da6f7","In recent years, many shape representations and geometric algorithms have been proposed for matching 3D shapes. Usually, each algorithm is tested on a different (small) database of 3D models, and thus no direct comparison is available for competing methods. In this paper, we describe the Princeton Shape Benchmark (PSB), a publicly available database of polygonal models collected from the World Wide Web and a suite of tools for comparing shape matching and classification algorithms. One feature of the benchmark is that it provides multiple semantic labels for each 3D model. For instance, it includes one classification of the 3D models based on function, another that considers function and form, and others based on how the object was constructed (e.g., man-made versus natural objects). We find that experiments with these classifications can expose different properties of shape-based retrieval algorithms. For example, out of 12 shape descriptors tested, Extended Gaussian Images [13] performed best for distinguishing man-made from natural objects, while they performed among the worst for distinguishing specific object types. Based on experiments with several different shape descriptors, we conclude that no single descriptor is best for all classifications, and thus the main contribution of this paper is to provide a framework to determine the conditions under which each descriptor performs best.",Conference Paper,"Final",Scopus,2-s2.0-6344252949
"Smith L.I.","A tutorial on principal components analysis",2002,"A Tutorial on Principal Components Analysis",1090,,[No abstract available],,"Final",Scopus,2-s2.0-0038171506
"Ng A.Y., Jordan M.I.","On discriminative vs. Generative classifiers: A comparison of logistic regression and naive bayes",2002,"Advances in Neural Information Processing Systems",1083,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-59549087165&partnerID=40&md5=bfb9721b89b79ab095f3d1961e5b122a","We compare discriminative and generative learning as typified by logist ic regression and naive Bayes. We show, contrary t o a widely- held belief that discriminative classifiers are almost always to be preferred, that there can often be two distinct regimes of performance as the training set size is increased, one in which each algorithm does better. This stems from the observation-which is borne out in repeated experiments-that while discriminative learning has lower asymptotic error, a generative classifier may also approach its (higher) asymptotic error much faster.",Conference Paper,"Final",Scopus,2-s2.0-59549087165
"Andrieu C., Doucet A., Holenstein R.","Particle Markov chain Monte Carlo methods",2010,"Journal of the Royal Statistical Society. Series B: Statistical Methodology",1017,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953523599&doi=10.1111%2fj.1467-9868.2009.00736.x&partnerID=40&md5=41fa380b3cd234c1280fd7588ea20a23","Markov chain Monte Carlo and sequential Monte Carlo methods have emerged as the two main tools to sample from high dimensional probability distributions. Although asymptotic convergence of Markov chain Monte Carlo algorithms is ensured under weak assumptions, the performance of these algorithms is unreliable when the proposal distributions that are used to explore the space are poorly chosen and/or if highly correlated variables are updated independently. We show here how it is possible to build efficient high dimensional proposal distributions by using sequential Monte Carlo methods. This allows us not only to improve over standard Markov chain Monte Carlo schemes but also to make Bayesian inference feasible for a large class of statistical models where this was not previously so. We demonstrate these algorithms on a non-linear state space model and a Lévy-driven stochastic volatility model. © 2010 Royal Statistical Society.",Article,"Final",Scopus,2-s2.0-77953523599
"Bremaud P.",[No title available],1999,"Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues",985,,[No abstract available],,,Scopus,2-s2.0-0003618624
"Eck Matthias, DeRose Tony, Duchamp Tom, Hoppe Hugues, Lounsbery Michael, Stuetzle Werner","Multiresolution analysis of arbitrary meshes",1995,"Proceedings of the ACM SIGGRAPH Conference on Computer Graphics",942,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029194710&doi=10.1145%2f218380.218440&partnerID=40&md5=9530f465cc0a897c830b736973d4436a","In computer graphics and geometric modeling, shapes are often represented by triangular meshes. With the advent of laser scanning systems, meshes of extreme complexity are rapidly becoming commonplace. Such meshes are notoriously expensive to store, transmit, render, and are awkward to edit. Multiresolution analysis offers a simple, unified, and theoretically sound approach to dealing with these problems. Lounsbery et al. have recently developed a technique for creating multiresolution representations for a restricted class of meshes with subdivision connectivity. Unfortunately, meshes encountered in practice typically do not meet this requirement. In this paper we present a method for overcoming the subdivision connectivity restriction, meaning that completely arbitrary meshes can now be converted to multiresolution form. The method is based on the approximation of an arbitrary initial mesh M by a mesh MJ that has subdivision connectivity and is guaranteed to be within a specified tolerance. The key ingredient of our algorithm is the construction of a parametrization of M over a simple domain. We expect this parametrization to be of use in other contexts, such as texture mapping or the approximation of complex meshes by NURBS patches.",Conference Paper,"Final",Scopus,2-s2.0-0029194710
"Zhu J., Zou H., Rosset S., Hastie T.","Multi-class AdaBoost",2009,"Statistics and Its Interface",900,,[No abstract available],,"Final",Scopus,2-s2.0-77958028886
"Wang Y., Sun Y., Liu Z., Sarma S.E., Bronstein M.M., Solomon J.M.","Dynamic graph Cnn for learning on point clouds",2019,"ACM Transactions on Graphics",852,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072184139&doi=10.1145%2f3326362&partnerID=40&md5=fe495da5ba4e550514d20230d9d5a61b","Point clouds provide a flexible geometric representation suitable for countless applications in computer graphics; they also comprise the raw output of most 3D data acquisition devices. While hand-designed features on point clouds have long been proposed in graphics and vision, however, the recent overwhelming success of convolutional neural networks (CNNs) for image analysis suggests the value of adapting insight from CNN to the point cloud world. Point clouds inherently lack topological information, so designing a model to recover topology can enrich the representation power of point clouds. To this end, we propose a new neural network module dubbed EdgeConv suitable for CNN-based high-level tasks on point clouds, including classification and segmentation. EdgeConv acts on graphs dynamically computed in each layer of the network. It is differentiable and can be plugged into existing architectures. Compared to existing modules operating in extrinsic space or treating each point independently, EdgeConv has several appealing properties: It incorporates local neighborhood information; it can be stacked applied to learn global shape properties; and in multi-layer systems affinity in feature space captures semantic characteristics over potentially long distances in the original embedding. We show the performance of our model on standard benchmarks, including ModelNet40, ShapeNetPart, and S3DIS. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Article,"Final",Scopus,2-s2.0-85072184139
"Koenderink J.J., van Doorn A.J.","Surface shape and curvature scales",1992,"Image and Vision Computing",844,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000113585&doi=10.1016%2f0262-8856%2892%2990076-F&partnerID=40&md5=91b389819caecfe84a52482fdb39a6f5","The classical surface curvature measures, such as the Gaussian and the mean curvature at a point of a surface, are not very indicative of local shape. The two principal curvatures (taken as a pair) are more informative, but one would prefer a single shape indicator rather than a pair of numbers. Moreover, the shape indicator should preferably be independent of the size i.e. the amount of curvature, as distinct from the type of curvature. We propose two novel measures of local shape, the 'curvedness' and the 'shape index'. The curvedness is a positive number that specifies the amount of curvature, whereas the shape index is a number in the range [-1, +1] and is scale invariant. The shape index captures the intuitive notion of 'local shape' particularly well. The shape index can be mapped upon an intuitively natural colour scale. Two complementary shapes (like stamp and mould) map to complementary hues. The symmetrical saddle (which is very special because it is self-complementary) maps to white. When a surface is tinted according to this colour scheme, this induces an immediate perceptual segmentation of convex, concave, and hyperbolic areas. We propose it as a useful tool in graphics representation of 3D shape. © 1992.",Article,"Final",Scopus,2-s2.0-0000113585
"Ros G., Sellart L., Materzynska J., Vazquez D., Lopez A.M.","The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes",2016,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",828,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986265711&doi=10.1109%2fCVPR.2016.352&partnerID=40&md5=fb0cdd5ff23f3fa3201e1789da46c819","Vision-based semantic segmentation in urban scenarios is a key functionality for autonomous driving. Recent revolutionary results of deep convolutional neural networks (DCNNs) foreshadow the advent of reliable classifiers to perform such visual tasks. However, DCNNs require learning of many parameters from raw images, thus, having a sufficient amount of diverse images with class annotations is needed. These annotations are obtained via cumbersome, human labour which is particularly challenging for semantic segmentation since pixel-level annotations are required. In this paper, we propose to use a virtual world to automatically generate realistic synthetic images with pixel-level annotations. Then, we address the question of how useful such data can be for semantic segmentation - in particular, when using a DCNN paradigm. In order to answer this question we have generated a synthetic collection of diverse urban images, named SYNTHIA, with automatically generated class annotations. We use SYNTHIA in combination with publicly available real-world urban images with manually provided annotations. Then, we conduct experiments with DCNNs that show how the inclusion of SYNTHIA in the training stage significantly improves performance on the semantic segmentation task. © 2016 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84986265711
"Qi C.R., Liu W., Wu C., Su H., Guibas L.J.","Frustum PointNets for 3D Object Detection from RGB-D Data",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",775,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062863854&doi=10.1109%2fCVPR.2018.00102&partnerID=40&md5=2f4eb64771771b51babefcbeefeaa06c","In this work, we study 3D object detection from RGBD data in both indoor and outdoor scenes. While previous methods focus on images or 3D voxels, often obscuring natural 3D patterns and invariances of 3D data, we directly operate on raw point clouds by popping up RGB-D scans. However, a key challenge of this approach is how to efficiently localize objects in point clouds of large-scale scenes (region proposal). Instead of solely relying on 3D proposals, our method leverages both mature 2D object detectors and advanced 3D deep learning for object localization, achieving efficiency as well as high recall for even small objects. Benefited from learning directly in raw point clouds, our method is also able to precisely estimate 3D bounding boxes even under strong occlusion or with very sparse points. Evaluated on KITTI and SUN RGB-D 3D detection benchmarks, our method outperforms the state of the art by remarkable margins while having real-time capability. © 2018 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85062863854
"Caruana R., Niculescu-Mizil A.","An empirical comparison of supervised learning algorithms",2006,"ACM International Conference Proceeding Series",767,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250744208&doi=10.1145%2f1143844.1143865&partnerID=40&md5=1fda44772658e0ba73425e3adb94d9d4","A number of supervised learning methods have been introduced in the last decade. Unfortunately, the last comprehensive empirical evaluation of supervised learning was the Statlog Project in the early 90's. We present a large-scale empirical comparison between ten supervised learning methods: SVMs, neural nets, logistic regression, naive bayes, memory-based learning, random forests, decision trees, bagged trees, boosted trees, and boosted stumps. We also examine the effect that calibrating the models via Platt Scaling and Isotonic Regression has on their performance. An important aspect of our study is the use of a variety of performance criteria to evaluate the learning methods.",Conference Paper,"Final",Scopus,2-s2.0-34250744208
"Libbrecht M.W., Noble W.S.","Machine learning applications in genetics and genomics",2015,"Nature Reviews Genetics",758,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929510967&doi=10.1038%2fnrg3920&partnerID=40&md5=cf588e81fa7f07b878d1a97abc56c16e","The field of machine learning, which aims to develop computer algorithms that improve with experience, holds promise to enable computers to assist humans in the analysis of large, complex data sets. Here, we provide an overview of machine learning applications for the analysis of genome sequencing data sets, including the annotation of sequence elements and epigenetic, proteomic or metabolomic data. We present considerations and recurrent challenges in the application of supervised, semi-supervised and unsupervised machine learning methods, as well as of generative and discriminative modelling approaches. We provide general guidelines to assist in the selection of these machine learning methods and their practical application for the analysis of genetic and genomic data sets. © 2015 Macmillan Publishers Limited. All rights reserved.",Review,"Final",Scopus,2-s2.0-84929510967
"Tang P., Huber D., Akinci B., Lipman R., Lytle A.","Automatic reconstruction of as-built building information models from laser-scanned point clouds: A review of related techniques",2010,"Automation in Construction",687,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956619234&doi=10.1016%2fj.autcon.2010.06.007&partnerID=40&md5=02fe8aaef91b458c0d2a1682bce87b22","Building information models (BIMs) are maturing as a new paradigm for storing and exchanging knowledge about a facility. BIMs constructed from a CAD model do not generally capture details of a facility as it was actually built. Laser scanners can be used to capture dense 3D measurements of a facility's as-built condition and the resulting point cloud can be manually processed to create an as-built BIM-a time-consuming, subjective, and error-prone process that could benefit significantly from automation. This article surveys techniques developed in civil engineering and computer science that can be utilized to automate the process of creating as-built BIMs. We sub-divide the overall process into three core operations: geometric modeling, object recognition, and object relationship modeling. We survey the state-of-the-art methods for each operation and discuss their potential application to automated as-built BIM creation. We also outline the main methods used by these algorithms for representing knowledge about shape, identity, and relationships. In addition, we formalize the possible variations of the overall as-built BIM creation problem and outline performance evaluation measures for comparing as-built BIM creation algorithms and tracking progress of the field. Finally, we identify and discuss technology gaps that need to be addressed in future research. © 2010 Elsevier B.V.",Review,"Final",Scopus,2-s2.0-77956619234
"Dai A., Chang A.X., Savva M., Halber M., Funkhouser T., Nießner M.","ScanNet: Richly-annotated 3D reconstructions of indoor scenes",2017,"Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017",680,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041928024&doi=10.1109%2fCVPR.2017.261&partnerID=40&md5=42a29ca9e1074ea0b45d1adbc6b71819","A key requirement for leveraging supervised deep learning methods is the availability of large, labeled datasets. Unfortunately, in the context of RGB-D scene understanding, very little data is available - current datasets cover a small range of scene views and have limited semantic annotations. To address this issue, we introduce ScanNet, an RGB-D video dataset containing 2.5M views in 1513 scenes annotated with 3D camera poses, surface reconstructions, and semantic segmentations. To collect this data, we designed an easy-to-use and scalable RGB-D capture system that includes automated surface reconstruction and crowd-sourced semantic annotation. We show that using this data helps achieve state-of-the-art performance on several 3D scene understanding tasks, including 3D object classification, semantic voxel labeling, and CAD model retrieval. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85041928024
"Rabbani T., Van Den Heuvel F.A., Vosselman G.","Segmentation of point clouds using smoothness constraint",2006,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",592,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021189132&partnerID=40&md5=e614b407c99ef4da37b4e8d90cbd7859","For automatic processing of point clouds their segmentation is one of the most important processes. The methods based on curvature and other higher level derivatives often lead to over segmentation, which later needs a lot of manual editing. We present a method for segmentation of point clouds using smoothness constraint, which finds smoothly connected areas in point clouds. It uses only local surface normals and point connectivity which can be enforced using either k-nearest or fixed distance neighbours. The presented method requires a small number of intuitive parameters, which provide a tradeoff between under- and over-segmentation. The application of the presented algorithm on industrial point clouds shows its effectiveness compared to curvature based approaches. © 2018 International Society for Photogrammetry and Remote Sensing. All rights reserved.",Conference Paper,"Final",Scopus,2-s2.0-85021189132
"Breiman L.","Bagging predictors",1996,"Machine Learning",582,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084725117&doi=10.1007%2fbf00058655&partnerID=40&md5=b87ff8a59f23d05118ed88d28edda5ea","Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy. © 1996 Kluwer Academic Publishers,.",Article,"Final",Scopus,2-s2.0-85084725117
"Moller T., Haines E.",[No title available],1999,"Real-Time Rendering",556,,[No abstract available],,,Scopus,2-s2.0-0003966414
"Hashem I.A.T., Chang V., Anuar N.B., Adewole K., Yaqoob I., Gani A., Ahmed E., Chiroma H.","The role of big data in smart city",2016,"International Journal of Information Management",547,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969143086&doi=10.1016%2fj.ijinfomgt.2016.05.002&partnerID=40&md5=613d659c72f579f784f5d859bc2faa6f","The expansion of big data and the evolution of Internet of Things (IoT) technologies have played an important role in the feasibility of smart city initiatives. Big data offer the potential for cities to obtain valuable insights from a large amount of data collected through various sources, and the IoT allows the integration of sensors, radio-frequency identification, and Bluetooth in the real-world environment using highly networked services. The combination of the IoT and big data is an unexplored research area that has brought new and interesting challenges for achieving the goal of future smart cities. These new challenges focus primarily on problems related to business and technology that enable cities to actualize the vision, principles, and requirements of the applications of smart cities by realizing the main smart environment characteristics. In this paper, we describe the state-of-the-art communication technologies and smart-based applications used within the context of smart cities. The visions of big data analytics to support smart cities are discussed by focusing on how big data can fundamentally change urban populations at different levels. Moreover, a future business model of big data for smart cities is proposed, and the business and technological research challenges are identified. This study can serve as a benchmark for researchers and industries for the future progress and development of smart cities in the context of big data. © 2016 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84969143086
"Salvi J., Matabosch C., Fofi D., Forest J.","A review of recent range image registration methods with accuracy evaluation",2007,"Image and Vision Computing",527,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847066338&doi=10.1016%2fj.imavis.2006.05.012&partnerID=40&md5=5d84274ee47ee097736e9cd7884aa05c","The three-dimensional reconstruction of real objects is an important topic in computer vision. Most of the acquisition systems are limited to reconstruct a partial view of the object obtaining in blind areas and occlusions, while in most applications a full reconstruction is required. Many authors have proposed techniques to fuse 3D surfaces by determining the motion between the different views. The first problem is related to obtaining a rough registration when such motion is not available. The second one is focused on obtaining a fine registration from an initial approximation. In this paper, a survey of the most common techniques is presented. Furthermore, a sample of the techniques has been programmed and experimental results are reported to determine the best method in the presence of noise and outliers, providing a useful guide for an interested reader including a Matlab toolbox available at the webpage of the authors. © 2006 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-33847066338
"Li Y., Zhang H., Shen Q.","Spectral-spatial classification of hyperspectral imagery with 3D convolutional neural network",2017,"Remote Sensing",514,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010690651&doi=10.3390%2frs9010067&partnerID=40&md5=f4bb149e680493177212b2bae0c010be","Recent research has shown that using spectral-spatial information can considerably improve the performance of hyperspectral image (HSI) classification. HSI data is typically presented in the format of 3D cubes. Thus, 3D spatial filtering naturally offers a simple and effective method for simultaneously extracting the spectral-spatial features within such images. In this paper, a 3D convolutional neural network (3D-CNN) framework is proposed for accurate HSI classification. The proposed method views the HSI cube data altogether without relying on any preprocessing or post-processing, extracting the deep spectral-spatial-combined features effectively. In addition, it requires fewer parameters than other deep learning-based methods. Thus, the model is lighter, less likely to over-fit, and easier to train. For comparison and validation, we test the proposed method along with three other deep learning-based HSI classification methods-namely, stacked autoencoder (SAE), deep brief network (DBN), and 2D-CNN-based methods-on three real-world HSI datasets captured by different sensors. Experimental results demonstrate that our 3D-CNN-based method outperforms these state-of-the-art methods and sets a new record. © 2017 by the authors; licensee MDPI, Basel, Switzerland.",Article,"Final",Scopus,2-s2.0-85010690651
"Armeni I., Sener O., Zamir A.R., Jiang H., Brilakis I., Fischer M., Savarese S.","3D semantic parsing of large-scale indoor spaces",2016,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",508,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986325920&doi=10.1109%2fCVPR.2016.170&partnerID=40&md5=e9ab45f07a81a40d4de3ff7333ee85c8","In this paper, we propose a method for semantic parsing the 3D point cloud of an entire building using a hierarchical approach: first, the raw data is parsed into semantically meaningful spaces (e.g. rooms, etc) that are aligned into a canonical reference coordinate system. Second, the spaces are parsed into their structural and building elements (e.g. walls, columns, etc). Performing these with a strong notation of global 3D space is the backbone of our method. The alignment in the first step injects strong 3D priors from the canonical coordinate system into the second step for discovering elements. This allows diverse challenging scenarios as man-made indoor spaces often show recurrent geometric patterns while the appearance features can change drastically. We also argue that identification of structural elements in indoor spaces is essentially a detection problem, rather than segmentation which is commonly used. We evaluated our method on a new dataset of several buildings with a covered area of over 6, 000m2 and over 215 million points, demonstrating robust results readily useful for practical applications. © 2016 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84986325920
"Becerik-Gerber B., Jazizadeh F., Li N., Calis G.","Application areas and data requirements for BIM-enabled facilities management",2012,"Journal of Construction Engineering and Management",504,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859575621&doi=10.1061%2f%28ASCE%29CO.1943-7862.0000433&partnerID=40&md5=ff02cb8ce9e1f4735b345031c839e3e4","Facilities management (FM) encompasses and requires multidisciplinary activities, and thus has extensive information requirements. While some of these needs are addressed by several existing FM information systems, building information modeling (BIM), which is becoming widely adopted by the construction industry, holds undeveloped possibilities for providing and supporting FM practices with its functionalities of visualization, analysis, control, and so on. This paper explores how BIM can be a beneficial platform for supplementing FM practices. An online survey and face-to-face interviews were conducted to assess the current status of BIM implementations in FM, potential applications, and the level of interest in the utilization of BIM. Interactions between BIM and FM are defined by illustrating application areas and data requirements for BIM-enabled FM practices. Highlighting the synergy between the two, this paper can help professionals recognize potential areas in which BIM can be useful in FM practices. © 2012 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84859575621
"Chua C.S., Jarvis R.","Point Signatures: A New Representation for 3D Object Recognition",1997,"International Journal of Computer Vision",477,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031246477&doi=10.1023%2fA%3a1007981719186&partnerID=40&md5=6d5995a0337db4a7f7b90b25d59e5d73","Few systems capable of recognizing complex objects with free-form (sculptured) surfaces have been developed. The apparent lack of success is mainly due to the lack of a competent modelling scheme for representing such complex objects. In this paper, a new form of point representation for describing 3D free-form surfaces is proposed. This representation, which we call the point signature, serves to describe the structural neighbourhood of a point in a more complete manner than just using the 3D coordinates of the point. Being invariant to rotation and translation, the point signature can be used directly to hypothesize the correspondence to model points with similar signatures. Recognition is achieved by matching the signatures of data points representing the sensed surface to the signatures of data points representing the model surface. The use of point signatures is not restricted to the recognition of a single-object scene to a small library of models. Instead, it can be extended naturally to the recognition of scenes containing multiple partially-overlapping objects (which may also be juxtaposed with each other) against a large model library. No preliminary phase of segmenting the scene into the component objects is required. In searching for the appropriate candidate model, recognition need not proceed in a linear order which can become prohibitive for a large model library. For a given scene, signatures are extracted at arbitrarily spaced seed points. Each of these signatures is used to vote for models that contain points having similar signatures. Inappropriate models with low votes can be rejected while the remaining candidate models are ordered according to the votes they received. In this way, efficient verification of the hypothesized candidates can proceed by testing the most likely model first. Experiments using real data obtained from a range finder have shown fast recognition from a library of fifteen models whose complexities vary from that of simple piecewise quadric shapes to complicated face masks. Results from the recognition of both single-object and multiple-object scenes are presented.",Article,"Final",Scopus,2-s2.0-0031246477
"Klokov R., Lempitsky V.","Escape from Cells: Deep Kd-Networks for the Recognition of 3D Point Cloud Models",2017,"Proceedings of the IEEE International Conference on Computer Vision",476,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041901821&doi=10.1109%2fICCV.2017.99&partnerID=40&md5=85cfeba7747d2e9ad079a292c83e9587","We present a new deep learning architecture (called Kdnetwork) that is designed for 3D model recognition tasks and works with unstructured point clouds. The new architecture performs multiplicative transformations and shares parameters of these transformations according to the subdivisions of the point clouds imposed onto them by kdtrees. Unlike the currently dominant convolutional architectures that usually require rasterization on uniform twodimensional or three-dimensional grids, Kd-networks do not rely on such grids in any way and therefore avoid poor scaling behavior. In a series of experiments with popular shape recognition benchmarks, Kd-networks demonstrate competitive performance in a number of shape recognition tasks such as shape classification, shape retrieval and shape part segmentation. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85041901821
"Bronstein A.M., Bronstein M.M., Guibas L.J., Ovsjanikov M.","Shape google: Geometric words and expressions for invariant shape retrieval",2011,"ACM Transactions on Graphics",459,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551691572&doi=10.1145%2f1899404.1899405&partnerID=40&md5=069360848250656e575866f54fb2535a","The computer vision and pattern recognition communities have recently witnessed a surge of feature-based methods in object recognition and image retrieval applications. These methods allow representing images as collections of ""visual words"" and treat them using text search approaches following the ""bag of features"" paradigm. In this article, we explore analogous approaches in the 3D world applied to the problem of nonrigid shape retrieval in large databases. Using multiscale diffusion heat kernels as ""geometric words,"" we construct compact and informative shape descriptors by means of the ""bag of features"" approach. We also show that considering pairs of ""geometric words"" (""geometric expressions"") allows creating spatially sensitive bags of features with better discriminative power. Finally, adopting metric learning approaches, we show that shapes can be efficiently represented as binary codes. Our approach achieves state-of-the-art results on the SHREC 2010 large-scale shape retrieval benchmark. © 2011 ACM.",Article,"Final",Scopus,2-s2.0-79551691572
"Johnson A.","Spin-images: A representation for 3-D surface matching",1997,"Spin-images: A Representation for 3-D Surface Matching",457,,[No abstract available],,"Final",Scopus,2-s2.0-0004957497
"Xiong X., Adan A., Akinci B., Huber D.","Automatic creation of semantically rich 3D building models from laser scanner data",2013,"Automation in Construction",422,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873283130&doi=10.1016%2fj.autcon.2012.10.006&partnerID=40&md5=61d3cec103ae96e1a906eb4213c948fc","In the Architecture, Engineering, and Construction (AEC) domain, semantically rich 3D information models are increasingly used throughout a facility's life cycle for diverse applications, such as planning renovations, space usage planning, and managing building maintenance. These models, which are known as building information models (BIMs), are often constructed using dense, three dimensional (3D) point measurements obtained from laser scanners. Laser scanners can rapidly capture the ""as-is"" conditions of a facility, which may differ significantly from the design drawings. Currently, the conversion from laser scan data to BIM is primarily a manual operation, and it is labor-intensive and can be error-prone. This paper presents a method to automatically convert the raw 3D point data from a laser scanner positioned at multiple locations throughout a facility into a compact, semantically rich information model. Our algorithm is capable of identifying and modeling the main visible structural components of an indoor environment (walls, floors, ceilings, windows, and doorways) despite the presence of significant clutter and occlusion, which occur frequently in natural indoor environments. Our method begins by extracting planar patches from a voxelized version of the input point cloud. The algorithm learns the unique features of different types of surfaces and the contextual relationships between them and uses this knowledge to automatically label patches as walls, ceilings, or floors. Then, we perform a detailed analysis of the recognized surfaces to locate openings, such as windows and doorways. This process uses visibility reasoning to fuse measurements from different scan locations and to identify occluded regions and holes in the surface. Next, we use a learning algorithm to intelligently estimate the shape of window and doorway openings even when partially occluded. Finally, occluded surface regions are filled in using a 3D inpainting algorithm. We evaluated the method on a large, highly cluttered data set of a building with forty separate rooms. © 2012 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84873283130
"Chen X., Kundu K., Zhang Z., Ma H., Fidler S., Urtasun R.","Monocular 3D Object Detection for Autonomous Driving",2016,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",414,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986267444&doi=10.1109%2fCVPR.2016.236&partnerID=40&md5=1db1ee6de8703ed2d9250f192ec36b19","The goal of this paper is to perform 3D object detection from a single monocular image in the domain of autonomous driving. Our method first aims to generate a set of candidate class-specific object proposals, which are then run through a standard CNN pipeline to obtain highquality object detections. The focus of this paper is on proposal generation. In particular, we propose an energy minimization approach that places object candidates in 3D using the fact that objects should be on the ground-plane. We then score each candidate box projected to the image plane via several intuitive potentials encoding semantic segmentation, contextual information, size and location priors and typical object shape. Our experimental evaluation demonstrates that our object proposal generation approach significantly outperforms all monocular approaches, and achieves the best detection performance on the challenging KITTI benchmark, among published monocular competitors. © 2016 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84986267444
"Watt A.",[No title available],1993,"3D Computer Graphics",409,,[No abstract available],,,Scopus,2-s2.0-0003802875
"Weinmann M., Jutzi B., Hinz S., Mallet C.","Semantic point cloud interpretation based on optimal neighborhoods, relevant features and efficient classifiers",2015,"ISPRS Journal of Photogrammetry and Remote Sensing",376,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939979079&doi=10.1016%2fj.isprsjprs.2015.01.016&partnerID=40&md5=0f9af8e0aaaee7e637fbf5f4ef885ed5","3D scene analysis in terms of automatically assigning 3D points a respective semantic label has become a topic of great importance in photogrammetry, remote sensing, computer vision and robotics. In this paper, we address the issue of how to increase the distinctiveness of geometric features and select the most relevant ones among these for 3D scene analysis. We present a new, fully automated and versatile framework composed of four components: (i) neighborhood selection, (ii) feature extraction, (iii) feature selection and (iv) classification. For each component, we consider a variety of approaches which allow applicability in terms of simplicity, efficiency and reproducibility, so that end-users can easily apply the different components and do not require expert knowledge in the respective domains. In a detailed evaluation involving 7 neighborhood definitions, 21 geometric features, 7 approaches for feature selection, 10 classifiers and 2 benchmark datasets, we demonstrate that the selection of optimal neighborhoods for individual 3D points significantly improves the results of 3D scene analysis. Additionally, we show that the selection of adequate feature subsets may even further increase the quality of the derived results while significantly reducing both processing time and memory consumption. © 2015 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).",Article,"Final",Scopus,2-s2.0-84939979079
"Lalonde J.-F., Vandapel N., Huber D.F., Hebert M.","Natural terrain classification using three-dimensional ladar data for ground robot mobility",2006,"Journal of Field Robotics",337,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-33751221647&doi=10.1002%2frob.20134&partnerID=40&md5=ef70718dd511dde0e295115b87d51567","In recent years, much progress has been made in outdoor autonomous navigation. However, safe navigation is still a daunting challenge in terrain containing vegetation. In this paper, we focus on the segmentation of ladar data into three classes using local three-dimensional point cloud statistics. The classes are: ""scatter"" to represent porous volumes such as grass and tree canopy; ""linear"" to capture thin objects like wires or tree branches, and finally ""surface"" to capture solid objects like ground surface, rocks, or large trunks. We present the details of the proposed method, and the modifications we made to implement it on-board an autonomous ground vehicle for real-time data processing. Finally, we present results produced from different stationary laser sensors and from field tests using an unmanned ground vehicle. © 2006 Wiley Periodicals, Inc.",Article,"Final",Scopus,2-s2.0-33751221647
"Yi L., Kim V.G., Ceylan D., Shen I.-C., Yan M., Su H., Lu C., Huang Q., Sheffer A., Guibas L.","A scalable active framework for region annotation in 3D shape collections",2016,"ACM Transactions on Graphics",322,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055445399&doi=10.1145%2f2980179.2980238&partnerID=40&md5=f238194ccd3c52131e00642b09538652","Large repositories of 3D shapes provide valuable input for data-driven analysis and modeling tools. They are especially powerful once annotated with semantic information such as salient regions and functional parts. We propose a novel active learning method capable of enriching massive geometric datasets with accurate semantic region annotations. Given a shape collection and a user-specified region label our goal is to correctly demarcate the corresponding regions with minimal manual work. Our active framework achieves this goal by cycling between manually annotating the regions, automatically propagating these annotations across the rest of the shapes, manually verifying both human and automatic annotations, and learning from the verification results to improve the automatic propagation algorithm. We use a unified utility function that explicitly models the time cost of human input across all steps of our method. This allows us to jointly optimize for the set of models to annotate and for the set of models to verify based on the predicted impact of these actions on the human efficiency. We demonstrate that incorporating verification of all produced labelings within this unified objective improves both accuracy and efficiency of the active learning procedure. We automatically propagate human labels across a dynamic shape network using a conditional random field (CRF) framework, taking advantage of global shape-to-shape similarities, local feature similarities, and point-to-point correspondences. By combining these diverse cues we achieve higher accuracy than existing alternatives. We validate our framework on existing benchmarks demonstrating it to be significantly more efficient at using human input compared to previous techniques. We further validate its efficiency and robustness by annotating a massive shape dataset, labeling over 93,000 shape parts, across multiple model classes, and providing a labeled part collection more than one order of magnitude larger than existing ones. © 2016 ACM.",Article,"Final",Scopus,2-s2.0-85055445399
"Schneider P.J., Eberly D.H.","Geometric Tools for Computer Graphics",2003,"Geometric Tools for Computer Graphics",319,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902947554&doi=10.1016%2fB978-1-55860-594-7.X5000-0&partnerID=40&md5=335dd318b99a79567dfffbcb4f6d9cc9","Do you spend too much time creating the building blocks of your graphics applications or finding and correcting errors? Geometric Tools for Computer Graphics is an extensive, conveniently organized collection of proven solutions to fundamental problems that you'd rather not solve over and over again, including building primitives, distance calculation, approximation, containment, decomposition, intersection determination, separation, and more. If you have a mathematics degree, this book will save you time and trouble. If you don't, it will help you achieve things you may feel are out of your reach. Inside, each problem is clearly stated and diagrammed, and the fully detailed solutions are presented in easy-to-understand pseudocode. You also get the mathematics and geometry background needed to make optimal use of the solutions, as well as an abundance of reference material contained in a series of appendices. © 2003 Elsevier Inc. All rights reserved.",Book,"Final",Scopus,2-s2.0-84902947554
"Pu S., Vosselman G.","Knowledge based reconstruction of building models from terrestrial laser scanning data",2009,"ISPRS Journal of Photogrammetry and Remote Sensing",310,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350622985&doi=10.1016%2fj.isprsjprs.2009.04.001&partnerID=40&md5=1bae0d7741dec872a8d9248ab59e0407","This paper presents an automatic method for reconstruction of building façade models from terrestrial laser scanning data. Important façade elements such as walls and roofs are distinguished as features. Knowledge about the features' sizes, positions, orientations, and topology is then introduced to recognize these features in a segmented laser point cloud. An outline polygon of each feature is generated by least squares fitting, convex hull fitting or concave polygon fitting, according to the size of the feature. Knowledge is used again to hypothesise the occluded parts from the directly extracted feature polygons. Finally, a polyhedron building model is combined from extracted feature polygons and hypothesised parts. The reconstruction method is tested with two data sets containing various building shapes. © 2009 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).",Article,"Final",Scopus,2-s2.0-70350622985
"Nüchter A., Hertzberg J.","Towards semantic maps for mobile robots",2008,"Robotics and Autonomous Systems",307,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-53849127134&doi=10.1016%2fj.robot.2008.08.001&partnerID=40&md5=186223e1198bf329e412ff762a3c909b","Intelligent autonomous action in ordinary environments calls for maps. 3D geometry is generally required for avoiding collision with complex obstacles and to self-localize in six degrees of freedom (6 DoF) (x, y, z positions, roll, yaw, and pitch angles). Meaning, in addition to geometry, becomes inevitable if the robot is supposed to interact with its environment in a goal-directed way. A semantic stance enables the robot to reason about objects; it helps disambiguate or round off sensor data; and the robot knowledge becomes reviewable and communicable. The paper describes an approach and an integrated robot system for semantic mapping. The prime sensor is a 3D laser scanner. Individual scans are registered into a coherent 3D geometry map by 6D SLAM. Coarse scene features (e.g., walls, floors in a building) are determined by semantic labeling. More delicate objects are then detected by a trained classifier and localized. In the end, the semantic maps can be visualized for human inspection. We sketch the overall architecture of the approach, explain the respective steps and their underlying algorithms, give examples based on a working robot implementation, and discuss the findings. © 2008 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-53849127134
"Rvachev V.L.",[No title available],1982,"Theory of R-functions and Some Applications",305,,[No abstract available],,,Scopus,2-s2.0-0003553984
"Sampath A., Shan J.","Segmentation and reconstruction of polyhedral building roofs from aerial lidar point clouds",2010,"IEEE Transactions on Geoscience and Remote Sensing",304,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149498757&doi=10.1109%2fTGRS.2009.2030180&partnerID=40&md5=25abf44837da89b9017316554a3c4b9c","This paper presents a solution framework for the segmentation and reconstruction of polyhedral building roofs from aerial LIght Detection And Ranging (lidar) point clouds. The eigenanalysis is first carried out for each roof point of a building within its Voronoi neighborhood. Such analysis not only yields the surface normal for each lidar point but also separates the lidar points into planar and nonplanar ones. In the second step, the surface normals of all planar points are clustered with the fuzzy k-means method. To optimize this clustering process, a potential-based approach is used to estimate the number of clusters, while considering both geometry and topology for the cluster similarity. The final step of segmentation separates the parallel and coplanar segments based on their distances and connectivity, respectively. Building reconstruction starts with forming an adjacency matrix that represents the connectivity of the segmented planar segments. A roof interior vertex is determined by intersecting all planar segments that meet at one point, whereas constraints in the form of vertical walls or boundary are applied to determine the vertices on the building outline. Finally, an extended boundary regularization approach is developed based on multiple parallel and perpendicular line pairs to achieve topologically consistent and geometrically correct building models. This paper describes the detail principles and implementation steps for the aforementioned solution framework. Results of a number of buildings with diverse roof complexities are presented and evaluated. © 2009 IEEE.",Article,"Final",Scopus,2-s2.0-78149498757
"Tatarchenko M., Dosovitskiy A., Brox T.","Octree Generating Networks: Efficient Convolutional Architectures for High-resolution 3D Outputs",2017,"Proceedings of the IEEE International Conference on Computer Vision",300,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041906390&doi=10.1109%2fICCV.2017.230&partnerID=40&md5=ba99afae6108db847f72435c1a5ecfe3","We present a deep convolutional decoder architecture that can generate volumetric 3D outputs in a compute- and memory-efficient manner by using an octree representation. The network learns to predict both the structure of the octree, and the occupancy values of individual cells. This makes it a particularly valuable technique for generating 3D shapes. In contrast to standard decoders acting on regular voxel grids, the architecture does not have cubic complexity. This allows representing much higher resolution outputs with a limited memory budget. We demonstrate this in several application domains, including 3D convolutional autoencoders, generation of objects and whole scenes from high-level representations, and shape from a single image. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85041906390
"Koppula H.S., Anand A., Joachims T., Saxena A.","Semantic labeling of 3D point clouds for indoor scenes",2011,"Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems 2011, NIPS 2011",290,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860629092&partnerID=40&md5=d81b5ae57ff5c4bca125aa68435a4c3a","Inexpensive RGB-D cameras that give an RGB image together with depth data have become widely available. In this paper, we use this data to build 3D point clouds of full indoor scenes such as an office and address the task of semantic labeling of these 3D point clouds. We propose a graphical model that captures various features and contextual relations, including the local visual appearance and shape cues, object co-occurence relationships and geometric relationships. With a large number of object classes and relations, the model's parsimony becomes important and we address that by using multiple types of edge potentials. The model admits efficient approximate inference, and we train it using a maximum-margin learning approach. In our experiments over a total of 52 3D scenes of homes and offices (composed from about 550 views, having 2495 segments labeled with 27 object classes), we get a performance of 84.06% in labeling 17 object classes for offices, and 73.38% in labeling 17 object classes for home scenes. Finally, we applied these algorithms successfully on a mobile robot for the task of finding objects in large cluttered rooms.",Conference Paper,"Final",Scopus,2-s2.0-84860629092
"Chen C.-S., Hung Y.-P.","RANSAC-Based DARCES: A new approach to fast automatic registration of partially overlapping range images",1999,"IEEE Transactions on Pattern Analysis and Machine Intelligence",263,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033220962&doi=10.1109%2f34.809117&partnerID=40&md5=599c31710964982a2cf7454b6f4a6ec1","In this paper, we propose a new method, the RANSAC-based DARCES method, which can solve the partially overlapping 3D registration problem without any initial estimation. For the noiseless case, the basic algorithm of our method can guarantee that the solution it finds is the true one, and its time complexity can be shown to be relatively low. An extra characteristic is that our method can be used even for the case that there are no local features in the 3D data sets. © 1999 IEEE.",Article,"Final",Scopus,2-s2.0-0033220962
"Munoz D., Bagnell J.A., Vandapel N., Hebert M.","Contextual classification with functional max-margin markov networks",2009,"2009 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2009",262,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-70450162267&doi=10.1109%2fCVPRW.2009.5206590&partnerID=40&md5=a9cac36a04b36a9a48793821fae9d1b8","We address the problem of label assignment in computer vision: given a novel 3-D or 2-D scene, we wish to assign a unique label to every site (voxel, pixel, superpixel, etc.). To this end, the Markov Random Field framework has proven to be a model of choice as it uses contextual information to yield improved classification results over locally independent classifiers. In this work we adapt a functional gradient approach for learning high-dimensional parameters of random fields in order to perform discrete, multi-label classification. With this approach we can learn robust models involving high-order interactions better than the previously used learning method. We validate the approach in the context of point cloud classification and improve the state of the art. In addition, we successfully demonstrate the generality of the approach on the challenging vision problem of recovering 3-D geometric surfaces from images © 2009 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-70450162267
"Hackel T., Savinov N., Ladicky L., Wegner J.D., Schindler K., Pollefeys M.","SEMANTIC3D.NET: A NEW LARGE-SCALE POINT CLOUD CLASSIFICATION BENCHMARK",2017,"ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences",240,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040692236&doi=10.5194%2fisprs-annals-IV-1-W1-91-2017&partnerID=40&md5=fd39b83943b97e48d15923780fea366d","This paper presents a new 3D point cloud classification benchmark data set with over four billion manually labelled points, meant as input for data-hungry (deep) learning methods. We also discuss first submissions to the benchmark that use deep convolutional neural networks (CNNs) as a work horse, which already show remarkable performance improvements over state-of-the-art. CNNs have become the de-facto standard for many tasks in computer vision and machine learning like semantic segmentation or object detection in images, but have no yet led to a true breakthrough for 3D point cloud labelling tasks due to lack of training data. With the massive data set presented in this paper, we aim at closing this data gap to help unleash the full potential of deep learning methods for 3D labelling tasks. Our semantic3D.net data set consists of dense point clouds acquired with static terrestrial laser scanners. It contains 8 semantic classes and covers a wide range of urban outdoor scenes: churches, streets, railroad tracks, squares, villages, soccer fields and castles. We describe our labelling interface and show that our data set provides more dense and complete point clouds with much higher overall number of labelled points compared to those already available to the research community. We further provide baseline method descriptions and comparison between methods submitted to our online system. We hope semantic3D.net will pave the way for deep learning methods in 3D point cloud labelling to learn richer, more general 3D representations, and first submissions after only a few months indicate that this might indeed be the case. © 2017 Copernicus GmbH. All rights reserved.",Conference Paper,"Final",Scopus,2-s2.0-85040692236
"Wu B., Wan A., Yue X., Keutzer K.","SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud",2018,"Proceedings - IEEE International Conference on Robotics and Automation",239,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062835622&doi=10.1109%2fICRA.2018.8462926&partnerID=40&md5=61c371775cb55d4dd9780c8d2d24bfe4","We address semantic segmentation of road-objects from 3D LiDAR point clouds. In particular, we wish to detect and categorize instances of interest, such as cars, pedestrians and cyclists. We formulate this problem as a point-wise classification problem, and propose an end-to-end pipeline called SqueezeSeg based on convolutional neural networks (CNN): the CNN takes a transformed LiDAR point cloud as input and directly outputs a point-wise label map, which is then refined by a conditional random field (CRF) implemented as a recurrent layer. Instance-level labels are then obtained by conventional clustering algorithms. Our CNN model is trained on LiDAR point clouds from the KITTI [1] dataset, and our point-wise segmentation labels are derived from 3D bounding boxes from KITTI. To obtain extra training data, we built a LiDAR simulator into Grand Theft Auto boldsymbol V (GTA-V), a popular video game, to synthesize large amounts of realistic training data. Our experiments show that SqueezeSeg achieves high accuracy with astonishingly fast and stable runtime (8.7pm 0.5 ms per frame), highly desirable for autonomous driving. Furthermore, additionally training on synthesized data boosts validation accuracy on real-world data. Our source code is open-source released111https://github.com/BichenWuUCB/SqueezeSeg. The paper is accompanied by a video222https://youtu.be/Xyn5Zd31m6s containing a high level introduction and demonstrations of this work. © 2018 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85062835622
"Bosché F., Ahmed M., Turkan Y., Haas C.T., Haas R.","The value of integrating Scan-to-BIM and Scan-vs-BIM techniques for construction monitoring using laser scanning and BIM: The case of cylindrical MEP components",2015,"Automation in Construction",235,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926221924&doi=10.1016%2fj.autcon.2014.05.014&partnerID=40&md5=da2a570eacf24c3dd2ca1103f3563fa3","There is a growing need for tools automating the processing of as-built 3D laser scanned data, and more particularly the comparison of this as-built data with planned works. This paper particularly considers the case of tracking MEP components with circular cross-sections, which essentially include pipes, and some conduits and ducts. Discrepancies between the as-built and as-planned status of pipes, conduit and ductwork result from changes that occur in the field and that are either unnoticed (human error) or not reflected in the 3D model. Previous research has shown that the Hough transform, with judiciously applied domain constraints, is a practical and cost-effective approach to find, recognize and reconstruct cylindrical MEP works within point clouds automatically. Previous research has also shown that ""Scan-vs-BIM"" systems that are based on the geometric alignment and comparison of as-built laser scans with as-designed BIM models can effectively recognize and identify MEP components as long as they are constructed near their as-planned locations. The research presented in this paper combines the two techniques in a unified approach for more robust automated comparison of as-built and as-planned cylindrical MEP works, thereby providing the basis for automated earned value tracking, automated percent-built-as-planned measures, and assistance for the delivery of as-built BIM models from as-designed ones. The proposed approach and its improved performance are validated using data acquired from an actual construction site. The results are very encouraging and demonstrate the added value of the proposed integrated approach over the rather simpler Scan-vs-BIM system. The two main areas of improved performance are: (1) the enabled recognition and identification of objects that are not built at their as-planned locations; and (2) the consideration for pipe completeness in the pipe recognition and identification metric. © 2014 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84926221924
"Borrmann D., Elseberg J., Lingemann K., Nüchter A.","The 3D Hough Transform for plane detection in point clouds: A review and a new accumulator design",2011,"3D Research",235,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860727746&doi=10.1007%2f3DRes.02%282011%293&partnerID=40&md5=1efc25e10d780f78bbee45f026c3cd8b","The Hough Transform is a well-known method for detecting parameterized objects. It is the de facto standard for detecting lines and circles in 2-dimensional data sets. For 3D it has attained little attention so far. Even for the 2D case high computational costs have lead to the development of numerous variations for the Hough Transform. In this article we evaluate different variants of the Hough Transform with respect to their applicability to detect planes in 3D point clouds reliably. Apart from computational costs, the main problem is the representation of the accumulator. Usual implementations favor geometrical objects with certain parameters due to uneven sampling of the parameter space. We present a novel approach to design the accumulator focusing on achieving the same size for each cell and compare it to existing designs. © 2011 3D Display Research Center and Springer-Verlag Berlin Heidelberg.",Article,"Final",Scopus,2-s2.0-84860727746
"Armeni I., Sax A., Zamir A.R., Savarese S.","Joint 2D-3D-Semantic Data for Indoor Scene Understanding",2017,"Joint 2D-3D-Semantic Data for Indoor Scene Understanding",232,,[No abstract available],,"Final",Scopus,2-s2.0-85030773563
"Shen Y., Feng C., Yang Y., Tian D.","Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",227,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057246492&doi=10.1109%2fCVPR.2018.00478&partnerID=40&md5=a48826095237d55946846fc3a647291a","Unlike on images, semantic learning on 3D point clouds using a deep network is challenging due to the naturally unordered data structure. Among existing works, PointNet has achieved promising results by directly learning on point sets. However, it does not take full advantage of a point's local neighborhood that contains fine-grained structural information which turns out to be helpful towards better semantic learning. In this regard, we present two new operations to improve PointNet with a more efficient exploitation of local structures. The first one focuses on local 3D geometric structures. In analogy to a convolution kernel for images, we define a point-set kernel as a set of learnable 3D points that jointly respond to a set of neighboring data points according to their geometric affinities measured by kernel correlation, adapted from a similar technique for point cloud registration. The second one exploits local high-dimensional feature structures by recursive feature aggregation on a nearest-neighbor-graph computed from 3D positions. Experiments show that our network can efficiently capture local information and robustly achieve better performances on major datasets. Our code is available at http://www.merl.com/research/license#KCNet. © 2018 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85057246492
"Ricci A.","A constructive geometry for computer graphics",1973,"The Computer Journal",226,,[No abstract available],,,Scopus,2-s2.0-0000397256
"Hackel T., Wegner J.D., Schindler K.","FAST SEMANTIC SEGMENTATION of 3D POINT CLOUDS with STRONGLY VARYING DENSITY",2016,"ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences",222,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046284404&doi=10.5194%2fisprs-annals-III-3-177-2016&partnerID=40&md5=5556f4f85ed8a006ba1d16f1f19874ab","We describe an effective and efficient method for point-wise semantic classification of 3D point clouds. The method can handle unstructured and inhomogeneous point clouds such as those derived from static terrestrial LiDAR or photogammetric reconstruction; and it is computationally efficient, making it possible to process point clouds with many millions of points in a matter of minutes. The key issue, both to cope with strong variations in point density and to bring down computation time, turns out to be careful handling of neighborhood relations. By choosing appropriate definitions of a point's (multi-scale) neighborhood, we obtain a feature set that is both expressive and fast to compute. We evaluate our classification method both on benchmark data from a mobile mapping platform and on a variety of large, terrestrial laser scans with greatly varying point density. The proposed feature set outperforms the state of the art with respect to per-point classification accuracy, while at the same time being much faster to compute.",Conference Paper,"Final",Scopus,2-s2.0-85046284404
"Pətrəucean V., Armeni I., Nahangi M., Yeung J., Brilakis I., Haas C.","State of research in automatic as-built modelling",2015,"Advanced Engineering Informatics",222,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937515039&doi=10.1016%2fj.aei.2015.01.001&partnerID=40&md5=96e6b0f83ff79ae9cc701178846dbec8","Building Information Models (BIMs) are becoming the official standard in the construction industry for encoding, reusing, and exchanging information about structural assets. Automatically generating such representations for existing assets stirs up the interest of various industrial, academic, and governmental parties, as it is expected to have a high economic impact. The purpose of this paper is to provide a general overview of the as-built modelling process, with focus on the geometric modelling side. Relevant works from the Computer Vision, Geometry Processing, and Civil Engineering communities are presented and compared in terms of their potential to lead to automatic as-built modelling. © 2015 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84937515039
"El Saddik A.","Digital Twins: The Convergence of Multimedia Technologies",2018,"IEEE Multimedia",218,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051272175&doi=10.1109%2fMMUL.2018.023121167&partnerID=40&md5=1f0cc65d2de15e4c4d8326890036049d","Originally developed to improve manufacturing processes, digital twins are being redefined as digital replications of living as well as nonliving entities that enable data to be seamlessly transmitted between the physical and virtual worlds. Digital twins facilitate the means to monitor, understand, and optimize the functions of all physical entities and for humans provide continuous feedback to improve quality of life and well-being. © 1994-2012 IEEE.",Article,"Final",Scopus,2-s2.0-85051272175
"Nguyen A., Le B.","3D point cloud segmentation: A survey",2013,"IEEE Conference on Robotics, Automation and Mechatronics, RAM - Proceedings",212,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898036866&doi=10.1109%2fRAM.2013.6758588&partnerID=40&md5=7dba34477f10c1207eb0d3a10490d1f5","3D point cloud segmentation is the process of classifying point clouds into multiple homogeneous regions, the points in the same region will have the same properties. The segmentation is challenging because of high redundancy, uneven sampling density, and lack explicit structure of point cloud data. This problem has many applications in robotics such as intelligent vehicles, autonomous mapping and navigation. Many authors have introduced different approaches and algorithms. In this survey, we examine methods that have been proposed to segment 3D point clouds. The advantages, disadvantages, and design mechanisms of these methods are analyzed and discussed. Finally, we outline the promising future research directions. © 2013 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84898036866
"Chernov N., Lesort C.","Least squares fitting of circles",2005,"Journal of Mathematical Imaging and Vision",201,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-24944557190&doi=10.1007%2fs10851-005-0482-8&partnerID=40&md5=78f40e60bc04d22d93de8b3c36717e6e","Fitting standard shapes or curves to incomplete data (which represent only a small part of the curve) is a notoriously difficult problem. Even if the curve is quite simple, such as an ellipse or a circle, it is hard to reconstruct it from noisy data sampled along a short arc. Here we study the least squares fit (LSF) of circular arcs to incomplete scattered data. We analyze theoretical aspects of the problem and reveal the cause of unstable behavior of conventional algorithms. We also find a remedy that allows us to build another algorithm that accurately fits circles to data sampled along arbitrarily short arcs. © 2005 Springer Science + Business Media, Inc.",Article,"Final",Scopus,2-s2.0-24944557190
"Marton Z.C., Rusu R.B., Beetz M.","On fast surface reconstruction methods for large and noisy point clouds",2009,"Proceedings - IEEE International Conference on Robotics and Automation",193,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059647843&doi=10.1109%2fROBOT.2009.5152628&partnerID=40&md5=1fc0b82fd0130f5cebaeeaf3e165f97f","In this paper we present a method for fast surface reconstruction from large noisy datasets. Given an unorganized 3D point cloud, our algorithm recreates the underlying surface's geometrical properties using data resampling and a robust triangulation algorithm in near realtime. For resulting smooth surfaces, the data is resampled with variable densities according to previously estimated surface curvatures. Incremental scans are easily incorporated into an existing surface mesh, by determining the respective overlapping area and reconstructing only the updated part of the surface mesh. The proposed framework is flexible enough to be integrated with additional point label information, where groups of points sharing the same label are clustered together and can be reconstructed separately, thus allowing fast updates via triangular mesh decoupling. To validate our approach, we present results obtained from laser scans acquired in both indoor and outdoor environments. © 2009 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85059647843
"Thompson W.B., Owen J.C., De St. Germain H.J., Stark Jr. S.R., Henderson T.C.","Feature-based reverse engineering of mechanical parts",1999,"IEEE Transactions on Robotics and Automation",192,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033078814&doi=10.1109%2f70.744602&partnerID=40&md5=ae9af5229051ff70bce97ab1a45f9cf8","Reverse engineering of mechanical parts requires extraction of information about an instance of a particular part sufficient to replicate the part using appropriate manufacturing techniques. This is important in a wide variety of situations, since functional CAD models are often unavailable or unusable for parts which must be duplicated or modified. Computer vision techniques applied to three-dimensional (3-D) data acquired using noncontact, 3-D position digitizers have the potential for significantly aiding the process. Serious challenges must be overcome, however, if sufficient accuracy is to be obtained and if models produced from sensed data are to be truly useful for manufacturing operations. This paper describes a prototype of a reverse engineering system which uses manufacturing features as geometric primitives. This approach has two advantages over current practice. The resulting models can be directly imported into feature-based CAD systems without loss of the semantics and topological information inherent in feature-based representations. In addition, the feature-based approach facilitates methods capable of producing highly accurate models, even when the original 3-D sensor data has substantial errors.",Article,"Final",Scopus,2-s2.0-0033078814
"Xiang Y., Choi W., Lin Y., Savarese S.","Data-driven 3D Voxel Patterns for object category recognition",2015,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",189,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959238956&doi=10.1109%2fCVPR.2015.7298800&partnerID=40&md5=c3ee953b0a86583f1fb24df83401370f","Despite the great progress achieved in recognizing objects as 2D bounding boxes in images, it is still very challenging to detect occluded objects and estimate the 3D properties of multiple objects from a single image. In this paper, we propose a novel object representation, 3D Voxel Pattern (3DVP), that jointly encodes the key properties of objects including appearance, 3D shape, viewpoint, occlusion and truncation. We discover 3DVPs in a data-driven way, and train a bank of specialized detectors for a dictionary of 3DVPs. The 3DVP detectors are capable of detecting objects with specific visibility patterns and transferring the meta-data from the 3DVPs to the detected objects, such as 2D segmentation mask, 3D pose as well as occlusion or truncation boundaries. The transferred meta-data allows us to infer the occlusion relationship among objects, which in turn provides improved object recognition results. Experiments are conducted on the KITTI detection benchmark [17] and the outdoor-scene dataset [41]. We improve state-of-the-art results on car detection and pose estimation with notable margins (6% in difficult data of KITTI). We also verify the ability of our method in accurately segmenting objects from the background and localizing them in 3D. © 2015 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84959238956
"Zhou Y., Tuzel O.","VoxelNet: End-to-end learning for point cloud based 3D object detection",2017,"Voxelnet: End-To-End Learning for Point Cloud Based 3D Object Detection",176,,[No abstract available],,"Final",Scopus,2-s2.0-85049882048
"Ochmann S., Vock R., Wessel R., Klein R.","Automatic reconstruction of parametric building models from indoor point clouds",2016,"Computers and Graphics (Pergamon)",176,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939192627&doi=10.1016%2fj.cag.2015.07.008&partnerID=40&md5=d9f51536ca4b70abfd05bbc547fce3c9","We present an automatic approach for the reconstruction of parametric 3D building models from indoor point clouds. While recently developed methods in this domain focus on mere local surface reconstructions which enable e.g. efficient visualization, our approach aims for a volumetric, parametric building model that additionally incorporates contextual information such as global wall connectivity. In contrast to pure surface reconstructions, our representation thereby allows more comprehensive use: first, it enables efficient high-level editing operations in terms of e.g. wall removal or room reshaping which always result in a topologically consistent representation. Second, it enables easy taking of measurements like e.g. determining wall thickness or room areas. These properties render our reconstruction method especially beneficial to architects or engineers for planning renovation or retrofitting. Following the idea of previous approaches, the reconstruction task is cast as a labeling problem which is solved by an energy minimization. This global optimization approach allows for the reconstruction of wall elements shared between rooms while simultaneously maintaining plausible connectivity between all wall elements. An automatic prior segmentation of the point clouds into rooms and outside area filters large-scale outliers and yields priors for the definition of labeling costs for the energy minimization. The reconstructed model is further enriched by detected doors and windows. We demonstrate the applicability and reconstruction power of our new approach on a variety of complex real-world datasets requiring little or no parameter adjustment. © 2015 The Authors. Published by Elsevier Ltd.",Article,"Final",Scopus,2-s2.0-84939192627
"Grilli E., Menna F., Remondino F.","A review of point clouds segmentation and classification algorithms",2017,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",173,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021757670&doi=10.5194%2fisprs-archives-XLII-2-W3-339-2017&partnerID=40&md5=3b5644d4a40c7b6a33d8e34e909529c2","Today 3D models and point clouds are very popular being currently used in several fields, shared through the internet and even accessed on mobile phones. Despite their broad availability, there is still a relevant need of methods, preferably automatic, to provide 3D data with meaningful attributes that characterize and provide significance to the objects represented in 3D. Segmentation is the process of grouping point clouds into multiple homogeneous regions with similar properties whereas classification is the step that labels these regions. The main goal of this paper is to analyse the most popular methodologies and algorithms to segment and classify 3D point clouds. Strong and weak points of the different solutions presented in literature or implemented in commercial software will be listed and shortly explained. For some algorithms, the results of the segmentation and classification is shown using real examples at different scale in the Cultural Heritage field. Finally, open issues and research topics will be discussed.",Conference Paper,"Final",Scopus,2-s2.0-85021757670
"Dick A.R., Torr P.H.S., Cipolla R.","Modelling and interpretation of architecture from several images",2004,"International Journal of Computer Vision",172,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042841708&doi=10.1023%2fB%3aVISI.0000029665.07652.61&partnerID=40&md5=ebf73444758ac3e738b55aec4d989254","This paper describes the automatic acquisition of three dimensional architectural models from short image sequences. The approach is Bayesian and model based. Bayesian methods necessitate the formulation of a prior distribution; however designing a generative model for buildings is a difficult task. In order to overcome this a building is described as a set of walls together with a 'Lego' kit of parameterised primitives, such as doors or windows. A prior on wall layout and a prior on the parameters of each primitive can then be defined. Part of this prior is learnt from training data and part comes from expert architects. The validity of the prior is tested by generating example buildings using MCMC and verifying that plausible buildings are generated under varying conditions. The same MCMC machinery can also be used for optimising the structure recovery, this time generating a range of possible solutions from the posterior. The fact that a range of solutions can be presented allows the user to select the best when the structure recovery is ambiguous.",Review,"Final",Scopus,2-s2.0-3042841708
"Kalogerakis E., Averkiou M., Maji S., Chaudhuri S.","3D Shape segmentation with projective convolutional networks",2017,"Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017",164,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042260380&doi=10.1109%2fCVPR.2017.702&partnerID=40&md5=f8890cc8eff827d87d6d12056cd6cd74","This paper introduces a deep architecture for segmenting 3D objects into their labeled semantic parts. Our architecture combines image-based Fully Convolutional Networks (FCNs) and surface-based Conditional Random Fields (CRFs) to yield coherent segmentations of 3D shapes. The image-based FCNs are used for efficient view-based reasoning about 3D object parts. Through a special projection layer, FCN outputs are effectively aggregated across multiple views and scales, then are projected onto the 3D object surfaces. Finally, a surface-based CRF combines the projected outputs with geometric consistency cues to yield coherent segmentations. The whole architecture (multi-view FCNs and CRF) is trained end-to-end. Our approach significantly outperforms the existing state-of-the-art methods in the currently largest segmentation benchmark (ShapeNet). Finally, we demonstrate promising segmentation results on noisy 3D shapes acquired from consumer-grade depth cameras. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85042260380
"BSI",[No title available],2013,"PAS 1192-2:2013: Specification for Information Management for the Capital/delivery Phase of Construction Projects Using Building Information Modelling",164,,[No abstract available],,"Final",Scopus,2-s2.0-84887062145
"Rabbani T., Van Den Heuvel F.","Efficient Hough transform for automatic detection of cylinders in point clouds",2005,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives",163,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970877112&partnerID=40&md5=4b9bc850142f2a4d9eda81a32a1e7b94","We present an efficient Hough transform for automatic detection of cylinders in point clouds. As cylinders are one of the most frequently used primitives for industrial design, automatic and robust methods for their detection and fitting are essential for reverse engineering from point clouds. The current methods employ automatic segmentation followed by geometric fitting, which requires a lot of manual interaction during modelling. Although Hough transform can be used for automatic detection of cylinders, the required 5D Hough space has a prohibitively high time and space complexity for most practical applications. We address this problem in this paper and present a sequential Hough transform for automatic detection of cylinders in point clouds. Our algorithm consists of two sequential steps of low dimensional Hough transforms. The first step, called Orientation Estimation, uses the Gaussian sphere of the input data and performs a 2D Hough Transform for finding strong hypotheses for the direction of cylinder axis. The second step of Position and Radius Estimation, consists of a 3D Hough transform for estimating cylinder position and radius. This sequential breakdown reduces the space and time complexity while retaining the advantages of robustness against outliers and multiple instances. The results of applying this algorithm to real data sets from two industrial sites are presented that demonstrate the effectiveness of this procedure for automatic cylinder detection. © 2005 International Society for Photogrammetry and Remote Sensing. All rights reserved.",Conference Paper,"Final",Scopus,2-s2.0-84970877112
"Kim V.G., Li W., Mitra N.J., Chaudhuri S., Di Verdi S., Funkhouser T.","Learning part-based templates from large collections of 3D shapes",2013,"ACM Transactions on Graphics",158,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880820276&doi=10.1145%2f2461912.2461933&partnerID=40&md5=a98ad714c0efc9a678bc107919efce6d","As large repositories of 3D shape collections continue to grow, understanding the data, especially encoding the inter-model similarity and their variations, is of central importance. For example, many data-driven approaches now rely on access to semantic segmentation information, accurate inter-model point-to-point correspondence, and deformation models that characterize the model collections. Existing approaches, however, are either supervised requiring manual labeling; or employ super-linear matching algorithms and thus are unsuited for analyzing large collections spanning many thousands of models.We propose an automatic algorithm that starts with an initial template model and then jointly optimizes for part segmentation, point-to-point surface correspondence, and a compact deformation model to best explain the input model collection. As output, the algorithm produces a set of probabilistic part-based templates that groups the original models into clusters of models capturing their styles and variations. We evaluate our algorithm on several standard datasets and demonstrate its scalability by analyzing much larger collections of up to thousands of shapes. Copyright © ACM 2013.",Article,"Final",Scopus,2-s2.0-84880820276
"Rusu R.B., Blodow N., Marton Z.C., Beetz M.","Close-range scene segmentation and reconstruction of 3D point cloud maps for mobile manipulation in domestic environments",2009,"2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2009",157,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-76249088726&doi=10.1109%2fIROS.2009.5354683&partnerID=40&md5=d5f3380980a7d8daf5cccecca18af811","In this paper we present a framework for 3D geometric shape segmentation for close-range scenes used in mobile manipulation and grasping, out of sensed point cloud data. Our proposed approach proposes a robust geometric mapping pipeline for large input datasets that extracts relevant objects useful for a personal robotic assistant to perform manipulation tasks. The objects are segmented out from partial views and a reconstructed model is computed by fitting geometric primitive classes such as planes, spheres, cylinders, and cones. The geometric shape coefficients are then used to reconstruct missing data. Residual points are resampled and triangulated, to create smooth decoupled surfaces that can be manipulated. The resulted map is represented as a hybrid concept and is comprised of 3D shape coefficients and triangular meshes used for collision avoidance in manipulation routines. © 2009 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-76249088726
"Carr J.C., Beatson R.K., McCallum B.C., Fright W.R., McLennan T.J., Mitchell T.J.","Smooth surface reconstruction from noisy range data",2003,"Proceedings of the 1st International Conference on Computer Graphics and Interactive Techniques in Australasia and South East Asia, GRAPHITE '03",156,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953211739&doi=10.1145%2f604471.604495&partnerID=40&md5=d790e7c29707cda8c64df101855c1bd2","This paper shows that scattered range data can be smoothed at low cost by fitting a Radial Basis Function (RBF) to the data and convolving with a smoothing kernel (low pass filtering). The RBF exactly describes the range data and interpolates across holes and gaps. The data is smoothed during evaluation of the RBF by simply changing the basic function. The amount of smoothing can be varied as required without having to fit a new RBF to the data. The key feature of our approach is that it avoids resampling the RBF on a fine grid or performing a numerical convolution. Furthermore, the computation required is independent of the extent of the smoothing kernel, i.e., the amount of smoothing. We show that particular smoothing kernels result in the applicability of fast numerical methods. We also discuss an alternative approach in which a discrete approximation to the smoothing kernel achieves similar results by adding new centres to the original RBF during evaluation. This approach allows arbitrary filter kernels, including anisotropic and spatially varying filters, to be applied while also using established fast evaluation methods. We illustrate both techniques with LIDAR laser scan data and noisy synthetic data. Copyright © 2003 by the Association for Computing Machinery, Inc.",Conference Paper,"Final",Scopus,2-s2.0-77953211739
"Wang C., Cho Y.K., Kim C.","Automatic BIM component extraction from point clouds of existing buildings for sustainability applications",2015,"Automation in Construction",155,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928163215&doi=10.1016%2fj.autcon.2015.04.001&partnerID=40&md5=7d2fa77c5aa1a0ff811ffd97ed438e3f","Building information models (BIMs) are increasingly being applied throughout a building's lifecycle for various applications, such as progressive construction monitoring and defect detection, building renovation, energy simulation, and building system analysis in the Architectural, Engineering, Construction, and Facility Management (AEC/FM) domains. In conventional approaches, as-is BIM is primarily manually created from point clouds, which is labor-intensive, costly, and time consuming. This paper proposes a method for automatically extracting building geometries from unorganized point clouds. The collected raw data undergo data downsizing, boundary detection, and building component categorization, resulting in the building components being recognized as individual objects and their visualization as polygons. The results of tests conducted on three collected as-is building data to validate the technical feasibility and evaluate the performance of the proposed method indicate that it can simplify and accelerate the as-is building model from the point cloud creation process. © 2015 Elsevier B.V.F.",Article,"Final",Scopus,2-s2.0-84928163215
"Jung J., Hong S., Jeong S., Kim S., Cho H., Hong S., Heo J.","Productive modeling for development of as-built BIM of existing indoor structures",2014,"Automation in Construction",154,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896541031&doi=10.1016%2fj.autcon.2014.02.021&partnerID=40&md5=da8b14909a907b5eefc4aa6bf59817eb","The as-built building information model (BIM) has a huge potential for enhancing the efficiency of building and maintenance operations. To facilitate existing-structure data acquisition for the as-built BIM, a terrestrial laser scanner, which is fast, simple to use, and yet highly accurate, is widely employed. However, as-built BIM creation of building interiors using scanned point clouds incurs critical difficulties: the complex design of indoor structures, not to mention obstacles, necessitates time-consuming manual operation and resultantly huge data sizes, which often leads to system slow-down or failure. To manage this problem, most of the recent and current research has looked to full automation; yet facility management personnel still rely on traditional field measurements because their qualitative results can only be obtained under ideal conditions or with some errors. Alternatively, in this paper, a more practical semi-automatic methodology for improved productivity of as-built BIM creation with respect to large and complex indoor environments is proposed. The proposed approach produces three-dimensional (3D) geometric drawings through three steps: segmentation for plane extraction, refinement for removal of noisy points, and boundary tracing for outline extraction. The experimental results for two test sites, a relatively simple corridor and a complex atrium, showed a high data-size reduction rate: to 3.8 and 4.3% of the original sizes, out of 51.5 and 111.5 million points, respectively. Based on the automatically produced geometric drawings and the remaining points, manual as-built BIM creation was conducted. Using the extracted lines as guides, each object and its relationship were more easily identified and modeled. At the same time, the great reduction in the point clouds' data sizes enabled the modeler, using the BIM software, to efficiently manipulate the geometric drawing without system slow-down or failure. The proposed approach was shown to be a potentially effective means of improving productivity and reliability in complex indoor as-built BIM production. © 2014 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84896541031
"Sorzano C.O.S., Vargas J., Montano A.P.","A survey of dimensionality reduction techniques",2014,"A Survey of Dimensionality Reduction Techniques",153,,[No abstract available],,"Final",Scopus,2-s2.0-84937487237
"Lai K., Bo L., Ren X., Fox D.","Sparse distance learning for object recognition combining RGB and depth information",2011,"Proceedings - IEEE International Conference on Robotics and Automation",153,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84455201478&doi=10.1109%2fICRA.2011.5980377&partnerID=40&md5=9c80328f01004bad9eb9443a86514af5","In this work we address joint object category and instance recognition in the context of RGB-D (depth) cameras. Motivated by local distance learning, where a novel view of an object is compared to individual views of previously seen objects, we define a view-to-object distance where a novel view is compared simultaneously to all views of a previous object. This novel distance is based on a weighted combination of feature differences between views. We show, through jointly learning perview weights, that this measure leads to superior classification performance on object category and instance recognition. More importantly, the proposed distance allows us to find a sparse solution via Group-Lasso regularization, where a small subset of representative views of an object is identified and used, with the rest discarded. This significantly reduces computational cost without compromising recognition accuracy. We evaluate the proposed technique, Instance Distance Learning (IDL), on the RGB-D Object Dataset, which consists of 300 object instances in 51 everyday categories and about 250,000 views of objects with both RGB color and depth. We empirically compare IDL to several alternative state-of-the-art approaches and also validate the use of visual and shape cues and their combination. © 2011 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84455201478
"Tomasi C., Manduchi R.","Bilateral filtering for gray and color images",1998,"Bilateral Filtering for Gray and Color Images",150,,[No abstract available],,"Final",Scopus,2-s2.0-35148864238
"van Ravenzwaaij D., Cassey P., Brown S.D.","A simple introduction to Markov Chain Monte–Carlo sampling",2018,"Psychonomic Bulletin and Review",145,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960417902&doi=10.3758%2fs13423-016-1015-8&partnerID=40&md5=91087ef38344d452b707165297721750","Markov Chain Monte–Carlo (MCMC) is an increasingly popular method for obtaining information about distributions, especially for estimating posterior distributions in Bayesian inference. This article provides a very basic introduction to MCMC sampling. It describes what MCMC is, and what it can be used for, with simple illustrative examples. Highlighted are some of the benefits and limitations of MCMC sampling, as well as different approaches to circumventing the limitations most likely to trouble cognitive scientists. © 2016, The Author(s).",Article,"Final",Scopus,2-s2.0-84960417902
"Oesau S., Lafarge F., Alliez P.","Indoor scene reconstruction using feature sensitive primitive extraction and graph-cut",2014,"ISPRS Journal of Photogrammetry and Remote Sensing",143,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896820022&doi=10.1016%2fj.isprsjprs.2014.02.004&partnerID=40&md5=5ee4f5e6274d1b7c788edf32d727479e","We present a method for automatic reconstruction of permanent structures, such as walls, floors and ceilings, given a raw point cloud of an indoor scene. The main idea behind our approach is a graph-cut formulation to solve an inside/outside labeling of a space partitioning. We first partition the space in order to align the reconstructed models with permanent structures. The horizontal structures are located through analysis of the vertical point distribution, while vertical wall structures are detected through feature preserving multi-scale line fitting, followed by clustering in a Hough transform space. The final surface is extracted through a graph-cut formulation that trades faithfulness to measurement data for geometric complexity. A series of experiments show watertight surface meshes reconstructed from point clouds measured on multi-level buildings. © 2014 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).",Article,"Final",Scopus,2-s2.0-84896820022
"Borenstein E., Ullman S.","Combined top-down/bottom-up segmentation",2008,"IEEE Transactions on Pattern Analysis and Machine Intelligence",132,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-56549121936&doi=10.1109%2fTPAMI.2007.70840&partnerID=40&md5=f98f74209abb210bd19b9ff8908a66fb","We construct a segmentation scheme that combines top-down with bottom-up processing. In the proposed scheme, segmentation and recognition are intertwined rather than proceeding in a serial manner. The top-down part applies stored knowledge about object shapes acquired through learning, whereas the bottom-up part creates a hierarchy of segmented regions based on uniformity criteria. Beginning with unsegmented training examples of class and non-class images, the algorithm constructs a bank of class-specific fragments and determines their figure-ground segmentation. This bank is then used to segment novel images in a top-down manner: the fragments are first used to recognize images containing class objects, and then to create a complete cover that best approximates these objects. The resulting segmentation is then integrated with bottom-up multi-scale grouping to better delineate the object boundaries. Our experiments, applied to a large set of four classes (horses, pedestrians, cars, faces), demonstrate segmentation results that surpass those achieved by previous top-down or bottom-up schemes. The main novel aspects of this work are the fragment learning phase, which efficiently learns the figure-ground labeling of segmentation fragments, even in training sets with high object and background variability; combining the top-down segmentation with bottom-up criteria to draw on their relative merits; and the use of segmentation to improve recognition. © 2008 IEEE.",Article,"Final",Scopus,2-s2.0-56549121936
"Adan A., Huber D.","3D reconstruction of interior wall surfaces under occlusion and clutter",2011,"Proceedings - 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission, 3DIMPVT 2011",131,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051993127&doi=10.1109%2f3DIMPVT.2011.42&partnerID=40&md5=2f0b1485c4119fdb3480856d42631d41","Laser scanners are often used to create 3D models of buildings for civil engineering applications. The current manual process is time-consuming and error-prone. This paper presents a method for using laser scanner data to model predominantly planar surfaces, such as walls, floors, and ceilings, despite the presence of significant amounts of clutter and occlusion, which occur frequently in natural indoor environments. Our goal is to recover the surface shape, detect and model any openings, and fill in the occluded regions. Our method identifies candidate surfaces for modeling, labels occluded surface regions, detects openings in each surface using supervised learning, and reconstructs the surface in the occluded regions. We evaluate the method on a large, highly cluttered data set of a building consisting of forty separate rooms. © 2011 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-80051993127
"Lai K., Fox D.","Object recognition in 3D point clouds using web data and domain adaptation",2010,"International Journal of Robotics Research",125,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954064287&doi=10.1177%2f0278364910369190&partnerID=40&md5=35224c1cab80ae7e681cc0d27f072d1a","In recent years, object detection has become an increasingly active field of research in robotics. An important problem in object detection is the availability of a sufficient amount of labeled training data to learn good classifiers. In this paper we show how to significantly reduce the need for manually labeled training data by leveraging data sets available on the World Wide Web. Specifically, we show how to use objects from Googles 3D Warehouse to train an object detection system for 3D point clouds collected by robots navigating through both urban and indoor environments. In order to deal with the different characteristics of the web data and the real robot data, we additionally use a small set of labeled point clouds and perform domain adaptation. Our experiments demonstrate that additional data taken from the 3D Warehouse along with our domain adaptation greatly improves the classification accuracy on real-world environments. © The Author(s), 2010.",Conference Paper,"Final",Scopus,2-s2.0-77954064287
"Anand A., Koppula H.S., Joachims T., Saxena A.","Contextually guided semantic labeling and search for three-dimensional point clouds",2013,"International Journal of Robotics Research",124,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872740146&doi=10.1177%2f0278364912461538&partnerID=40&md5=30d81ad289eb67a33062e2d7ab22de86","RGB-D cameras, which give an RGB image together with depths, are becoming increasingly popular for robotic perception. In this paper, we address the task of detecting commonly found objects in the three-dimensional (3D) point cloud of indoor scenes obtained from such cameras. Our method uses a graphical model that captures various features and contextual relations, including the local visual appearance and shape cues, object co-occurrence relationships and geometric relationships. With a large number of object classes and relations, the model's parsimony becomes important and we address that by using multiple types of edge potentials. We train the model using a maximum-margin learning approach. In our experiments concerning a total of 52 3D scenes of homes and offices (composed from about 550 views), we get a performance of 84.06% and 73.38% in labeling office and home scenes respectively for 17 object classes each. We also present a method for a robot to search for an object using the learned model and the contextual information available from the current labelings of the scene. We applied this algorithm successfully on a mobile robot for the task of finding 12 object classes in 10 different offices and achieved a precision of 97.56% with 78.43% recall.1 © The Author(s) 2012.",Article,"Final",Scopus,2-s2.0-84872740146
"Xiao J., Furukawa Y.","Reconstructing the World’s Museums",2014,"International Journal of Computer Vision",123,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920259397&doi=10.1007%2fs11263-014-0711-y&partnerID=40&md5=364c72f209d7c89b7cf425fb7831f5b8","Virtual exploration tools for large indoor environments (e.g. museums) have so far been limited to either blueprint-style 2D maps that lack photo-realistic views of scenes, or ground-level image-to-image transitions, which are immersive but ill-suited for navigation. On the other hand, photorealistic aerial maps would be a useful navigational guide for large indoor environments, but it is impossible to directly acquire photographs covering a large indoor environment from aerial viewpoints. This paper presents a 3D reconstruction and visualization system for automatically producing clean and well-regularized texture-mapped 3D models for large indoor scenes, from ground-level photographs and 3D laser points. The key component is a new algorithm called “inverse constructive solid geometry (CSG)” for reconstructing a scene with a CSG representation consisting of volumetric primitives, which imposes powerful regularization constraints. We also propose several novel techniques to adjust the 3D model to make it suitable for rendering the 3D maps from aerial viewpoints. The visualization system enables users to easily browse a large-scale indoor environment from a bird’s-eye view, locate specific room interiors, fly into a place of interest, view immersive ground-level panorama views, and zoom out again, all with seamless 3D transitions. We demonstrate our system on various museums, including the Metropolitan Museum of Art in New York City—one of the largest art galleries in the world. © 2014, Springer Science+Business Media New York.",Article,"Final",Scopus,2-s2.0-84920259397
"Frueh C., Zakhor A.","Constructing 3D city models by merging ground-based and airborne views",2003,"Proceedings of the IEEE Computer Society Conference on Computer  Vision and Pattern Recognition",123,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041438692&partnerID=40&md5=bb1d7d1d6b4c87378b77fe73cb76cbfe","In this paper, we present a fast approach to automated generation of textured 3D city models with both high details at ground level, and complete coverage for bird's-eye view. A close-range facade model is acquired at the ground level by driving a vehicle equipped with laser scanners and a digital camera under normal traffic conditions on public roads; a far-range Digital Surface Map (DSM), containing complementary roof and terrain shape, is created from airborne laser scans, then triangulated, and finally texture mapped with aerial imagery. The facade models are first registered with respect to the DSM by using Monte-Carlo-Localization, and then merged with the DSM by removing redundant parts and filling gaps. The developed algorithms are evaluated on a data set acquired in downtown Berkeley.",Conference Paper,"Final",Scopus,2-s2.0-0041438692
"McCormac J., Handa A., Leutenegger S., Davison A.J.","SceneNet RGB-D: Can 5M Synthetic Images Beat Generic ImageNet Pre-training on Indoor Segmentation?",2017,"Proceedings of the IEEE International Conference on Computer Vision",120,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041892894&doi=10.1109%2fICCV.2017.292&partnerID=40&md5=ca5504be9e45cca5580cd5d199f6d51b","We introduce SceneNet RGB-D, a dataset providing pixel-perfect ground truth for scene understanding problems such as semantic segmentation, instance segmentation, and object detection. It also provides perfect camera poses and depth data, allowing investigation into geometric computer vision problems such as optical flow, camera pose estimation, and 3D scene labelling tasks. Random sampling permits virtually unlimited scene configurations, and here we provide 5M rendered RGB-D images from 16K randomly generated 3D trajectories in synthetic layouts, with random but physically simulated object configurations. We compare the semantic segmentation performance of network weights produced from pretraining on RGB images from our dataset against generic VGG-16 ImageNet weights. After fine-tuning on the SUN RGB-D and NYUv2 real-world datasets we find in both cases that the synthetically pre-trained network outperforms the VGG-16 weights. When synthetic pre-training includes a depth channel (something ImageNet cannot natively provide) the performance is greater still. This suggests that large-scale high-quality synthetic RGB datasets with task-specific labels can be more useful for pretraining than real-world generic pre-training such as ImageNet. We host the dataset at http://robotvault. bitbucket.io/scenenet-rgbd.html. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85041892894
"Zeeshan Zia M., Stark M., Schiele B., Schindler K.","Detailed 3D representations for object recognition and modeling",2013,"IEEE Transactions on Pattern Analysis and Machine Intelligence",117,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884582487&doi=10.1109%2fTPAMI.2013.87&partnerID=40&md5=0be00d1f660be2458e3a0c0b38ea51e7","Geometric 3D reasoning at the level of objects has received renewed attention recently in the context of visual scene understanding. The level of geometric detail, however, is typically limited to qualitative representations or coarse boxes. This is linked to the fact that today's object class detectors are tuned toward robust 2D matching rather than accurate 3D geometry, encouraged by bounding-box-based benchmarks such as Pascal VOC. In this paper, we revisit ideas from the early days of computer vision, namely, detailed, 3D geometric object class representations for recognition. These representations can recover geometrically far more accurate object hypotheses than just bounding boxes, including continuous estimates of object pose and 3D wireframes with relative 3D positions of object parts. In combination with robust techniques for shape description and inference, we outperform state-of-the-art results in monocular 3D pose estimation. In a series of experiments, we analyze our approach in detail and demonstrate novel applications enabled by such an object class representation, such as fine-grained categorization of cars and bicycles, according to their 3D geometry, and ultrawide baseline matching. © 1979-2012 IEEE.",Article,"Final",Scopus,2-s2.0-84884582487
"Bosché F.","Plane-based registration of construction laser scans with 3D/4D building models",2012,"Advanced Engineering Informatics",115,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-83555160969&doi=10.1016%2fj.aei.2011.08.009&partnerID=40&md5=efe3ca2c8238b6c766f22a93ec18adba","With the development of building information modelling (BIM) and terrestrial laser scanning (TLS) in the architecture, engineering, construction and facility management (AEC/FM) industry, the registration of site laser scans and project 3D (BIM) models in a common coordinate system is becoming critical to effective project control. The co-registration of 3D datasets is normally performed in two steps: coarse registration followed by fine registration. Focusing on the coarse registration, model-scan registration has been well investigated in the past, but it is shown in this article that the context of the AEC/FM industry presents specific (1) constraints that make fully-automated registration very complex and often ill-posed, and (2) advantages that can be leveraged to develop simpler yet effective registration methods. This paper thus presents a novel semi-automated plane-based registration system for coarse registration of laser scanned 3D point clouds with project 3D models in the context of the AEC/FM industry. The system is based on the extraction of planes from the laser scanned point cloud and project 3D/4D model. Planes are automatically extracted from the 3D/4D model. For the point cloud data, two methods are investigated. The first one is fully automated, and the second is a semi-automated but effective one-click RANSAC-supported extraction method. In both cases, planes are then manually but intuitively matched by the user. Experiments, which compare the proposed system to software packages commonly used in the AEC/FM industry, demonstrate that at least as good registration quality can be achieved by the proposed system, in a simpler and faster way. It is concluded that, in the AEC/FM context, the proposed plane-based registration system is a compelling alternative to standard point-based registration techniques. © 2011 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-83555160969
"Hua B.-S., Pham Q.-H., Nguyen D.T., Tran M.-K., Yu L.-F., Yeung S.-K.","SceneNN: A scene meshes dataset with aNNotations",2016,"Proceedings - 2016 4th International Conference on 3D Vision, 3DV 2016",112,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011301107&doi=10.1109%2f3DV.2016.18&partnerID=40&md5=6e118ac12b2554bc75a6e71a9fb85388","Several RGB-D datasets have been publicized over the past few years for facilitating research in computer vision and robotics. However, the lack of comprehensive and fine-grained annotation in these RGB-D datasets has posed challenges to their widespread usage. In this paper, we introduce SceneNN, an RGB-D scene dataset consisting of 100 scenes. All scenes are reconstructed into triangle meshes and have per-vertex and per-pixel annotation. We further enriched the dataset with fine-grained information such as axis-aligned bounding boxes, oriented bounding boxes, and object poses. We used the dataset as a benchmark to evaluate the state-of-the-art methods on relevant research problems such as intrinsic decomposition and shape completion. Our dataset and annotation tools are available at http://www.scenenn.net. © 2016 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85011301107
"Dimitrov A., Golparvar-Fard M.","Segmentation of building point cloud models including detailed architectural/structural features and MEP systems",2015,"Automation in Construction",112,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926221525&doi=10.1016%2fj.autcon.2014.12.015&partnerID=40&md5=540b9cc0d94b782cf74cd5615dda9a61","Accurate and rapidly produced 3D models of the as-built environment can be significant assets for a variety of Engineering scenarios. Starting with a point cloud of a scene - generated using laser scanners or image-based reconstruction methods - the user must first identify collections of points that belong to individual surfaces, and then, fit surfaces and solid geometry objects appropriate for the analysis. When performed manually, this task is often prohibitively time consuming and, in response, several research groups have recently focused on developing methods for automating the modeling process. Due to the limitations of the data collection processes as well as the complexity of as-built scenes, automated 3D modeling still presents many challenges. To overcome existing limitations, in this paper, we propose a new region growing method for robust context-free segmentation of unordered point clouds based on geometrical continuities. In our method, the user sets a single parameter which accounts for the desired level of abstraction. We treat this parameter as a locally adaptive threshold to account for local context. Our method of segmentation starts with a multi-scale feature detection, describing surface roughness and curvature around each 3D point, and is followed by seed finding and region growing steps. Experimental results from seven challenging point clouds of the built environment demonstrate that our method can account for variability in point cloud density, surface roughness, curvature, and clutter within a single scene. © 2014 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84926221525
"Huang H., Brenner C., Sester M.","A generative statistical approach to automatic 3D building roof reconstruction from laser scanning data",2013,"ISPRS Journal of Photogrammetry and Remote Sensing",105,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874782123&doi=10.1016%2fj.isprsjprs.2013.02.004&partnerID=40&md5=ba1d877a8e90cd2b23bef1b974de3e95","This paper presents a generative statistical approach to automatic 3D building roof reconstruction from airborne laser scanning point clouds. In previous works, bottom-up methods, e.g., points clustering, plane detection, and contour extraction, are widely used. Due to the data artefacts caused by tree clutter, reflection from windows, water features, etc., the bottom-up reconstruction in urban areas may suffer from a number of incomplete or irregular roof parts. Manually given geometric constraints are usually needed to ensure plausible results. In this work we propose an automatic process with emphasis on top-down approaches. The input point cloud is firstly pre-segmented into subzones containing a limited number of buildings to reduce the computational complexity for large urban scenes. For the building extraction and reconstruction in the subzones we propose a pure top-down statistical scheme, in which the bottom-up efforts or additional data like building footprints are no more required. Based on a predefined primitive library we conduct a generative modeling to reconstruct roof models that fit the data. Primitives are assembled into an entire roof with given rules of combination and merging. Overlaps of primitives are allowed in the assembly. The selection of roof primitives, as well as the sampling of their parameters, is driven by a variant of Markov Chain Monte Carlo technique with specified jump mechanism. Experiments are performed on data-sets of different building types (from simple houses, high-rise buildings to combined building groups) and resolutions. The results show robustness despite the data artefacts mentioned above and plausibility in reconstruction. © 2013 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).",Article,"Final",Scopus,2-s2.0-84874782123
"Xiong X., Huber D.","Using context to create semantic 3D models of indoor environments",2010,"British Machine Vision Conference, BMVC 2010 - Proceedings",105,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898408564&doi=10.5244%2fC.24.45&partnerID=40&md5=5f2f9be775244aea0be398b894a62338","Semantic 3D models of buildings encode the geometry as well as the identity of key components of a facility, such as walls, floors, and ceilings. Manually constructing such a model is a time-consuming and error-prone process. Our goal is to automate this process using 3D point data from a laser scanner. Our hypothesis is that contextual information is important to reliable performance in unmodified environments, which are often highly cluttered. We use a Conditional Random Field (CRF) model to discover and exploit contextual information, classifying planar patches extracted from the point cloud data. We compare the results of our context-based CRF algorithm with a context-free method based on L2 norm regularized Logistic Regression (RLR). We find that using certain contextual information along with local features leads to better classification results. © 2010. The copyright of this document resides with its authors.",Conference Paper,"Final",Scopus,2-s2.0-84898408564
"Dave B., Buda A., Nurminen A., Främling K.","A framework for integrating BIM and IoT through open standards",2018,"Automation in Construction",104,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051379498&doi=10.1016%2fj.autcon.2018.07.022&partnerID=40&md5=9daa502dc1dc7080a41fcd01842cb455","The built environment provides significant opportunities for IoT (Internet of Things) deployment, and can be singled out as one of the most important aspects for IoT related research. While the IoT deployment in the built environment is growing exponentially, there exists a gap in integrating these two in a systematic way through open standards and systems. From technological perspective, there is a need for convergence of diverse fields ranging from Building Information Systems and Building Services to Building Automation Systems, and IoT devices and finally the end user services to develop smart, user oriented applications. This paper outlines the efforts to develop a platform that integrates the built environment data with IoT sensors in a campus wide, web based system called Otaniemi3D that provides information about energy usage, occupancy and user comfort by integrating Building Information Models and IoT devices through open messaging standards (O-MI and O-DF) and IFC models. The paper describes the design criteria, the system architecture, the workflow and a proof of concept with potential use cases that integrate IoT with the built environment. Initial results show that both the end users and other research groups can benefit from such platforms by either consuming the data in their daily life or using the data for more advance research. © 2018 The Authors",Article,"Final",Scopus,2-s2.0-85051379498
"Snyder W.E., Qi H.",[No title available],2004,"Machine Vision",103,,[No abstract available],,"Final",Scopus,2-s2.0-33750284375
"Dai A., Ritchie D., Bokeloh M., Reed S., Sturm J., Niebner M.","ScanComplete: Large-Scale Scene Completion and Semantic Segmentation for 3D Scans",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",102,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056788236&doi=10.1109%2fCVPR.2018.00481&partnerID=40&md5=7ab6bbb1e29f486af1ba9eca9e6d0318","We introduce ScanComplete, a novel data-driven approach for taking an incomplete 3D scan of a scene as input and predicting a complete 3D model along with per-voxel semantic labels. The key contribution of our method is its ability to handle large scenes with varying spatial extent, managing the cubic growth in data size as scene size increases. To this end, we devise a fully-convolutional generative 3D CNN model whose filter kernels are invariant to the overall scene size. The model can be trained on scene subvolumes but deployed on arbitrarily large scenes at test time. In addition, we propose a coarse-to-fine inference strategy in order to produce high-resolution output while also leveraging large input context sizes. In an extensive series of experiments, we carefully evaluate different model design choices, considering both deterministic and probabilistic models for completion and semantic inference. Our results show that we outperform other methods not only in the size of the environments handled and processing efficiency, but also with regard to completion quality and semantic segmentation performance by a significant margin. © 2018 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85056788236
"Bosché F., Guillemet A., Turkan Y., Haas C.T., Haas R.","Tracking the built status of MEP works: Assessing the value of a Scan-vs-BIM system",2014,"Journal of Computing in Civil Engineering",97,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902439119&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000343&partnerID=40&md5=6112d40443ae46f2617e9d1e8a90e802","Mechanical, electrical, and plumbing (MEP) works constitute a large portion of construction costs and thus need to be appropriately tracked. Assessment of the built status of MEP works in construction projects is however typically limited to subcontractor claims augmented and contrasted with periodic manual inspection. A more detailed manual inspection is costly and not considered worthwhile on most projects. Within a Scan-vs-BIM object recognition framework, three-dimensional laser scanning and project 3D/4D BIM models jointly offer the opportunity for a frequent, detailed, and semantically rich assessment of as-built status of construction projects at a cost that continues to decline. This potential has already been demonstrated for tracking structural works, but remains to be assessed in regard to other work sections, in particular MEP works. This paper explores that opportunity. A Scan-vs-BIM processing system is described with some enhancements over previous works. It is then tested with a representative and challenging case study of the construction of a utility corridor in a university engineering building. The results indicate that the proposed system is significantly challenged when tracking MEP systems constructed using traditional on-site fabrication, due to changes or adjustments made on-site that lead to actual component layouts varying in comparison to designed layouts. This performance could be revisited in cases where off-site prefabrication and preassembly is implemented. The results nonetheless lead the authors to propose a novel data processing system (conceptually described in this paper) integrating Scan-vs-BIM and Scan-to-BIM approaches. This system should provide superior performance over existing systems, enabling automated and robust quality control (including the estimation of the emerging performance metric percent built as designed) and delivery of true as-built BIM models to facility owners and managers. © 2014 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84902439119
"Belsky M., Sacks R., Brilakis I.","Semantic Enrichment for Building Information Modeling",2016,"Computer-Aided Civil and Infrastructure Engineering",94,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959473792&doi=10.1111%2fmice.12128&partnerID=40&md5=ffd52fbb199c0e06b1e302a331dd40d5","Significant difficulties remain in exchanging information between building information modeling (BIM) tools. The industry foundation classes (IFC) exchange schema is too generic to capture the full semantic meaning needed for direct use by different construction project stakeholders' BIM tools. Although BIM standards that prescribe model view definitions (MVD) for domain-specific exchanges are under development, insufficient semantic definition of exchanges prevents achievement of the full potential of BIM through seamless interoperability. We propose an innovative approach for supplementing an IFC exchange file with semantically useful concepts inferred from the explicit and implicit information contained in the building model. A prototype software was implemented to test the applicability of the approach. It consists of a rule-processing engine and allows composition of inference rule-sets that can be tailored for different domains. The tests demonstrate semantic enrichment with precast concrete building models, adding inferred joint, slab aggregation and connection concepts. © 2016 Computer-Aided Civil and Infrastructure Engineering.",Article,"Final",Scopus,2-s2.0-84959473792
"Steder B., Grisetti G., Burgard W.","Robust place recognition for 3D range data based on point features",2010,"Proceedings - IEEE International Conference on Robotics and Automation",94,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955803543&doi=10.1109%2fROBOT.2010.5509401&partnerID=40&md5=a73847d37690610173fb31cdbc45c69b","The problem of place recognition appears in different mobile robot navigation problems including localization, SLAM, or change detection in dynamic environments. Whereas this problem has been studied intensively in the context of robot vision, relatively few approaches are available for three-dimensional range data. In this paper, we present a novel and robust method for place recognition based on range images. Our algorithm matches a given 3D scan against a database using point features and scores potential transformations by comparing significant points in the scans. A further advantage of our approach is that the features allow for a computation of the relative transformations between scans which is relevant for registration processes. Our approach has been implemented and tested on different 3D data sets obtained outdoors. In several experiments we demonstrate the advantages of our approach also in comparison to existing techniques. ©2010 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-77955803543
"Hackel T., Wegner J.D., Schindler K.","Contour detection in unstructured 3D point clouds",2016,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",93,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986287982&doi=10.1109%2fCVPR.2016.178&partnerID=40&md5=98a604573bbc2339ab83733830f73b62","We describe a method to automatically detect contours, i.e. lines along which the surface orientation sharply changes, in large-scale outdoor point clouds. Contours are important intermediate features for structuring point clouds and converting them into high-quality surface or solid models, and are extensively used in graphics and mapping applications. Yet, detecting them in unstructured, inhomogeneous point clouds turns out to be surprisingly difficult, and existing line detection algorithms largely fail. We approach contour extraction as a two-stage discriminative learning problem. In the first stage, a contour score for each individual point is predicted with a binary classifier, using a set of features extracted from the point's neighborhood. The contour scores serve as a basis to construct an overcomplete graph of candidate contours. The second stage selects an optimal set of contours from the candidates. This amounts to a further binary classification in a higher-order MRF, whose cliques encode a preference for connected contours and penalize loose ends. The method can handle point clouds > 107 points in a couple of minutes, and vastly outperforms a baseline that performs Canny-style edge detection on a range image representation of the point cloud. © 2016 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84986287982
"Sacks R., Kaner I., Eastman C.M., Jeong Y.-S.","The Rosewood experiment - Building information modeling and interoperability for architectural precast facades",2010,"Automation in Construction",92,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950862404&doi=10.1016%2fj.autcon.2009.11.012&partnerID=40&md5=8952cecf113384c1c2776f3341db12a0","The Rosewood experiment examined building information modeling (BIM) and product data exchange in the design and fabrication of architectural precast façades. The façade panels of a 16 story office building were designed and fabricated using traditional CAD, while a parallel workflow was performed independently using BIM tools. No limitations were encountered in designing and detailing of precast façade pieces with current software. Production of the same set of drawings showed a productivity gain of 57% over the CAD process. However, the data exchanges between architectural and precast engineering systems were incomplete and inconsistent, confirming the need for BIM exchange standards. The existing Industry Foundation Classes schema (IFC version 2x3) lacks precast-specific entities and property sets. The majority of the difficulties can be traced to a loss in translation of semantic meaning for the objects exchanged. © 2009 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-77950862404
"Kwon S.-W., Bosche F., Kim C., Haas C.T., Liapi K.A.","Fitting range data to primitives for rapid local 3D modeling using sparse range point clouds",2004,"Automation in Construction",90,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0347411213&doi=10.1016%2fj.autcon.2003.08.007&partnerID=40&md5=eedc044d02cb6950bb13734a9c6fefb5","Techniques to rapidly model local spaces, using 3D range data, can enable implementation of: (1) real-time obstacle avoidance for improved safety, (2) advanced automated equipment control modes, and (3) as-built data acquisition for improved quantity tracking, engineering, and project control systems. The objective of the research reported here was to develop rapid local spatial modeling tools. Algorithms for fitting sparse range point clouds to geometric primitives such as spheres, cylinders, and cuboids have been developed as well as methods for merging primitives into assemblies. Results of experiments are presented and practical usage and limitations are discussed. © 2003 Elsevier B.V. All rights reserved.",Conference Paper,"Final",Scopus,2-s2.0-0347411213
"Qi C.R., Su H., Mo K., Guibas L.J.","Pointnet: Deep learning on point sets for 3d classification and segmentation",2016,"CVPR",89,,[No abstract available],,"Final",Scopus,2-s2.0-85046645498
"Greenspan M., Godin G.","A nearest neighbor method for efficient ICP",2001,"Proceedings of International Conference on 3-D Digital Imaging and Modeling, 3DIM",88,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941004262&doi=10.1109%2fIM.2001.924426&partnerID=40&md5=3ae1efaa825d141c3a9a5996b678bf6d","A novel solution is presented to the Nearest Neighbor Problem that is specifically tailored for determining correspondences within the Iterative Closest Point Algorithm. The reference point set P is preprocessed by calculating for each point p→i∈P that neighborhood of points which lie within a certain distance ε of p→i. The points within each ε-neighborhood are sorted by increasing distance to their respective p→i. At runtime, the correspondences are tracked across iterations, and the previous correspondence is used as an estimate of the current correspondence. If the estimate satifies a constraint, called the Spherical Constraint, then the nearest neighbor falls within the ε-neighborhood of the estimate. A novel theorem, the Ordering Theorem, is presented which allows the Triangle Inequality to efficiently prune points from the sorted ε-neighborhood from further consideration. The method has been implemented and is demonstrated to be more efficient than both the k-d tree and Elias methods. After ∼40 iterations, fewer than 2 distance calculations were required on average per correspondence, which is close to the theoretical minimum of 1. Furthermore, after 20 iterations the time expense per iteration was demonstrated to be negligibly more than simply looping through the points. © 2001 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84941004262
"Munoz D., Vandapel N., Hebert M.","Directional associative Markov Network for 3-D point cloud classification",2008,"4th International Symposium on 3D Data Processing, Visualization and Transmission, 3DPVT 2008 - Proceedings",86,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923094225&partnerID=40&md5=58347191ef5a3024c135465957fe1e7b","In this paper we address the problem of automated three dimensional point cloud interpretation. This problem is important for various tasks from environment modeling to obstacle avoidance for autonomous robot navigation. In addition to locally extracted features, classifiers need to utilize contextual information in order to perform well. A popular approach to account for context is to utilize the Markov Random Field framework. One recent variant that has successfully been used for the problem considered is the Associative Markov Network (AMN). We extend the AMN model to learn directionality in the clique potentials, resulting in a new anisotropic model that can be efficiently learned using the subgradient method. We validate the proposed approach using data collected from different range sensors and show better performance against standard AMN and Support Vector Machine algorithms. © 2008 Georgia Institute of Technology.",Conference Paper,"Final",Scopus,2-s2.0-84923094225
"Riveiro B., DeJong M.J., Conde B.","Automated processing of large point clouds for structural health monitoring of masonry arch bridges",2016,"Automation in Construction",83,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960402665&doi=10.1016%2fj.autcon.2016.02.009&partnerID=40&md5=5c92b3f73bf65d8352f84a693a17702a","Laser scanning technology is gaining popularity in a wide range of applications due to the increasing accuracy and speed at which data can be collected and an increase in laser scan data processing tools. Nevertheless, manual operations for specific applications are time consuming and can require high-performance computers to produce suitable models for further operations. Thus, laser scan data are underused in the civil engineering community. New procedures that automate the data processing for specific but repetitive infrastructure typologies are required to make full use of the technology as a basic tool for infrastructure assessment and asset management. This paper presents a new method for fully automated point cloud segmentation of masonry arch bridges. The method efficiently creates segmented, spatially related and organized point clouds, which each contain the relevant geometric data for a particular component (pier, arch, spandrel wall, etc.) of the structure. The segmentation is based in the combination of a heuristic approach and image processing tools adapted to voxel structures. The proposed methodology provides the essential processed data required for structural health monitoring of masonry arch bridges based on geometric anomalies. The method was validated using a representative sample of masonry arch bridges. The results demonstrate that this tool can provide data for further structural operations without requiring neither training in laser scanning technology nor high-performance computers for such data processing. © 2016 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84960402665
"Kim C., Kim C., Son H.","Fully automated registration of 3D data to a 3D CAD model for project progress monitoring",2013,"Automation in Construction",83,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884500230&doi=10.1016%2fj.autcon.2013.01.005&partnerID=40&md5=4f212c5b87def5fb207492e98fc11a06","Alignment of the 3D data with the 3D CAD model allows for analysis of the progress of the construction project or retrieval of the desired 3D object model for use in 3D as-built modeling. The aim of this study was to propose a fully automated registration process that allows for alignment of the 3D data with the 3D CAD model. The resulting process encompasses three pre-processing steps: point cloud representation, noise filtering, and data re-sampling. Then, after the pre-processing stage, a two-step global-to-local registration procedure is applied: PCA-based global registration followed by a local registration technique that uses ICP and the Levenberg-Marquardt algorithm. The proposed process was tested through a field experiment. The experimental results demonstrate that the proposed process is not only capable of fully automating the registration of 3D data to a 3D CAD model but also beneficial for use in project progress monitoring. © 2013 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84884500230
"Koch C., Paal S., Rashidi A., Zhu Z., König M., Brilakis I.","Achievements and challenges in machine vision-based inspection of large concrete structures",2014,"Advances in Structural Engineering",79,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899409100&doi=10.1260%2f1369-4332.17.3.303&partnerID=40&md5=dc0c2b8310f34c047e6935a4c14137c2","Large concrete structures need to be inspected in order to assess their current physical and functional state, to predict future conditions, to support investment planning and decision making, and to allocate limited maintenance and rehabilitation resources. Current procedures in condition and safety assessment of large concrete structures are performed manually leading to subjective and unreliable results, costly and time-consuming data collection, and safety issues. To address these limitations, automated machine vision-based inspection procedures have increasingly been proposed by the research community. This paper presents current achievements and open challenges in vision-based inspection of large concrete structures. First, the general concept of Building Information Modeling is introduced. Then, vision-based 3D reconstruction and as-built spatial modeling of concrete civil infrastructure are presented. Following that, the focus is set on structural member recognition as well as on concrete damage detection and assessment exemplified for concrete columns. Although some challenges are still under investigation, it can be concluded that vision-based inspection methods have significantly improved over the last 10 years, and now, as-built spatial modeling as well as damage detection and assessment of large concrete structures have the potential to be fully automated.",Article,"Final",Scopus,2-s2.0-84899409100
"Yang J., Shi Z., Wu Z.","Vision-based action recognition of construction workers using dense trajectories",2016,"Advanced Engineering Informatics",78,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966925836&doi=10.1016%2fj.aei.2016.04.009&partnerID=40&md5=e3029100250fdc2761e5e12d4b6d47f0","Wide spread monitoring cameras on construction sites provide large amount of information for construction management. The emerging of computer vision and machine learning technologies enables automated recognition of construction activities from videos. As the executors of construction, the activities of construction workers have strong impact on productivity and progress. Compared to machine work, manual work is more subjective and may differ largely in operation flow and productivity among different individuals. Hence only a handful of work studies on vision based action recognition of construction workers. Lacking of publicly available datasets is one of the main reasons that currently hinder advancement. The paper studies worker actions comprehensively, abstracts 11 common types of actions from 5 kinds of trades and establishes a new real world video dataset with 1176 instances. For action recognition, a cutting-edge video description method, dense trajectories, has been applied. Support vector machines are integrated with a bag-of-features pipeline for action learning and classification. Performances on multiple types of descriptors (Histograms of Oriented Gradients - HOG, Histograms of Optical Flow - HOF, Motion Boundary Histogram - MBH) and their combination have been evaluated. Discussion on different parameter settings and comparison to the state-of-the-art method are provided. Experimental results show that the system with codebook size 500 and MBH descriptor has achieved an average accuracy of 59% for worker action recognition, outperforming the state-of-the-art result by 24%. © 2016 Elsevier Ltd.",Article,"Final",Scopus,2-s2.0-84966925836
"Walsh S.B., Borello D.J., Guldur B., Hajjar J.F.","Data processing of point clouds for object detection for structural engineering applications",2013,"Computer-Aided Civil and Infrastructure Engineering",78,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880146006&doi=10.1111%2fmice.12016&partnerID=40&md5=4543f3fcad9d1ceed57cadbb570230e9","This research investigates the use of high-resolution three-dimensional terrestrial laser scanners as tools to capture geometric range data of complex scenes for structural engineering applications. Laser scanning technology is continuously improving, with commonly available scanners now able to capture over 1,000,000 points per second with an accuracy of ∼0.1 mm. This research focuses on developing the foundation toward the use of laser scanning to structural engineering applications, including structural health monitoring, collapse assessment, and post-hazard response assessment. One of the keys to this work is to establish a process for extracting important information from raw laser-scanned data sets such as the location, orientation, and size of objects in a scene, and location of damaged regions on a structure. A methodology for processing range data to identify objects in the scene is presented. Previous work in this area has created an initial foundation of basic data processing steps. Existing algorithms, including sharp feature detection and segmentation are implemented and extended in this work. Additional steps to remove extraneous and outlying points are added. Object detection based on a predefined library is developed allowing generic description of objects. The algorithms are demonstrated on synthetic scenes as well as validated on range data collected from an experimental test specimen and a collapsed bridge. The accuracy of the object detection is presented, demonstrating the applicability of the methodology. These additional steps and modifications to existing algorithms are presented to advance the performance of data processing on laser scan range data sets for future application in structural engineering applications such as robust determination of damage location and finite element modeling. © 2013 Computer-Aided Civil and Infrastructure Engineering.",Article,"Final",Scopus,2-s2.0-84880146006
"Behley J., Steinhage V., Cremers A.B.","Performance of histogram descriptors for the classification of 3D laser range data in urban environments",2012,"Proceedings - IEEE International Conference on Robotics and Automation",77,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864421786&doi=10.1109%2fICRA.2012.6225003&partnerID=40&md5=5085408106ed03d1a068bb8678a59318","The selection of suitable features and their parameters for the classification of three-dimensional laser range data is a crucial issue for high-quality results. In this paper we compare the performance of different histogram descriptors and their parameters on three urban datasets recorded with various sensors - sweeping SICK lasers, tilting SICK lasers and a Velodyne 3D laser range scanner. These descriptors are 1D, 2D, and 3D histograms capturing the distribution of normals or points around a query point. We also propose a novel histogram descriptor, which relies on the spectral values in different scales. We argue that choosing a larger support radius and a z-axis based global reference frame/axis can boost the performance of all kinds of investigated classification models significantly. The 3D histograms relying on the point distribution, normal orientations, or spectral values, turned out to be the best choice for the classification in urban environments. © 2012 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84864421786
"Lee J., Son H., Kim C., Kim C.","Skeleton-based 3D reconstruction of as-built pipelines from laser-scan data",2013,"Automation in Construction",75,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884499636&doi=10.1016%2fj.autcon.2013.05.009&partnerID=40&md5=e4710df610a66f183e4fedbe0631fe7e","There has been a growing demand for an as-built 3D pipeline model. Although several studies on automation of the process of reconstruction of as-built 3D pipelines have been carried out, previous approaches have been limited to the generation of only a portion of an entire 3D pipeline. The aim of this study was to propose an automated approach to the generation of as-built 3D pipeline models of entire pipelines composed of straight pipes, elbows, and tee pipes from laser-scan data. First, the skeletons of individual pipelines are extracted. Then the extracted skeletons are segmented into their individual components, and a set of parameters for them are calculated. The experimental results show that the proposed approach is robust to incompleteness of the laser-scan data, as well as to noise and to density variations in the data. As a result, the proposed method enables the generation of reliable as-built 3D pipeline models. © 2013 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84884499636
"Poullis C.","A framework for automatic modeling from point cloud data",2013,"IEEE Transactions on Pattern Analysis and Machine Intelligence",74,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884573272&doi=10.1109%2fTPAMI.2013.64&partnerID=40&md5=6768d5fbdd4c0fff18306c0cae893dc9","We propose a complete framework for the automatic modeling from point cloud data. Initially, the point cloud data are preprocessed into manageable datasets, which are then separated into clusters using a novel two-step, unsupervised clustering algorithm. The boundaries extracted for each cluster are then simplified and refined using a fast energy minimization process. Finally, three-dimensional models are generated based on the roof outlines. The proposed framework has been extensively tested, and the results are reported. © 1979-2012 IEEE.",Article,"Final",Scopus,2-s2.0-84884573272
"Awwad T.M., Zhu Q., Du Z., Zhang Y.","An improved segmentation approach for planar surfaces from unstructured 3D point clouds",2010,"Photogrammetric Record",74,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951661846&doi=10.1111%2fj.1477-9730.2009.00564.x&partnerID=40&md5=54479e19beb1a07d5294beb2d7d897c0","The extraction of object features from massive unstructured point clouds with different local densities, especially in the presence of random noisy points, is not a trivial task even if that feature is a planar surface. Segmentation is the most important step in the feature extraction process. In practice, most segmentation approaches use geometrical information to segment the 3D point cloud. The features generally include the position of each point (X, Y and Z), locally estimated surface normals and residuals of best fitting surfaces; however, these features could be affected by noisy points and in consequence directly affect the segmentation results. Therefore, massive unstructured and noisy point clouds also lead to bad segmentation (over-segmentation, under-segmentation or no segmentation). While the RANSAC (random sample consensus) algorithm is effective in the presence of noise and outliers, it has two significant disadvantages, namely, its efficiency and the fact that the plane detected by RANSAC may not necessarily belong to the same object surface; that is, spurious surfaces may appear, especially in the case of parallel-gradual planar surfaces such as stairs. The innovative idea proposed in this paper is a modification for the RANSAC algorithm called Seq-NV-RANSAC. This algorithm checks the normal vector (NV) between the existing point clouds and the hypothesised RANSAC plane, which is created by three random points, under an intuitive threshold value. After extracting the first plane, this process is repeated sequentially (Seq) and automatically, until no planar surfaces can be extracted from the remaining points under the existing threshold value. This prevents the extraction of spurious surfaces, brings an improvement in quality to the computed attributes and increases the degree of automation of surface extraction. Thus the best fit is achieved for the real existing surfaces. © 2010 The Authors. Journal Compilation © 2010 The Remote Sensing and Photogrammetry Society and Blackwell Publishing Ltd.",Article,"Final",Scopus,2-s2.0-77951661846
"Ochmann S., Vock R., Klein R.","Automatic reconstruction of fully volumetric 3D building models from oriented point clouds",2019,"ISPRS Journal of Photogrammetry and Remote Sensing",72,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063442343&doi=10.1016%2fj.isprsjprs.2019.03.017&partnerID=40&md5=5cf9d1476f8ef76576bea4b3e2454e39","We present a novel method for reconstructing parametric, volumetric, multi-story building models from unstructured, unfiltered indoor point clouds with oriented normals by means of solving an integer linear optimization problem. Our approach overcomes limitations of previous methods in several ways: First, we drop assumptions about the input data such as the availability of separate scans as an initial room segmentation. Instead, a fully automatic room segmentation and outlier removal is performed on the unstructured point clouds. Second, restricting the solution space of our optimization approach to arrangements of volumetric wall entities representing the structure of a building enforces a consistent model of volumetric, interconnected walls fitted to the observed data instead of unconnected, paper-thin surfaces. Third, we formulate the optimization as an integer linear programming problem which allows for an exact solution instead of the approximations achieved with most previous techniques. Lastly, our optimization approach is designed to incorporate hard constraints which were difficult or even impossible to integrate before. We evaluate and demonstrate the capabilities of our proposed approach on a variety of complex real-world point clouds. © 2019",Article,"Final",Scopus,2-s2.0-85063442343
"Olsen M.J., Roe G.V., Glennie C., Persi F., Reedy M., Hurwitz D., Williams K., Tuss H., Squellati A., Knodler M.","""Guidelines for the use of mobile LiDAR in transportation applications""",2013,"Guidelines for the Use of Mobile LIDAR in Transportation Applications",72,,[No abstract available],,"Final",Scopus,2-s2.0-84884685158
"Kjer H.M., Wilm J.","Evaluation of surface registration algorithms for PET motion correction",2010,"Evaluation of Surface Registration Algorithms for PET Motion Correction",72,,[No abstract available],,"Final",Scopus,2-s2.0-84870817734
"Valero E., Adán A., Cerrada C.","Automatic method for building indoor boundary models from dense point clouds collected by laser scanners",2012,"Sensors (Switzerland)",71,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871677181&doi=10.3390%2fs121216099&partnerID=40&md5=f8a1c49af3a3651b10ead594a2fe4a78","In this paper we present a method that automatically yields Boundary Representation Models (B-rep) for indoors after processing dense point clouds collected by laser scanners from key locations through an existing facility. Our objective is particularly focused on providing single models which contain the shape, location and relationship of primitive structural elements of inhabited scenarios such as walls, ceilings and floors. We propose a discretization of the space in order to accurately segment the 3D data and generate complete B-rep models of indoors in which faces, edges and vertices are coherently connected. The approach has been tested in real scenarios with data coming from laser scanners yielding promising results. We have deeply evaluated the results by analyzing how reliably these elements can be detected and how accurately they are modeled. © 2012 by the authors; licensee MDPI, Basel, Switzerland.",Article,"Final",Scopus,2-s2.0-84871677181
"Triebel R., Kersting K., Burgard W.","Robust 3D scan point classification using associative Markov networks",2006,"Proceedings - IEEE International Conference on Robotics and Automation",71,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845652336&doi=10.1109%2fROBOT.2006.1642094&partnerID=40&md5=65608a564305efb8a65f5dad4d1c58b9","In this paper we present an efficient technique to learn Associative Markov Networks (AMNs) for the segmentation of 3D scan data. Our technique is an extension of the work recently presented by Anguelov et al. [1], in which AMNs are applied and the learning is done using max-margin optimization. In this paper we show that by adaptively reducing the training data, the training process can be performed much more efficiently while still achieving good classification results. The reduction is obtained by utilizing kd-trees and pruning them appropriately. Our algorithm does not require any additional parameters and yields an abstraction of the training data. In experiments with real data collected from a mobile outdoor robot we demonstrate that our approach yields accurate segmentations. ©2006 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-33845652336
"Rvachev V.L.",[No title available],1974,"Methods of Logic Algebra in Mathematical Physics",71,,[No abstract available],,"Final",Scopus,2-s2.0-0012981733
"Limberger F.A., Oliveira M.M.","Real-time detection of planar regions in unorganized point clouds",2015,"Pattern Recognition",68,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925356037&doi=10.1016%2fj.patcog.2014.12.020&partnerID=40&md5=d7611fec29c430845d83971a59f13bd5","Automatic detection of planar regions in point clouds is an important step for many graphics, image processing, and computer vision applications. While laser scanners and digital photography have allowed us to capture increasingly larger datasets, previous techniques are computationally expensive, being unable to achieve real-time performance for datasets containing tens of thousands of points, even when detection is performed in a non-deterministic way. We present a deterministic technique for plane detection in unorganized point clouds whose cost is O(nlogn) in the number of input samples. It is based on an efficient Hough-transform voting scheme and works by clustering approximately co-planar points and by casting votes for these clusters on a spherical accumulator using a trivariate Gaussian kernel. A comparison with competing techniques shows that our approach is considerably faster and scales significantly better than previous ones, being the first practical solution for deterministic plane detection in large unorganized point clouds. © 2015 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84925356037
"Laefer D.F., Truong-Hong L., Carr H., Singh M.","Crack detection limits in unit based masonry with terrestrial laser scanning",2014,"NDT and E International",68,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890779641&doi=10.1016%2fj.ndteint.2013.11.001&partnerID=40&md5=a5cbd3d34ce352497f042f62b1ff7f72","This paper presents the fundamental mathematics to determine the minimum crack width detectable with a terrestrial laser scanner in unit-based masonry. Orthogonal offset, interval scan angle, crack orientation, and crack depth are the main parameters. The theoretical work is benchmarked against laboratory tests using 4 samples with predesigned crack widths of 1-7 mm scanned at orthogonal distances of 5.0-12.5 m and at angles of 0 -30. Results showed that absolute errors of crack width were mostly less than 1.37 mm when the orthogonal distance varied 5.0-7.5 m but significantly increased for greater distances. The orthogonal distance had a disproportionately negative effect compared to the scan angle. © 2013 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84890779641
"Masuda T.","Registration and integration of multiple range images by matching signed distance fields for object shape modeling",2002,"Computer Vision and Image Understanding",66,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0043031061&doi=10.1006%2fcviu.2002.0982&partnerID=40&md5=902adc9b92d83f17516926c7690a5fed","Modeling object shapes from multiple range images requires three processes: correction of measurement errors, registration of data shapes, and integrating them as a unified shape representation. We propose a method by which these tasks can be solved simultaneously. Discrete samples of the signed distance field (SDF) of the object surface are used as the shape representation. If the data shapes are registered correctly, the SDFs should match in the common coordinate system. The data shapes are first integrated by averaging the data SDFs assuming that they are roughly pre-registered. Then, each data shape is registered to the integrated shape by estimating the optimal transformation. Integration and registration are alternately iterated until the input shapes are properly registered to the integrated shape. Weighting values are controlled to reject outliers derived from measurement errors and wrong correspondences. The proposed method does not suffer from cumulative registration errors because all data shapes are registered to the integrated shape. From the SDF shape representation, a polygon surface model is directly generated. The method was tested on synthetic and real range images.",Article,"Final",Scopus,2-s2.0-0043031061
"Gould S., Baumstarck P., Quigley M., Ng A.Y., Koller D.","Integrating visual and range data for robotic object detection",2008,"ECCV Workshop on Multi-camera and Multi-modal Sensor Fusion Algorithms and Applications (M2SFA2)",65,,[No abstract available],,"Final",Scopus,2-s2.0-76249104768
"Liu Y., Xiong Y.","Automatic segmentation of unorganized noisy point clouds based on the Gaussian map",2008,"CAD Computer Aided Design",64,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-44249120508&doi=10.1016%2fj.cad.2008.02.004&partnerID=40&md5=e0001e25e0b43e0c6760fd756078badb","A nonparametric clustering algorithm, called cell mean shift (CMS), is developed to extract clusters of a set of points on the Gaussian sphere S2. It is computationally more efficient than the traditional mean shift (MS). Based on the singular value decomposition, the dimensional analysis is introduced to classify these clusters into point-, curve-, and area-form clusters. Each cluster is the Gaussian image of a set of points which will be examined by a connected search in R3. An orientation analysis of the Gaussian map to area-form clusters is applied to identify hyperbolic and elliptical regions. A signed point-to-plane distance function is used to identify points of convex and concave regions. Segmentation results of several real as well as synthetic point clouds, together with complexity analyses, are presented. © 2008 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-44249120508
"Boulch A., Marlet R.","Deep Learning for Robust Normal Estimation in Unstructured Point Clouds",2016,"Computer Graphics Forum",63,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982124657&doi=10.1111%2fcgf.12983&partnerID=40&md5=ec2c6200a70353cafc53ce82f9e703ed","Normal estimation in point clouds is a crucial first step for numerous algorithms, from surface reconstruction and scene understanding to rendering. A recurrent issue when estimating normals is to make appropriate decisions close to sharp features, not to smooth edges, or when the sampling density is not uniform, to prevent bias. Rather than resorting to manually-designed geometric priors, we propose to learn how to make these decisions, using ground-truth data made from synthetic scenes. For this, we project a discretized Hough space representing normal directions onto a structure amenable to deep learning. The resulting normal estimation method outperforms most of the time the state of the art regarding robustness to outliers, to noise and to point density variation, in the presence of sharp edges, while remaining fast, scaling up to millions of points. © 2016 The Author(s) Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",Article,"Final",Scopus,2-s2.0-84982124657
"Budroni A., Boehm J.","Automated 3D reconstruction of interiors from point clouds",2010,"Int. J. Archit. Comput.",63,,[No abstract available],,"Final",Scopus,2-s2.0-84873288546
"Patil A.K., Holi P., Lee S.K., Chai Y.H.","An adaptive approach for the reconstruction and modeling of as-built 3D pipelines from point clouds",2017,"Automation in Construction",62,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007247145&doi=10.1016%2fj.autcon.2016.12.002&partnerID=40&md5=f01f1045257c33357152ff1b4bdf997e","Automated extraction of 3D geometric shapes such as planes, spheres, cylinders, cones, and tori in laser-scanned point clouds is a challenging problem and a tedious process, especially when using cluttered data. This paper describes a modification of the existing Hough transform for the automatic detection of cylinder parameters in point clouds. Careful analysis reveals that the existing method still has excessive space and time complexity or yields imprecise outcomes. The approach described here modifies the orientation estimation with an area-based adaptive method that utilizes a small accumulator to detect significant peaks in the Hough space in the presence of single or multiple cylinders in the point cloud data. After orientation estimation, the position and radius are estimated using an orthonormal coordinate system with a circle fitting algorithm. These modifications are tested with extensive sets of real point cloud data, and experimental results show that the presented approach minimizes the space and time complexity. After detection, the relationship between cylinders is reconstructed to form a continuous axis network by tracking cylinder parameters obtained from earlier steps. Using the axis network of cylinders obtained from point clouds, models of entire pipelines that include straight pipes, elbow joints, and T-junctions are determinately defined, and output data is reconstructed in Smart Plant 3D (SP3D). The presented results show that the proposed approach indeed improves the computational complexity by reducing the space and time, and yields methods that can be employed in the automation of 3D pipeline model reconstruction. © 2016 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85007247145
"Shu Z., Qi C., Xin S., Hu C., Wang L., Zhang Y., Liu L.","Unsupervised 3D shape segmentation and co-segmentation via deep learning",2016,"Computer Aided Geometric Design",62,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977950750&doi=10.1016%2fj.cagd.2016.02.015&partnerID=40&md5=c2fbb47468a52e37d31f0d0f616cfdca","In this paper, we propose a novel unsupervised algorithm for automatically segmenting a single 3D shape or co-segmenting a family of 3D shapes using deep learning. The algorithm consists of three stages. In the first stage, we pre-decompose each 3D shape of interest into primitive patches to generate over-segmentation and compute various signatures as low-level shape features. In the second stage, high-level features are learned, in an unsupervised style, from the low-level ones based on deep learning. Finally, either segmentation or co-segmentation results can be quickly reported by patch clustering in the high-level feature space. The experimental results on the Princeton Segmentation Benchmark and the Shape COSEG Dataset exhibit superior segmentation performance of the proposed method over the previous state-of-the-art approaches. © 2016 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84977950750
"Zhang R., Candra S.A., Vetter K., Zakhor A.","Sensor fusion for semantic segmentation of urban scenes",2015,"Proceedings - IEEE International Conference on Robotics and Automation",62,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938274661&doi=10.1109%2fICRA.2015.7139439&partnerID=40&md5=ee46f720815fb388e2919cf499acc83c","Semantic understanding of environments is an important problem in robotics in general and intelligent autonomous systems in particular. In this paper, we propose a semantic segmentation algorithm which effectively fuses information from images and 3D point clouds. The proposed method incorporates information from multiple scales in an intuitive and effective manner. A late-fusion architecture is proposed to maximally leverage the training data in each modality. Finally, a pairwise Conditional Random Field (CRF) is used as a post-processing step to enforce spatial consistency in the structured prediction. The proposed algorithm is evaluated on the publicly available KITTI dataset [1] [2], augmented with additional pixel and point-wise semantic labels for building, sky, road, vegetation, sidewalk, car, pedestrian, cyclist, sign/pole, and fence regions. A per-pixel accuracy of 89.3% and average class accuracy of 65.4% is achieved, well above current state-of-the-art [3]. © 2015 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84938274661
"Ahmed M.F., Haas C.T., Haas R.","Automatic detection of cylindrical objects in built facilities",2014,"Journal of Computing in Civil Engineering",61,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898995395&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000329&partnerID=40&md5=f8005fbd9560c63affb5ea7c2b508b80","Three-dimensional (3D) facility models are in increasing demand for design, maintenance, operations, and construction project management. For industrial and research facilities, a key focus is piping, which may comprise 50% of the value of the facility. In this paper, a practical and cost-effective approach based on the Hough transform and judicious use of domain constraints is presented to automatically find, recognize, and reconstruct 3D pipes within laser-scan-acquired point clouds. The core algorithm utilizes the Hough transform's efficacy for detecting parametric shapes in noisy data by applying it to projections of orthogonal slices to grow cylindrical pipe shapes within a 3D point-cloud. This supports faster and less-expensive built-facility modeling. It is validated using laser-scanner data from construction of the Engineering-VI building on the University of Waterloo campus. The system works on a typical laptop. Recognition results are within a few millimeters to centimeters accuracy in accordance with the chosen tessellation of the Hough space. Broad applications to pipe-network modeling are possible. © 2014 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84898995395
"Liu Y.-J., Zhang J.-B., Hou J.-C., Ren J.-C., Tang W.-Q.","Cylinder detection in large-scale point cloud of pipeline plant",2013,"IEEE Transactions on Visualization and Computer Graphics",61,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883110063&doi=10.1109%2fTVCG.2013.74&partnerID=40&md5=9dd296d4048c050fc0cc3a876bd500a8","The huge number of points scanned from pipeline plants make the plant reconstruction very difficult. Traditional cylinder detection methods cannot be applied directly due to the high computational complexity. In this paper, we explore the structural characteristics of point cloud in pipeline plants and define a structure feature. Based on the structure feature, we propose a hierarchical structure detection and decomposition method that reduces the difficult pipeline-plant reconstruction problem in R3 into a set of simple circle detection problems in R2. Experiments with industrial applications are presented, which demonstrate the efficiency of the proposed structure detection method. © 2013 IEEE.",Article,"Final",Scopus,2-s2.0-84883110063
"Chi S., Caldas C.H., Kim D.Y.","A methodology for object identification and tracking in construction based on spatial modeling and image matching techniques",2009,"Computer-Aided Civil and Infrastructure Engineering",60,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-60749127599&doi=10.1111%2fj.1467-8667.2008.00580.x&partnerID=40&md5=9320a5721ffe546dfb2ac3a773c0e79e","Understanding the motion characteristics of on-site objects is desirable for the analysis of construction work zones, especially in problems related to safety and productivity studies. This article presents a methodology for rapid object identification and tracking. The proposed methodology contains algorithms for spatial modeling and image matching. A high-frame-rate range sensor was utilized for spatial data acquisition. The experimental results indicated that an occupancy grid spatial modeling algorithm could quickly build a suitable work zone model from the acquired data. The results also showed that an image matching algorithm is able to find the most similar object from a model database and from spatial models obtained from previous scans. It is then possible to use the matched information to successfully identify and track objects. © 2009 Computer-Aided Civil and Infrastructure Engineering.",Article,"Final",Scopus,2-s2.0-60749127599
"Nahangi M., Haas C.T.","Automated 3D compliance checking in pipe spool fabrication",2014,"Advanced Engineering Informatics",59,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924079175&doi=10.1016%2fj.aei.2014.04.001&partnerID=40&md5=4bcb01aea1b11ec19236c57773ac76fb","In pipe spool assemblies used in construction, pre-fabrication errors inevitably occur due to the complexity of the tasks involved in the pipe spool fabrication process, the inaccuracy of the tools employed for performing these tasks, human error, and inadequate inspection and monitoring during the process. Permanent deflections may also occur during shipment and transportation. After delivery at construction sites, defective spools must be detected and further consideration given to the erection of the spools to tolerance levels specified; otherwise, the repair and realignment associated with rework can cause schedule delays and consequent substantial costs increases. This paper presents an automated approach for monitoring and assessing fabricated pipe spools using automated scan-to-BIM registration. Defects are detected through a neighborhood-based Iterative Closest Point (ICP) approach for the registration process. While this technique can be broadly employed, this paper focuses on industrial construction facilities with particular emphasis on pipe spool assemblies. Experiments show that the proposed approach can be employed for the automatic and continual monitoring of such assemblies throughout fabrication, assembly and erection to enable timely detection and characterization of deviations. The main contribution of the work presented in this paper is an automated 3D inspection framework and algorithms for construction assemblies in general and pipe spools in particular. © 2014 The Authors. Published by Elsevier Ltd.",Conference Paper,"Final",Scopus,2-s2.0-84924079175
"Kawashima K., Kanai S., Date H.","As-built modeling of piping system from terrestrial laser-scanned point clouds using normal-based region growing",2014,"Journal of Computational Design and Engineering",59,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011609914&doi=10.7315%2fJCDE.2014.002&partnerID=40&md5=38a72b47f1b41eebc3ef34ba3f85cd5b","Recently, renovations of plant equipment have been more frequent because of the shortened lifespans of the products, and as-built models from large-scale laser-scamied data is expected to streamline rebuilding processes. However, the laser-scanned data of an existing plant has an enormous amount ofpoints, captures inmcate objects, and includes a high noise level, so the manual reconstmction of a 3D model is very time-consuming and costly. Among plant equipment, piping systems account for the greatest proportion. Therefore, the purpose of this research was to propose an algorithm which could automatically recognize a piping system from the terrestrial laser- scanned data plant equipment. The straight pomon pipes, connecting parts, and connection relationship ofthe piping system can be recognized in this algorithm. Normal-based region growing and cylinder surface fitting can extract all possible locations ofpipes, including straight pipes, elbows, and junctions. Tracing the axes of a piping system enables the recognition of the positions of these elements and their connection relationship. Using only point clouds, the recognition algorithm can be performed in a fUlly automatic way. The algorithm was applied to large-scale scamied data of an oil rig and a chemical plant. Recognition rates of about 86%, 88%, and 71% were achieved straight pipes, elbows, andjunctions, respectively. © 2014 Society of CAD/CAM Engineers & Techno-Press",Article,"Final",Scopus,2-s2.0-85011609914
"Luximon Y., Ball R., Justice L.","The 3D Chinese head and face modeling",2012,"CAD Computer Aided Design",59,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-81855166641&doi=10.1016%2fj.cad.2011.01.011&partnerID=40&md5=f1384e2d639fcea639ba349ff2baa8b7","Perfect fit for people has always been a target for product design. Designers commonly use traditional anthropometric dimensions for 3D product design thus creating a lot of fitting problems when dealing with the complexities of human body shapes. The development of recent 3D anthropometric survey has created an opportunity for complex shape analysis on human model by collecting 3D scan data. Using 3D point cloud data from the SizeChina survey, a methodology of creating a homologous 3D head and face model was demonstrated in this study. Anatomical and virtual landmarks, and surface modeling algorithm based on point cloud data were applied in building the model. The head and face models for all scans had the same amount of vertices with consistent features. The average Chinese models showed obvious differences between male and female. The variations of head and face shapes were analyzed using Principal Component Analysis and the results showed that the largest variations among people were general size, especially for width and depth. However face height, forehead, back of the head, chin and jaw area were also important when describing the 3D shape. The results from this study may be useful in the design of head and facial products. © 2011 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-81855166641
"Song S., Chandraker M.","Joint SFM and detection cues for monocular 3D localization in road scenes",2015,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",58,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959250551&doi=10.1109%2fCVPR.2015.7298997&partnerID=40&md5=b7409e614a7252ae3b8e2b3c2d6fa821","We present a system for fast and highly accurate 3D localization of objects like cars in autonomous driving applications, using a single camera. Our localization framework jointly uses information from complementary modalities such as structure from motion (SFM) and object detection to achieve high localization accuracy in both near and far fields. This is in contrast to prior works that rely purely on detector outputs, or motion segmentation based on sparse feature tracks. Rather than completely commit to tracklets generated by a 2D tracker, we make novel use of raw detection scores to allow our 3D bounding boxes to adapt to better quality 3D cues. To extract SFM cues, we demonstrate the advantages of dense tracking over sparse mechanisms in autonomous driving scenarios. In contrast to complex scene understanding, our formulation for 3D localization is efficient and can be regarded as an extension of sparse bundle adjustment to incorporate object detection cues. Experiments on the KITTI dataset show the efficacy of our cues, as well as the accuracy and robustness of our 3D object localization relative to ground truth and prior works. © 2015 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84959250551
"Laefer D.F., Truong-Hong L.","Toward automatic generation of 3D steel structures for building information modelling",2017,"Automation in Construction",57,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998610801&doi=10.1016%2fj.autcon.2016.11.011&partnerID=40&md5=152e1de7f8343fb8aa4c1e97d4a0bb08","Building information models (BIMs) are becoming standard for new construction. Extending this trend to existing structures is complicated because of an absence of reliable documentation and the cost of generating it anew. To overcome this problem, this paper proposes a method to identify automatically structural steel members from a terrestrial laser scan point cloud and to generate that geometry in a BIM compatible format. The proper shape and dimensions of the cross-section are established by employing kernel density estimation. A method associated with measured metrics is introduced to determine the best match of various cross-sections, from a prepopulated library. The proposed method successfully identified up to 92.0% of the required cross-sections and 81.3% of structural members across two steel frames of different shapes, sizes, and configurations. © 2016",Article,"Final",Scopus,2-s2.0-84998610801
"Vosselman G.","Advanced point cloud processing",2009,"Photogrammetric Week '09",57,,[No abstract available],,"Final",Scopus,2-s2.0-78149415543
"Chung D.H., Yun I.D., Lee S.U.","Registration of multiple-range views using the reverse-calibration technique",1998,"Pattern Recognition",57,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032044710&doi=10.1016%2fS0031-3203%2897%2900063-0&partnerID=40&md5=b611e0717c8d121008c435decc633b66","In this paper we propose a new registration algorithm. The proposed algorithm consists of two steps. The first step is to estimate the transformation parameters among multiple-range views, making use of the eigenvectors of the weighted covariance matrix of the 3-D coordinates of data points. The weighting factors are carefully selected to take into account the projection effect caused by different viewpoints. The next step is to register the views iteratively with the estimated transformation parameters as initial values. To solve the correspondence problem, the reverse calibration technique is used, which is adapted to the space-encoding range finder. The object function, defined by means of the reverse calibration technique, is minimized iteratively. Experimental results show that the proposed algorithm is very fast and efficient. © 1998 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-0032044710
"Dimitrov A., Gu R., Golparvar-Fard M.","Non-Uniform B-Spline Surface Fitting from Unordered 3D Point Clouds for As-Built Modeling",2016,"Computer-Aided Civil and Infrastructure Engineering",56,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955142057&doi=10.1111%2fmice.12192&partnerID=40&md5=b465aa9f5c87966f67f174c7c39cffb3","The three-dimensional mapping of the built environment is of particular importance for engineering applications such as monitoring work-in-progress and energy performance simulation. The state-of-the-art methods for fitting primitives, non-uniform B-Spline surface (NURBS) and solid geometry to point clouds still fail to account for all the topological variations or struggle with mapping of physical space to parameter space given unordered, incomplete, and noisy point clouds. Assuming an input of points that can be described by a single non-self-intersecting NURBS, this article presents a new method that leverages segmented point clouds and outputs NURBS surfaces. It starts by successively fitting uniform B-Spline curves in two-dimensional as planar cross-sectional cuts on each surface. An intermediate B-Spline surface is then computed by globally optimizing and lofting over the cross-sections. This surface is used to parameterize the points and perform final refinement to a NURBS. For cylindrical segments such as pipes, a new supervised method is also introduced to string the fitted segments, identify connection types, standardize the connections, and then refine them using NURBS optimization. Experimental results show the applicability of the proposed methods for as-built modeling purposes. © 2016 Computer-Aided Civil and Infrastructure Engineering.",Article,"Final",Scopus,2-s2.0-84955142057
"Czerniawski T., Sankaran B., Nahangi M., Haas C., Leite F.","6D DBSCAN-based segmentation of building point clouds for planar object classification",2018,"Automation in Construction",55,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039972426&doi=10.1016%2fj.autcon.2017.12.029&partnerID=40&md5=07bc66256ea24205b3a81fc254a33e95","Due to constraints in manufacturing and construction, buildings and many of the manmade objects within them are often rectangular and composed of planar parts. Detection and analysis of planes is, therefore, central to processing point clouds captured in these spaces. This paper presents a study of the semantic information stored in the planar objects of noisy building point clouds. The dataset considered is the Scene Meshes Dataset with aNNotations (SceneNN), a collection of over 100 indoor scenes captured by consumer-grade depth cameras. All planar objects within the dataset are detected using a new point cloud segmentation method that applies Density Based Spatial Clustering of Applications with Noise (DBSCAN) in a six dimensional clustering space. With all planes isolated, an extensive list of features describing the planes is extracted and studied using feature selection. Then dimensionality reduction and unsupervised learning are used to explore the discriminative ability of the final feature set as well as emergent class groupings. Finally, we train a bagged decision tree classifier that achieves 71.2% accuracy in predicting the object class from which individual planes originate. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85039972426
"Su Y.-T., Bethel J., Hu S.","Octree-based segmentation for terrestrial LiDAR point cloud data in industrial applications",2016,"ISPRS Journal of Photogrammetry and Remote Sensing",55,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955317752&doi=10.1016%2fj.isprsjprs.2016.01.001&partnerID=40&md5=3566088bb2faab928c62177dccad87d2","Automated and efficient algorithms to perform segmentation of terrestrial LiDAR data is critical for exploitation of 3D point clouds, where the ultimate goal is CAD modeling of the segmented data. In this work, a novel segmentation technique is proposed, starting with octree decomposition to recursively divide the scene into octants or voxels, followed by a novel split and merge framework that uses graph theory and a series of connectivity analyses to intelligently merge components into larger connected components. The connectivity analysis, based on a combination of proximity, orientation, and curvature connectivity criteria, is designed for the segmentation of pipes, vessels, and walls from terrestrial LiDAR data of piping systems at industrial sites, such as oil refineries, chemical plants, and steel mills. The proposed segmentation method is exercised on two terrestrial LiDAR datasets of a steel mill and a chemical plant, demonstrating its ability to correctly reassemble and segregate features of interest. © 2016 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).",Article,"Final",Scopus,2-s2.0-84955317752
"Dore C., Murphy M.","Semi-automatic generation of as-built BIM façade geometry from laser and image data",2014,"Journal of Information Technology in Construction",53,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894458566&partnerID=40&md5=7c304c8ee886d90e745fa880ffe06542","This article outlines a new semi-automatic approach for generating accurate BIM facade models for existing buildings from laser and image data. Two new developments for as-built BIM modelling are presented in this article. The first is a new library of reusable parametric objects designed for modelling classical architectural elements from survey data. These library objects are dynamic and have parameters that can instantly alter the shape, size and other properties of objects. The parametric architectural objects have been designed from historic manuscripts and architectural pattern books. These parametric objects were built using an embedded programming language within the ArchiCAD BIM software called Geometric Description Language (GDL). The second development which is described in more detail in this article is a complete parametric building façade. This parametric building facade can be used as a template for fast and efficient generation of BIM facade geometry. The design of this parametric façade incorporates concepts from procedural modelling which is an automated approach to generating 3D geometries based on rules and algorithms. Parametric architectural objects are automatically combined with rules to generate many different façade arrangements which are controlled by user parameters. When automatically generating a façade, the initial position and size of elements are estimated using classical architectural proportions. Object can then be graphically edited individually or in groups to match the computer generated geometry to survey data. The parametric façade template has also been implemented with the Geometric Description Language for ArchiCAD BIM software. This enables the tools developed to utilise the full benefits of BIM software which includes automated construction or conservation documents, semantic object oriented objects based on IFC semantic classes, automatic lists of objects and material and the ability to add and link additional information to the model. Initial user tests have indicated that the parametric façade is more efficient than previous methods for creating accurate façade models from survey data. The façade template also provides an easier solution for generating façade models when compared to existing methods. Non-specialist users with little experience in 3D modelling can easily generate and modify the façade template by altering parameters graphically or from a dialogue box. © 2014 The authors.",Article,"Final",Scopus,2-s2.0-84894458566
"Gorse C., Highfield D.","Refurbishment and Upgrading of Buildings",2009,"Refurbishment and Upgrading of Buildings",53,,[No abstract available],,"Final",Scopus,2-s2.0-78349251421
"Sacks R., Kedar A., Borrmann A., Ma L., Brilakis I., Hüthwohl P., Daum S., Kattel U., Yosef R., Liebich T., Barutcu B.E., Muhic S.","SeeBridge as next generation bridge inspection: Overview, Information Delivery Manual and Model View Definition",2018,"Automation in Construction",52,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042407578&doi=10.1016%2fj.autcon.2018.02.033&partnerID=40&md5=a088875ae311b0f4ac4d4e88cb6d1111","Innovative solutions for rapid and intelligent survey and assessment methods are required in maintenance, repair, retrofit and rebuild of enormous numbers of bridges in service throughout the world. Motivated by this need, a next-generation integrated bridge inspection system, called SeeBridge, has been proposed. An Information Delivery Manual (IDM) was compiled to specify the technical components, activities and information exchanges in the SeeBridge process, and a Model View Definition (MVD) was prepared to specify the data exchange schema to serve the IDM. The MVD was bound to the IFC4 Add2 data schema standard. The IDM and MVD support research and development of the system by rigorously defining the information and data that structure bridge engineers' knowledge. The SeeBridge process is mapped, parts of the data repositories are presented, and the future use of the IDM is discussed. The development underlines the real potential for automated inspection of infrastructure at large, because it demonstrates that the hurdles in the way of automated acquisition of detailed and semantically rich models of existing infrastructure are computational in nature, not instrumental, and are surmountable with existing technologies. © 2018",Article,"Final",Scopus,2-s2.0-85042407578
"Zia M.Z., Stark M., Schindler K.","Are cars just 3D boxes? Jointly estimating the 3D shape of multiple objects",2014,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",51,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911441879&doi=10.1109%2fCVPR.2014.470&partnerID=40&md5=d24a5955864276f4683754436e5cf9bd","Current systems for scene understanding typically represent objects as 2D or 3D bounding boxes. While these representations have proven robust in a variety of applications, they provide only coarse approximations to the true 2D and 3D extent of objects. As a result, object-object interactions, such as occlusions or ground-plane contact, can be represented only superficially. In this paper, we approach the problem of scene understanding from the perspective of 3D shape modeling, and design a 3D scene representation that reasons jointly about the 3D shape of multiple objects. This representation allows to express 3D geometry and occlusion on the fine detail level of individual vertices of 3D wireframe models, and makes it possible to treat dependencies between objects, such as occlusion reasoning, in a deterministic way. In our experiments, we demonstrate the benefit of jointly estimating the 3D shape of multiple objects in a scene over working with coarse boxes, on the recently proposed KITTI dataset of realistic street scenes. © 2014 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84911441879
"Qiu R., Zhou Q.-Y., Neumann U.","Pipe-run extraction and reconstruction from point clouds",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",51,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906519154&doi=10.1007%2f978-3-319-10578-9_2&partnerID=40&md5=13b72ff172b40ca5b076b279a8a74143","This paper presents automatic methods to extract and reconstruct industrial site pipe-runs from large-scale point clouds. We observe three key characteristics in this modeling problem, namely, primitives, similarities, and joints. While primitives capture the dominant cylindric shapes, similarities reveal the inter-primitive relations intrinsic to industrial structures because of human design and construction. Statistical analysis over point normals discovers primitive similarities from raw data to guide primitive fitting, increasing robustness to data noise and incompleteness. Finally, joints are automatically detected to close gaps and propagate connectivity information. The resulting model is more than a collection of 3D triangles, as it contains semantic labels for pipes as well as their connectivity. © 2014 Springer International Publishing.",Conference Paper,"Final",Scopus,2-s2.0-84906519154
"Lari Z., Habib A.","An adaptive approach for the segmentation and extraction of planar and linear/cylindrical features from laser scanning data",2014,"ISPRS Journal of Photogrammetry and Remote Sensing",50,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902352918&doi=10.1016%2fj.isprsjprs.2013.12.001&partnerID=40&md5=e575d24436fef9b1aff8f026968d9724","Laser scanning systems have been established as leading tools for the collection of high density three-dimensional data over physical surfaces. The collected point cloud does not provide semantic information about the characteristics of the scanned surfaces. Therefore, different processing techniques have been developed for the extraction of useful information from this data which could be applied for diverse civil, industrial, and military applications. Planar and linear/cylindrical features are among the most important primitive information to be extracted from laser scanning data, especially those collected in urban areas. This paper introduces a new approach for the identification, parameterization, and segmentation of these features from laser scanning data while considering the internal characteristics of the utilized point cloud - i.e., local point density variation and noise level in the dataset. In the first step of this approach, a Principal Component Analysis of the local neighborhood of individual points is implemented to identify the points that belong to planar and linear/cylindrical features and select their appropriate representation model. For the detected planar features, the segmentation attributes are then computed through an adaptive cylinder neighborhood definition. Two clustering approaches are then introduced to segment and extract individual planar features in the reconstructed parameter domain. For the linear/cylindrical features, their directional and positional parameters are utilized as the segmentation attributes. A sequential clustering technique is proposed to isolate the points which belong to individual linear/cylindrical features through directional and positional attribute subspaces. Experimental results from simulated and real datasets demonstrate the feasibility of the proposed approach for the extraction of planar and linear/cylindrical features from laser scanning data. © 2013 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).",Article,"Final",Scopus,2-s2.0-84902352918
"Rvachev V.L.","Analytical description of some geometric objects",1963,"Dokl AS USSR",47,,[No abstract available],,"Final",Scopus,2-s2.0-0000126612
"Stavroulaki M.E., Riveiro B., Drosopoulos G.A., Solla M., Koutsianitis P., Stavroulakis G.E.","Modelling and strength evaluation of masonry bridges using terrestrial photogrammetry and finite elements",2016,"Advances in Engineering Software",46,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954290687&doi=10.1016%2fj.advengsoft.2015.12.007&partnerID=40&md5=79b2f4a7363bfd97edff8050bd4f535d","Several numerical models are presented in this article, for the study of the ultimate behaviour of a real stone arch bridge. For the exact representation of the geometry an integral and comprehensive survey involving Terrestrial Photogrammetry and Ground Penetrating Radar is in order to provide a realistic 3D geometric model for the subsequent mechanical analysis of the bridge. The accuracy of the photogrammetric method permitted detecting cracks in different areas and the GPR completed the geometric model with information of hidden parts such as backfill, arch ring thickness, etc. Finite element analysis models, incorporating damage, elastoplasticity and contact, are then developed. Comparison between these models is considered in a single arch of the structure. The classical four hinges mechanism appears in the arch. A model of the whole structure, where the arch and the fill are taken into account, is finally developed. Results show how damage is developed in the body of the arch, for loadings that include forces, or vertical and transverse displacements in the supports. © 2016 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-84954290687
"Khaloo A., Lattanzi D.","Robust normal estimation and region growing segmentation of infrastructure 3D point cloud models",2017,"Advanced Engineering Informatics",45,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026651225&doi=10.1016%2fj.aei.2017.07.002&partnerID=40&md5=addbd242963c3123b4c32dfde9535133","Modern remote sensing technologies such as three-dimensional (3D) laser scanners and image-based 3D scene reconstruction are in increasing demand for applications in civil infrastructure design, maintenance, operation, and as-built construction verification. The complex nature of the 3D point clouds these technologies generate, as well as the often massive scale of the 3D data, make it inefficient and time consuming to manually analyze and manipulate point clouds, and highlights the need for automated analysis techniques. This paper presents one such technique, a new region growing algorithm for the automated segmentation of both planar and non-planar surfaces in point clouds. A core component of the algorithm is a new point normal estimation method, an essential task for many point cloud processing algorithms. The newly developed estimation method utilizes robust multivariate statistical outlier analysis for reliable normal estimation in complex 3D models, considering that these models often contain regions of varying surface roughness, a mixture of high curvature and low curvature regions, and sharp features. An adaptation of Mahalanobis distance, in which the mean vector and covariance matrix are derived from a high-breakdown multivariate location and scale estimator called Deterministic MM-estimator (DetMM) is used to find and discard outlier points prior to estimating the best local tangent plane around any point in a cloud. This approach is capable of more accurately estimating point normals located in highly curved regions or near sharp features. Thereafter, the estimated point normals serve a region growing segmentation algorithm that only requires a single input parameter, an improvement over existing methods which typically require two control parameters. The reliability and robustness of the normal estimation subroutine was compared against well-known normal estimation methods including the Minimum Volume Ellipsoid (MVE) and Minimum Covariance Determinant (MCD) estimators, along with Maximum Likelihood Sample Consensus (MLESAC). The overall region growing segmentation algorithm was then experimentally validated on several challenging 3D point clouds of real-world infrastructure systems. The results indicate that the developed approach performs more accurately and robustly in comparison with conventional region growing methods, particularly in the presence of sharp features, outliers and noise. © 2017 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85026651225
"Kim C., Son H., Kim C.","Fully automated as-built 3D pipeline extraction method from laser-scanned data based on curvature computation",2015,"Journal of Computing in Civil Engineering",44,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932178153&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000401&partnerID=40&md5=f5b86c12548f09428dc082489c145bea","There has been a growing demand for the three-dimensional (3D) reconstruction of as-built pipelines. The as-built 3D pipeline reconstruction process consists of the measurement of an industrial plant, identification of pipelines, and generation of 3D models of the pipelines. Although measurement is now efficiently performed using laser-scanning technology, and in spite of significant progress in 3D pipeline model generation, the identification of pipelines from large and complex sets of laser-scanned data continues to pose a challenge. The aim of this study is to propose a method to automatically extract 3D points corresponding to as-built pipelines that occupy large areas of industrial plants from laser-scanned data. The proposed extraction method consists of the following steps: preprocessing, segmentation of the 3D point cloud, feature extraction based on curvature computation, and pipeline classification. An experiment was performed at an operating industrial plant to validate the proposed method. The experimental result revealed that the proposed method can indeed contribute to the automation of as-built 3D pipeline reconstruction. © 2014 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84932178153
"Zhang G., Vela P.A., Karasev P., Brilakis I.","A sparsity-inducing optimization-based algorithm for planar patches extraction from noisy point-cloud data",2015,"Computer-Aided Civil and Infrastructure Engineering",42,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920928237&doi=10.1111%2fmice.12063&partnerID=40&md5=74f5599bf4d836b51046b3b52ecc2315","Currently, much of the manual labor needed to generate as-built building information models (BIMs) of existing facilities is spent converting raw point cloud data sets (PCDs) to BIM descriptions. Automating the PCD conversion process can drastically reduce the cost of generating as-built BIMs. Due to the widespread existence of planar structures in civil infrastructures, detecting and extracting planar patches from raw PCDs is a fundamental step in the conversion pipeline from PCDs to BIMs. However, existing methods cannot effectively address both automatically detecting and extracting planar patches from infrastructure PCDs. The existing methods cannot resolve the problem due to the large scale and model complexity of civil infrastructure, or due to the requirements of extra constraints or known information. To address the problem, this article presents a novel framework for automatically detecting and extracting planar patches from large-scale and noisy raw PCDs. The proposed method automatically detects planar structures, estimates the parametric plane models, and determines the boundaries of the planar patches. The first step recovers existing linear dependence relationships amongst points in the PCD by solving a group-sparsity inducing optimization problem. Next, a spectral clustering procedure based on the recovered linear dependence relationships segments the PCD. Then, for each segmented group, model parameters of the extracted planes are estimated via singular value decomposition (SVD) and maximum likelihood estimation sample consensus (MLESAC). Finally, the α-shape algorithm detects the boundaries of planar structures based on a projection of the data to the planar model. The proposed approach is evaluated comprehensively by experiments on two types of PCDs from real-world infrastructures, one captured directly by laser scanners and the other reconstructed from video using structure-from-motion techniques. To evaluate the performance comprehensively, five evaluation metrics are proposed which measure different aspects of performance. Experimental results reveal that the proposed method outperforms the existing methods, in the sense that the method automatically and accurately extracts planar patches from large-scaled raw PCDs without any extra constraints nor user assistance. © 2014 Computer-Aided Civil and Infrastructure Engineering.",Article,"Final",Scopus,2-s2.0-84920928237
"Kokkinos I., Maragos P., Yuille A.","Bottom-up & top-down object detection using primal sketch features and graphical models",2006,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",42,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845571966&doi=10.1109%2fCVPR.2006.74&partnerID=40&md5=73e686b347333e2d2469d8957f4211e1","A combination of techniques that is becoming increasingly popular is the construction of part-based object representations using the outputs of interest-point detectors. Our contributions in this paper are twofold: first, we propose a primal-sketch-based set of image tokens that are used for object representation and detection. Second, top-down information is introduced based on an efficient method for the evaluation of the likelihood of hypothesized part locations. This allows us to use graphical model techniques to complement bottom-up detection, by proposing and finding the parts of the object that were missed by the front-end feature detection stage. Detection results for four object categories validate the merits of this joint top-down and bottom-up approach. © 2006 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-33845571966
"Qi C.R., Su H., Niessner M., Dai A., Yan M., Guibas L.J.",[No title available],2016,"Volumetric and Multi-View Cnns for Object Classification on 3D Data",41,,[No abstract available],,"Final",Scopus,2-s2.0-85013920603
"Kaiser A., Ybanez Zepeda J.A., Boubekeur T.","A Survey of Simple Geometric Primitives Detection Methods for Captured 3D Data",2019,"Computer Graphics Forum",40,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050403720&doi=10.1111%2fcgf.13451&partnerID=40&md5=706ad770de501d5c66d560c872dce8bd","The amount of captured 3D data is continuously increasing, with the democratization of consumer depth cameras, the development of modern multi-view stereo capture setups and the rise of single-view 3D capture based on machine learning. The analysis and representation of this ever growing volume of 3D data, often corrupted with acquisition noise and reconstruction artefacts, is a serious challenge at the frontier between computer graphics and computer vision. To that end, segmentation and optimization are crucial analysis components of the shape abstraction process, which can themselves be greatly simplified when performed on lightened geometric formats. In this survey, we review the algorithms which extract simple geometric primitives from raw dense 3D data. After giving an introduction to these techniques, from the acquisition modality to the underlying theoretical concepts, we propose an application-oriented characterization, designed to help select an appropriate method based on one's application needs and compare recent approaches. We conclude by giving hints for how to evaluate these methods and a set of research challenges to be explored. © 2018 The Authors Computer Graphics Forum © 2018 The Eurographics Association and John Wiley & Sons Ltd.",Article,"Final",Scopus,2-s2.0-85050403720
"Li W., Saeedi S., McCormac J., Clark R., Tzoumanikas D., Ye Q., Huang Y., Tang R., Leutenegger S.","Interiornet: Mega-scale multi-sensor photo-realistic indoor scenes dataset",2019,"British Machine Vision Conference 2018, BMVC 2018",39,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084016718&partnerID=40&md5=7665d1b50dccb9662a6bcf34eec29896","Datasets have gained an enormous amount of popularity in the computer vision community, from training and evaluation of Deep Learning-based methods to benchmarking Simultaneous Localization and Mapping (SLAM). Without a doubt, synthetic imagery bears a vast potential due to scalability in terms of amounts of data obtainable without tedious manual ground truth annotations or measurements. Here, we present a dataset with the aim of providing a higher degree of photo-realism, larger scale, more variability as well as serving a wider range of purposes compared to existing datasets. Our dataset leverages the availability of millions of professional interior designs and millions of production-level furniture and object assets - all coming with fine geometric details and high-resolution texture. We render high-resolution and high frame-rate video sequences following realistic trajectories while supporting various camera types as well as providing inertial measurements. Together with the release of the dataset, we will make executable program of our interactive simulator software as well as our renderer available at https://interiornetdataset.github.io. To showcase the usability and uniqueness of our dataset, we show benchmarking results of both sparse and dense SLAM algorithms. © 2018. The copyright of this document resides with its authors.",Conference Paper,"Final",Scopus,2-s2.0-85084016718
"Cabaleiro M., Riveiro B., Arias P., Caamaño J.C., Vilán J.A.","Automatic 3D modelling of metal frame connections from LiDAR data for structural engineering purposes",2014,"ISPRS Journal of Photogrammetry and Remote Sensing",39,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904892158&doi=10.1016%2fj.isprsjprs.2014.07.006&partnerID=40&md5=feb7440dd860da54b7eda2a10e150649","The automatic generation of 3D as-built models from LiDAR data is a topic where significant progress has been made in recent years. This paper describes a new method for the detection and automatic 3D modelling of frame connections and the formation of profiles comprising a metal frame from LiDAR data. The method has been developed using an approach to create 2.5D density images for subsequent processing using the Hough transform. The structure connections can be automatically identified after selecting areas in the point cloud. As a result, the coordinates of the connection centre, composition (profiles, size and shape of the haunch) and direction of their profiles are extracted. A standard file is generated with the data obtained from the geometric and semantic characterisation of the connections. The 3D model of connections and metal frames, which are suitable for processing software for structural engineering applications, are generated automatically based on this file. The algorithm presented in this paper has been tested under laboratory conditions and also with several industrial portal frames, achieving promising results. Finally, 3D models were generated, and structural calculations were performed. © 2014 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).",Article,"Final",Scopus,2-s2.0-84904892158
"Ji Y., Borrmann A., Beetz J., Obergrießer M.","Exchange of parametric bridge models using a neutral data format",2013,"Journal of Computing in Civil Engineering",39,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886449217&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000286&partnerID=40&md5=bf1408c6af337114266c4914be559e68","Parametric modeling is a well-established methodology in the field of mechanical engineering. It allows for the creation of flexible geometric models using parameters for dimensions and makes it possible to define numeric relationships between these parameters by means of mathematical formulas and define geometric-topological constraints between geometric entities. The result is a flexible geometric model that can be steered through the manipulation of its primary parameters. In contrast to explicit geometric models with fixed dimensions, a parametric model can capture the design intent and represent domain knowledge. The use of parametric modeling techniques is particularly beneficial for designing bridges. This is because the geometric design of bridges is mainly determined by external constraints resulting from the size and the layout of both the overlying and the undercrossing carriageway. This reduces the effort required for reworking when changes are made, while simultaneously providing a high degree of reusability for the model in other, similar projects, resulting in significantly increased efficiency in the bridge design process. Because of the strong fragmentation of the architecture, engineering, and construction (AEC) industry, the data exchange between the different participants in a construction project is of crucial importance. The use of neutral, open data formats has proved to be the most suitable approach to realize this data exchange. However, currently existing neutral data formats do not allow for an exchange of parametric geometry. To overcome these technical limitations, this paper introduces an extension to the IFC-Bridge format, thus providing a means of interchanging parametric bridge models. This article describes in detail the necessary entities introduced to define parameters and capture dimensional and geometric constraints. The suitability of the developed extensions is proved by presenting the successful transfer of parametric bridge models between two parametric design systems as well as from a design system to a structural analysis system. © 2013 American Society of Civil Engineers.",Conference Paper,"Final",Scopus,2-s2.0-84886449217
"Weinmann M., Jutzi B., Mallet C., Weinmann M.","GEOMETRIC FEATURES and THEIR RELEVANCE for 3D POINT CLOUD CLASSIFICATION",2017,"ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences",38,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044510127&doi=10.5194%2fisprs-annals-IV-1-W1-157-2017&partnerID=40&md5=42ce6cee6b2f221578ac48c809423209","In this paper, we focus on the automatic interpretation of 3D point cloud data in terms of associating a class label to each 3D point. While much effort has recently been spent on this research topic, little attention has been paid to the influencing factors that affect the quality of the derived classification results. For this reason, we investigate fundamental influencing factors making geometric features more or less relevant with respect to the classification task. We present a framework which consists of five components addressing point sampling, neighborhood recovery, feature extraction, classification and feature relevance assessment. To analyze the impact of the main influencing factors which are represented by the given point sampling and the selected neighborhood type, we present the results derived with different configurations of our framework for a commonly used benchmark dataset for which a reference labeling with respect to three structural classes (linear structures, planar structures and volumetric structures) as well as a reference labeling with respect to five semantic classes (Wire, Pole/Trunk, Façade, Ground and Vegetation) is available. © 2017 Copernicus GmbH. All rights reserved.",Conference Paper,"Final",Scopus,2-s2.0-85044510127
"Czerniawski T., Nahangi M., Haas C., Walbridge S.","Pipe spool recognition in cluttered point clouds using a curvature-based shape descriptor",2016,"Automation in Construction",38,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991200926&doi=10.1016%2fj.autcon.2016.08.011&partnerID=40&md5=1a9f94bb082dfa4e7a9a88c5f9e08134","Automating dimensional compliance control and progress tracking using computer vision has been identified as a central opportunity for improvement in the construction industry. Current 3D imaging sensors provide massive amounts of spatial data that remain underutilized due to the prohibitively time-consuming manual process of extracting usable information. Desired information is typically centered on a specific object of interest within 3D images, so there is a need for construction specific object recognition processes. In this paper, we present an automated method for locating and extracting pipe spools in cluttered point cloud scans. The method is based on local data level curvature estimation, clustering, and bag-of-features matching. Experimental results from two point clouds containing pipe spool objects demonstrate the method's ability to successfully extract spools from cluttered scenes as well as differentiate between similar spools in a single scene. © 2016 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84991200926
"Stergiou C., Psannis K.E.","Efficient and secure BIG data delivery in Cloud Computing",2017,"Multimedia Tools and Applications",37,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017107163&doi=10.1007%2fs11042-017-4590-4&partnerID=40&md5=18e0cd9cae83714522ceef8822aa3996","Big Data (BD) is a new technology which rapidly growing in the telecommunications sectors, especially in the contemporary field of wireless telecommunications. Another technology that grows rapidly in the field of wireless telecommunications is Cloud Computing (CC). CC concerns an infrastructure where data storage and processing take place outside of the user’s device. Both of them face security and privacy issues in their function. In order to improve them and to optimize their privacy and security issues conducted the present survey. In this paper, we survey BD and CC technology and their basic characteristics, with a focus on the security and privacy issues of both technologies. Specifically, we try to combine the functionality of the two technologies (i.e BD and CC) with the aim to examine the frequent features, and also to discover the benefits related in security issues of their integration. Concluding, we present a new method of an algorithm that can be used for the purpose of improving Cloud Computing’s security through the use of algorithms that can provide more privacy in the data related to Big Data technology. At the end, there is a survey about the challenges of the integration of BD and CC related to their security level. © 2017, Springer Science+Business Media New York.",Article,"Final",Scopus,2-s2.0-85017107163
"Borrmann A., König M., Koch C., Beetz J.","Building information modeling: Technology foundations and industry practice",2018,"Building Information Modeling: Technology Foundations and Industry Practice",36,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063561220&doi=10.1007%2f978-3-319-92862-3&partnerID=40&md5=8c214df31ebf588d96314a68ac86f930","Building Information Modeling (BIM) refers to the consistent and continuous use of digital information throughout the entire lifecycle of a built facility, including its design, construction and operation. In order to exploit BIM methods to their full potential, a fundamental grasp of their key principles and applications is essential. Accordingly, this book combines discussions of theoretical foundations with reports from the industry on currently applied best practices. The book's content is divided into six parts: Part I discusses the technological basics of BIM and addresses computational methods for the geometric and semantic modeling of buildings, as well as methods for process modeling. Next, Part II covers the important aspect of the interoperability of BIM software products and describes in detail the standardized data format Industry Foundation Classes. It presents the different classification systems, discusses the data format CityGML for describing 3D city models and COBie for handing over data to clients, and also provides an overview of BIM programming tools and interfaces. Part III is dedicated to the philosophy, organization and technical implementation of BIM-based collaboration, and discusses the impact on legal issues including construction contracts. In turn, Part IV covers a wide range of BIM use cases in the different lifecycle phases of a built facility, including the use of BIM for design coordination, structural analysis, energy analysis, code compliance checking, quantity take-off, prefabrication, progress monitoring and operation. In Part V, a number of design and construction companies report on the current state of BIM adoption in connection with actual BIM projects, and discuss the approach pursued for the shift toward BIM, including the hurdles taken. Lastly, Part VI summarizes the book's content and provides an outlook on future developments. The book was written both for professionals using or programming such tools, and for students in Architecture and Construction Engineering programs. © Springer International Publishing AG, part of Springer Nature 2015, 2018. All rights reserved.",Book,"Final",Scopus,2-s2.0-85063561220
"Wang Y., Zou Y., Henrickson K., Wang Y., Tang J., Park B.-J.","Google Earth elevation data extraction and accuracy assessment for transportation applications",2017,"PLoS ONE",36,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018245007&doi=10.1371%2fjournal.pone.0175756&partnerID=40&md5=a0c1cf5cb503035b317b7e80e84248fa","Roadway elevation data is critical for a variety of transportation analyses. However, it has been challenging to obtain such data and most roadway GIS databases do not have them. This paper intends to address this need by proposing a method to extract roadway elevation data from Google Earth (GE) for transportation applications. A comprehensive accuracy assessment of the GE-extracted elevation data is conducted for the area of conterminous USA. The GE elevation data was compared with the ground truth data from nationwide GPS benchmarks and roadway monuments from six states in the conterminous USA. This study also compares the GE elevation data with the elevation raster data from the U.S. Geological Survey National Elevation Dataset (USGS NED), which is a widely used data source for extracting roadway elevation. Mean absolute error (MAE) and root mean squared error (RMSE) are used to assess the accuracy and the test results show MAE, RMSE and standard deviation of GE roadway elevation error are 1.32 meters, 2.27 meters and 2.27 meters, respectively. Finally, the proposed extraction method was implemented and validated for the following three scenarios: (1) extracting roadway elevation differentiating by directions, (2) multi-layered roadway recognition in freeway segment and (3) slope segmentation and grade calculation in freeway segment. The methodology validation results indicate that the proposed extraction method can locate the extracting route accurately, recognize multi-layered roadway section, and segment the extracted route by grade automatically. Overall, it is found that the high accuracy elevation data available from GE provide a reliable data source for various transportation applications. © 2017 Wang et al.This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",Article,"Final",Scopus,2-s2.0-85018245007
"Shi Y., Long P., Xu K., Huang H., Xiong Y.","Data-driven contextual modeling for 3D scene understanding",2016,"Computers and Graphics (Pergamon)",36,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955616048&doi=10.1016%2fj.cag.2015.11.003&partnerID=40&md5=5d3d3ce64efb5350e83d7147b9f41c9f","The recent development of fast depth map fusion technique enables the realtime, detailed scene reconstruction using commodity depth camera, making the indoor scene understanding more possible than ever. To address the specific challenges in object analysis at subscene level, this work proposes a data-driven approach to modeling contextual information covering both intra-object part relations and inter-object object layouts. Our method combines the detection of individual objects and object groups within the same framework, enabling contextual analysis without knowing the objects in the scene a priori. The key idea is that while contextual information could benefit the detection of either individual objects or object groups, both can contribute to object extraction when objects are unknown. Our method starts with a robust segmentation and partitions a subscene into segments, each of which represents either an independent object or a part of some object. A set of classifiers are trained for both individual objects and object groups, using a database of 3D scene models. We employ the multiple kernel learning (MKL) to learn per-category optimized classifiers for objects and object groups. Finally, we perform a graph matching to extract objects using the classifiers, thus grouping the segments into either an object or an object group. The output is an object-level labeled segmentation of the input subscene. Experiments demonstrate that the unified contextual analysis framework achieves robust object detection and recognition over cluttered subscenes. © 2015 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84955616048
"Tang P., Akinci B.","Automatic execution of workflows on laser-scanned data for extracting bridge surveying goals",2012,"Advanced Engineering Informatics",35,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867899122&doi=10.1016%2fj.aei.2012.07.004&partnerID=40&md5=e5516d3ab572ee24907b9a951a1fc6a6","Graphical abstract: Highlights: Manual data processing impedes bridge inspectors from effectively using 3D data. A framework for executing user-defined 3D data processing workflows is developed. Automatic workflow executions save more than 70% of surveying goal extraction time. Workflow automation enables quantitative characterization of data processing options With the capability of capturing detailed geometry of bridges in minutes, laser scanning technology has attracted the interests of bridge inspectors and researchers in the domain of bridge management. A challenge of effectively utilizing laser scanned point clouds for bridge inspection is that inspectors need to manually extract and measure large numbers of geometric features (e.g., points) for deriving geometric information items (e.g., the minimum underclearance) of bridges, named as bridge surveying goals in this research. Tedious manual data processing impedes inspectors from quantitatively understanding how various data processing options (e.g., algorithms, parameter values) influence the data processing time and the reliabilities of the surveying goal results. This paper shows the needs of automatic workflow executions for extracting surveying goals from laser scanned point clouds, and presents a computational framework for addressing these needs. This computational framework is composed of formal representations of workflows and mechanisms for constructing and executing workflows. Using a prototype system implemented based on this framework, we constructed and quantitatively characterized three workflows for extracting three representative bridge surveying goals, using three metrics of workflow performance defined in this research: exhaustiveness of measurement sampling, reliability of surveying goal results, and time efficiency. © 2012 Elsevier Ltd. All rights reserved.",Conference Paper,"Final",Scopus,2-s2.0-84867899122
"Valero E., Adan A., Cerrada C.","Automatic construction of 3D basic-semantic models of inhabited interiors using laser scanners and RFID sensors",2012,"Sensors (Switzerland)",35,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861552895&doi=10.3390%2fs120505705&partnerID=40&md5=609ead68aaa11dba819e6c6789d605c1","This paper is focused on the automatic construction of 3D basic-semantic models of inhabited interiors using laser scanners with the help of RFID technologies. This is an innovative approach, in whose field scarce publications exist. The general strategy consists of carrying out a selective and sequential segmentation from the cloud of points by means of different algorithms which depend on the information that the RFID tags provide. The identification of basic elements of the scene, such as walls, floor, ceiling, windows, doors, tables, chairs and cabinets, and the positioning of their corresponding models can then be calculated. The fusion of both technologies thus allows a simplified 3D semantic indoor model to be obtained. This method has been tested in real scenes under difficult clutter and occlusion conditions, and has yielded promising results. © 2012 by the authors; licensee MDPI, Basel, Switzerland.",Article,"Final",Scopus,2-s2.0-84861552895
"Valero E., Adán A., Bosché F.","Semantic 3D reconstruction of furnished interiors using laser scanning and RFID technology",2016,"Journal of Computing in Civil Engineering",34,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975263210&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000525&partnerID=40&md5=1bcff0e06c34f4f09988dfa05d24c1f5","Terrestrial Laser Scanning (TLS) technology is increasingly used for the generation of accurate three-dimensional (3D) models of objects and scenes. But converting the acquired 3D point cloud data into a representative, semantic 3D model of the scene requires advanced processing and skills. This research field is challenging, particularly when considering inhabited, furnished environments that are characterised by clutter and occlusions. This paper presents a TLS data-processing pipeline aimed at producing semantic 3D models of furnished office and home interiors. The structure of rooms (floor, ceiling, and walls with window and door openings) is created using Boundary Representation (B-Rep) models that not only encode the geometry of those elements, but also their connectivity. Windows and doors are recognized and modeled using a novel method based on molding detection. For the furniture, the approach uniquely integrates smart technology [radio frequency identification (RFID)] that is increasingly used for Facilities Management (FM). RFID tags attached to furniture are sensed at the same time as laser scanning is conducted. The collected IDs are used to retrieve discriminatory geometric information about those objects from the building's FM database; this information is used to support their recognition and modeling in the point cloud data. The manuscript particularly reports results for the recognition and modeling of chairs, tables, and wardrobes (and other similar objects like chests of drawers). Extended experimentation of the method has been carried out in real scenarios yielding encouraging results. © 2015 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84975263210
"Huang J., You S.","Point cloud matching based on 3D self-similarity",2012,"IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",33,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864980305&doi=10.1109%2fCVPRW.2012.6238913&partnerID=40&md5=67bdf784ce8766e9ef866bcfccbba936","Point cloud is one of the primitive representations of 3D data nowadays. Despite that much work has been done in 2D image matching, matching 3D points achieved from different perspective or at different time remains to be a challenging problem. This paper proposes a 3D local descriptor based on 3D self-similarities. We not only extend the concept of 2D self-similarity [1] to the 3D space, but also establish the similarity measurement based on the combination of geometric and photometric information. The matching process is fully automatic i.e. needs no manually selected land marks. The results on the LiDAR and model data sets show that our method has robust performance on 3D data under various transformations and noises. © 2012 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84864980305
"Li Y., Wu X., Wu X., Chrysathou Y., Sharf A., Cohen-Or D., Mitra N.J.","GlobFit: Consistently Fitting Primitives by Discovering Global Relations",2011,"ACM Transactions on Graphics",33,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024253284&doi=10.1145%2f2010324.1964947&partnerID=40&md5=bb86cddce6306ab99fddfddf2c741a95","Given a noisy and incomplete point set, we introduce a method that simultaneously recovers a set of locally fitted primitives along with their global mutual relations. We operate under the assumption that the data corresponds to a man-made engineering object consisting of basic primitives, possibly repeated and globally aligned under common relations. We introduce an algorithm to directly couple the local and global aspects of the problem. The local fit of the model is determined by how well the inferred model agrees to the observed data, while the global relations are iteratively learned and enforced through a constrained optimization. Starting with a set of initial RANSAC based locally fitted primitives, relations across the primitives such as orientation, placement, and equality are progressively learned and conformed to. In each stage, a set of feasible relations are extracted among the candidate relations, and then aligned to, while best fitting to the input data. The global coupling corrects the primitives obtained in the local RANSAC stage, and brings them to precise global alignment. We test the robustness of our algorithm on a range of synthesized and scanned data, with varying amounts of noise, outliers, and non-uniform sampling, and validate the results against ground truth, where available. © 2011, ACM. All rights reserved.",Article,"Final",Scopus,2-s2.0-85024253284
"Kim H., Haas C.T., Rauch A.F., Browne C.","Dimensional ratios for stone aggregates from three-dimensional laser scans",2002,"Journal of Computing in Civil Engineering",33,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-16444378194&doi=10.1061%2f%28ASCE%290887-3801%282002%2916%3a3%28175%29&partnerID=40&md5=942c9c96e60e9985e4c3a87958bb2a39","The ""laser-based aggregate scanning system"" (LASS) was developed to rapidly and accurately characterize the three-dimensional shape properties of unbound stone aggregates. A linear motion slide, a laser line scanner, and an integrated computer constitute the hardware of the LASS. Using profile data obtained from laser scans of aggregate particles spread out on a platform, the LASS software virtually rotates each irregularly shaped particle to determine the three principal dimensions used to characterize particle shape. The computational method employed can rapidly process the scanned data without losing critical information. Two hundred randomly selected particles, which have variable material and shape characteristics, were manually measured to obtain data that were then used to verify the accuracy of the LASS results. Good correlation with the manual measurements demonstrates that laser profiling has the potential to be a powerful tool for rapidly analyzing the dimensions of irregularly shaped objects, and could be used for quality-control testing and performance-related characterization of stone aggregate materials. © ASCE,.",Article,"Final",Scopus,2-s2.0-16444378194
"Sharif M.-M., Nahangi M., Haas C., West J.","Automated Model-Based Finding of 3D Objects in Cluttered Construction Point Cloud Models",2017,"Computer-Aided Civil and Infrastructure Engineering",32,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029210189&doi=10.1111%2fmice.12306&partnerID=40&md5=32096b6e05eabc7ca96164b8a09f95b3","Finding construction components in cluttered point clouds is a critical pre-processing task that requires intensive and manual operations. Accurate isolation of an object from point clouds is a key for further processing steps such as positive identification, scan-to-building information modeling (BIM), and robotic manipulation. Manual isolaton is tedious, time consuming, and disconnected from the automated tasks involved in the process. This article adapts and examines a method for finding objects within 3D point clouds robustly, quickly, and automatically. A local feature on a pair of points is employed for representing 3D shapes. The method has three steps: (1) offline model library generation, (2) online searching and matching, and (3) match refinement and isolation. Experimental tests are carried out for finding industrial (curvilinear) and structural (rectilinear) elements. The method is verified under various circumstances in order to measure its performance toward addressing the major challenges involved in 3D object finding. Results show that the method is sufficiently quick and robust to be integrated with automated process control frameworks. © 2017 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85029210189
"Kim H., Rauch A.F., Haas C.T.","Automated quality assessment of stone aggregates based on laser imaging and a neural network",2004,"Journal of Computing in Civil Engineering",32,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-16444382403&doi=10.1061%2f%28ASCE%290887-3801%282004%2918%3a1%2858%29&partnerID=40&md5=eb050946d6f2112abd7b739c5a0fd02c","An automated quality assessment technique is proposed for rapidly detecting excessive size variations during the production of stone aggregates. The system uses a laser profiler to scan collections of aggregate particles and obtain three-dimensional data points on the particle surfaces. For computational efficiency, the resulting data are converted into digital images. Wavelet transforms are then applied to the images to extract features indicative of the material gradation. These wavelet-based features are used as inputs to an artificial neural network, which is trained to classify the aggregate sample. Taken together, these components form a neural network-based classification system that can determine whether or not an aggregate product is in compliance with a given specification. Verification tests show that this approach could potentially help to determine, in an accurate and fast (real-time) manner, when adjustments or repairs to the production equipment are needed. © ASCE,.",Article,"Final",Scopus,2-s2.0-16444382403
"Xu K., Kim V.G., Huang Q., Kalogerakis E.","Data-Driven Shape Analysis and Processing",2017,"Computer Graphics Forum",31,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014968807&doi=10.1111%2fcgf.12790&partnerID=40&md5=af779137908a60858bad271b9c0e83b8","Data-driven methods serve an increasingly important role in discovering geometric, structural and semantic relationships between shapes. In contrast to traditional approaches that process shapes in isolation of each other, data-driven methods aggregate information from 3D model collections to improve the analysis, modelling and editing of shapes. Data-driven methods are also able to learn computational models that reason about properties and relationships of shapes without relying on hard-coded rules or explicitly programmed instructions. Through reviewing the literature, we provide an overview of the main concepts and components of these methods, as well as discuss their application to classification, segmentation, matching, reconstruction, modelling and exploration, as well as scene analysis and synthesis. We conclude our report with ideas that can inspire future research in data-driven shape analysis and processing. © 2016 The Authors Computer Graphics Forum © 2016 The Eurographics Association and John Wiley & Sons Ltd.",Article,"Final",Scopus,2-s2.0-85014968807
"Szpak Z.L., Chojnacki W., van den Hengel A.","Guaranteed Ellipse Fitting with a Confidence Region and an Uncertainty Measure for Centre, Axes, and Orientation",2015,"Journal of Mathematical Imaging and Vision",31,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939947202&doi=10.1007%2fs10851-014-0536-x&partnerID=40&md5=099ddffe39770949a3764641b48554cf","A simple and fast ellipse estimation method is presented based on optimisation of the Sampson distance serving as a measure of the quality of fit between a candidate ellipse and data points. Generation of ellipses, not just conics, as estimates is ensured through the use of a parametrisation of the set of all ellipses. Optimisation of the Sampson distance is performed with the aid of a custom variant of the Levenberg–Marquardt algorithm. The method is supplemented with a measure of uncertainty of an ellipse fit in two closely related forms. One of these concerns the uncertainty in the algebraic parameters of the fit and the other pertains to the uncertainty in the geometrically meaningful parameters of the fit such as the centre, axes, and major axis orientation. In addition, a means is provided for visualising the uncertainty of an ellipse fit in the form of planar confidence regions. For moderate noise levels, the proposed estimator produces results that are fully comparable in accuracy to those produced by the much slower maximum likelihood estimator. Due to its speed and simplicity, the method may prove useful in numerous industrial applications where a measure of reliability for geometric ellipse parameters is required. © 2014, Springer Science+Business Media New York.",Article,"Final",Scopus,2-s2.0-84939947202
"Yabuki N., Lebegue E., Gual J., Shitani T., Zhantao L.","International collaboration for developing the bridge product model IFC-Bridge",2006,"Proceedings of the Joint International Conference on Computing and Decision Making in Civil and Building Engineering",31,,[No abstract available],,"Final",Scopus,2-s2.0-58149255879
"Flach P.","The many faces of ROC analysis in machine learning",2004,"ICML Tutorial",31,,[No abstract available],,"Final",Scopus,2-s2.0-14844342344
"Van Berlo L.A.H.M., Beetz J., Bos P., Hendriks H., Van Tongeren R.C.J.","Collaborative engineering with IFC: New insights and technology",2012,"eWork and eBusiness in Architecture, Engineering and Construction - Proceedings of the European Conference on Product and Process Modelling 2012, ECPPM 2012",30,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863508957&partnerID=40&md5=59ed7172fd4cec6c0ae975e3ab618054","The concept of working in one central Building Information Model (BIM) is becoming increasingly popular. Reports in literature as well as industry practitioners describe the lack of good implementations for IFC import/export in current software tools. The so-called 'round tripping' of an IFC model cannot be performed without data loss, making the merging of data into one central data repository impractical. This feeds discussions about the workability of IFC in relation to a homogeneous software environment. In the Netherlands several experiments were conducted to research if IFC still meets the needs from theAEC industry. The observations and opinions from users refute current theories and perceptions on collaborations using IFC. This paper describes a collaboration process called 'reference models'. User opinions from the research state that the use of IFC, in an suitable collaboration process, meets the needs of the industry even better than homogeneous proprietary software environments. © 2012 Taylor & Francis Group.",Conference Paper,"Final",Scopus,2-s2.0-84863508957
"Ma L., Sacks R., Kattel U., Bloch T.","3D Object Classification Using Geometric Features and Pairwise Relationships",2018,"Computer-Aided Civil and Infrastructure Engineering",29,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036554829&doi=10.1111%2fmice.12336&partnerID=40&md5=9576f932175c414701195f08759d7eff","Object classification is a key differentiator of building information modeling (BIM) from three-dimensional (3D) computer-aided design (CAD). Incorrect object classification impedes the full exploitation of BIM models. Models prepared using domain-specific software cannot ensure correct object classification when transferred to other domains, and research on reconstruction of BIM models using spatial survey has not proved a full capability to classify objects. This research proposed an integrated approach to object classification that applied domain experts’ knowledge of shape features and pairwise relationships of 3D objects to effectively classify objects using a tailored matching algorithm. Among its contributions: the algorithms implemented for shape and spatial feature identification could process various complex 3D geometry; the method devised for compilation of the knowledge base considered both rigor and confidence of the inference; the algorithm for matching provides mathematical measurement of the object classification results. The integrated approach has been applied to classify 3D bridge objects in two models: a model prepared using incorrect object types and a model manually reconstructed using point cloud data. All these objects were successfully classified. © 2017 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85036554829
"Konstantinou E., Brilakis I.","Matching Construction Workers across Views for Automated 3D Vision Tracking On-Site",2018,"Journal of Construction Engineering and Management",28,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047057175&doi=10.1061%2f%28ASCE%29CO.1943-7862.0001508&partnerID=40&md5=4679d9efd7b27a63b9e828afbe437167","Computer vision-based tracking methods are used to track construction resources for productivity and safety purposes. This type of tracking requires that targets be accurately matched across multiple camera views to obtain a three-dimensional (3D) trajectory out of two or more two-dimensional (2D) trajectories. This matching is straightforward when it involves easily distinguishable targets in uncluttered scenes. This can be challenging in industrial scenes such as construction sites due to congestion, occlusions, and workers in greatly similar high-visibility apparel. This paper proposes a novel vision-based method that addresses all these issues. It uses as input the output of a 2D vision-based tracking method and searches for potential matches in three sequential steps. It terminates only when a positive match is found. The first step returns the strongest candidate by correlating a segment of workers' past 2D trajectories. The second uses geometric restrictions, whereas the third correlates color intensity values. The proposed method features a promising performance of 97% precision, 98% recall, and 95% accuracy. © 2018 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85047057175
"Ladrón De Guevara I., Muñoz J., De Cózar O.D., Blázquez E.B.","Robust fitting of circle arcs",2011,"Journal of Mathematical Imaging and Vision",27,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953165680&doi=10.1007%2fs10851-010-0249-8&partnerID=40&md5=11ceab95a83617b42b8768c1b4ee7126","Geometric fitting is present in different fields of sciences, engineering and astronomy. In particular, circular arc primitives are some of the most commonly employed geometric features in digital image analysis and visual pattern recognition. In this paper, a robust geometric method based on mean absolute error to fit a set of points is proposed. Most geometric and algebraic methods are sensitive to noise and outlier points and so the results are not usually acceptable. It is well known that the least absolute error criterion leads to robust estimations. However, the objective function is non differentiable and thus algorithms based on gradient cannot be applied. We propose an algorithm based on left and right side partial derivatives that is computationally efficient as an alternative to conventional algorithms, and evaluate the sensitivity of circle fits for different types of data. © 2010 Springer Science+Business Media, LLC.",Article,"Final",Scopus,2-s2.0-79953165680
"Jones S., Laquidara-Carr D., Lorenz A., Buckley B., Barnett S.","The business value of bim for infrastructure 2017",2017,"The Business Value of BIM for Infrastructure 2017",26,,[No abstract available],,"Final",Scopus,2-s2.0-85047721262
"Gao T., Akinci B., Ergan S., Garrett J.","An approach to combine progressively captured point clouds for BIM update",2015,"Advanced Engineering Informatics",26,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960809050&doi=10.1016%2fj.aei.2015.08.005&partnerID=40&md5=efdd3261dcc7f35ef68f5f1ee79adb7d","Building information models (BIMs) provide opportunities to serve as an information repository to store and deliver as-built information. Since a building is not always constructed exactly as the design information specifies, there will be discrepancies between a BIM created in the design phase (called as-designed BIM) and the as-built conditions. Point clouds captured by laser scans can be used as a reference to update an as-designed BIM into an as-built BIM (i.e., the BIM that captures the as-built information). Occlusions and construction progress prevent a laser scan performed at a single point in time to capture a complete view of building components. Progressively scanning a building during the construction phase and combining the progressively captured point cloud data together can provide the geometric information missing in the point cloud data captured previously. However, combining all point cloud data will result in large file sizes and might not always guarantee additional building component information. This paper provides the details of an approach developed to help engineers decide on which progressively captured point cloud data to combine in order to get more geometric information and eliminate large file sizes due to redundant point clouds. © 2015 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84960809050
"Fehr J., Streicher A., Burkhardt H.","A Bag of Features approach for 3D shape retrieval",2009,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",24,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-72449204237&doi=10.1007%2f978-3-642-10331-5_4&partnerID=40&md5=5a34c4d9d54f6a37c115947c8a400082","In this paper, we present an adaptation the Bag of Features (BoF) concept to 3D shape retrieval problems. The BoF approach has recently become one of the most popular methods in 2D image retrieval. We extent this approach from 2D images to 3D shapes. Following the BoF outline, we address the necessary modifications for the 3D extension and present novel solutions for the parameterization of 3D patches, a 3D rotation invariant similarity measure for these patches and a method for the codebook generation. We experimentally evaluate the performance of our methods on the Princeton Shape Benchmark. © 2009 Springer-Verlag.",Conference Paper,"Final",Scopus,2-s2.0-72449204237
"Li X., Godil A.","Exploring the bag-of-words method for 3D shape retrieval",2009,"Proceedings - International Conference on Image Processing, ICIP",24,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951967782&doi=10.1109%2fICIP.2009.5414415&partnerID=40&md5=69380622212e30b46586a47170ccd37e","This paper investigates the capabilities of the Bag-of-Words (BW) method in the 3D shape retrieval field. The contributions of this paper are: 1) the 3D shape retrieval task is categorized from different points of view: specific vs. generic, partial-to-global (PG) vs. global-to-global (GG) retrieval, and articulated vs. non-articulated; 2) The spatial information, which is represented as concentric spheres, is integrated into the framework to improve the discriminative capability; 3) the analysis of the experimental results on Purdue Engineering Benchmark (PEB) [4] reveals that some properties of the BW approach make it perform better on the PG task than the GG task. 4) The BW approach is evaluated on non-articulated database PEB [4] and articulated database McGill Shape Benchmark (MSB) [17] and compared to other methods. ©2009 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-77951967782
"Wang Y., Hao W., Ning X., Zhao M., Zhang J., Shi Z., Zhang X.","Automatic segmentation of urban point clouds based on the gaussian map",2013,"Photogrammetric Record",23,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889678237&doi=10.1111%2fphor.12041&partnerID=40&md5=63a1be81bc7abcd7a55d7501458aed5b","A comprehensive method to segment urban point clouds based on the Gaussian map is presented. The normals of point clouds are firstly mapped to the Gaussian sphere and then partitioned into groups using a mean shift clustering algorithm. Next, a distance-based clustering method is presented to tackle overlapping surfaces which avoids under-segmentation. Based on the properties of the Gaussian map and the geometric information of the points, primitive shapes such as planes, cylinders, cones and spheres are recognised. Trees, cars, street lights and other objects are then segmented by using the distance-based clustering method after removing the planes, cylinders, cones and spheres from the large urban scenes. Finally, a refinement process based on primitive shapes is implemented to improve the segmentation results which effectively avoids over-segmentation. Experimental results demonstrate that the proposed method can be used as a robust way to segment urban point clouds based on the Gaussian map. © 2013 The Remote Sensing and Photogrammetry Society and John Wiley & Sons Ltd.",Article,"Final",Scopus,2-s2.0-84889678237
"Fumarola M., Poelman R.","Generating virtual environments of real world facilities: Discussing four different approaches",2011,"Automation in Construction",23,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952628809&doi=10.1016%2fj.autcon.2010.08.004&partnerID=40&md5=4ae6d1fd239e78ee31f925c049ddeac1","There is an increasing need to generate detailed real-time virtual environments that closely mimic real world facilities. Approaches for the generation of virtual environments can be manual, automatic, or hybrid. Manual approaches are time consuming, inaccurate, and coarse whereas automatically generated data sets are less than optimal for practical use within real-time virtual environments because of the huge unstructured amount of data. Therefore, common approaches are most likely to have a balance between human and computer effort. Based on different projects, we discuss possible distributions of manual and automatic methods for the generation of 3D virtual environments. We present different facets of the pipeline from initial data gathering up to the final deliverable. The approaches employed in these projects vary from fully hand made up to semi-automatic reconstruction of the environments. The paper concludes with recommendations regarding the reconstruction methods. © 2010 Elsevier B.V. All rights reserved.",Conference Paper,"Final",Scopus,2-s2.0-79952628809
"Fuchs S., Kadolsky M., Scherer R.J.","Formal description of a generic multi-model",2011,"Proceedings of the 2011 20th IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises, WETICE 2011",22,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052623240&doi=10.1109%2fWETICE.2011.34&partnerID=40&md5=144625190e310ef1382748ad576ba21a","Multi-Models address issues of nD modeling problems in construction information processes. They provide a temporary and loose coupling by aggregating instances of possibly orthogonal domain models and expressing explicit relations between their elements. To provide a base for prototypical and specific multi-model support as well as the development of generic multi-model based tools, the authors propose a data schema for a generic multi-model, consisting of an ID-based link model and two elementary model representations. Specifications of optional meta-data provide structural and semantic description of the data. © 2011 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-80052623240
"Wimmer M., Radig B., Beetz M.","A person and context specific approach for skin color classification",2006,"Proceedings - International Conference on Pattern Recognition",22,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-34047197020&doi=10.1109%2fICPR.2006.151&partnerID=40&md5=1118a455dfe1404c5af6ec98a70b473a","Skin color is an important feature of faces. Various applications benefit from robust skin color detection. Depending on camera settings, illumination, shadows, people's tans, and ethnic groups skin color looks differently, which is a challenging aspect for detecting it automatically. In this paper, we present an approach that uses a high level vision module to detect an image specific skin color model. This model is then used to adapt parametric skin color classifiers to the processed image. This approach is capable to distinguish skin color from extremely similar colors, such as lip color or eyebrow color. Its high speed and high accuracy make it appropriate for real time applications such as face tracking and recognition of facial expressions. © 2006 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-34047197020
"Czerniawski T., Nahangi M., Walbridge S., Haas C.","Automated removal of planar clutter from 3D point clouds for improving industrial object recognition",2016,"ISARC 2016 - 33rd International Symposium on Automation and Robotics in Construction",21,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994310384&doi=10.22260%2fisarc2016%2f0044&partnerID=40&md5=858050003bb414fa82efd23a39618460","The industrial construction industry makes use of prefabrication, preassembly, modularization and offsite fabrication (PPMOF) for project execution because they offer a superior level of control as compared to on-site operations. This control is enabled by systematic and thorough performance feedback loops. Improvement of the feedback systems within these facilities will require a transition away from suboptimal manual data collection to more reliable automated data collection and processing. Laser scanners are an effective tool for automatically gathering dimensional data but extraction of useful information from point clouds remains a challenge. The speed of 3D object recognition methods depends on the size of the search space. Methods for reducing this search space are needed in order to improve the performance of 3D object recognition and subsequent information extraction. Large planar objects (e.g. floors and walls) constitute a large portion of the search space in fabrication facilities, yet are rarely the objects of interest for analysis. In this paper, an automated framework for detecting and removing large planes in point clouds is presented to speed up object recognition. The raw point cloud is first Guassian mapped to normal vector space by calculating normal vectors at each point. The Gaussian sphere is clustered using a density-based clustering algorithm and major parallel planes are segmented from the rest of the point cloud. The major planes are removed and the remaining objects in the scene continue on to 3D object recognition. Results show the algorithm for automatic plane removal can reduce the search space for object recognition by as much as 60% or 70%.",Conference Paper,"Final",Scopus,2-s2.0-84994310384
"Hullo J.-F., Thibault G., Boucheny C., Dory F., Mas A.","Multi-sensor as-built models of complex industrial architectures",2015,"Remote Sensing",20,,[No abstract available],,"Final",Scopus,2-s2.0-84971560890
"Grinbaum A.","Which Fine-Tuning Arguments Are Fine?",2012,"Foundations of Physics",20,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859102202&doi=10.1007%2fs10701-012-9629-9&partnerID=40&md5=7a8bed575a18b17ae9b0eaeb99aaae88","Fine-tuning arguments are a frequent find in the literature on quantum field theory. They are based on naturalness-an aesthetic criterion that was given a precise definition in the debates on the Higgs mechanism. We follow the history of such definitions and of their application at the scale of electroweak symmetry breaking. They give rise to a special interpretation of probability, which we call Gedankenfrequency. Finally, we show that the argument from naturalness has been extended to comparing different models of the physics beyond the Standard Model and that naturalness in this case can at best be understood a socio-historic heuristic. © 2012 Springer Science+Business Media, LLC.",Article,"Final",Scopus,2-s2.0-84859102202
"Weisstein E.W.","Moore-Penrose matrix inverse",2014,"Moore-Penrose Matrix Inverse",19,,[No abstract available],,"Final",Scopus,2-s2.0-33749431173
"Zhang G., Vela P.A., Brilakis I.","Automatic generation of as-built geometric civil infrastructure models from point cloud data",2014,"Computing in Civil and Building Engineering - Proceedings of the 2014 International Conference on Computing in Civil and Building Engineering",19,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934282688&doi=10.1061%2f9780784413616.051&partnerID=40&md5=10de89f75793dc580d6924b1c3aea097","Converting remote sensing point cloud data (PCD) into solid CAD models consisting of civil infrastructure components is a crucial step in generating the as-built building information models. Previous research has enabled automatic generation of surface primitives from raw PCDs. However, the fully automatic conversion from surface primitives to infrastructure component models remains an unsolved problem. In this work, an automatic and linear-runtime approach is presented which generates the as-built infrastructure component models by recognizing the solid CAD entities and learning the infrastructure component labels from the fitted surface primitives. The algorithm utilizes a decision tree with the following decision variables: the type, parametric model, orientation, and mutual geometric relations of the fitted surface primitives. The decision tree is trained with easily generated synthetic data and is applied to query real-world data with complexity O (1). The output of the solid entities includes cuboid, cylinder, and ball, and the infrastructure component labels (such as columns, caps, deck, and beams). The algorithm is tested with various PCDs modeling real bridges. © ASCE 2014.",Conference Paper,"Final",Scopus,2-s2.0-84934282688
"Su Y.-T., Bethel J.","Detection and robust estimation of cylinder features in point clouds",2010,"American Society for Photogrammetry and Remote Sensing Annual Conference 2010: Opportunities for Emerging Geospatial Technologies",19,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868517907&partnerID=40&md5=b72aeef03150e4e3cfa7a3417c6497ae","The objective of this work is to develop new methods for efficient automatic 3D modeling of existing industrial installations from point cloud data. Traditionally, cylinder feature extraction algorithms utilize 5D Hough transforms, resulting in impractically high computational complexity. A more efficient approach uses a 2D Hough transform to estimate orientation followed by a 3D Hough transform to detect position, but still has extensive runtimes and lacks robustness in dense point cloud data. This work endeavors to (1) further decrease the runtime for cylinder feature extraction by implementing a coarse-to-fine approach, and (2) improve the robustness of the algorithm in detecting multiple cylinders by applying a clustering algorithm. In the coarse-to-fine approach, an initial estimate of the cylinder feature is quickly generated by coarsely sampling the Hough space. Subsequently, the search space is iteratively restricted based on the previous estimate while increasing sampling density to generate continually improving feature estimates until a stop criterion is reached. Results show that the implemented coarse-to-fine approach yielded an improvement in orientation estimate accuracy of 20% while reducing runtime by 74%. To improve the robustness of the Hough transform in the presence of multiple cylinders, a clustering technique is implemented on the accumulator. First, cells in the accumulator with small number of accumulations are discarded to facilitate the computation of a hierarchical tree. Clustering is then applied to group the remaining cells into clusters representing different cylinders. This method improves robustness as well as accuracy of feature extraction in point cloud data with diverse cylinders.",Conference Paper,"Final",Scopus,2-s2.0-84868517907
"Bassier M., Klein R., Van Genechten B., Vergauwen M.","IFCWALL RECONSTRUCTION from UNSTRUCTURED POINT CLOUDS",2018,"ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences",18,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048404607&doi=10.5194%2fisprs-annals-IV-2-33-2018&partnerID=40&md5=0ef7a9f4aadd8393138a48e90f7be8d7","The automated reconstruction of Building Information Modeling (BIM) objects from point cloud data is still ongoing research. A key aspect is the creation of accurate wall geometry as it forms the basis for further reconstruction of objects in a BIM. After segmenting and classifying the initial point cloud, the labelled segments are processed and the wall topology is reconstructed. However, the preocedure is challenging due to noise, occlusions and the complexity of the input data.<br>In this work, a method is presented to automatically reconstruct consistent wall geometry from point clouds. More specifically, the use of room information is proposed to aid the wall topology creation. First, a set of partial walls is constructed based on classified planar primitives. Next, the rooms are identified using the retrieved wall information along with the floors and ceilings. The wall topology is computed by the intersection of the partial walls conditioned on the room information. The final wall geometry is defined by creating IfcWallStandardCase objects conform the IFC4 standard. The result is a set of walls according to the as-built conditions of a building. The experiments prove that the used method is a reliable framework for wall reconstruction from unstructured point cloud data. Also, the implementation of room information reduces the rate of false positives for the wall topology. Given the walls, ceilings and floors, 94% of the rooms is correctly identified. A key advantage of the proposed method is that it deals with complex rooms and is not bound to single storeys. © 2018 Copernicus GmbH. All rights reserved.",Conference Paper,"Final",Scopus,2-s2.0-85048404607
"Hou J., Dai A., Nießner M.","3D-SIS: 3D Semantic Instance Segmentation of RGB-D Scans",2018,"3d-sis: 3d Semantic Instance Segmentation of Rgb-d Scans",18,,[No abstract available],,"Final",Scopus,2-s2.0-85080041124
"Perez-Gallardo Y., Cuadrado J.L.L., Crespo Á.G., de Jesús C.G.","GEODIM: A Semantic model-based system for 3D recognition of industrial scenes",2017,"Intelligent Systems Reference Library",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015451563&doi=10.1007%2f978-3-319-51905-0_7&partnerID=40&md5=93ea0241f17f88e732ebfaf5bf7cb646","Keeping an inventory of the facilities within a factory implies high costs in terms of time, effort, and knowledge, since it demands the detailed, orderly, and valued description of the items within the plant. One way to accomplish this task within scanned industrial scenes is through the combination of an object recognition algorithm with semantic technology. This research therefore introduces GEODIM, a semantic model-based system for recognition of 3D scenes of indoor spaces in factories. The system relies on the two aforementioned technologies to describe industrial digital scenes with logical, physical, and semantic information. GEODIM extends the functionality of traditional object recognition algorithms by incorporating semantics in order to identify and characterize recognized geometric primitives along with rules for the composition of real objects. This research also describes a real case where GEODIM processes were applied and presents its qualitative evaluation. © Springer International Publishing AG 2017.",Book Chapter,"Final",Scopus,2-s2.0-85015451563
"Nahangi M., Czerniawski T., Haas C.T., Walbridge S., West J.","Parallel systems and structural frames realignment planning and actuation strategy",2016,"Journal of Computing in Civil Engineering",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975284999&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000545&partnerID=40&md5=e0e235a77063bb34abd8f5d0ede2fb1d","Parallel structural systems and assemblies are challenging to erect, align and plumb on construction sites due to their complex geometries and current heuristic realignment strategies. Examples of parallel systems include complicated pipe modules and pipe racks in the industrial construction sector. This paper presents a generalized approach analogous to robotics and inverse kinematics for building parallel systems' realignment planning, introduced using a series approach. In addition to the calculation of a realignment strategy, feasible applications of such a strategy are also investigated in this paper. The framework for realigning parallel systems has two primary steps: (1) as-built status identification by capturing the geometric state of construction assemblies using three-dimensional (3D) imaging theories, and (2) realignment calculation and actuation based on degrees of freedom (DOFs) defined during the development of the kinematics chains of assemblies. A Quasi-Newton-Raphson (QNR) method is employed for solving the kinematics equation of the inverse kinematics analogy. Experimental results show that the developed algorithms are sufficiently accurate to capture any incurred geometrical discrepancies in parallel construction assemblies and proactively calculate and plan for efficient realignment strategies. Generalization of realignment calculation for parallel systems and realignment actuation are the key contributions of this work. © 2015 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84975284999
"Andrews J., Séquin C.H.","Type-Constrained Direct Fitting of Quadric Surfaces",2013,"Computer-Aided Design and Applications",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885404608&doi=10.1080%2f16864360.2013.834155&partnerID=40&md5=de7845c74ebecdcd00e4cfa0bda2cbe4","We present a catalog of type-specific, direct quadric fitting methods: Given a selection of a point cloud or triangle mesh, and a desired quadric type (e.g. cone, ellipsoid, paraboloid, etc), our methods recover a best-fit surface of the given type to the given data. Type-specific quadric fitting methods are scattered throughout the literature; here we present a thorough, practical collection in one place. We add new methods to handle neglected quadric types, such as non-circular cones and general rotationally symmetric quadrics. We improve upon existing methods for ellipsoid- and hyperboloid-specific fitting. Our catalog handles a wide range of quadric types with just two high-level fitting strategies, making it simpler to understand and implement. © 2013 Copyright CAD Solutions, LLC.",Article,"Final",Scopus,2-s2.0-84885404608
"Zhang G., Vela P.A., Brilakis I.","Detecting, fitting, and classifying surface primitives for infrastructure point cloud data",2013,"Computing in Civil Engineering - Proceedings of the 2013 ASCE International Workshop on Computing in Civil Engineering",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887369290&doi=10.1061%2f9780784413029.074&partnerID=40&md5=79e265e09235701bba84d15dc31928d6","This paper presents a novel algorithm for detecting, fitting and classifying the embedded surface primitives from a point cloud dataset (PCD). Given a noisy infrastructure PCD, the final output of the algorithm consists of segmented surfaces, their estimated quadric models and corresponding surface classification. Initially, the PCD is down-sampled with a k-d tree structure then segmented via subspace learning. After pose recovery for each segmented group via singular value decomposition, a full quadric model is fit in MLESAC using the direct linear transform for parameter estimation. From the model parameters, the surface is classified from the rank, determinant, and eigenvalues of the parameter matrices. Finally, model merging is performed to simplify the results. A real-world PCD of a bridge is used to test the algorithm. The experimental validation of the algorithm demonstrates that the surface primitives are accurately estimated and classified. © 2013 American Society of Civil Engineers.",Conference Paper,"Final",Scopus,2-s2.0-84887369290
"Behley J., Kersting K., Schulz D., Steinhage V., Cremers A.B.","Learning to hash logistic regression for fast 3D scan point classification",2010,"IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010 - Conference Proceedings",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651472675&doi=10.1109%2fIROS.2010.5650093&partnerID=40&md5=ec15230a7007aabd88daf0028d4c9ca1","Segmenting range data into semantic categories has become a more and more active field of research in robotics. In this paper, we advocate to view this task as a problem of fast, large-scale retrieval. Intuitively, given a dataset of millions of labeled scan points and their neighborhoods, we simply search for similar points in the datasets and use the labels of the retrieved ones to predict the labels of a novel point using some local prediction model such as majority vote or logistic regression. However, actually carrying this out requires highly efficient ways of (1) storing millions of scan points in memory and (2) quickly finding similar scan points to a target scan point. In this paper, we propose to address both issues by employing Weiss et al.'s recent spectral hashing. It represents each item in a database by a compact binary code that is constructed so that similar items will have similar binary code words. In turn, similar neighbors have codes within a small Hamming distance of the code for the query. Then, we learn a logistic regression model locally over all points with the same binary code word. Our experiments on real world 3D scans show that the resulting approach, called spectrally hashed logistic regression, can be ultra fast at prediction time and outperforms state-of-the art approaches such as logistic regression and nearest neighbor. ©2010 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-78651472675
"Frangopol D.M.","Probability concepts in engineering: Emphasis on applications to civil and environmental engineering",2008,"Struct. Infrastruct. Eng",17,,[No abstract available],,"Final",Scopus,2-s2.0-85002188763
"Perez-Perez Y., Golparvar-Fard M., El-Rayes K.","Semantic and Geometric Labeling for Enhanced 3D Point Cloud Segmentation",2016,"Construction Research Congress 2016: Old and New Construction Technologies Converge in Historic San Juan - Proceedings of the 2016 Construction Research Congress, CRC 2016",16,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976412190&doi=10.1061%2f9780784479827.253&partnerID=40&md5=952e38c49c0d40b490ade4f907a45884","Accurate and rapidly produced 3D models of the built environment from point cloud data can be used in a variety of engineering applications. When performed manually, this task is often time consuming and labor intensive. In response, several research groups have recently focused on developing methods for segmenting point cloud data based on appearance and geometric information into distinct subsets, and populating the scenes with surface objects. However, these methods, particularly where building systems are in close proximity of architectural/structural elements, still result in over-segmentation or require significant fine-tuning to produce acceptable results. To overcome these limitations, this paper presents a new procedure that takes in a point cloud - segmented at a user-desired level of abstraction - as an input and by considering neighborhood context via a Markov Random Field optimization framework, labels each distinct subset with semantic (wall, ceiling, floor, pipes) and geometric (horizontal, vertical, cylindrical) categories. Experimental results, using real-world point cloud data, show that the method achieves the state-of-the-art performance on semantic and geometric labeling of point cloud data. It is also shown how understanding semantic regions in point clouds - improved via geometric labels - can facilitate the process of generating as-built 3D models from point cloud data. © ASCE.",Conference Paper,"Final",Scopus,2-s2.0-84976412190
"Waibel P., Matthes J., Gröll L.","Constrained Ellipse Fitting with Center on a Line",2015,"Journal of Mathematical Imaging and Vision",15,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942195761&doi=10.1007%2fs10851-015-0584-x&partnerID=40&md5=e3b0c1010439b736a28d6969829ed149","Fitting an ellipse to given data points is a common optimization task in computer vision problems. However, the possibility of incorporating the prior constraint “the ellipse’s center is located on a given line” into the optimization algorithm has not been examined so far. This problem arises, for example, by fitting an ellipse to data points representing the path of the image positions of an adhesion inside a rotating vessel whose position of the rotational axis in the image is known. Our new method makes use of a constrained algebraic cost function with the incorporated “ellipse center on given line”-prior condition in a global convergent one-dimensional optimization approach. Further advantages of the algorithm are computational efficiency and numerical stability. © 2015, Springer Science+Business Media New York.",Article,"Final",Scopus,2-s2.0-84942195761
"Belsky M., Eastman C., Sacks R., Venugopal M., Aram S., Yang D.","Interoperability for precast concrete building models",2014,"PCI Journal",14,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898664550&doi=10.15554%2fpcij.03012014.144.155&partnerID=40&md5=b01654fe4251eeb7e2ef70333d73480b","The precast concrete National BIM Standard (NBIMS) initiative is an industrywide effort encompassing the major building model exchanges dealing with precast concrete and addressing a range of contracting and procurement methods. The standard was developed according to the guidelines described within the NBIMS for facilitating information exchanges and improving interoperability. The precast concrete NBIMS effort is the first of its kind to deal with a large set of exchanges. The tradeoffs and advantages of this large-scale approach are reviewed as well as areas that require additional attention. Two demonstrations were conducted to showcase the functionality that the software companies are developing in support of the standard and to provide an example of the potential of open BIM. They also revealed the importance of full validation testing and certification.",Review,"Final",Scopus,2-s2.0-84898664550
"Ghahremani K., Khaloo A., Mohamadi S., Lattanzi D.","Damage Detection and Finite-Element Model Updating of Structural Components through Point Cloud Analysis",2018,"Journal of Aerospace Engineering",13,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049050412&doi=10.1061%2f%28ASCE%29AS.1943-5525.0000885&partnerID=40&md5=0e5e7a5ce9750d83783905320711ffe3","Accurate and rapid condition assessment of in-service structural components is critical to ensure safety and serviceability. One major assessment consideration is the detection and quantification of structural section loss due to deterioration, for instance, from corrosion. Modern three-dimensional (3D) imaging techniques, which generate high-resolution 3D point clouds, are capable of detecting and measuring these deteriorations. However, despite advancements in the fields of automated point cloud analysis for as-built modeling and structural inspection, the potential use of spatial 3D data for updating numerical finite-element (FE) models of structures is still an emergent topic. This paper presents a localized methodology for the automatic and systematic detection and quantification of damages in structural components using high-fidelity 3D point cloud data, followed by a corresponding local update to an FE model. In this study, 3D point cloud data of a targeted structure were first obtained by using dense structure from motion (DSfM) algorithms. Section loss damage was then identified and located through computer vision and 3D data processing techniques. In order to preserve data integrity and resolve localized high-fidelity details, direct 3D point cloud comparisons were performed. An experimental study validating the developed approach is presented as well. The results indicate that the presented methodology will enable engineers to use the updated structural model to determine the reserved capacity and remaining service life of structural elements, though further studies on methods to improve mesh generation and defect quantification are warranted. © 2018 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85049050412
"Lu R., Brilakis I.","Recursive segmentation for as-is bridge information modelling",2017,"Lean & Computing in Construction Congress (LC3)",12,,[No abstract available],,"Final",Scopus,2-s2.0-85047144737
"Edwards J., Townsend A.","Buildings under refurbishment and retrofit",2011,"Buildings under Refurbishment and Retrofit",12,,[No abstract available],,"Final",Scopus,2-s2.0-84983477511
"Agrawal A., Nakazawa A., Takemura H.","MMM-classification of 3D range data",2009,"Proceedings - IEEE International Conference on Robotics and Automation",12,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350399148&doi=10.1109%2fROBOT.2009.5152539&partnerID=40&md5=83ae396a5ccb527344aad678369944ba","This paper presents a method for accurately segmenting and classifying 3D range data into particular object classes. Object classification of input images is necessary for applications including robot navigation and automation, in particular with respect to path planning. To achieve robust object classification, we propose the idea of an object feature which represents a distribution of neighboring points around a target point. In addition, rather than processing raw points, we reconstruct polygons from the point data, introducing connectivity to the points. With these ideas, we can refine the Markov Random Field (MRF) calculation with more relevant information with regards to determining ""related points"". The algorithm was tested against five outdoor scenes and provided accurate classification even in the presence of many classes of interest.© 2009 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-70350399148
"Wyngaerd J.V., Van Gool L.","Coarse registration of surface patches with local symmetries",2003,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",12,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949009832&doi=10.1007%2f3-540-47967-8_38&partnerID=40&md5=114dedb9753bd9aaf1906a57d460e4ac","Most 3D recording methods generate multiple partial reconstructions that must be integrated to form a complete model. The coarse registration step roughly aligns the parts with each other. Several methods for coarse registration have been developed that are based on matching points between different parts. These methods look for interest points and use a point signature that encodes the local surface geometry to find corresponding points. We developed a technique that is complementary to these methods. Local descriptions can fail or can be highly inefficient when the surfaces contain local symmetries. Instead of discarding these regions, we introduce a method that first uses the Gaussian image to detect planar, cylindrical and conical regions and uses this information to compute the rigid motion between the patches. For combining the information from multiple regions to a single solution, we use a a Hough space that accumulates votes for candidate transformations. Due to their symmetry, they update a subspace of parameter space instead of a single bin. Experiments on real range data from different views of the same object show that the method can find the rigid motion to put the patches in the same coordinates system. © Springer-Verlag Berlin Heidelberg 2002.",Conference Paper,"Final",Scopus,2-s2.0-84949009832
"Wang M., Qiu S., Dong H., Wang Y.","Design an IoT-based building management cloud platform for green buildings",2017,"Proceedings - 2017 Chinese Automation Congress, CAC 2017",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050288273&doi=10.1109%2fCAC.2017.8243793&partnerID=40&md5=d0e91287e34c869a4563fff64262005c","Green building plays an important role in the development of the construction industry. The key issue of green building is how to operate itself. This paper presents a building management cloud platform for green buildings. Its goal is to realize building operation management by using the technologies of cloud computing and Internet of things. The cloud servers provide data storage, computing and hosting. The software takes the responsibility for visualization interfaces and modularization services. The hardware development makes devices and things to connect the network. Many functions such as monitoring, controlling, data processing, management and services customization have been integrated in the building management cloud platform. © 2017 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85050288273
"Wang M., Liu K., Yang G., Xie J.","Three-dimensional slope stability analysis using laser scanning and numerical simulation",2017,"Geomatics, Natural Hazards and Risk",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013478342&doi=10.1080%2f19475705.2017.1290696&partnerID=40&md5=31ccff450abdb88d4f86abf71bc941b7","Detailed surface topography is important when analyzing the stability of slopes. Recent advances in new technologies such as interferometric synthetic aperture radar and light detection and ranging have allowed us to obtain high-precision profiles of distant landscapes and objects including detailed slope information for three-dimensional (3D) slope stability analysis. However, techniques of reconstructing 3D numerical models from scanned data of slope geometry have not been well investigated or tested. This paper proposes a comprehensive approach that integrates laser scanning and finite element method for slope stability analysis, particularly failure prediction under precipitation scenarios. The methodology is applied to a slope in the Wenchuan earthquake-stricken mountainous region that failed in 2013, triggered by severe rainfall. The modelling results show that the surface sampling resolution can affect the prediction accuracy of the potential failure zones. When constructing the slope model, the selected surface grid should be fine enough to capture the important topographic features of the slope while minimizing computation demand. This paper confirms that the proposed method can be successfully used to identify the potential failure zones of the investigated slope under severe rainfall conditions. © 2017 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",Article,"Final",Scopus,2-s2.0-85013478342
"Handa A., Patraucean V., Badrinarayanan V., Stent S., Cipolla R.","SynthCam3D: Semantic understanding with synthetic indoor scenes",2015,"Synthcam3d: Semantic Understanding with Synthetic Indoor Scenes",11,,[No abstract available],,"Final",Scopus,2-s2.0-84986315679
"Song X., Jüttler B.","Modeling and 3D object reconstruction by implicitly defined surfaces with sharp features",2009,"Computers and Graphics (Pergamon)",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349278600&doi=10.1016%2fj.cag.2009.03.021&partnerID=40&md5=3d29b7a0594017f4812763ba8b61c3f5","We propose a new method for describing sharp features (i.e., edges and vertices) of implicitly defined surfaces. We consider an initial implicitly defined surface, which is represented as the zero set of a C1 smooth scalar field with non-vanishing gradients. In order to represent sharp edges and vertices, this surface is augmented by adding new types of implicit representations, called edge descriptors and vertex descriptors. They are defined with the help of the distance field of edge curves. In our implementation, we use circular splines to describe these edge curves, since they support a fast and non-iterative closest point computation. After adding the edge and vertex descriptors to the initial scalar field, the zero set of the augmented function contains the sharp features. We apply the new representation to surface modeling by implicitly defined surfaces with sharp features and to object reconstruction. In the latter case we describe an algorithm for detecting the sharp curves and vertices of a shape which is given by an unorganized point cloud, which are then approximated by circular splines, in order to define the edge and vertex descriptors. © 2009 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-67349278600
"Chow R.","Evolving genotype to phenotype mappings with a multiple-chromosome genetic algorithm",2004,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-35048822939&doi=10.1007%2f978-3-540-24854-5_100&partnerID=40&md5=9deac93550f4bbbc65af08183c7981b1","This paper presents an evolutionary coding method that maps genotype to phenotype in a genetic algorithm. Unlike traditional genetic algorithms, the proposed algorithm involves mating and reproduction of cells that have multiple chromosomes instead of single chromosomes. The algorithm also evolves the mapping from genotype to phenotype rather than using a fixed mapping that is associated with one particular encoding method. The genotype-to-phenotype mapping is conjectured to explicitly capture important schema information. Some empirical results are presented to demonstrate the efficacy of the algorithm with some GA-Hard problems. © Springer-Verlag Berlin Heidelberg 2004.",Article,"Final",Scopus,2-s2.0-35048822939
"Babahajiani P., Fan L., Kamarainen J.-K., Gabbouj M.","Comprehensive Automated 3D Urban Environment Modelling Using Terrestrial Laser Scanning Point Cloud",2016,"IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010219874&doi=10.1109%2fCVPRW.2016.87&partnerID=40&md5=d43c5023755a53990271b04694df00ad","In this paper we present a novel street scene modelling framework, which takes advantage of 3D point cloud captured by a high definition LiDAR laser scanner. We propose an automatic and robust approach to detect, segment and classify urban objects from point clouds hence reconstructing a comprehensive 3D urban environment model. Our system first automatically segments grounds point cloud. Then building facades will be detected by using binary range image processing. Remained point cloud will be grouped into voxels and subsequently transformed into super voxels. Local 3D features are extracted from super voxels and classified by trained boosted decision trees with semantic classes e.g. tree, pedestrian, and car. Given labeled point cloud the proposed algorithm reconstructs the realistic model in two phases. Firstly building facades will be rendered by ShadVis algorithm. In the second step we apply a novel and fast method for fitting the solid predefined template mesh models to non-building labeled point cloud. The proposed method is evaluated both quantitatively and qualitatively on a challenging TLS NAVTEQ True databases. © 2016 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85010219874
"Trimble Navigation Limited",[No title available],2016,"SketchUp",10,,[No abstract available],,"Final",Scopus,2-s2.0-85020015011
"Kim C., Son H., Kim C.","Knowledge-based approach for 3D reconstruction of as-built industrial plant models from laser-scan data",2013,"ISARC 2013 - 30th International Symposium on Automation and Robotics in Construction and Mining, Held in Conjunction with the 23rd World Mining Congress",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893521004&partnerID=40&md5=71058e819d40c3d8bac38425480ed7e1","The three-dimensional (3D) reconstruction of as-built industrial plant models plays an important role in revamping planning, maintenance planning, and preparation for dismantling during the lifecycle of industrial plants. Recently, the 3D reconstruction of existing industrial plants was conducted using laserscan data to make surveying processes more efficient. However, the current 3D reconstruction process from laser-scan data is still limited due to the need for significant human assistance. Although a great deal of effort has been made to efficiently reconstruct 3D as-built industrial plant models, the presence of objects-such as equipment, pipelines, and valves of different sizes and shapes-in existing industrial plants significantly increases the complexity of laser-scan data and makes automating the reconstruction process more challenging in practice. The purpose of this study is to propose a knowledge-based approach for the 3D reconstruction of as-built industrial plant models from unstructured laser-scan data. First, pipelines were extracted from laser-scan data based on surface curvature information and knowledge about pipelines' sizes from existing piping and instrumentation diagrams (P&ID). Once entire pipelines were extracted, they were modeled based on skeleton features. Then, the remaining objects were clustered and grouped separately via the region grouping process. Afterward, clustered objects were retrieved and modeled based on global feature-based matching from the 3D database. Finally, the resulting model was checked to ensure that it was well-reconstructed according to the information regarding the relationships among objects abstracted from the existing P&ID. The preliminary results on actual industrial plants show that integrating knowledge into the reconstruction steps played an important role in the proposed approach and that this approach obtained accurate as-built industrial plant models from unstructured laser-scan data. The proposed approach could be successfully utilized to assist in many applications during the lifecycle of industrial plants.",Conference Paper,"Final",Scopus,2-s2.0-84893521004
"Foley J.","Chapter 12.7: Constructive solid geometry",1996,"Computer Graphics: Principles and Practice",10,,[No abstract available],,"Final",Scopus,2-s2.0-85093480643
"Borrmann A., Amann J., Chipman T., Hyvärinen J., Liebich T., Muhič S., Mol L., Plume J., Scarponcini P.","IFC Infra Overall Architecture Project Documentation and Guidelines, BuildingSMART",2021,"IFC Infra Overall Architecture Project Documentation and Guidelines",9,,[No abstract available],,"Final",Scopus,2-s2.0-85088434803
"Roynard X., Deschaud J.-E., Goulette F.","Paris-lille-3D: A point cloud dataset for urban scene segmentation and classification",2018,"IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",9,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060852706&doi=10.1109%2fCVPRW.2018.00272&partnerID=40&md5=042abc3ebb115ac4e1a867788e5fe74f","This article presents a dataset called Paris-Lille-3D. This dataset is composed of several point clouds of outdoor scenes in Paris and Lille, France, with a total of more than 140 million hand labeled and classified points with more than 50 classes (e.g., the ground, cars and benches). This dataset is large enough and of high enough quality to further research on techniques regarding the automatic classification of urban point clouds. The fields to which that research may be applied are vast, as it provides the ability to increase productivity in regards to the management of urban infrastructures. Moreover, this type of data has the potential to be crucial in the field of autonomous vehicles. © 2018 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85060852706
"Maturana D., Scherer S.",[No title available],2015,"Voxnet: A 3d convolutional neural network for real-time object recognition",9,,[No abstract available],,"Final",Scopus,2-s2.0-85038093968
[No author name available],[No title available],2018,"Level of Development (Lod) Specification Part 1 & Commentary",8,,[No abstract available],,"Final",Scopus,2-s2.0-85073011572
"Nahangi M., Czerniawski T., Haas C.T.","Automated 3d shape detection and outlier removal in cluttered laser scans of industrial assemblies",2015,"Proc. of the International Conference of Innovation in Construction",8,,[No abstract available],,"Final",Scopus,2-s2.0-84976452937
"BIFM",[No title available],2012,"BIM and FM: Bridging the Gap for Success",8,,[No abstract available],,"Final",Scopus,2-s2.0-84931464899
"Altun H., Sinekli R., Tekbas U., Karakaya F., Peker M.","An efficient color detection in RGB space using hierarchical neural network structure",2011,"INISTA 2011 - 2011 International Symposium on INnovations in Intelligent SysTems and Applications",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-79961205068&doi=10.1109%2fINISTA.2011.5946088&partnerID=40&md5=61a13783ec263529725e96c82b800e40","Color detection is generally a primary stage in most of the image processing application, if the application is based on the color information, such as road sign detection, face detection, skin color detection, object detection and object tracking etc. As the performance of subsequent modules in an image processing application is adversely affected by the previous modules, the accuracy of color detection with a high performance inevitably becomes crucial in some applications. This paper introduces a method for an efficient color detection in RGB space using an ensemble of experts in hierarchical structure. In this structure, a set of experts is assigned to evaluate R, G, B components of a pixel and then constructs a degree of membership to the set of predefined class of colors for the given pixel. Then a master neural network constructs its final decision based on the membership probabilities provided by the set of experts. Qualitative and quantitative evaluations of the results show that the proposed hierarchical structure of neural networks is superior over the conventional neural network classifier in color detection. © 2011 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-79961205068
"Agapaki E., Brilakis I.","Prioritising object types of industrial facilities to reduce As-Is modelling time",2017,"Proceedings of the 33Rd Annual ARCOM Conference",7,,[No abstract available],,"Final",Scopus,2-s2.0-85049087113
"Muñoz-Pérez J., De Cózar-Macías O.D., Blázquez-Parra E.B., Ladrón De Guevara-López I.","Multicriteria robust fitting of elliptical primitives",2014,"Journal of Mathematical Imaging and Vision",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900846152&doi=10.1007%2fs10851-013-0480-1&partnerID=40&md5=8de640c61881401a56b0e70a66721f1e","Geometric fitting is present in different fields of science, engineering and astronomy. In particular, ellipse shapes are some of the most commonly employed geometric features in digital image analysis and visual pattern recognition. Most geometric and algebraic methods are sensitive to noise and outlier points and so the results are not usually acceptable. In this paper, a robust geometric multicriteria method based on the mean absolute geometric error and the eccentricity to fit an ellipse to set of points is proposed. It is well known that the least mean absolute error criterion leads to robust estimations. The experimental results on different real and synthetic data have shown that the proposed algorithm is robust to outliers. Moreover, it allows us to identify outliers and remove them. © 2013 Springer Science+Business Media New York.",Article,"Final",Scopus,2-s2.0-84900846152
"Heider P., Pierre-Pierre A., Li R., Mueller R., Grimm C.","Comparing local shape descriptors",2012,"Visual Computer",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865329072&doi=10.1007%2fs00371-012-0725-9&partnerID=40&md5=3b8c26cba7315efb9e293bc8c766d83f","Local shape descriptors can be used for a variety of tasks, from registration to comparison to shape analysis and retrieval. There have been a variety of local shape descriptors developed for these tasks, which have been evaluated in isolation or in pairs, but not against each other. We provide a survey of existing descriptors and a framework for comparing them.We perform a detailed evaluation of the descriptors using real data sets from a variety of sources. We first evaluate how stable these metrics are under changes in mesh resolution, noise, and smoothing. We then analyze the discriminatory ability of the descriptors for the task of shape matching. Finally, we compare the descriptors on a shape classification task. Our conclusion is that sampling the normal distribution and the mean curvature, using 25 samples, and reducing this data to 5-10 samples via Principal Components Analysis, provides robustness to noise and the best shape discrimination results. For shape classification, mean curvature sampled at the vertex or averaged, and the more global Shape Diameter Function, performed the best. © Springer-Verlag 2012.",Article,"Final",Scopus,2-s2.0-84865329072
"Agapaki E., Glyn-Davies A., Mandoki S., Brilakis I.","CLOI: A Shape Classification Benchmark Dataset for Industrial Facilities",2019,"Computing in Civil Engineering 2019: Smart Cities, Sustainability, and Resilience - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2019",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068742341&doi=10.1061%2f9780784482445.009&partnerID=40&md5=ff28e571066cb90b59a6cb72a1a287d8","Generation of digital models of existing industrial facilities is labor intensive and expensive. The use of state-of-the-art deep learning algorithms can assist to reduce the modelling time and cost. However large databases of labelled, laser-scanned industrial facilities do not exist to date, henceforth training of deep learning models is not possible. Our paper solves this problem by proposing a new benchmark dataset, which consists of five labelled industrial plants. The labelling schema that we followed for the generation of this dataset is based on the frequency of appearance of industrial object types. We labelled the ten most frequent industrial object shapes as identified in previous work. We present CLOI (channels, L-shapes, circular sections, I-shapes): a richly annotated large-scale repository of shapes represented by labelled point clusters. CLOI has more than 140 million hand labelled points and serves as the foundation for researchers who are interested in automated modelling of industrial assets using deep learning algorithms. © 2019 American Society of Civil Engineers.",Conference Paper,"Final",Scopus,2-s2.0-85068742341
[No author name available],[No title available],2015,"3-Digital Built Britain Level 3 Building Information Modelling - Strategic Plan",6,,[No abstract available],,"Final",Scopus,2-s2.0-85079968348
"Birdal T., Busam B., Navab N., Ilic S., Sturm P.","A Minimalist Approach to Type-Agnostic Detection of Quadrics in Point Clouds",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061860442&doi=10.1109%2fCVPR.2018.00372&partnerID=40&md5=3d4d018225a2b37cc9fb1aa65d304116","This paper proposes a segmentation-free, automatic and efficient procedure to detect general geometric quadric forms in point clouds, where clutter and occlusions are inevitable. Our everyday world is dominated by man-made objects which are designed using 3D primitives (such as planes, cones, spheres, cylinders, etc.). These objects are also omnipresent in industrial environments. This gives rise to the possibility of abstracting 3D scenes through primitives, thereby positions these geometric forms as an integral part of perception and high level 3D scene understanding. As opposed to state-of-the-art, where a tailored algorithm treats each primitive type separately, we propose to encapsulate all types in a single robust detection procedure. At the center of our approach lies a closed form 3D quadric fit, operating in both primal & dual spaces and requiring as low as 4 oriented-points. Around this fit, we design a novel, local null-space voting strategy to reduce the 4-point case to 3. Voting is coupled with the famous RANSAC and makes our algorithm orders of magnitude faster than its conventional counterparts. This is the first method capable of performing a generic cross-type multi-object primitive detection in difficult scenes. Results on synthetic and real datasets support the validity of our method. © 2018 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85061860442
"Nagase M., Akizuki S., Hashimoto M.","3-D feature point matching for object recognition based on estimation of local shape distinctiveness",2013,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884480804&doi=10.1007%2f978-3-642-40261-6_57&partnerID=40&md5=f6e8be049b9f42112f1335a8bf445a8e","In this paper, we propose a reliable 3-D object recognition method that can statistically minimize object mismatching. Our method basically uses a 3-D object model that is represented as a set of feature points with 3-D coordinates. Each feature point also has an attribute value for the local shape around the point. The attribute value is represented as an orientation histogram of a normal vector calculated by using several neighboring feature points around each point. Here, the important thing is this attribute value means its local shape. By estimating the relative similarity of two points of all possible combinations in the model, we define the distinctiveness of each point. In the proposed method, only a small number of distinctive feature points are selected and used for matching with all feature points extracted from an acquired range image. Finally, the position and pose of the target object can be estimated from a number of correctly matched points. Experimental results using actual scenes have demonstrated that the recognition rate of our method is 93.8%, which is 42.2% higher than that of the conventional Spin Image method. Furthermore, its computing time is about nine times faster than that of the Spin Image method. © 2013 Springer-Verlag.",Conference Paper,"Final",Scopus,2-s2.0-84884480804
"Lévy B., Zhang H.","The Elements of geometry processing",2011,"SIGGRAPH Asia 2011 Courses, SA'11",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862914053&doi=10.1145%2f2077434.2077439&partnerID=40&md5=e0c82c02189c45c52c8fb3db7ea42d75","Geometry processing is a fast-growing area of research that designs efficient algorithms for the acquisition, reconstruction, analysis, manipulation, simulation and transmission of 3D models. This course covers different aspects of Geometry Processing, related with the reconstruction of high-level information from raw data. The first part of the course explains how starting with a point set (e.g. acquired with a 3D scanner), one can reconstruct a valid mesh, and then recover higher-level information (symmetry, structuration into parts). The second part is related with mesh-based computations (e.g. UV mapping and deformations) that need to define a function space over the mesh. We will introduce finite elements, spectral function bases and some of their applications. © 2011 ACM.",Conference Paper,"Final",Scopus,2-s2.0-84862914053
"Schorr M., Borrmann A., Obergriesser M., Ji Y., Gnthner W., Rank E.","Employing product data management systems in civil engineering projects: Functionality analysis and assessment",2011,"Journal of Computing in Civil Engineering",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84055218226&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000135&partnerID=40&md5=620d58fb9e882f8021a5347bcc15decf","Product data management (PDM) systems are well-established in the manufacturing industry. They form the standard solution for the central storage of all data relating to a product and the processes involved in its manufacture. Particularly, the consistent management of computer-aided design (CAD) models, including sophisticated versioning techniques, access rights management, and the integrated workflow management, are attractive features for using PDM systems for civil engineering projects. This paper investigates the technical concepts behind PDM systems and compares their suitability as a data management solution in civil engineering projects with that of document management systems and product model servers. Alongside a comparative study of the major PDM systems available on the market, we also present a case study involving a PDM system that has been employed for a concrete civil engineering project. © 2011 American Society of Civil Engineers.",Conference Paper,"Final",Scopus,2-s2.0-84055218226
"López-Rubio E., Thurnhofer-Hemsi K., de Cózar-Macías Ó.D., Blázquez-Parra E.B., Muñoz-Pérez J., Ladrón de Guevara-López I.","Robust Fitting of Ellipsoids by Separating Interior and Exterior Points During Optimization",2017,"Journal of Mathematical Imaging and Vision",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007174597&doi=10.1007%2fs10851-016-0700-6&partnerID=40&md5=a13bbf0566a61f82ae08760da1d1cf63","Fitting geometric or algebraic surfaces to 3D data is a pervasive problem in many fields of science and engineering. In particular, ellipsoids are some of the most employed features in computer graphics and sensor calibrations. They are also useful in pattern recognition, computer vision, body detection and electronic device design. Standard ellipsoid fitting techniques to solve this problem involve the minimization of squared errors. However, most of these procedures are sensitive to noise. Here, we propose a method based on the minimization of absolute errors. Although our algorithm is iterative, an adaptive step size is used to achieve a faster convergence. This leads to a substantial improvement in robustness against outlier data. The proposal is demonstrated with several computational examples which comprise synthetic data and real data from a 3D scanner and a stereo camera. © 2016, Springer Science+Business Media New York.",Article,"Final",Scopus,2-s2.0-85007174597
[No author name available],[No title available],2016,"National BIM Report",4,,[No abstract available],,"Final",Scopus,2-s2.0-85082447774
"Yeung J., Nahangi M., Shahtaheri Y., Haas C., Walbridge S., West J.","Comparison of methods used for detecting unknown structural elements in three-dimensional point clouds",2014,"Construction Research Congress 2014: Construction in a Global Network - Proceedings of the 2014 Construction Research Congress",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904709350&doi=10.1061%2f9780784413517.0097&partnerID=40&md5=98f07f84591a194d1c2b2e39409b4853","Three-dimensional (3D) imaging technologies, in particular 3D laser scanners, are becoming more accessible and more accurate. These advances are providing engineers and architects with vast quantities of raw, geometric data. Whereas this data is visually appealing and intuitive to the human eye, it contains very little meaning beyond that. The research presented in this paper presents and compares methods for attributing meaning to dense 3D point clouds. Two of the methods developed and presented utilize 2D and 3D Hough transforms to represent the points as lines and planes. The third method uses point segmentation techniques to group points belonging to the same plane. The initial focus is on structural steel systems and connections modeling for analysis of reuse. The advantages and disadvantages of each method are outlined, and each method is evaluated for its potential to provide engineers and architects with useful and meaningful point clouds from 3D laser scanners. The point segmentation techniques exhibit the most potential by allowing for the location and orientation of any surface to be identified. © 2014 American Society of Civil Engineers.",Conference Paper,"Final",Scopus,2-s2.0-84904709350
[No author name available],[No title available],2018,"International Home of OpenBIM",3,,[No abstract available],,"Final",Scopus,2-s2.0-85068792670
[No author name available],[No title available],2017,"Measuring Progress and Defining Productivity Metrics in Model-Based Engineering",3,,[No abstract available],,"Final",Scopus,2-s2.0-85053920755
[No author name available],[No title available],2017,"NBS National BIM Report",3,,[No abstract available],,"Final",Scopus,2-s2.0-85044178743
"Grinstead C.M., Snell J.L.","Markov Chains",2010,"Introduction to Probability",3,,[No abstract available],,"Final",Scopus,2-s2.0-85046351033
"Yang S., Dizaji M.S., Harris D.K.","Integrating 3D scanning within a simulation framework for structural mechanics",2018,"Proceedings of SPIE - The International Society for Optical Engineering",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049571032&doi=10.1117%2f12.2300762&partnerID=40&md5=7fccfaa001d24ef5cc9910026089af3a","Advances in imaging technologies and techniques have created new opportunities to leverage high-resolution 3D laser scanning as a non-destructive evaluation (NDE) tool for describing surface features of engineered components. These tools are capable of resolving sub-millimeter details including flaws and defects, thus providing quantitative data about features that have historically been assessed via subjective visual assessments. This data is invaluable to our understanding of the performance of existing structural system and provides a mechanism for quantitatively linking observable features to operational performance via numerical simulation. However, the workflow associated with this integration is not direct and presents some challenges when translating dense point cloud datasets into simulation tools such as traditional finite element models. This paper presents the results of a laboratory scale study on structural components that translates condition data derived from a 3D laser scanning system into a computation model capable of describing the mechanical response of the components. This work specifically explores the trade-offs between scanning resolution and model approximation using the proposed system. Performance of the imaging and mapping scheme was validated through laboratory-scale testing of structural component using 3D digital image correlation, which enabled full-field deformation characterization, and correlation with the numerical model prediction. Results of this study provide the foundation of a computational framework for establishing the fundamental link between visually observable geometric changes and the numerical models that engineers use to understand the performance of engineered systems. © 2018 SPIE.",Conference Paper,"Final",Scopus,2-s2.0-85049571032
[No author name available],[No title available],2017,"3D Laser Scanner FARO Focus - 3D Surveying - Overview",2,,[No abstract available],,"Final",Scopus,2-s2.0-85093488415
"Autodesk","Revit Family",2016,"Revit Family",2,,[No abstract available],,"Final",Scopus,2-s2.0-85044616503
"Wei L., Huang Q., Ceylan D., Vouga E., Li H.","Dense human body correspondences using convolutional networks",2016,"Dense Human Body Correspondences Using Convolutional Networks",2,,[No abstract available],,"Final",Scopus,2-s2.0-85067629843
"Sergey Ioffe G., Christian Szegedy G.","Batch normalization",2015,"Icml",2,,[No abstract available],,"Final",Scopus,2-s2.0-85078548882
"Pang G., Qiu R., Huang J., You S., Neumann U.","Automatic 3D industrial point cloud classification and modeling",2015,"SPE Western Regional Meeting 2015: Old Horizons, New Horizons Through Enabling Technology",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960464363&doi=10.2118%2f174069-ms&partnerID=40&md5=b97dc7f04b898e0d5cfaa98f8e1c1ef8","3D classification and modeling of point clouds is an important but time-consuming process, with many applications in petroleum engineering and other applications, inspiring extensive research in automatic methods. Prior efforts focus on primitive geometry, street structures or indoor objects, but industrial data has rarely been pursued. Industrial sites are often captured by laser scanners, producing 3D point clouds of visible surfaces. Creating a higher level model from such point clouds now requires extensive manual labeling and fitting of surfaces and their connections. Computer-aided editing systems and automatic methods exist, but with limited capabilities. Existing methods for industrial point cloud modeling are not able to effectively process an industrial scene containing primitive shapes, general objects and instrumentations, as well as the connectivity between them. Our work presents a method which automatically generates a 3D classified model from 3D point cloud data. An industrial point cloud is treated as a collection of pipes, planes and general objects, and we thus divide the modeling problem into three sub-problems: pipe modeling, plane classification, and object recognition. Two primitive extraction processes detect cylinder or planar geometry in the scene, while general objects modeling employs modeling-by-recognition, which detects clusters of 3D points in a scan that match 3D models of objects stored in a prebuilt object library. The results of all three components, including extracted primitives and recognized objects, are integrated to obtain the complete 3D model. Experiments with several point cloud datasets demonstrate that the presented method automatically produces classified models of large and complex industrial scenes, with a quality that outperforms leading commercial modeling software and is comparable to professional hand-made models. Pipes, planes and different types of objects are individually detected and classified. The result display is freely switchable between mesh model for efficiency and point cloud for accuracy, not achievable in simple surface fitting methods. Copyright © (2015) by the Society of Petroleum Engineers. All rights reserved.",Conference Paper,"Final",Scopus,2-s2.0-84960464363
"Fernandes R.","Advantages and disadvantages of BIM platforms on construction site",2013,"Dep. Civ. Eng.",2,,[No abstract available],,"Final",Scopus,2-s2.0-85093484285
"Vince J.",[No title available],2013,"Calculus for Computer Graphics",2,,[No abstract available],,"Final",Scopus,2-s2.0-85093485421
"Weisstein E.W.",[No title available],2018,"Elliptic Paraboloid [WWW Document]. MathWorld - A Wolfram Web Resour",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093493833
"Agapaki E., Karatzia X., Mylonakis G.","Higher-order Winkler solutions for laterally-loaded piles",2018,"16th European Conference on Earthquake Engineering. Thessaloniki",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093479883
[No author name available],"What is OPEN BIM and why should you care?",2017,"Information about OPEN Building Information Modeling and its Importance",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093494511
[No author name available],"Introducing open & closed BIM",2017,"BIM J",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093490422
[No author name available],[No title available],2017,"Global Digital Twin Market Is Estimated to Grow at a CAGR of 37% from 2017 to 2023",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093485914
[No author name available],[No title available],2017,,1,,[No abstract available],,"Final",Scopus,2-s2.0-85093483688
[No author name available],[No title available],2017,"Today in Energy - Daily Prices - Prices - U.S. Energy Information Administration (EIA)",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093480728
[No author name available],[No title available],2017,"BuildingSMART",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093478026
[No author name available],[No title available],2016,"IfcAdvancedBrep. IFC4 Add2",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093490631
"Belsky M.",[No title available],2015,"A framework for semantic enrichment of IFC building models",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093477233
[No author name available],[No title available],2014,"Business Value of BIM in Global Markets 2014.Pdf",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093493879
[No author name available],[No title available],2013,"2-Construction 2025. Industrial Strategy: Government and Industry in Partnership",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093479650
"Bey A., Chaine R., Marc R., Thibault G., Akkouche S.",[No title available],2011,"Reconstruction of Consistent 3D CAD Models from Point Cloud Data Using a Priori CAD Models",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093481442
"Panushev I., Eastman C., Sacks R., Venugopal M., Aram V.","Development of the national BIM standard (NBIMS) for precast/prestressed concrete",2010,"Proceedings of the 27th International Conference on Information Technology in Construction",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093477373
"Reznik H., Mayer H.",[No title available],2008,"Implicit Shape Models, Self-Diagnosis, and Model Selection for 3D Façade Interpretation 187-196",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093484616
"Saatkamp J., Schmittwilken J.","Generative Models and Markov chain Monte Carlo Techniques for detection and reconstruction of stairs from point clouds",2007,"ISPRES Workshop on Updating Geo-Spatial Databases with Imagery the 5th ISPRS Workshop on DMGISs",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093476356
"Cross G., Zisserman A.",[No title available],2002,"Quadric Reconstruction from Dual-Space Geometry",1,,[No abstract available],,"Final",Scopus,2-s2.0-85093485575
