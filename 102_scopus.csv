Authors,Title,Year,Source title,Cited by,Link,Abstract,Document Type,Publication Stage,Source,EID
"Quigley M., Conley K., Gerkey B.P., Faust J., Foote T., Leibs J., Wheeler R., Ng A.Y.","ROS: An open-source robot operating system",2009,"ICRA Workshop on Open Source Software",5122,,[No abstract available],,"Final",Scopus,2-s2.0-77957352104
"Koenig N., Howard A.","Design and use paradigms for Gazebo, an open-source multi-robot simulator",2004,"2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",1607,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-14044257268&partnerID=40&md5=d469678f36673d212d0c42ecf11416ab","Simulators have played a critical role in robotics research as tools for quick and efficient testing of new concepts, strategies, and algorithms. To date, most simulators have been restricted to 2D worlds, and few have matured to the point where they are both highly capable and easily adaptable. Gazebo is designed to fill this niche by creating a 3D dynamic multi-robot environment capable of recreating the complex worlds that will be encountered by the next generation of mobile robots. Its open source status, fine grained control, and high fidelity place Gazebo in a unique position to become more than just a stepping stone between the drawing board and real hardware: data visualization, simulation of remote environments, and even reverse engineering of black-box systems are all possible applications. Gazebo is developed in cooperation with the Player and Stage projects [1], [2], [3], and is available from http://playerstage.sourceforge.net/gazebo/gazebo.html.",Conference Paper,"Final",Scopus,2-s2.0-14044257268
"Şucan I.A., Moll M., Kavraki L.","The open motion planning library",2012,"IEEE Robotics and Automation Magazine",776,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871385657&doi=10.1109%2fMRA.2012.2205651&partnerID=40&md5=bce18fde61a714b54dcaff67af3bbc0c","The open motion planning library (OMPL) is a new library for sampling-based motion planning, which contains implementations of many state-of-the-art planning algorithms. The library is designed in a way that it allows the user to easily solve a variety of complex motion planning problems with minimal input. A simple graphical user interface (GUI) built on top of the library, a number of tutorials, demos, and programming assignments are designed to teach students about sampling-based motion planning. The library is also available for use through Robot Operating System (ROS). OMPL is structured to have a clear mapping between the motion planning concepts used in the literature and the classes that are defined in the implementation. A software package that is complementary to OMPL is OpenRAVE, designed to be a complete package for robotics. OMPL is intended for use in research and education, as well as in industry, due to its clarity, efficiency, simple integration with other software packages and straight-forward integration of external contributions.",Article,"Final",Scopus,2-s2.0-84871385657
"Barbosa F., Woetzel J., Mischke J., Ribeirinho M.J., Sridhar M., Parsons M., Bertram N., Brown S.","Reinventing Construction: A Route to Higher Productivity",2017,"Reinventing Construction: A Route to Higher Productivity",356,,[No abstract available],,"Final",Scopus,2-s2.0-85046345496
"Chitta S., Sucan I., Cousins S.","MoveIt!",2012,"IEEE Robotics and Automation Magazine",250,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859727432&doi=10.1109%2fMRA.2011.2181749&partnerID=40&md5=80ed6ca64dca4b38c93c98d2bbc3a9f4","MoveIt! is a set of software packages integrated with the Robot Operating System (ROS) and designed specifically to provide mobile manipulation. MoveIt! will allow robots to build up a representation of their environment using data fused from three-dimensional (3-D) and other sensors, generate motion plans that effectively and safely move the robot around in the environment, and execute the motion plans while constantly monitoring the environment for changes. Lightweight ROS bindings and wrappers will allow ROS users to easily configure and interface with the components of MoveIt!. Advanced users and application developers will be able to directly incorporate the core capabilities in MoveIt! through libraries without needing to depend on a large part of ROS. MoveIt! will be crucial in the goal of enabling safer, more capable robots that can function effectively in human environments.",Short Survey,"Final",Scopus,2-s2.0-84859727432
"Pan J., Chitta S., Manocha D.","FCL: A general purpose library for collision and proximity queries",2012,"Proceedings - IEEE International Conference on Robotics and Automation",250,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864484328&doi=10.1109%2fICRA.2012.6225337&partnerID=40&md5=454da98a23e11ae3ad3ba56fc2a7eda5","We present a new collision and proximity library that integrates several techniques for fast and accurate collision checking and proximity computation. Our library is based on hierarchical representations and designed to perform multiple proximity queries on different model representations. The set of queries includes discrete collision detection, continuous collision detection, separation distance computation and penetration depth estimation. The input models may correspond to triangulated rigid or deformable models and articulated models. Moreover, FCL can perform probabilistic collision checking between noisy point clouds that are captured using cameras or LIDAR sensors. The main benefit of FCL lies in the fact that it provides a unified interface that can be used by various applications. Furthermore, its flexible architecture makes it easier to implement new algorithms within this framework. The runtime performance of the library is comparable to state of the art collision and proximity algorithms. We demonstrate its performance on synthetic datasets as well as motion planning and grasping computations performed using a two-armed mobile manipulation robot. © 2012 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84864484328
"CPWR – The Center for Construction Research and Training","The Construction Chart Book",2020,"The Construction Chart Book",119,,[No abstract available],,"Final",Scopus,2-s2.0-0042978815
"Du J., Zou Z., Shi Y., Zhao D.","Zero latency: Real-time synchronization of BIM data in virtual reality for collaborative decision-making",2018,"Automation in Construction",97,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031747080&doi=10.1016%2fj.autcon.2017.10.009&partnerID=40&md5=b174e5343565c812ade9ead2d6bf45e1","Virtual Reality (VR) has attracted increasing attention of the Architecture, Engineering, Construction and Facility Management (AEC/FM) industry in recent years, as it shows a great potential to improve workflow efficiency through enhanced common understanding. A problem with current VR applications in AEC/FM is that the manual conversation from official design data (e.g., a BIM model) to VR displays is difficult and time consuming. There is a lack of automated and efficient data transfer approach between BIM and VR. In this paper, we will introduce a BIM[sbnd]VR real-time synchronization system called BVRS, which is based on an innovative Cloud-based BIM metadata interpretation and communication method. BVRS allows users to update BIM model changes in VR headsets (such as Oculus Rift DK2) automatically and simultaneously. We tested BVRS in a variety of design change scenarios including changing object dimensions, changing object locations and changing object types. Results confirmed the usability and efficiency of BVRS. © 2017 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85031747080
"Davila Delgado J.M., Oyedele L., Ajayi A., Akanbi L., Akinade O., Bilal M., Owolabi H.","Robotics and automated systems in construction: Understanding industry-specific challenges for adoption",2019,"Journal of Building Engineering",78,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073652295&doi=10.1016%2fj.jobe.2019.100868&partnerID=40&md5=4a7777bb736cc946a648ff39cb1c7623","The construction industry is a major economic sector, but it is plagued with inefficiencies and low productivity. Robotics and automated systems have the potential to address these shortcomings; however, the level of adoption in the construction industry is very low. This paper presents an investigation into the industry-specific factors that limit the adoption in the construction industry. A mixed research method was employed combining literature review, qualitative and quantitative data collection and analysis. Three focus groups with 28 experts and an online questionnaire were conducted. Principal component and correlation analyses were conducted to group the identified factors and find hidden correlations. The main identified challenges were grouped into four categories and ranked in order of importance: contractor-side economic factors, client-side economic factors, technical and work-culture factors, and weak business case factors. No strong correlation was found among factors. This study will help stakeholders to understand the main industry-specific factors limiting the adoption of robotics and automated systems in the construction industry. The presented findings will support stakeholders to devise mitigation strategies. © 2019 The Authors",Article,"Final",Scopus,2-s2.0-85073652295
"Smits R.",[No title available],0000,"KDL: Kinematics and Dynamics Library",75,,[No abstract available],,"Final",Scopus,2-s2.0-78650276513
"Kim D., Kim J., Lee K., Park C., Song J., Kang D.","Excavator tele-operation system using a human arm",2009,"Automation in Construction",71,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-57649234925&doi=10.1016%2fj.autcon.2008.07.002&partnerID=40&md5=73ae9e9c184a9a42a2fe86ce992c4e48","It is difficult, for those without experience, to operate and manipulate a mechanical excavator. There is a long learning process to gain the skills required in operating the excavator's overall swing motions as well as movements of its boom, arm and bucket. In addition it is dangerous to operate such excavators on an inclined plane as this can lead to instability and puts the operator at great risk. In this study, a simple light weight tele-operation system has been developed for the excavator for dealing with these problems. Three sensors are attached to the operator's arm, in order to detect his movements. The operating commands for the actuators of an excavator will be transmitted via Bluetooth wireless communications. The new tele-operation system developed is simple, cost effective and lighter compared to typical haptic devices using a force feedback mechanisms. The operating algorithm has been modified and verified in many test cases. Prior to testing, the algorithms have been verified using the visual simulator, OpenGL. The operating system to operate the excavator easily and safely is developed and the control algorithm verified by tests. © 2008 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-57649234925
"Chitta S., Marder-Eppstein E., Meeussen W., Pradeep V., Rodríguez Tsouroukdissian A., Bohren J., Coleman D., Magyar B., Raiola G., Lüdtke M., Fernández Perdomo E.","Ros control: A generic and simple control framework for ros",2017,"The Journal of Open Source Software",68,,[No abstract available],,"Final",Scopus,2-s2.0-85051855317
"Feng C., Xiao Y., Willette A., McGee W., Kamat V.R.","Vision guided autonomous robotic assembly and as-built scanning on unstructured construction sites",2015,"Automation in Construction",60,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944441544&doi=10.1016%2fj.autcon.2015.06.002&partnerID=40&md5=a0dbc77e8100bb4028a22408a31909af","Unlike robotics in the manufacturing industry, on-site construction robotics has to consider and address two unique challenges: 1) the rugged, evolving, and unstructured environment of typical work sites; and 2) the reversed spatial relationship between the product and the manipulator, i.e., the manipulator has to travel to and localize itself at the work face, rather than a partially complete product arriving at an anchored manipulator. The presented research designed and implemented algorithms that address these challenges and enable autonomous robotic assembly of freeform modular structures on construction sites. Building on the authors' previous work in computer-vision-based pose estimation, the designed algorithms enable a mobile robotic manipulator to: 1) autonomously identify and grasp prismatic building components (e.g., bricks, blocks) that are typically non-unique and arbitrarily stored on-site; and 2) assemble these components into pre-designed modular structures. The algorithms use a single camera and a visual marker-based metrology to rapidly establish local reference frames and to detect staged building components. Based on the design of the structure being assembled, the algorithms automatically determine the assembly sequence. Furthermore, if a 3D camera is mounted on the manipulator, 3D point clouds can be readily captured and registered into a same reference frame through our marker-based metrology and the manipulator's internal encoders, either after construction to facilitate as-built Building Information Model (BIM) generation, or during construction to document details of the progress. Implemented using a 7-axis KUKA KR100 robotic manipulator, the presented robotic system has successfully assembled various structures and created as-built 3D point cloud models autonomously, demonstrating the designed algorithms' effectiveness in autonomous on-site construction robotics applications. © 2015 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84944441544
"You S., Kim J.-H., Lee S., Kamat V., Robert L.P., Jr.","Enhancing perceived safety in human–robot collaborative construction using immersive virtual environments",2018,"Automation in Construction",43,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053825953&doi=10.1016%2fj.autcon.2018.09.008&partnerID=40&md5=c1e1bba33f5315cf12725d702df4d61f","Advances in robotics now permit humans to work collaboratively with robots. However, humans often feel unsafe working alongside robots. Our knowledge of how to help humans overcome this issue is limited by two challenges. One, it is difficult, expensive and time-consuming to prototype robots and set up various work situations needed to conduct studies in this area. Two, we lack strong theoretical models to predict and explain perceived safety and its influence on human–robot work collaboration (HRWC). To address these issues, we introduce the Robot Acceptance Safety Model (RASM) and employ immersive virtual environments (IVEs) to examine perceived safety of working on tasks alongside a robot. Results from a between-subjects experiment done in an IVE show that separation of work areas between robots and humans increases perceived safety by promoting team identification and trust in the robot. In addition, the more participants felt it was safe to work with the robot, the more willing they were to work alongside the robot in the future. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85053825953
"Wang Q., Guo J., Kim M.-K.","An application oriented scan-to-bim framework",2019,"Remote Sensing",36,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061404405&doi=10.3390%2frs11030365&partnerID=40&md5=bca16a5fa53459f9247d5f848a48aac0","Building information modelling (BIM) has been adopted in the construction industry. The success of BIM implementation relies on the accurate building information stored in BIM models. However, building information in BIM models can be inaccurate, out-of-date, or missing in real-world projects. 3D laser scanning has been leveraged to capture the accurate as-is conditions of buildings and create as-is BIM models of buildings; this is known as the scan-to-BIM process. Although industry practitioners and researchers have implemented and studied the scan-to-BIM process, there is no framework that systematically defines and discusses the key steps and considerations in the process. This study proposes an application-oriented framework for scan-to-BIM, which describes the four major steps of a scan-to-BIM process and their relationships. The framework is oriented towards the specific BIM application to be implemented using the created as-is BIM, and includes four steps: (1) identification of information requirements, (2) determination of required scan data quality, (3) scan data acquisition, and (4) as-is BIM reconstruction. Two illustrative examples are provided to demonstrate the feasibility of the proposed scan-to-BIM framework. Furthermore, future research directions within the scan-to-BIM framework are suggested. © 2019 by the authors.",Article,"Final",Scopus,2-s2.0-85061404405
"Jen Y.H., Taha Z., Vui L.J.","VR-Based robot programming and simulation system for an industrial robot",2008,"International Journal of Industrial Engineering : Theory Applications and Practice",29,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77749317403&partnerID=40&md5=ae7f705fabd5ef683135c3d1db53b1c6","Traditional robot programming such as teach by lead etc have been used for many years. These methods are considered not efficient and outdated in the current industrial and market demands. In this paper, virtual reality (VR) technology is used to improve human-robot interface - no complicated command or programming knowledge is required. The system is divided into three major parts: task teaching by demonstration in a computer generated virtual environment, a graphical robot simulator with intelligent robot command generator and last but not least, real task execution. The user is requested to complete the desired task in a virtual teaching system by wearing a data glove attached with a sensor tracker. The process path will be simulated and analyzed to obtain the optimum trajectory. Robot motions can be checked through the simulation program and robot program can be generated for the real task execution. © INTERNATIONAL JOURNAL OF INDUSTRIAL ENGINEERING.",Article,"Final",Scopus,2-s2.0-77749317403
"Xu L., Feng C., Kamat V.R., Menassa C.C.","An Occupancy Grid Mapping enhanced visual SLAM for real-time locating applications in indoor GPS-denied environments",2019,"Automation in Construction",27,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064747805&doi=10.1016%2fj.autcon.2019.04.011&partnerID=40&md5=3bfe222f42d71a43a6e92cbbbce3ed3b","Current Real-Time Locating Systems (RTLS)typically deployed in indoor built environments are generally based on wireless technologies, fixed cameras, or Lidar-based Simultaneous Localization and Mapping (SLAM), which generally suffer from the drawbacks of low accuracy, reliance on existing infrastructures that may be not available in the deployed environments, labor-intensive environment instrumentation, or economic infeasibility for wide deployment. By improving an ORB RGB-D SLAM with Occupancy Grid Mapping, this paper proposes a new indoor RTLS that can be readily adapted and deployed for a broad range of indoor locating applications while overcoming the limitations faced by current solutions. In addition to the sparse feature map that is maintained by ORB SLAM itself, a new 2D mapping module is developed to build and maintain an additional 2D Occupancy Grid Map (OGM). The 2D OGM is built with the 3D camera poses estimated by Visual SLAM (vSLAM)and laser scans extracted from the point cloud observed by the camera from those poses. In addition, the Robot Operating System (ROS)visualization tools are used to overlay real-time current camera poses and observations (virtual laser scans)on the OGM. This approach not only provides more intuitive pose information to users and allows them to interact with the system, but also enables path planning and continuous navigation, which cannot be implemented directly on vSLAM's original feature map. The localization accuracy of the proposed system is experimentally evaluated with a set of visual landmarks that are installed in a large-scale building environment. The achieved marker position measurement accuracy ranges from 0.039 m to 0.186 m and the marker distance measurement accuracy ranges from 0.018 m to 0.235 m, proving the method's feasibility and applicability in providing real-time and accurate localization for a wide range of applications within constructed facilities and the built environment. Three examples are provided to highlight such potential applications, including path planning and real-time navigation, geo-tagged date collection and location-aware point cloud updating. © 2019 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85064747805
"Lundeen K.M., Kamat V.R., Menassa C.C., McGee W.","Autonomous motion planning and task execution in geometrically adaptive robotized construction work",2019,"Automation in Construction",25,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059588840&doi=10.1016%2fj.autcon.2018.12.020&partnerID=40&md5=eec116e8c4725ff5808a6f1c87fe6d9a","This research explores a means by which a construction robot can leverage its sensors and a Building Information Model (BIM) to perceive and model the actual geometry of its workpieces, adapt its work plan, and execute work in a construction environment. The adaptive framework uses the Generalized Resolution Correlative Scan Matching (GRCSM) search algorithm for model registration, a new formulation for fill plan adaptation, and new hardware for robotic material dispensing. Joint filling is used as a case study to demonstrate the formulation of an adaptive plan and evaluate a robot's ability to perform adaptive work in an environment where the actual location and geometry of its workpieces may deviate from their designed counterparts. Averaged across five experiments, the robot was found capable of identifying the true position and orientation of the joint's center with a mean norm positioning error of 0.11 mm and orientation error of 1.1 ° . The adaptive framework offers significant promise for a range of construction activities, including those involving objects of complex geometry and detailed work. © 2019 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85059588840
"Lundeen K.M., Kamat V.R., Menassa C.C., McGee W.","Scene understanding for adaptive manipulation in robotized construction work",2017,"Automation in Construction",21,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021346169&doi=10.1016%2fj.autcon.2017.06.022&partnerID=40&md5=85594cda1c29f12e0a1831acd14fca66","Unlike manufacturing robots, whose kinematics are pre-programmed based on robust metrology, tight tolerances, and rigid workpieces, construction robots operate under conditions of imperfect metrology, loose tolerances, and large workpiece uncertainties. Despite having access to a designed Building Information Model (BIM), construction robots must sense and model their actual environment, and adapt their kinematic plan to compensate for deviations from the expected. This research investigates methods to enable the autonomous sensing and modeling of construction objects so construction robots can ultimately adapt to unexpected circumstances and perform quality work. To that end, two construction component model fitting techniques are presented, namely the Clustering and Iterative Closest Point (CICP) construction component model fitting technique and the Generalized Resolution Correlative Scan Matching (GRCSM) construction component model fitting technique. The GRCSM construction component model fitting technique employs the presented GRCSM search algorithm, which is a modified version of the existing Multi-Resolution Correlative Scan Matching (MRCSM) search algorithm. Three experiments are presented to evaluate the ability of the CICP and GRCSM construction component model fitting techniques to model construction features. It was found that the CICP and GRCSM construction component model fitting techniques are capable of estimating the pose and geometry of arbitrarily shaped objects and construction joints, but are susceptible to modeling error. Despite their limitations, the CICP and GRCSM construction component model fitting techniques appear to be promising tools for the geometric estimation of construction features, especially for situations involving full automation, detailed construction work, incomplete sensor data, and complex object geometry. © 2017 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85021346169
"Chotiprayanakul P., Liu D.K., Dissanayake G.","Human-robot-environment interaction interface for robotic grit-blasting of complex steel bridges",2012,"Automation in Construction",21,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863697780&doi=10.1016%2fj.autcon.2012.04.014&partnerID=40&md5=e8145c0f06105dde90a43884d95fb796","This paper presents a human-robot-environment interaction (HREI) interface using haptic feedback for a grit-blasting robot operating in close proximity to a complex steel bridge structure. The productivity requirements dictate the need for efficient algorithms for mapping, exploration, and collision-free motion planning. While a large portion of the grit-blasting operation can be automated, a tele-operation is essential to deal with some difficult to access sections such as edges, complex corners, and surfaces which can only be approached through hole. A 3-dimensional virtual force field (3D-VF 2) method is developed for capturing the relationship between the robot and its environment. A novel haptic force generation method and a workspace mapping algorithm allow intuitive interaction between the operator and the robot through haptic feedback. The strategies presented are verified in extensive simulations and experiments conducted on a steel bridge with a prototype grit-blasting robot. © 2012 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84863697780
"Tavares P., Costa C.M., Rocha L., Malaca P., Costa P., Moreira A.P., Sousa A., Veiga G.","Collaborative Welding System using BIM for Robotic Reprogramming and Spatial Augmented Reality",2019,"Automation in Construction",20,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067040551&doi=10.1016%2fj.autcon.2019.04.020&partnerID=40&md5=b5c99a6354ccbe7b961d641d9c891faf","The optimization of the information flow from the initial design and through the several production stages plays a critical role in ensuring product quality while also reducing the manufacturing costs. As such, in this article we present a cooperative welding cell for structural steel fabrication that is capable of leveraging the Building Information Modeling (BIM) standards to automatically orchestrate the necessary tasks to be allocated to a human operator and a welding robot moving on a linear track. We propose a spatial augmented reality system that projects alignment information into the environment for helping the operator tack weld the beam attachments that will be later on seam welded by the industrial robot. This way we ensure maximum flexibility during the beam assembly stage while also improving the overall productivity and product quality since the operator no longer needs to rely on error prone measurement procedures and he receives his tasks through an immersive interface, relieving him from the burden of analyzing complex manufacturing design specifications. Moreover, no expert robotics knowledge is required to operate our welding cell because all the necessary information is extracted from the Industry Foundation Classes (IFC), namely the CAD models and welding sections, allowing our 3D beam perception systems to correct placement errors or beam bending, which coupled with our motion planning and welding pose optimization system ensures that the robot performs its tasks without collisions and as efficiently as possible while maximizing the welding quality. © 2019 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85067040551
"Fukuda T., Fujisawa Y.","A new robotic manipulator in construction based on man-robot cooperation work",1991,"Proc. of the 8th International Symposium on Automation and Robotics in Construction",18,,[No abstract available],,"Final",Scopus,2-s2.0-33847744821
"Liang C.J., Lundeen K.M., McGee W., Menassa C.C., Lee S., Kamat V.R.","Stacked hourglass networks for markerless pose estimation of articulated construction robots",2018,"ISARC 2018 - 35th International Symposium on Automation and Robotics in Construction and International AEC/FM Hackathon: The Future of Building Things",15,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088408166&doi=10.22260%2fisarc2018%2f0120&partnerID=40&md5=8287a439d71e7fed435e1f13a21b8e1b","The objective of this research is to evaluate vision-based pose estimation methods for on-site construction robots. The prospect of human-robot collaborative work on construction sites introduces new workplace hazards that must be mitigated to ensure safety. Human workers working on tasks alongside construction robots must perceive the interaction to be safe to ensure team identification and trust. Detecting the robot pose in real-time is thus a key requirement in order to inform the workers and to enable autonomous operation. Vision-based (marker-less, marker-based) and sensor-based (IMU, UWB) are two of the main methods for estimating robot pose. The marker-based and sensor-based methods require some additional preinstalled sensors or markers, whereas the marker-less method only requires an on-site camera system, which is common on modern construction sites. In this research, we develop a marker-less pose estimation system, which is based on a convolutional neural network (CNN) human pose estimation algorithm: stacked hourglass networks. The system is trained with image data collected from a factory setup environment and labels of excavator pose. We use a KUKA robot arm with a bucket mounted on the end-effector to represent a robotic excavator in our experiment. We evaluate the marker-less method and compare the result with the robot’s ground truth pose. The preliminary results show that the marker-less method is capable of estimating the pose of the excavator based on a state-of-the-art human pose estimation algorithm. © ISARC 2018 - 35th International Symposium on Automation and Robotics in Construction and International AEC/FM Hackathon: The Future of Building Things. All rights reserved.",Conference Paper,"Final",Scopus,2-s2.0-85088408166
"Jung K., Chu B., Park S., Hong D.","An implementation of a teleoperation system for robotic beam assembly in construction",2013,"International Journal of Precision Engineering and Manufacturing",14,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875913955&doi=10.1007%2fs12541-013-0049-3&partnerID=40&md5=e82283aed87467de3d303aa465caa8cd","Recently, a robot-based construction automation (RCA) project was finished in Korea, whose purpose was to employ a robotic system instead of human labor in steel beam assembly tasks. In that research, a robotic beam assembly (RBA) system was developed to execute a beam assembly task. A field application using the RBA system at an actual construction site was completed. Because a human operator had to board the cabin and manipulate the system in the air, causing possible safety problems, a teleoperation system was developed and is the subject of this paper. To evaluate the performance of the teleoperation system, a pointing task experiment based on Fitts' law was conducted to determine whether it obeyed speed-accuracy tradeoff rules. Results are discussed and an overview of the actual bolting test using the teleoperation system is presented here. Finally, conclusions are drawn about the feasibility of implementing an RBA system with teleoperation in actual building construction applications. © 2013 Korean Society for Precision Engineering and Springer-Verlag Berlin Heidelberg.",Article,"Final",Scopus,2-s2.0-84875913955
"Liang C.-J., Kamat V.R., Menassa C.C.","Teaching robots to perform quasi-repetitive construction tasks through human demonstration",2020,"Automation in Construction",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088870979&doi=10.1016%2fj.autcon.2020.103370&partnerID=40&md5=f5067f34b6e7f3f67e1c6051e3e7275c","Robots can assist workers in performing physically-demanding construction tasks, which are typically quasi-repetitive, wherein the geometry of the workspace is dissimilar despite similar tasks. As a result, robots must determine motion trajectories based on the encountered workspace geometry. Learning from Demonstration (LfD) methods have the potential to be used in teaching robots specific tasks through human demonstration, such that robots can then perform learned tasks under different conditions. In this paper, the LfD method is investigated to teach robots how to perform quasi-repetitive construction tasks. Considering ceiling tile installation as the experimental process, the tasks of maneuvering and positioning tiles in a ceiling grid are defined as the target knowledge to be learned. Using a set of human demonstration videos, the designed approach first translates the physical work context, e.g., the pose of the tile, to the target digital twin, i.e., the workspace as-perceived by the robot. The Reinforcement Learning method is then applied to generate the control policy for the robot to perform the subsequent tasks. The proposed method is evaluated in the Robot Operating System (ROS) Gazebo simulator using a KUKA mobile industrial robotic arm emulator and 60 different scenes as test cases. The results show a 78% success rate in installing ceiling tiles based on 3000 virtual and 85 real demonstration videos. The success rate tends to continually rise with an increase in the number of real demonstration videos, confirming the promise and applicability of the LfD method in teaching robot apprentices to perform quasi-repetitive tasks on construction sites. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85088870979
"Liang C.J., Kamat V.R., Menassa C.C.","Teaching robots to perform construction tasks via learning from demonstration",2019,"Proceedings of the 36th International Symposium on Automation and Robotics in Construction, ISARC 2019",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071479614&doi=10.22260%2fisarc2019%2f0175&partnerID=40&md5=ba6cfbaffbfc8afebd22f5203ee25fd3","Robots are expected to be widely used on future construction sites to assist human workers in the performance of repetitive physically-demanding tasks. Unlike typical manufacturing assembly lines, where parts are delivered to robots and workers in stationary workstations, construction robots and human workers must accumulate all necessary resources and repeatedly navigate to desired assembly locations on-site to perform useful work. The condition of such resources and the geometry of the environment are constantly changing and generally unstructured. As a result, the motion trajectories of any robot arms cannot be programmed beforehand. The robots must define the trajectory based on the encountered workspace geometry. Learning from Demonstration (LfD) methods have the potential to be used in teaching robots specific skills through human demonstration such that the robots can repeat the same process in different conditions. In this research, we explore the LfD method to teach robots to perform repetitive but geometrically adaptive construction tasks of installing suspended ceiling tiles within pre-assembled ceiling grids. The developed method translates the work context from the set of training videos demonstrated by humans to the target scene, then applies the reinforcement learning method to generate the policy for the robot to perform the subsequent ceiling tile installation. The first phase of the proposed method, i.e., the context translation model, is implemented and evaluated by characterizing whether robot-installed ceiling tiles are successfully moved to the grid area. The experiments demonstrate promising results that show the applicability of the LfD method in teaching robots to perform geometrically-adaptive construction tasks. © 2019 International Association for Automation and Robotics in Construction I.A.A.R.C. All rights reserved.",Conference Paper,"Final",Scopus,2-s2.0-85071479614
"Su X., Cai H.","Enabling Construction 4D Topological Analysis for Effective Construction Planning",2016,"Journal of Computing in Civil Engineering",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952361602&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000463&partnerID=40&md5=4c5cc9b2774292c5440cb1a975651b70","Construction four-dimensional (4D) models have emerged to become a powerful tool for effective construction planning and control. However, the emphasis has been visualization and 4D topological analysis capabilities are not well-incorporated in the existing practice. Some 4D models enabled space-time conflict detection or site layout analysis, subtypes of 4D topological analysis; these functions are fragmented and constrained in particular construction scenarios. This paper presents a generic construction 4D topology framework that enables 4D topological analysis to support a wide range of construction planning tasks. The framework includes a 4D topological representation method that formalizes the spatial-temporal relationships between construction activities, a topology categorization method that formats the 4D topological representations into task templates, and a mathematical method to conduct the analysis. The framework is tested in a prototype through a case study, which proves that the framework is able to facilitate many construction planning works such as space-time conflict detection and test for crane's cover range. © 2014 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84952361602
"Lee S., Moon J.I.","Introduction of human-robot cooperation technology at construction sites",2014,"31st International Symposium on Automation and Robotics in Construction and Mining, ISARC 2014 - Proceedings",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912529986&partnerID=40&md5=c24a8f35a28e76529085f65cd1ad6f42","Currently, a new construction method using a robotic system is widely spreading in construction sites. This study is related to introduction of human-robot cooperation technology which can improve convenience and productivity through the efficient interaction between a worker and a robotic system while doing glass panel installation works. Based on the analysis on glass panel installation with a glazing robot, functional requirements and approaches to address these requirements that can implement human-robot cooperative manipulation at construction sites. A practical example, which is applied to a specific target construction site, is also described in this paper. After field test at a real construction site, productivity and safety of the proposed system are compared with the existing glass panel installation system.",Conference Paper,"Final",Scopus,2-s2.0-84912529986
"Milberg C., Tommelein I.","Role of tolerances and process capability data in product and process design integration",2003,"Construction Research Congress",6,,[No abstract available],,"Final",Scopus,2-s2.0-84940847101
"Liu M.","Video-Based Human Motion Capture and Force Estimation for Comprehensive On-Site Ergonomic Risk Assessment",2019,"Video-Based Human Motion Capture and Force Estimation for Comprehensive On-Site Ergonomic Risk Assessment",3,,[No abstract available],,"Final",Scopus,2-s2.0-85084131593
"Yu Y.-H., Yeh C.-H., Lee T.-T., Chen P.-Y., Shiau Y.-H.","Chip-based real-time gesture tracking for construction robot's guidance",2014,"31st International Symposium on Automation and Robotics in Construction and Mining, ISARC 2014 - Proceedings",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912575639&partnerID=40&md5=b6c26df3e41a96829c98545132d1a7ff","Mobile robots in automation construction have been designed for applications of craning, conveying, excavating, and floor polishing. These robots nowadays are equipped with various sensors to detect environmental information and finish tasks autonomously. When robot's navigating path needs to be rescheduled, the supervisor of robot can duly interrupt system and then redefines a new route for robot. In addition to robot remote control by radio signals, using digital camera to receive instructions from supervisor's gestures is also effective and can avoid the drawback of networked data routing. In this paper, we propose a gesture tracking system by simulating a traffic light baton to guide a differential drive robot in construction site. Here a real-time moving object detection first tracks supervisor's waves (gestures) with digital camera. Next the system determines guiding direction and steering angles based on fuzzy logic. All of our designs are implemented in single FPGA chip for operating under rigor environments. The experimental results demonstrate that proposed gesture tracking system is accurate and promising for chip-based gesture guidance on construction robots in the future.",Conference Paper,"Final",Scopus,2-s2.0-84912575639
[No author name available],[No title available],2020,"Construction loses 975, 000 jobs in april, due to covid-19 impacts",2,,[No abstract available],,"Final",Scopus,2-s2.0-85109414963
"Hornung A, Wurm KM, Bennewitz M, Stachniss C, Burgard W","An efficient probabilistic 3d mapping framework based on octrees armin hornung",2013,"Autonomous Robots Journal",1,,[No abstract available],,"Final",Scopus,2-s2.0-85109385449
[No author name available],[No title available],0000,,1,,[No abstract available],,"Final",Scopus,2-s2.0-85109421349
[No author name available],[No title available],0000,,1,,[No abstract available],,"Final",Scopus,2-s2.0-85109421291
[No author name available],[No title available],0000,"Mule",1,,[No abstract available],,"Final",Scopus,2-s2.0-85109366322
[No author name available],[No title available],0000,,1,,[No abstract available],,"Final",Scopus,2-s2.0-85109359930
