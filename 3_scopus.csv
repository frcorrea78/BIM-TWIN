Authors,Title,Year,Source title,Cited by,Link,Abstract,Document Type,Publication Stage,Source,EID
"Cha Y.-J., Choi W., Büyüköztürk O.","Deep Learning-Based Crack Damage Detection Using Convolutional Neural Networks",2017,"Computer-Aided Civil and Infrastructure Engineering",1230,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017098035&doi=10.1111%2fmice.12263&partnerID=40&md5=87d7eba45c1f214484ad1b45c978fcb4","A number of image processing techniques (IPTs) have been implemented for detecting civil infrastructure defects to partially replace human-conducted onsite inspections. These IPTs are primarily used to manipulate images to extract defect features, such as cracks in concrete and steel surfaces. However, the extensively varying real-world situations (e.g., lighting and shadow changes) can lead to challenges to the wide adoption of IPTs. To overcome these challenges, this article proposes a vision-based method using a deep architecture of convolutional neural networks (CNNs) for detecting concrete cracks without calculating the defect features. As CNNs are capable of learning image features automatically, the proposed method works without the conjugation of IPTs for extracting features. The designed CNN is trained on 40 K images of 256 × 256 pixel resolutions and, consequently, records with about 98% accuracy. The trained CNN is combined with a sliding window technique to scan any image size larger than 256 × 256 pixel resolutions. The robustness and adaptability of the proposed approach are tested on 55 images of 5,888 × 3,584 pixel resolutions taken from a different structure which is not used for training and validation processes under various conditions (e.g., strong light spot, shadows, and very thin cracks). Comparative studies are conducted to examine the performance of the proposed CNN using traditional Canny and Sobel edge detection methods. The results show that the proposed method shows quite better performances and can indeed find concrete cracks in realistic situations. © 2017 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85017098035
"Van der Aalst W.","Process mining: Data science in action",2016,"Process Mining: Data Science in Action",1144,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979530122&doi=10.1007%2f978-3-662-49851-4&partnerID=40&md5=2c9677c2cfe2b253453b40c50e86ebb3","This is the second edition of Wil van der Aalst’s seminal book on process mining, which now discusses the field also in the broader context of data science and big data approaches. It includes several additions and updates, e.g. on inductive mining techniques, the notion of alignments, a considerably expanded section on software tools and a completely new chapter of process mining in the large. It is self-contained, while at the same time covering the entire process-mining spectrum from process discovery to predictive analytics. After a general introduction to data science and process mining in Part I, Part II provides the basics of business process modeling and data mining necessary to understand the remainder of the book. Next, Part III focuses on process discovery as the most important process mining task, while Part IV moves beyond discovering the control flow of processes, highlighting conformance checking, and organizational and time perspectives. Part V offers a guide to successfully applying process mining in practice, including an introduction to the widely used open-source tool ProM and several commercial products. Lastly, Part VI takes a step back, reflecting on the material presented and the key open challenges. Overall, this book provides a comprehensive overview of the state of the art in process mining. It is intended for business process analysts, business consultants, process managers, graduate students, and BPM researchers. © Springer-Verlag Berlin Heidelberg 2011, 2016.",Book,"Final",Scopus,2-s2.0-84979530122
"Amasyali K., El-Gohary N.M.","A review of data-driven building energy consumption prediction studies",2018,"Renewable and Sustainable Energy Reviews",581,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029080224&doi=10.1016%2fj.rser.2017.04.095&partnerID=40&md5=f0c2e1a87e727aed8fc24f8a10e07baf","Energy is the lifeblood of modern societies. In the past decades, the world's energy consumption and associated CO2 emissions increased rapidly due to the increases in population and comfort demands of people. Building energy consumption prediction is essential for energy planning, management, and conservation. Data-driven models provide a practical approach to energy consumption prediction. This paper offers a review of the studies that developed data-driven building energy consumption prediction models, with a particular focus on reviewing the scopes of prediction, the data properties and the data preprocessing methods used, the machine learning algorithms utilized for prediction, and the performance measures used for evaluation. Based on this review, existing research gaps are identified and future research directions in the area of data-driven building energy consumption prediction are highlighted. © 2017 Elsevier Ltd",Review,"Final",Scopus,2-s2.0-85029080224
"Mellit A., Kalogirou S.A.","Artificial intelligence techniques for photovoltaic applications: A review",2008,"Progress in Energy and Combustion Science",543,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-47149095417&doi=10.1016%2fj.pecs.2008.01.001&partnerID=40&md5=e28ee9ba9d25d189c05d4ca4b8f58480","Artificial intelligence (AI) techniques are becoming useful as alternate approaches to conventional techniques or as components of integrated systems. They have been used to solve complicated practical problems in various areas and are becoming more popular nowadays. They can learn from examples, are fault tolerant in the sense that they are able to handle noisy and incomplete data, are able to deal with nonlinear problems and once trained can perform prediction and generalization at high speed. AI-based systems are being developed and deployed worldwide in a wide variety of applications, mainly because of their symbolic reasoning, flexibility and explanation capabilities. AI has been used in different sectors, such as engineering, economics, medicine, military, marine, etc. They have also been applied for modeling, identification, optimization, prediction, forecasting and control of complex systems. The paper outlines an understanding of how AI systems operate by way of presenting a number of problems in photovoltaic systems application. Problems presented include three areas: forecasting and modeling of meteorological data, sizing of photovoltaic systems and modeling, simulation and control of photovoltaic systems. Published literature presented in this paper show the potential of AI as design tool in photovoltaic systems. © 2008 Elsevier Ltd. All rights reserved.",Review,"Final",Scopus,2-s2.0-47149095417
"Zhang S., Teizer J., Lee J.-K., Eastman C.M., Venugopal M.","Building Information Modeling (BIM) and Safety: Automatic Safety Checking of Construction Models and Schedules",2013,"Automation in Construction",489,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869092675&doi=10.1016%2fj.autcon.2012.05.006&partnerID=40&md5=8bb5402a6ddb270b76f0f31c18d1dbd7","Construction safety is a national and worldwide issue. This paper contributes in solving this problem by applying automated safety rule checking to Building Information Models (BIM). Algorithms that automatically analyze a building model to detect safety hazards and suggest preventive measures to users are developed for different cases involving fall related hazards. As BIM is changing the way construction can be approached, the presented work and case studies extend BIM to include automated hazard identification and correction during construction planning and in certain cases, during design. A rule-based engine that utilizes this framework is implemented on top of a commercially available BIM platform to show the feasibility of the approach. As a result, the developed automated safety checking platform informs construction engineers and managers by reporting, why, where, when, and what safety measures are needed for preventing fall-related accidents before construction starts. The safety area reviewed is fall protection. An example case study of such a system is also provided. © 2012 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84869092675
"Qi Q., Tao F.","Digital Twin and Big Data Towards Smart Manufacturing and Industry 4.0: 360 Degree Comparison",2018,"IEEE Access",488,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041173790&doi=10.1109%2fACCESS.2018.2793265&partnerID=40&md5=421f931c692160832c81d6535ddfea0a","With the advances in new-generation information technologies, especially big data and digital twin, smart manufacturing is becoming the focus of global manufacturing transformation and upgrading. Intelligence comes from data. Integrated analysis for the manufacturing big data is beneficial to all aspects of manufacturing. Besides, the digital twin paves a way for the cyber-physical integration of manufacturing, which is an important bottleneck to achieve smart manufacturing. In this paper, the big data and digital twin in manufacturing are reviewed, including their concept as well as their applications in product design, production planning, manufacturing, and predictive maintenance. On this basis, the similarities and differences between big data and digital twin are compared from the general and data perspectives. Since the big data and digital twin can be complementary, how they can be integrated to promote smart manufacturing are discussed. © 2013 IEEE.",Article,"Final",Scopus,2-s2.0-85041173790
"Cha Y.-J., Choi W., Suh G., Mahmoudkhani S., Büyüköztürk O.","Autonomous Structural Visual Inspection Using Region-Based Deep Learning for Detecting Multiple Damage Types",2018,"Computer-Aided Civil and Infrastructure Engineering",466,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035234880&doi=10.1111%2fmice.12334&partnerID=40&md5=cf9b656fd922a5ecac9a14eb602b3f0f","Computer vision-based techniques were developed to overcome the limitations of visual inspection by trained human resources and to detect structural damage in images remotely, but most methods detect only specific types of damage, such as concrete or steel cracks. To provide quasi real-time simultaneous detection of multiple types of damages, a Faster Region-based Convolutional Neural Network (Faster R-CNN)-based structural visual inspection method is proposed. To realize this, a database including 2,366 images (with 500 × 375 pixels) labeled for five types of damages—concrete crack, steel corrosion with two levels (medium and high), bolt corrosion, and steel delamination—is developed. Then, the architecture of the Faster R-CNN is modified, trained, validated, and tested using this database. Results show 90.6%, 83.4%, 82.1%, 98.1%, and 84.7% average precision (AP) ratings for the five damage types, respectively, with a mean AP of 87.8%. The robustness of the trained Faster R-CNN is evaluated and demonstrated using 11 new 6,000 × 4,000-pixel images taken of different structures. Its performance is also compared to that of the traditional CNN-based method. Considering that the proposed method provides a remarkably fast test speed (0.03 seconds per image with 500 × 375 resolution), a framework for quasi real-time damage detection on video using the trained networks is developed. © 2017 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85035234880
"Ahmad A.S., Hassan M.Y., Abdullah M.P., Rahman H.A., Hussin F., Abdullah H., Saidur R.","A review on applications of ANN and SVM for building electrical energy consumption forecasting",2014,"Renewable and Sustainable Energy Reviews",465,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894599627&doi=10.1016%2fj.rser.2014.01.069&partnerID=40&md5=fc7b0135e7af442826dc425ac96beed9","The rapid development of human population, buildings and technology application currently has caused electric consumption to grow rapidly. Therefore, efficient energy management and forecasting energy consumption for buildings are important in decision-making for effective energy saving and development in particular places. This paper reviews the building electrical energy forecasting method using artificial intelligence (AI) methods such as support vector machine (SVM) and artificial neural networks (ANN). Both methods are widely used in the field of forecasting and their aim on finding the most accurate approach is ever continuing. Besides the already existing single method of forecasting, the hybridization of the two forecasting methods has the potential to be applied for more accurate results. Further research works are currently ongoing, regarding the potential of hybrid method of Group Method of Data Handling (GMDH) and Least Square Support Vector Machine (LSSVM), or known as GLSSVM, to forecast building electrical energy consumption. © 2014 Elsevier Ltd.",Review,"Final",Scopus,2-s2.0-84894599627
"Chen F.-C., Jahanshahi M.R.","NB-CNN: Deep Learning-Based Crack Detection Using Convolutional Neural Network and Naïve Bayes Data Fusion",2018,"IEEE Transactions on Industrial Electronics",444,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032444624&doi=10.1109%2fTIE.2017.2764844&partnerID=40&md5=2e9b35c05382169ece0a561ee29193b5","Regular inspection of nuclear power plant components is important to guarantee safe operations. However, current practice is time consuming, tedious, and subjective, which involves human technicians reviewing the inspection videos and identifying cracks on reactors. A few vision-based crack detection approaches have been developed for metallic surfaces, and they typically perform poorly when used for analyzing nuclear inspection videos. Detecting these cracks is a challenging task since they are tiny, and noisy patterns exist on the components' surfaces. This study proposes a deep learning framework, based on a convolutional neural network (CNN) and a Naïve Bayes data fusion scheme, called NB-CNN, to analyze individual video frames for crack detection while a novel data fusion scheme is proposed to aggregate the information extracted from each video frame to enhance the overall performance and robustness of the system. To this end, a CNN is proposed to detect crack patches in each video frame, while the proposed data fusion scheme maintains the spatiotemporal coherence of cracks in videos, and the Naïve Bayes decision making discards false positives effectively. The proposed framework achieves a 98.3% hit rate against 0.1 false positives per frame that is significantly higher than state-of-the-art approaches as presented in this paper. © 1982-2012 IEEE.",Article,"Final",Scopus,2-s2.0-85032444624
"Koch C., Georgieva K., Kasireddy V., Akinci B., Fieguth P.","A review on computer vision based defect detection and condition assessment of concrete and asphalt civil infrastructure",2015,"Advanced Engineering Informatics",428,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937520680&doi=10.1016%2fj.aei.2015.01.008&partnerID=40&md5=bfb6a9a05d7c835f47e516b1a941e49a","To ensure the safety and the serviceability of civil infrastructure it is essential to visually inspect and assess its physical and functional condition. This review paper presents the current state of practice of assessing the visual condition of vertical and horizontal civil infrastructure; in particular of reinforced concrete bridges, precast concrete tunnels, underground concrete pipes, and asphalt pavements. Since the rate of creation and deployment of computer vision methods for civil engineering applications has been exponentially increasing, the main part of the paper presents a comprehensive synthesis of the state of the art in computer vision based defect detection and condition assessment related to concrete and asphalt civil infrastructure. Finally, the current achievements and limitations of existing methods as well as open research challenges are outlined to assist both the civil engineering and the computer science research community in setting an agenda for future research. © 2015 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84937520680
"Bos F., Wolfs R., Ahmed Z., Salet T.","Additive manufacturing of concrete in construction: potentials and challenges of 3D concrete printing",2016,"Virtual and Physical Prototyping",420,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980338880&doi=10.1080%2f17452759.2016.1209867&partnerID=40&md5=d45ce270facd96f05be5090b7685073f","Additive manufacturing is gaining ground in the construction industry. The potential to improve on current construction methods is significant. One of such methods being explored currently, both in academia and in construction practice, is the additive manufacturing of concrete (AMoC). Albeit a steadily growing number of researchers and private enterprises active in this field, AMoC is still in its infancy. Different variants in this family of manufacturing methods are being developed and improved continuously. Fundamental scientific understanding of the relations between design, material, process, and product is being explored. The collective body of work in that area is still very limited. After sketching the potential of AMoC for construction, this paper introduces the variants of AMoC under development around the globe and goes on to describe one of these in detail, the 3D Concrete Printing (3DCP) facility of the Eindhoven University of Technology. It is compared to other AMoC methods as well as to 3D printing in general. Subsequently, the paper will address the characteristics of 3DCP product geometry and structure, and discuss issues on parameter relations and experimental research. Finally, it will present the primary obstacles that stand between the potential of 3DCP and large-scale application in practice, and discuss the expected evolution of AMoC in general. © 2016 Informa UK Limited, trading as Taylor & Francis Group.",Article,"Final",Scopus,2-s2.0-84980338880
"Zhang A., Wang K.C.P., Li B., Yang E., Dai X., Peng Y., Fei Y., Liu Y., Li J.Q., Chen C.","Automated Pixel-Level Pavement Crack Detection on 3D Asphalt Surfaces Using a Deep-Learning Network",2017,"Computer-Aided Civil and Infrastructure Engineering",380,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029008687&doi=10.1111%2fmice.12297&partnerID=40&md5=e8547a71c68aa6e32bd689bc4c505e0e","The CrackNet, an efficient architecture based on the Convolutional Neural Network (CNN), is proposed in this article for automated pavement crack detection on 3D asphalt surfaces with explicit objective of pixel-perfect accuracy. Unlike the commonly used CNN, CrackNet does not have any pooling layers which downsize the outputs of previous layers. CrackNet fundamentally ensures pixel-perfect accuracy using the newly developed technique of invariant image width and height through all layers. CrackNet consists of five layers and includes more than one million parameters that are trained in the learning process. The input data of the CrackNet are feature maps generated by the feature extractor using the proposed line filters with various orientations, widths, and lengths. The output of CrackNet is the set of predicted class scores for all pixels. The hidden layers of CrackNet are convolutional layers and fully connected layers. CrackNet is trained with 1,800 3D pavement images and is then demonstrated to be successful in detecting cracks under various conditions using another set of 200 3D pavement images. The experiment using the 200 testing 3D images showed that CrackNet can achieve high Precision (90.13%), Recall (87.63%) and F-measure (88.86%) simultaneously. Compared with recently developed crack detection methods based on traditional machine learning and imaging algorithms, the CrackNet significantly outperforms the traditional approaches in terms of F-measure. Using parallel computing techniques, CrackNet is programmed to be efficiently used in conjunction with the data collection software. © 2017 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85029008687
"Castanedo F.","A review of data fusion techniques",2013,"The Scientific World Journal",375,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888882639&doi=10.1155%2f2013%2f704504&partnerID=40&md5=5240b8a31c1d990f044fb8c7eace30bb","The integration of data and knowledge from several sources is known as data fusion. This paper summarizes the state of the data fusion field and describes the most relevant studies. We first enumerate and explain different classification schemes for data fusion. Then, the most common algorithms are reviewed. These methods and algorithms are presented using three different categories: (i) data association, (ii) state estimation, and (iii) decision fusion. © 2013 Federico Castanedo.",Review,"Final",Scopus,2-s2.0-84888882639
"Barbosa F., Woetzel J., Mischke J., Ribeirinho M.J., Sridhar M., Parsons M., Bertram N., Brown S.","Reinventing Construction: A Route to Higher Productivity",2017,"Reinventing Construction: A Route to Higher Productivity",356,,[No abstract available],,"Final",Scopus,2-s2.0-85046345496
"Taylan O., Bafail A.O., Abdulaal R.M.S., Kabli M.R.","Construction projects selection and risk assessment by fuzzy AHP and fuzzy TOPSIS methodologies",2014,"Applied Soft Computing Journal",341,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893226274&doi=10.1016%2fj.asoc.2014.01.003&partnerID=40&md5=00b8082e3277957906d93fa36982c990","Construction projects are initiated in dynamic environment which result in circumstances of high uncertainty and risks due to accumulation of many interrelated parameters. The purpose of this study is to use novel analytic tools to evaluate the construction projects and their overall risks under incomplete and uncertain situations. It was also aimed to place the risk in a proper category and predict the level of it in advance to develop strategies and counteract the high-risk factors. The study covers identifying the key risk criteria of construction projects at King Abdulaziz University (KAU), and assessing the criteria by the integrated hybrid methodologies. The proposed hybrid methodologies were initiated with a survey for data collection. The relative importance index (RII) method was applied to prioritize the project risks based on the data obtained. The construction projects were then categorized by fuzzy AHP and fuzzy TOPSIS methodologies. Fuzzy AHP (FAHP) was used to create favorable weights for fuzzy linguistic variable of construction projects overall risk. The fuzzy TOPSIS method is very suitable for solving group decision making problems under the fuzzy environment. It attempted to incorporate vital qualitative attributes in performance analysis of construction projects and transformed the qualitative data into equivalent quantitative measures. Thirty construction projects were studied with respect to five main criteria that are the time, cost, quality, safety and environment sustainability. The results showed that these novel methodologies are able to assess the overall risks of construction projects, select the project that has the lowest risk with the contribution of relative importance index. This approach will have potential applications in the future. © 2014 Published by Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84893226274
"Hamdy M., Hasan A., Siren K.","A multi-stage optimization method for cost-optimal and nearly-zero-energy building solutions in line with the EPBD-recast 2010",2013,"Energy and Buildings",306,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870668912&doi=10.1016%2fj.enbuild.2012.08.023&partnerID=40&md5=4112e4149256f08c401440aea4b53364","Finding cost-optimal solutions towards nearly-zero-energy buildings (nZEBs) in accordance with European energy performance of buildings directive (EPBD-recast 2010) is a challenging task. It requires exploring a huge number of possible combinations of energy-saving measures (ESMs) and energy-supply systems including renewable energy sources (RESs), under a comparative framework methodology. The current study introduces efficient, transparent, and time-saving simulation-based optimization method for such explorations. The method is applied to find the cost-optimal and nZEB energy performance levels for a study case of a single-family house in Finland. Different options of building-envelope parameters, heat-recovery units, and heating/cooling systems as well as various sizes of thermal and photovoltaic solar systems are explored as design options via three-stage optimization. The resulted economic and environmental trade-offs show that primary energy consumption ≥93 and ≤103 kWh/m2a is a cost-optimal energy performance level. It is economically feasible to achieve nZEB with 70 kWh/m2a. However, incentives (e.g., energy credits) are required to reach lower-environmental- impact houses. Investing in low-operating-cost environmentally friendly heating system (e.g. ground source heat pump) is a key element for optimal solutions. The optimal implementation of ESMs and RES depends significantly on the installed heating/cooling system and the escalation rate of the energy price. © 2012 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84870668912
"Dung C.V., Anh L.D.","Autonomous concrete crack detection using deep fully convolutional neural network",2019,"Automation in Construction",303,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058160438&doi=10.1016%2fj.autcon.2018.11.028&partnerID=40&md5=fa81b76ea6afa2a43f7746ea1dc47149","Crack detection is a critical task in monitoring and inspection of civil engineering structures. Image classification and bounding box approaches have been proposed in existing vision-based automated concrete crack detection methods using deep convolutional neural networks. The current study proposes a crack detection method based on deep fully convolutional network (FCN) for semantic segmentation on concrete crack images. Performance of three different pre-trained network architectures, which serves as the FCN encoder's backbone, is evaluated for image classification on a public concrete crack dataset of 40,000 227 × 227 pixel images. Subsequently, the whole encoder-decoder FCN network with the VGG16-based encoder is trained end-to-end on a subset of 500 annotated 227 × 227-pixel crack-labeled images for semantic segmentation. The FCN network achieves about 90% in average precision. Images extracted from a video of a cyclic loading test on a concrete specimen are used to validate the proposed method for concrete crack detection. It was found that cracks are reasonably detected and crack density is also accurately evaluated. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85058160438
"Fan C., Xiao F., Zhao Y.","A short-term building cooling load prediction method using deep learning algorithms",2017,"Applied Energy",301,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015712839&doi=10.1016%2fj.apenergy.2017.03.064&partnerID=40&md5=f1868ff156c947099a8b32fa938caea2","Short-term building cooling load prediction is the essential foundation for many building energy management tasks, such as fault detection and diagnosis, demand-side management and control optimization. Conventional methods, which heavily rely on physical principles, have limited power in practice as their performance is subject to many physical assumptions. By contrast, data-driven methods have gained huge interests due to their flexibility in model development and the rich data available in modern buildings. The rapid development in data science has provided advanced data analytics to tackle prediction problems in a more convenient, efficient and effective way. This paper investigates the potential of one of the most promising techniques in advanced data analytics, i.e., deep learning, in predicting 24-h ahead building cooling load profiles. Deep learning refers to a collection of machine learning algorithms which are powerful in revealing nonlinear and complex patterns in big data. Deep learning can be used either in a supervised manner to develop prediction models with given inputs and output (i.e., cooling load), or in an unsupervised manner to extract meaningful features from raw data as model inputs. This study exploits the potential of deep learning in both manners, and compares its performance in cooling load prediction with typical feature extraction methods and popular prediction techniques in the building field. The results show that deep learning can enhance the performance of building cooling load prediction, especially when used in an unsupervised manner for constructing high-level features as model inputs. Using the features extracted by unsupervised deep learning as inputs for cooling load prediction can evidently enhance the prediction performance. The findings are enlightening and could bring more flexible and effective solutions for building energy predictions. © 2017",Article,"Final",Scopus,2-s2.0-85015712839
"Kim T.-Y., Cho S.-B.","Predicting residential energy consumption using CNN-LSTM neural networks",2019,"Energy",290,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067643645&doi=10.1016%2fj.energy.2019.05.230&partnerID=40&md5=684382de611bb3073627660c2a1f55f4","The rapid increase in human population and development in technology have sharply raised power consumption in today's world. Since electricity is consumed simultaneously as it is generated at the power plant, it is important to accurately predict the energy consumption in advance for stable power supply. In this paper, we propose a CNN-LSTM neural network that can extract spatial and temporal features to effectively predict the housing energy consumption. Experiments have shown that the CNN-LSTM neural network, which combines convolutional neural network (CNN) and long short-term memory (LSTM), can extract complex features of energy consumption. The CNN layer can extract the features between several variables affecting energy consumption, and the LSTM layer is appropriate for modeling temporal information of irregular trends in time series components. The proposed CNN-LSTM method achieves almost perfect prediction performance for electric energy consumption that was previously difficult to predict. Also, it records the smallest value of root mean square error compared to the conventional forecasting methods for the dataset on individual household power consumption. The empirical analysis of the variables confirms what affects to forecast the power consumption most. © 2019 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85067643645
"Niu D., Wang Y., Wu D.D.","Power load forecasting using support vector machine and ant colony optimization",2010,"Expert Systems with Applications",290,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449525203&doi=10.1016%2fj.eswa.2009.08.019&partnerID=40&md5=44bc8644d6363c86b2b933a90ef3cf69","This paper creates a system for power load forecasting using support vector machine and ant colony optimization. The method of colony optimization is employed to process large amount of data and eliminate redundant information. The system mines the historical daily loading which has the same meteorological category as the forecasting day in order to compose data sequence with highly similar meteorological features. With this method, we reduced SVM training data and overcame the disadvantage of very large data and slow processing speed when constructing SVM model. This paper proposes a new feature selection mechanism based on ant colony optimization in an attempt to combat the aforemention difficulties. The method is then applied to find optimal feature subsets in the fuzzy-rough data reduction process. The present work is applied to complex systems monitoring, the ant colony optimization can mine the data more overall and accurate than the original fuzzy-rough method, an entropy-based feature selector, and a transformation-based reduction method, PCA. Comparing with single SVM and BP neural network in short-term load forecasting, this new method can achieve greater forecasting accuracy. It denotes that the SVM-learning system has advantage when the information preprocessing is based on data mining technology. © 2009 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-70449525203
"Nieto-Morote A., Ruz-Vila F.","A fuzzy approach to construction project risk assessment",2011,"International Journal of Project Management",288,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650831689&doi=10.1016%2fj.ijproman.2010.02.002&partnerID=40&md5=728ef25853f1ec11f188eba665c1de21","The increasing complexity and dynamism of construction projects have imposed substantial uncertainties and subjectivities in the risk analysis process. Most of the real-world risk analysis problems contain a mixture of quantitative and qualitative data; therefore quantitative risk assessment techniques are inadequate for prioritizing risks. This article presents a risk assessment methodology based on the Fuzzy Sets Theory, which is an effective tool to deal with subjective judgement, and on the Analytic Hierarchy Process (AHP), which is used to structure a large number of risks. The proposed methodology incorporates knowledge and experience acquired from many experts, since they carry out the risks identification and their structuring, and also the subjective judgements of the parameters which are considered to assess the overall risk factor: risk impact, risk probability and risk discrimination. All of these factors are expressed by qualitative scales which are defined by trapezoidal fuzzy numbers to capture the vagueness in the linguistic variables. The most notable differences with other fuzzy risk assessment methods are the use of an algorithm to handle the inconsistencies in the fuzzy preference relation when pair-wise comparison judgements are necessary, and the use of trapezoidal fuzzy numbers until the defuzzification step. An illustrative example on risk assessment of a rehabilitation project of a building is used to demonstrate the proposed methodology. © 2010 Elsevier Ltd and IPMA.",Article,"Final",Scopus,2-s2.0-78650831689
"Li X., Yi W., Chi H.-L., Wang X., Chan A.P.C.","A critical review of virtual and augmented reality (VR/AR) applications in construction safety",2018,"Automation in Construction",287,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034043364&doi=10.1016%2fj.autcon.2017.11.003&partnerID=40&md5=2ee7532a8fe659b1dda070548e3767b4","Construction is a high hazard industry which involves many factors that are potentially dangerous to workers. Safety has always been advocated by many construction companies, and they have been working hard to make sure their employees are protected from fatalities and injuries. With the advent of Virtual and Augmented Reality (VR/AR), there has been a witnessed trend of capitalizing on sophisticated immersive VR/AR applications to create forgiving environments for visualizing complex workplace situations, building up risk-preventive knowledge and undergoing training. To better understand the state-of-the-art of VR/AR applications in construction safety (VR/AR-CS) and from which to uncover the related issues and propose possible improvements, this paper starts with a review and synthesis of research evidence for several VR/AR prototypes, products and the related training and evaluation paradigms. Predicated upon a wide range of well-acknowledged scholarly journals, this paper comes up with a generic taxonomy consisting of VR/AR technology characteristics, application domains, safety scenarios and evaluation methods. According to this taxonomy, a number of technical features and types that could be implemented in the context of construction safety enhancement are derived and further elaborated, while significant application domains and trends regarding the VR/AR-CS research are generalized, i.e., hazards recognition and identification, safety training and education, safety instruction and inspection, and so on. Last but not least, this study sets forth a list of gaps derived from the in-depth review and comes up with the prospective research works. It is envisioned that the outcomes of this paper could assist both researchers and industrial practitioners with appreciating the research and practice frontier of VR/AR-CS and soliciting the latest VR/AR applications. © 2017 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85034043364
"Bilal M., Oyedele L.O., Qadir J., Munir K., Ajayi S.O., Akinade O.O., Owolabi H.A., Alaka H.A., Pasha M.","Big Data in the construction industry: A review of present status, opportunities, and future trends",2016,"Advanced Engineering Informatics",287,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978529080&doi=10.1016%2fj.aei.2016.07.001&partnerID=40&md5=2e3c4aa24b24f44b04d3ef411258aa75","The ability to process large amounts of data and to extract useful insights from data has revolutionised society. This phenomenon—dubbed as Big Data—has applications for a wide assortment of industries, including the construction industry. The construction industry already deals with large volumes of heterogeneous data; which is expected to increase exponentially as technologies such as sensor networks and the Internet of Things are commoditised. In this paper, we present a detailed survey of the literature, investigating the application of Big Data techniques in the construction industry. We reviewed related works published in the databases of American Association of Civil Engineers (ASCE), Institute of Electrical and Electronics Engineers (IEEE), Association of Computing Machinery (ACM), and Elsevier Science Direct Digital Library. While the application of data analytics in the construction industry is not new, the adoption of Big Data technologies in this industry remains at a nascent stage and lags the broad uptake of these technologies in other fields. To the best of our knowledge, there is currently no comprehensive survey of Big Data techniques in the context of the construction industry. This paper fills the void and presents a wide-ranging interdisciplinary review of literature of fields such as statistics, data mining and warehousing, machine learning, and Big Data Analytics in the context of the construction industry. We discuss the current state of adoption of Big Data in the construction industry and discuss the future potential of such technologies across the multiple domain-specific sub-areas of the construction industry. We also propose open issues and directions for future work along with potential pitfalls associated with Big Data adoption in the industry. © 2016 Elsevier Ltd",Review,"Final",Scopus,2-s2.0-84978529080
"Asadi E., Silva M.G.D., Antunes C.H., Dias L., Glicksman L.","Multi-objective optimization for building retrofit: A model using genetic algorithm and artificial neural network and an application",2014,"Energy and Buildings",265,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905044286&doi=10.1016%2fj.enbuild.2014.06.009&partnerID=40&md5=8b2b938fe6c85cf32b7d2b2ad9f7622b","Retrofitting of existing buildings offers significant opportunities for improving occupants' comfort and well-being, reducing global energy consumption and greenhouse gas emissions. This is being considered as one of the main approaches to achieve sustainability in the built environment at relatively low cost and high uptake rates. Although a wide range of retrofit technologies is readily available, methods to identify the most suitable set of retrofit actions for particular projects are still a major technical and methodological challenge. This paper presents a multi-objective optimization model using genetic algorithm (GA) and artificial neural network (ANN) to quantitatively assess technology choices in a building retrofit project. This model combines the rapidity of evaluation of ANNs with the optimization power of GAs. A school building is used as a case study to demonstrate the practicability of the proposed approach and highlight potential problems that may arise. The study starts with the individual optimization of objective functions focusing on building's characteristics and performance: energy consumption, retrofit cost, and thermal discomfort hours. Then a multi-objective optimization model is developed to study the interaction between these conflicting objectives and assess their trade-offs. © 2014 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84905044286
"Zhou Z., Goh Y.M., Li Q.","Overview and analysis of safety management studies in the construction industry",2015,"Safety Science",252,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909954125&doi=10.1016%2fj.ssci.2014.10.006&partnerID=40&md5=b8a2d49afba3af6b64709cbcf8343ef8","Persistent endeavors have been made to promote construction safety, but fatalities still plague the industry. Recently there had been an emergence of a variety of construction safety research focusing on topics such as safety competency, accident statistics, design for safety, and safety culture. A large number of construction safety studies with the variety of topics make it difficult for stakeholders to have an overview of this field. Hence a systematic review of previous studies is paramount for facilitating sharing useful research findings and accessing future trends in construction safety research. A five-step framework was proposed in this review. The analysis focused on publication year, journal title, country/region distribution, organizational level, project phase, project type, innovative technology application and research topic. Three groups of construction safety research were identified. The first group of research is conducted from the perspective of safety management process, such as safety assessment and safety program. The second group aims to explore the impact of individual and group characteristics in relation to construction safety, such as worker behavior, perception, and safety climate. The third group utilizes accident/incident data to improve safety performance. In order to better capture construction safety research trend, these studies were discussed from chronological and thematic perspectives. Four main research findings including construction safety research perspectives, construction safety research trends, innovative technology applications in construction safety, and safety information flow, were gained. Finally, this review identified and discussed research gaps and corresponding agenda which can serve as guidance for future construction safety research. © 2014 Elsevier Ltd.",Review,"Final",Scopus,2-s2.0-84909954125
"Bughin J.","Artificial intelligence. The next digital frontier?",2017,"Artificial Intelligence the Next Digital Frontier?",246,,[No abstract available],,"Final",Scopus,2-s2.0-85029695623
"Delgarm N., Sajadi B., Kowsary F., Delgarm S.","Multi-objective optimization of the building energy performance: A simulation-based approach by means of particle swarm optimization (PSO)",2016,"Applied Energy",245,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960901998&doi=10.1016%2fj.apenergy.2016.02.141&partnerID=40&md5=d91072883ecf972c8be8bffbf6037bae","This paper proposes an efficient methodology for the simulation-based multi-objective optimization problems, which addresses important limitations for the optimization of the building energy performance. In this work, a mono- and multi-objective particle swarm optimization (MOPSO) algorithm is coupled with EnergyPlus building energy simulation software to find a set of non-dominated solutions to enhance the building energy performance. To evaluate the capability and effectiveness of the approach, the developed method is applied to a single room model, and the effect of building architectural parameters including, the building orientation, the shading overhang specifications, the window size, and the glazing and the wall material properties on the building energy consumption are studied in four major climatic regions of Iran. In the optimization section, mono-criterion and multi-criteria optimization analyses of the annual cooling, heating, and lighting electricity consumption are examined to understand interactions between the objective functions and to minimize the annual total building energy demand. The achieved optimum solutions from the multi-objective optimization process are also reported as Pareto optimal fronts. Finally, the result of multi-criteria minimization is compared with the mono-criterion ones. The results of the triple-objective optimization problem point out that for our typical model, the annual cooling electricity decreases about 19.8-33.3%; while the annual heating and lighting ones increase 1.7-4.8% and 0.5-2.6%, respectively, in comparison to the baseline model for four diverse climatic regions of Iran. In addition, the optimum design leads to 1.6-11.3% diminution of the total annual building electricity demand. The proposed optimization method shows a powerful and useful tool that can save time while searching for the optimal solutions with conflicting objective functions; therefore facilitate decision making in early phases of a building design in order to enhance its energy efficiency. © 2016 Elsevier Ltd.",Article,"Final",Scopus,2-s2.0-84960901998
"Seo J., Han S., Lee S., Kim H.","Computer vision techniques for construction safety and health monitoring",2015,"Advanced Engineering Informatics",236,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937513003&doi=10.1016%2fj.aei.2015.02.001&partnerID=40&md5=efb67ebcd634c01aa44a4ef355f166ca","For construction safety and health, continuous monitoring of unsafe conditions and action is essential in order to eliminate potential hazards in a timely manner. As a robust and automated means of field observation, computer vision techniques have been applied for the extraction of safety related information from site images and videos, and regarded as effective solutions complementary to current time-consuming and unreliable manual observational practices. Although some research efforts have been directed toward computer vision-based safety and health monitoring, its application in real practice remains premature due to a number of technical issues and research challenges in terms of reliability, accuracy, and applicability. This paper thus reviews previous attempts in construction applications from both technical and practical perspectives in order to understand the current status of computer vision techniques, which in turn suggests the direction of future research in the field of computer vision-based safety and health monitoring. Specifically, this paper categorizes previous studies into three groups - object detection, object tracking, and action recognition - based on types of information required to evaluate unsafe conditions and acts. The results demonstrate that major research challenges include comprehensive scene understanding, varying tracking accuracy by camera position, and action recognition of multiple equipment and workers. In addition, we identified several practical issues including a lack of task-specific and quantifiable metrics to evaluate the extracted information in safety context, technical obstacles due to dynamic conditions at construction sites and privacy issues. These challenges indicate a need for further research in these areas. Accordingly, this paper provides researchers insights into advancing knowledge and techniques for computer vision-based safety and health monitoring, and offers fresh opportunities and considerations to practitioners in understanding and adopting the techniques. © 2015 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84937513003
"Labonnote N., Rønnquist A., Manum B., Rüther P.","Additive construction: State-of-the-art, challenges and opportunities",2016,"Automation in Construction",226,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994104884&doi=10.1016%2fj.autcon.2016.08.026&partnerID=40&md5=6ce46542b6bece63aec76459b94a6d16","The present study has investigated to what extent additive manufacturing technologies can be successfully applied to the construction of large-scale structures. The central concept of additive construction was defined, and a systematic mapping study was performed in order to assemble relevant publications selected according to a well-defined set of criteria. Knowledge gathered from the relevant publications was organised into four main categories: material science, engineering, building design and market analysis. The lack of focus of material science research towards the characterisation and potential improvement of construction-related material properties has been emphasised. The evolution of technological solutions to deposit the construction materials from gantry solutions to more lightweight systems has been described. The governing parameters for deciding on the most appropriate solutions have been identified as the type of building component, the location for production, and the assembly technique. Benefits of additive construction for building design were shown to mostly address the perspective of end-users, but should instead be understood as the emergence of new opportunities and new constraints that will necessitate a greater degree of rational decision-making in the design phase. The relevant markets for additive construction were shown to be closely related to the inherent specificities of the project in question. This implies that additive construction can be successfully applied in connection with general housing projects only if housing in general changes to become more optimised and more individualised. It was concluded that additive construction has the potential to revolutionise the construction industry, its success depending on how the whole building industry is ready to tackle three challenges: the need for an architectural paradigm shift, the need for a holistic design process, and the need for rational designs. A list of suggestions for further research is provided, among them the development of tools for assessing the disruptive potential of additive construction in an objective and scientific way. © 2016 Elsevier B.V.",Review,"Final",Scopus,2-s2.0-84994104884
"Edwards R.E., New J., Parker L.E.","Predicting future hourly residential electrical consumption: A machine learning case study",2012,"Energy and Buildings",220,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861802647&doi=10.1016%2fj.enbuild.2012.03.010&partnerID=40&md5=ad3d091263a9c01eb50ba4935f93c52a","Traditional whole building energy modeling suffers from several factors, including the large number of inputs required for building characterization, simplifying assumptions, and the gap between the as-designed and as-built building. Prior work has attempted to mitigate these problems by using sensor-based machine learning approaches to statistically model energy consumption, applying the techniques primarily to commercial building data, which makes use of hourly consumption data. It is unclear, however, whether these techniques can translate to residential buildings, since the energy usage patterns may vary significantly. Until now, most residential modeling research only had access to monthly electrical consumption data. In this article, we report on the evaluation of seven different machine learning algorithms applied to a new residential data set that contains sensor measurements collected every 15 min, with the objective of determining which techniques are most successful for predicting next hour residential building consumption. We first validate each learner's correctness on the ASHRAE Great Energy Prediction Shootout, confirming existing conclusions that Neural Network-based methods perform best on commercial buildings. However, our additional results show that these methods perform poorly on residential data, and that Least Squares Support Vector Machines perform best - a technique not previously applied to this domain. © 2012 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84861802647
"Spencer B.F., Jr., Hoskere V., Narazaki Y.","Advances in Computer Vision-Based Civil Infrastructure Inspection and Monitoring",2019,"Engineering",217,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063608159&doi=10.1016%2fj.eng.2018.11.030&partnerID=40&md5=378e795cc233a18b51bb1077fa23e4e9","Computer vision techniques, in conjunction with acquisition through remote cameras and unmanned aerial vehicles (UAVs), offer promising non-contact solutions to civil infrastructure condition assessment. The ultimate goal of such a system is to automatically and robustly convert the image or video data into actionable information. This paper provides an overview of recent advances in computer vision techniques as they apply to the problem of civil infrastructure condition assessment. In particular, relevant research in the fields of computer vision, machine learning, and structural engineering is presented. The work reviewed is classified into two types: inspection applications and monitoring applications. The inspection applications reviewed include identifying context such as structural components, characterizing local and global visible damage, and detecting changes from a reference image. The monitoring applications discussed include static measurement of strain and displacement, as well as dynamic measurement of displacement for modal analysis. Subsequently, some of the key challenges that persist toward the goal of automated vision-based civil infrastructure and monitoring are presented. The paper concludes with ongoing work aimed at addressing some of these stated challenges. © 2019",Review,"Final",Scopus,2-s2.0-85063608159
"Chae Y.T., Horesh R., Hwang Y., Lee Y.M.","Artificial neural network model for forecasting sub-hourly electricity usage in commercial buildings",2016,"Energy and Buildings",215,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949591010&doi=10.1016%2fj.enbuild.2015.11.045&partnerID=40&md5=ab344a96499daa9cd3520d57872d87b8","Short-term load forecasting of building electricity usage is of great importance for anomaly detection on electricity usage pattern and management of building energy consumption in an environment where electricity pricing is dynamically determined based on the peak energy consumption. In this paper, we present a data-driven forecasting model for day-ahead electricity usage of buildings in 15-minute resolution. By using variable importance analysis, we have selected key variables: day type indicator, time-of-day, HVAC set temperature schedule, outdoor air dry-bulb temperature, and outdoor humidity as the most important predictors for electricity consumption. This study proposes a short-term building energy usage forecasting model based on an Artificial Neural Network (ANN) model with Bayesian regularization algorithm and investigates how the network design parameters such as time delay, number of hidden neurons, and training data effect on the model capability and generality. The results demonstrate that the proposed model with adaptive training methods is capable to predict the electricity consumption with 15-minute time intervals and the daily peak electricity usage reasonably well in a test case of a commercial building complex. © 2015 Published by Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84949591010
"Salehi H., Burgueño R.","Emerging artificial intelligence methods in structural engineering",2018,"Engineering Structures",214,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047606626&doi=10.1016%2fj.engstruct.2018.05.084&partnerID=40&md5=0a3596ec2c77a63b304dfbc42142fc8d","Artificial intelligence (AI) is proving to be an efficient alternative approach to classical modeling techniques. AI refers to the branch of computer science that develops machines and software with human-like intelligence. Compared to traditional methods, AI offers advantages to deal with problems associated with uncertainties and is an effective aid to solve such complex problems. In addition, AI-based solutions are good alternatives to determine engineering design parameters when testing is not possible, thus resulting in significant savings in terms of human time and effort spent in experiments. AI is also able to make the process of decision making faster, decrease error rates, and increase computational efficiency. Among the different AI techniques, machine learning (ML), pattern recognition (PR), and deep learning (DL) have recently acquired considerable attention and are establishing themselves as a new class of intelligent methods for use in structural engineering. The objective of this review paper is to summarize techniques concerning applications of the noted AI methods in structural engineering developed over the last decade. First, a general introduction to AI is presented and the importance of AI in structural engineering is described. Thereafter, a review of recent applications of ML, PR, and DL in the field is provided, and the capability of such methods to address the restrictions of conventional models are discussed. Further, the advantages of employing such algorithmic methods are discussed in detail. Finally, potential research avenues and emerging trends for employing ML, PR, and DL are presented, and their limitations are discussed. © 2018 Elsevier Ltd",Review,"Final",Scopus,2-s2.0-85047606626
"Xiong B., Skitmore M., Xia B.","A critical review of structural equation modeling applications in construction research",2015,"Automation in Construction",198,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922502969&doi=10.1016%2fj.autcon.2014.09.006&partnerID=40&md5=c57f29e054900fb2e7d67153feaca562","Structural equation modeling (SEM) is a versatile multivariate statistical technique, and applications have been increasing since its introduction in the 1980s. This paper provides a critical review of 84 articles involving the use of SEM to address construction related problems over the period 1998-2012 including, but not limited to, seven top construction research journals. After conducting a yearly publication trend analysis, it is found that SEM applications have been accelerating over time. However, there are inconsistencies in the various recorded applications and several recurring problems exist. The important issues that need to be considered are examined in research design, model development and model evaluation and are discussed in detail with reference to current applications. A particularly important issue concerns the construct validity. Relevant topics for efficient research design also include longitudinal or cross-sectional studies, mediation and moderation effects, sample size issues and software selection. A guideline framework is provided to help future researchers in construction SEM applications. © 2014 Elsevier B.V. All rights reserved.",Review,"Final",Scopus,2-s2.0-84922502969
"Hosseini M.R., Martek I., Zavadskas E.K., Aibinu A.A., Arashpour M., Chileshe N.","Critical evaluation of off-site construction research: A Scientometric analysis",2018,"Automation in Construction",195,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038865118&doi=10.1016%2fj.autcon.2017.12.002&partnerID=40&md5=ee31060d9814475dcf709a34e3164e0a","Practical interest in ‘off-site construction’ has risen remarkably over the last decade, and with it there has been a burgeoning of academic research in the field. Complementing this research, a number of literature reviews have been conducted. None, however, are systematic. This study addresses this lack, offering the first bibliometric study to explore the state of off-site construction research (OCR). A quantitative approach using ‘science mapping’ techniques is employed to examine 501 top-ranked construction journal articles. Longitudinal trends in publishing are identified, as are dominant research sub-fields, their connectedness with other areas of study, as well as citation patterns, publication journal areas of focus, key research institutions, key research persons, along with the extent to which these interact with each other in research networks. The findings are instructive in identifying the deficiencies in current research. Among these is a bias towards product research over operations and management, and a sharp compartmentalization of sub-fields, with little or no cross-fertilization between researcher areas, the researchers themselves, nor the research institutions. Clearly, this awareness will inform industry, journal editors and researchers of the need for a deeper exchange of ideas in any future research efforts. © 2017 Elsevier B.V.",Review,"Final",Scopus,2-s2.0-85038865118
"Mocanu E., Mocanu D.C., Nguyen P.H., Liotta A., Webber M.E., Gibescu M., Slootweg J.G.","On-Line Building Energy Optimization Using Deep Reinforcement Learning",2019,"IEEE Transactions on Smart Grid",192,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046827366&doi=10.1109%2fTSG.2018.2834219&partnerID=40&md5=357f11b8a30873d6a7820269e1901550","Unprecedented high volumes of data are becoming available with the growth of the advanced metering infrastructure. These are expected to benefit planning and operation of the future power systems and to help customers transition from a passive to an active role. In this paper, we explore for the first time in the smart grid context the benefits of using deep reinforcement learning, a hybrid type of methods that combines reinforcement learning with deep learning, to perform on-line optimization of schedules for building energy management systems. The learning procedure was explored using two methods, Deep Q-learning and deep policy gradient, both of which have been extended to perform multiple actions simultaneously. The proposed approach was validated on the large-scale Pecan Street Inc. database. This highly dimensional database includes information about photovoltaic power generation, electric vehicles and buildings appliances. Moreover, these on-line energy scheduling strategies could be used to provide real-time feedback to consumers to encourage more efficient use of electricity. © 2010-2012 IEEE.",Article,"Final",Scopus,2-s2.0-85046827366
"Wang P., Wu P., Wang J., Chi H.-L., Wang X.","A critical review of the use of virtual reality in construction engineering education and training",2018,"International Journal of Environmental Research and Public Health",192,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048463913&doi=10.3390%2fijerph15061204&partnerID=40&md5=41a0a5269de86d30ba80d108328bf82f","Virtual Reality (VR) has been rapidly recognized and implemented in construction engineering education and training (CEET) in recent years due to its benefits of providing an engaging and immersive environment. The objective of this review is to critically collect and analyze the VR applications in CEET, aiming at all VR-related journal papers published from 1997 to 2017. The review follows a three-stage analysis on VR technologies, applications and future directions through a systematic analysis. It is found that the VR technologies adopted for CEET evolve over time, from desktop-based VR, immersive VR, 3D game-based VR, to Building Information Modelling (BIM)-enabled VR. A sibling technology, Augmented Reality (AR), for CEET adoptions has also emerged in recent years. These technologies have been applied in architecture and design visualization, construction health and safety training, equipment and operational task training, as well as structural analysis. Future research directions, including the integration of VR with emerging education paradigms and visualization technologies, have also been provided. The findings are useful for both researchers and educators to usefully integrate VR in their education and training programs to improve the training performance. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.",Review,"Final",Scopus,2-s2.0-85048463913
"Ding L., Fang W., Luo H., Love P.E.D., Zhong B., Ouyang X.","A deep hybrid learning model to detect unsafe behavior: Integrating convolution neural networks and long short-term memory",2018,"Automation in Construction",191,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034071172&doi=10.1016%2fj.autcon.2017.11.002&partnerID=40&md5=90cd06efe43d85a2e92e88a04d3e5dad","Computer vision and pattern recognition approaches have been applied to determine unsafe behaviors on construction sites. Such approaches have been reliant on the computation of artificially complex image features that utilize a cumbersome parameter re-adjustment process. The creation of image features that can recognize unsafe actions, however, poses a significant research challenge on construction sites. This due to the prevailing complexity of spatio-temporal features, lighting, and the array of viewpoints that are required to identify an unsafe action. Considering these challenges, a new hybrid deep learning model that integrates a convolution neural network (CNN) and long short-term memory (LSTM) that automatically recognizes workers' unsafe actions is developed. The proposed hybrid deep learning model is used to: (1) identify unsafe actions; (2) collect motion data and site videos; (3) extract the visual features from videos using a CNN model; and (4) sequence the learning features that are enabled by the use of LSTM models. An experiment is used to test the model's ability to detect unsafe actions. The results reveal that the developed hybrid model (CNN + LSTM) is able to accurately detect safe/unsafe actions conducted by workers on-site. The model's accuracy exceeds the current state-of-the-art descriptor-based methods for detecting points of interest on images. © 2017",Article,"Final",Scopus,2-s2.0-85034071172
"Abdelgawad M., Fayek A.R.","Risk management in the construction industry using combined fuzzy FMEA and fuzzy AHP",2010,"Journal of Construction Engineering and Management",190,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955892275&doi=10.1061%2f%28ASCE%29CO.1943-7862.0000210&partnerID=40&md5=04cfc96e0b370cf57939d0e16141b919","Failure mode and effect analysis (FMEA) is recognized as one of the most beneficial techniques in reliability programs. FMEA is a structured technique that can help in identifying all failure modes within a system, assessing their impact, and planning for corrective actions. Although this technique has been widely used in many industries, it has some limitations. The purpose of this paper is to extend the application of FMEA to risk management in the construction industry. Fuzzy logic and fuzzy analytical hierarchy process (AHP) are used to address the limitations of traditional FMEA. In essence, this method explores the concept of fuzzy expert systems to map the relationship between impact (I), probability of occurrence (P), and detection/control (D) and the level of criticality of risk events. A case study is presented to validate the concept. The results obtained confirm the capability of fuzzy FMEA and fuzzy AHP to address several drawbacks of the traditional FMEA application. The use of this approach can support the project management team to establish corrective actions in a timely manner. © 2010 ASCE.",Article,"Final",Scopus,2-s2.0-77955892275
"Tang S., Shelden D.R., Eastman C.M., Pishdad-Bozorgi P., Gao X.","A review of building information modeling (BIM) and the internet of things (IoT) devices integration: Present status and future trends",2019,"Automation in Construction",180,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060885881&doi=10.1016%2fj.autcon.2019.01.020&partnerID=40&md5=7f882d4aa0b2c069887a02c5094892d6","The integration of Building Information Modeling (BIM) with real-time data from the Internet of Things (IoT) devices presents a powerful paradigm for applications to improve construction and operational efficiencies. Connecting real-time data streams from the rapidly expanding set of IoT sensor networks to the high-fidelity BIM models provides numerous applications. However, BIM and IoT integration research are still in nascent stages, there is a need to understand the current situation of BIM and IoT device integration. This paper conducts a comprehensive review with the intent to identify common emerging areas of application and common design patterns in the approach to tackling BIM-IoT device integration along with an examination of current limitations and predictions of future research directions. Altogether, 97 papers from 14 AEC related journals and databases in other industry over the last decade were reviewed. Several prevalent domains of application namely Construction Operation and Monitoring, Health & Safety Management, Construction Logistic & Management, and Facility Management were identified. The authors summarized 5 integration methods with description, examples, and discussion. These integration methods are utilizing BIM tools’ APIs and relational database, transform BIM data into a relational database using new data schema, create new query language, using semantic web technologies and hybrid approach. Based on the observed limitations, prominent future research directions are suggested, focusing on service-oriented architecture (SOA) patterns and web services-based strategies for BIM and IoT integration, establishing information integration & management standards, solving interoperability issue, and cloud computing. © 2019 Elsevier B.V.",Review,"Final",Scopus,2-s2.0-85060885881
"Buchanan C., Gardner L.","Metal 3D printing in construction: A review of methods, research, applications, opportunities and challenges",2019,"Engineering Structures",172,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056997953&doi=10.1016%2fj.engstruct.2018.11.045&partnerID=40&md5=db89155bc7285352926554cc50f1a3ef","3D printing, more formally known as additive manufacturing (AM), has the potential to revolutionise the construction industry, with foreseeable benefits including greater structural efficiency, reduction in material consumption and wastage, streamlining and expedition of the design-build process, enhanced customisation, greater architectural freedom and improved accuracy and safety on-site. Unlike traditional manufacturing methods for construction products, metal 3D printing offers ready opportunities to create non-prismatic sections, internal stiffening, openings, functionally graded elements, variable microstructures and mechanical properties through controlled heating and cooling and thermally-induced prestressing. Additive manufacturing offers many opportunities for the construction sector, but there will also be fresh challenges and demands, such as the need for more digitally savvy engineers, greater use of advanced computational analysis and a new way of thinking for the design and verification of structures, with greater emphasis on inspection and load testing. It is envisaged that AM will complement, rather than replace, conventional production processes, with clear potential for hybrid solutions and structural strengthening and repairs. These opportunities and challenges are explored in this paper as part of a wider review of different methods of metal 3D printing, research and early applications of additive manufacturing in the construction industry. Lessons learnt for metal 3D printing in construction from additive manufacturing using other materials and in other industries are also presented. © 2018 Elsevier Ltd",Review,"Final",Scopus,2-s2.0-85056997953
"Wang Z., Wang Y., Zeng R., Srinivasan R.S., Ahrentzen S.","Random Forest based hourly building energy prediction",2018,"Energy and Buildings",168,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046377108&doi=10.1016%2fj.enbuild.2018.04.008&partnerID=40&md5=06e8337878581c76f66fbb173d64b5e1","Accurate building energy prediction plays an important role in improving the energy efficiency of buildings. This paper proposes a homogeneous ensemble approach, i.e., use of Random Forest (RF), for hourly building energy prediction. The approach was adopted to predict the hourly electricity usage of two educational buildings in North Central Florida. The RF models trained with different parameter settings were compared to investigate the impact of parameter setting on the prediction performance of the model. The results indicated that RF was not very sensitive to the number of variables (mtry) and using empirical mtry is preferable because it saves time and is more accurate. RF was compared with regression tree (RT) and Support Vector Regression (SVR) to validate the superiority of RF in building energy prediction. The prediction performances of RF measured by performance index (PI) were 14–25% and 5–5.5% better than RT and SVR, respectively, indicating that RF was the best prediction model in the comparison. Moreover, an analysis based on the variable importance of RF was performed to identify the most influential features during different semesters. The results showed that the most influential features vary depending on the semester, indicating the existence of different operational conditions for the tested buildings. A further comparison between RF trained with yearly and monthly data indicated that the energy usage prediction for educational buildings could be improved by taking into consideration their energy behavior changes during different semesters. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85046377108
"Selakov A., Cvijetinović D., Milović L., Mellon S., Bekut D.","Hybrid PSO-SVM method for short-term load forecasting during periods with significant temperature variations in city of Burbank",2014,"Applied Soft Computing Journal",164,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891616845&doi=10.1016%2fj.asoc.2013.12.001&partnerID=40&md5=e6da517ce3391f4db198716ff15f5f40","This paper proposes a practical new hybrid model for short term electrical load forecasting based on particle swarm optimization (PSO) and support vector machines (SVM). Proposed PSO-SVM model is targeted for forecast load during periods with significant temperature variations. The proposed model detects periods when temperature significantly changes based on weather (temperature) forecast and decides whether the model can be trained just on recent history (typically 4 weeks ago) or such history has to be modified with data for similar days taken from history beyond recent history when such weather conditions were detected. Architecture of the solution consists of three modules, preprocessing module, SVM module and PSO module. The algorithm has been tested in city of Burbank utility, USA and obtained results show better accuracy comparing to results generated with classical methods of training on recent history only or similar days only. © 2013 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84891616845
"Bock T.","The future of construction automation: Technological disruption and the upcoming ubiquity of robotics",2015,"Automation in Construction",159,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944442053&doi=10.1016%2fj.autcon.2015.07.022&partnerID=40&md5=d087adf88d09f37e03e60cb49f899506","The following article reviews past and current tendencies and derives and describes opportunities for future construction automation that go beyond the current notion of construction automation. Various indicators suggest that conventional construction methodology has reached its limits. An overlay of S-curves can be used to describe the relationship between the stagnation and technical limits of conventional construction and the initiation, development, and growth of new strategies and technologies of construction automation. Although approaches of construction automation are still in an innovation or seed phase, it can be expected that with continued effort put into research and development these approaches may soon enter into the growth phase and encounter adoption on a larger scale. Furthermore, the article shows that over time, the ability of robot systems has grown, allowing them to work more and more in comparably unstructured environments as well as to be deployed in numerous and diverse fields. Currently, it can already be observed that construction automation technology, STCR approaches, service robot systems, and other microsystems technology are merging with the built environment, becoming inherent elements of buildings, building components, and building furniture. © 2015 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84944442053
"Xue Y., Li Y.","A Fast Detection Method via Region-Based Fully Convolutional Neural Networks for Shield Tunnel Lining Defects",2018,"Computer-Aided Civil and Infrastructure Engineering",158,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050164444&doi=10.1111%2fmice.12367&partnerID=40&md5=ce2733115a8a9b9675c8afa1bb31d7be","Tunnel lining defects are an important indicator reflecting the safety status of shield tunnels. Inspired by the state-of-the-art deep learning, a method for automatic intelligent classification and detection methodology of tunnel lining defects is presented. A fully convolutional network (FCN) model for classification is proposed. Information about defects, collected using charge-coupled device cameras, was used to train the model. The model's performance was compared to those of GoogLeNet and VGG. The best-set accuracy of the proposed model was over 95% at a test-time speed of 48 ms per image. For defects detection, image features were computed from large-scale images by the FCN and then detected using a region proposal network and position-sensitive region of interest pooling. Some indices (detection rate, detection accuracy, and detection efficiency, locating accuracy) were used to evaluate the model. The comparisons with faster R-CNN and a traditional method were conducted. The results show that the model is very fast and efficient, allowing automatic intelligent classification and detection of tunnel lining defects. © 2018 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85050164444
"Turk Ž., Klinc R.","Potentials of Blockchain Technology for Construction Management",2017,"Procedia Engineering",152,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030479533&doi=10.1016%2fj.proeng.2017.08.052&partnerID=40&md5=4878dacb604a1adffad4e389b518d155","Blockchain technology enables distributed, encrypted and secure logging of digital transactions. It is the underlying technology of Bitcoin and other cryptocurrencies. Blockchain is expected to revolutionize computing in several areas, particularly where centralization was unnatural and privacy was important. In the paper, we present research on where and how this technology could be useful in the construction industry. The work is based on the study of literature on open issues that exist in construction process management. These are than matched to the capabilities of blockchain. We are motivated by the fact that construction projects involve a dynamic grouping of several companies. We study the degree to which the relationships among them are hierarchical or peer-to-peer and note that particularly in information intensive phases, centralization of information management was necessary because of technology. When using un-constraining technology, communication patterns among participants show a peer-to-peer nature of the relationships. In such environment, blockchain can provide a trustworthy infrastructure for information management during all building life-cycle stages. Even if building information modelling (BIM) is used, which assumes a centralized building information model, there is a role for blockchain to manage information on who did what and when and thus provide a basis for any legal arguments that might occur. On the construction site blockchain can improve the reliability and trustworthiness of construction logbooks, works performed and material quantities recorded. In the facility maintenance phase, blockchain's main potential is the secure storage of sensor data which are sensitive to privacy. We conclude that blockchain provides solutions to many current problems in construction information management. However, it is more likely that it will be built into generic IT infrastructure on top of which construction applications are built, rather than used directly by authors of construction related software. It has a potential to make construction processes less centralized which opens needs for research in that direction. © 2017 The Authors.",Conference Paper,"Final",Scopus,2-s2.0-85030479533
"Biswas M.A.R., Robinson M.D., Fumo N.","Prediction of residential building energy consumption: A neural network approach",2016,"Energy",152,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994045716&doi=10.1016%2fj.energy.2016.10.066&partnerID=40&md5=68eeef986b259f242f3672e0b8482e23","Some of the challenges to predict energy utilization has gained recognition in the residential sector due to the significant energy consumption in recent decades. However, the modeling of residential building energy consumption is still underdeveloped for optimal and robust solutions while this research area has become of greater relevance with significant advances in computation and simulation. Such advances include the advent of artificial intelligence research in statistical model development. Artificial neural network has emerged as a key method to address the issue of nonlinearity of building energy data and the robust calculation of large and dynamic data. The development and validation of such models on one of the TxAIRE Research houses has been demonstrated in this paper. The TxAIRE houses have been designed to serve as realistic test facilities for demonstrating new technologies. The input variables used from the house data include number of days, outdoor temperature and solar radiation while the output variables are house and heat pump energy consumption. The models based on Levenberg-Marquardt and OWO-Newton algorithms had promising results of coefficients of determination within 0.87–0.91, which is comparable to prior literature. Further work will be explored to develop a robust model for residential building application. © 2016 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-84994045716
"Li C., Ding Z., Zhao D., Yi J., Zhang G.","Building energy consumption prediction: An extreme deep learning approach",2017,"Energies",150,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042162845&doi=10.3390%2fen10101525&partnerID=40&md5=cf6ba2aff91042f283734a43bb2424eb","Building energy consumption prediction plays an important role in improving the energy utilization rate through helping building managers to make better decisions. However, as a result of randomness and noisy disturbance, it is not an easy task to realize accurate prediction of the building energy consumption. In order to obtain better building energy consumption prediction accuracy, an extreme deep learning approach is presented in this paper. The proposed approach combines stacked autoencoders (SAEs) with the extreme learning machine (ELM) to take advantage of their respective characteristics. In this proposed approach, the SAE is used to extract the building energy consumption features, while the ELM is utilized as a predictor to obtain accurate prediction results. To determine the input variables of the extreme deep learning model, the partial autocorrelation analysis method is adopted. Additionally, in order to examine the performances of the proposed approach, it is compared with some popular machine learning methods, such as the backward propagation neural network (BPNN), support vector regression (SVR), the generalized radial basis function neural network (GRBFNN) and multiple linear regression (MLR). Experimental results demonstrate that the proposed method has the best prediction performance in different cases of the building energy consumption. © 2017 MDPI AG. All Rights Reserved.",Article,"Final",Scopus,2-s2.0-85042162845
"Wang X., Love P.E.D., Kim M.J., Park C.-S., Sing C.-P., Hou L.","A conceptual framework for integrating building information modeling with augmented reality",2013,"Automation in Construction",150,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878587673&doi=10.1016%2fj.autcon.2012.10.012&partnerID=40&md5=046bea5bd3acd088041e9cddf7a1739e","During the last two decades, designers have been embracing building information modeling (BIM) to improve the quality of the documentation that is produced as well as constructability. While BIM has become an innate feature of the design process within the construction industry, there have been limited investigations that have examined how it can be integrated into real-time communication on-site. In addressing this gap, this paper proposes a conceptual framework that integrates BIM with augmented reality (AR) so as to enable the physical context of each construction activity or task to be visualized in real-time. To be effective, it is suggested that AR should be ubiquitous (including context awareness) and thus operate in conjunction with tracking and sensing technologies such as radio frequency identification (RFID), laser pointing, sensors and motion tracking. © 2012 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84878587673
"Wang X., Truijens M., Hou L., Wang Y., Zhou Y.","Integrating Augmented Reality with Building Information Modeling: Onsite construction process controlling for liquefied natural gas industry",2014,"Automation in Construction",145,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894209434&doi=10.1016%2fj.autcon.2013.12.003&partnerID=40&md5=8ad30fcb5904b5d7704af3a3303af358","The extent of effectiveness of real-time communication within BIM environment is somehow restrained due to the limited sense of immersion into virtual environments. The objective of this paper highlights the need for a structured methodology of fully integrating Augmented Reality (AR) technology in BIM. Based on the generic review of BIM in construction, this paper forms the rationales for the onsite information system for construction site activities, and then formulates the methods of configuring BIM + AR prototypes. It is demonstrated that, extended to the site via the ""hand"" of AR, the BIM solution can address more real problems, such as low productivity in retrieving information, tendency of committing error in assembly, and low efficiency of communication and problem solving. © 2013 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84894209434
"Li S., Zhao X., Zhou G.","Automatic pixel-level multiple damage detection of concrete structure using fully convolutional network",2019,"Computer-Aided Civil and Infrastructure Engineering",140,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060349743&doi=10.1111%2fmice.12433&partnerID=40&md5=92919b6386f4bb0b1707c6769b2f725f","Deep learning-based structural damage detection methods overcome the limitation of inferior adaptability caused by extensively varying real-world situations (e.g., lighting and shadow changes). However, most deep learning-based methods detect structural damage at the image level and grid-cell level. To provide pixel-level detection of multiple damages, a Fully Convolutional Network (FCN)-based multiple damages detection method for concrete structure is proposed. To realize this method, a database of 2,750 images (with 504 × 376 pixels) including crack, spalling, efflorescence, and hole images in concrete structure is built, and the four damages included in those images are labeled manually. Then, the architecture of the FCN is modified, trained, validated, and tested using this database. A strategy of model-based transfer learning is used to initialize the parameters of the FCN during the training process. The results show 98.61% pixel accuracy (PA), 91.59% mean pixel accuracy (MPA), 84.53% mean intersection over union (MIoU), and 97.34% frequency weighted intersection over union (FWIoU). Subsequently, the robustness and adaptability of the trained FCN model is tested and the damage is extracted, where damage areas are provided according to a calibrated relation between the ratio (the pixel area and true area of the detected object) and the distance from the smartphone to the concrete surface using a laser range finder. A comparative study is conducted to examine the performance of the proposed FCN-based approach using a SegNet-based method. The results show that the proposed method substantiates quite better performance and can indeed detect multiple concrete damages at the pixel level in realistic situations. © 2019 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85060349743
"Fang W., Ding L., Luo H., Love P.E.D.","Falls from heights: A computer vision-based approach for safety harness detection",2018,"Automation in Construction",139,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042916507&doi=10.1016%2fj.autcon.2018.02.018&partnerID=40&md5=63d472a881eba74b0511d7e8c33a4805","Falls from heights (FFH) are major contributors of injuries and deaths in construction. Yet, despite workers being made aware of the dangers associated with not wearing a safety harness, many forget or purposefully do not wear them when working at heights. To address this problem, this paper develops an automated computer vision-based method that uses two convolutional neural network (CNN) models to determine if workers are wearing their harness when performing tasks while working at heights. The algorithms developed are: (1) a Faster-R-CNN to detect the presence of a worker; and (2) a deep CNN model to identify the harness. A database of photographs of people working at heights was created from activities undertaken on several construction projects in Wuhan, China. The database was then used to test and train the developed networks. The precision and recall rates for the Faster R-CNN were 99% and 95%, and the CNN models 80% and 98%, respectively. The results demonstrate that the developed method can accurately detect workers not wearing their harness. Thus, the computer vision-based approach developed can be used by construction and safety managers as a mechanism to proactively identify unsafe behavior and therefore take immediate action to mitigate the likelihood of a FFH occurring. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85042916507
"Zou Y., Kiviniemi A., Jones S.W.","A review of risk management through BIM and BIM-related technologies",2017,"Safety Science",139,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955321043&doi=10.1016%2fj.ssci.2015.12.027&partnerID=40&md5=ebe86112b5d46f3ad1d0733f2ab133f3","Risk management in the AEC (Architecture, Engineering and Construction) industry is a global issue. Failure to adequately manage risks may not only lead to difficulties in meeting project objectives but also influence land-use planning and urban spatial design in the future growth of cities. Due to the rapid development and adoption of BIM (Building Information Modelling) and BIM-related digital technologies, the use of these technologies for risk management has become a growing research trend leading to a demand for a thorough review of the state-of-the-art of these developments. This paper presents a summary of traditional risk management, and a comprehensive and extensive review of published literature concerning the latest efforts of managing risk using technologies, such as BIM, automatic rule checking, knowledge based systems, reactive and proactive IT (information technology)-based safety systems. The findings show that BIM could not only be utilised to support the project development process as a systematic risk management tool, but it could also serve as a core data generator and platform to allow other BIM-based tools to perform further risk analysis. Most of the current efforts have concentrated on investigating technical developments, and the management of construction personnel safety has been the main interest so far. Because of existing technical limitations and the lack of “human factor” testing, BIM-based risk management has not been commonly used in real environments. In order to overcome this gap, future research is proposed that should: (1) have a multi-disciplinary system-thinking, (2) investigate implementation methods and processes, (3) integrate traditional risk management with new technologies, and (4) support the development process. © 2016 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-84955321043
"Gogna A., Tayal A.","Metaheuristics: Review and application",2013,"Journal of Experimental and Theoretical Artificial Intelligence",137,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887827270&doi=10.1080%2f0952813X.2013.782347&partnerID=40&md5=093719d8c0b7a2fdb49aea418ac6393f","The area of metaheuristics has grown immensely in the past two decades as a solution to real-world optimisation problems. They are able to perform well in situations where exact optimisation techniques fail to deliver satisfactory results. For complex optimisation problems (Nondeterministic polynomial time-hard problems), metaheuristic techniques are able to generate good quality solution in relatively much less time than traditional optimisation techniques. Metaheuristics find applications in a wide range of areas including finance, planning, scheduling and engineering design. This paper presents a review of various metaheuristic algorithms, their methodology, recent trends and applications. © 2013 Taylor & Francis.",Article,"Final",Scopus,2-s2.0-84887827270
"Jaskowski P., Biruk S., Bucon R.","Assessing contractor selection criteria weights with fuzzy AHP method application in group decision environment",2010,"Automation in Construction",134,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-76549121003&doi=10.1016%2fj.autcon.2009.12.014&partnerID=40&md5=dae2b85473ec87f77b7f19bfa8516fa3","A tender procedure should facilitate selection of a reliable contractor with consideration to many criteria. Polish public procurement law, harmonized with EU guidelines on the subject, describes selection procedures in detail. Similar procedures are adopted by private sector clients as there exist no private sector specific procurement codes of practice. In the case of public procurement, the bid selection criteria have to refer to the object of procurement and not to the proprieties of a bidder. The client, in order to assure adequate quality of works (i.e. selection of a reliable and capable contractor) can, within the limits enforced by law, set conditions the bidders have to fulfill if they are to participate in a tender or negotiation procedure. The assessment based on criteria related with a bidder's technical and economic capability can be made also at the prequalification stage in restricted tendering procedures. The authors suggest the application of an extended fuzzy AHP method to the process of group decision making. This approach facilitates defining criteria weights by aggregation of decision makers' judgments. The paper presents an example that illustrates this approach to determining criteria weights for bidder assessment. The results show that the proposed fuzzy AHP method is superior to the traditional AHP in terms of improved quality of criteria prioritization. © 2009 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-76549121003
"Li K., Hu C., Liu G., Xue W.","Building's electricity consumption prediction using optimized artificial neural networks and principal component analysis",2015,"Energy and Buildings",133,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942304105&doi=10.1016%2fj.enbuild.2015.09.002&partnerID=40&md5=839ae3af86c2ba143ee70bdb60a1f360","As a popular data driven method, artificial neural networks (ANNs) have been widely applied in building energy prediction field for decades. To improve the short term prediction accuracy, this paper presents a kind of optimized ANN model for hourly prediction of building electricity consumption. An improved Particle Swarm Optimization algorithm (iPSO) is applied to adjust ANN structure's weights and threshold values. The principal component analysis (PCA) is used to select the significant modeling inputs and simplify the model structure. The investigation utilizes two different historical data sets in hourly interval, which are collected from the Energy Prediction Shootout contest I and a campus building located in East China. For performance comparison, another two prediction models, ANN model and hybrid Genetic Algorithm-ANN (GA-ANN) model are also constructed in this study. The comparison results reveal that both iPSO-ANN and GA-ANN models have better accuracy than that of ANN ones. From the perspective of time consuming, the iPSO-ANN model has shorter modeling time than GA-ANN method. The proposed prediction model can be thought as an alternative technique for online prediction tasks of building electricity consumption. © 2015 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84942304105
"Plevris V., Papadrakakis M.","A Hybrid Particle Swarm-Gradient Algorithm for Global Structural Optimization",2011,"Computer-Aided Civil and Infrastructure Engineering",131,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650319923&doi=10.1111%2fj.1467-8667.2010.00664.x&partnerID=40&md5=83265e5a2ad972a54f7d49694c1a2aee","The particle swarm optimization (PSO) method is an instance of a successful application of the philosophy of bounded rationality and decentralized decision making for solving global optimization problems. A number of advantages with respect to other evolutionary algorithms are attributed to PSO making it a prospective candidate for optimum structural design. The PSO-based algorithm is robust and well suited to handle nonlinear, nonconvex design spaces with discontinuities, exhibiting fast convergence characteristics. Furthermore, hybrid algorithms can exploit the advantages of the PSO and gradient methods. This article presents in detail the basic concepts and implementation of an enhanced PSO algorithm combined with a gradient-based quasi-Newton sequential quadratic programming (SQP) method for handling structural optimization problems. The proposed PSO is shown to explore the design space thoroughly and to detect the neighborhood of the global optimum. Then the mathematical optimizer, starting from the best estimate of the PSO and using gradient information, accelerates convergence toward the global optimum. A nonlinear weight update rule for PSO and a simple, yet effective, constraint handling technique for structural optimization are also proposed. The performance, the functionality, and the effect of different setting parameters are studied. The effectiveness of the approach is illustrated in some benchmark structural optimization problems. The numerical results confirm the ability of the proposed methodology to find better optimal solutions for structural optimization problems than other optimization algorithms. © 2010 Computer-Aided Civil and Infrastructure Engineering.",Article,"Final",Scopus,2-s2.0-78650319923
"Han T., Jiang D., Zhao Q., Wang L., Yin K.","Comparison of random forest, artificial neural networks and support vector machine for intelligent diagnosis of rotating machinery",2018,"Transactions of the Institute of Measurement and Control",128,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028327277&doi=10.1177%2f0142331217708242&partnerID=40&md5=df0ab39fe6e2426f3482844e5cbda508","Nowadays, the data-driven diagnosis method, exploiting pattern recognition method to diagnose the fault patterns automatically, achieves much success for rotating machinery. Some popular classification algorithms such as artificial neural networks and support vector machine have been extensively studied and tested with many application cases, while the random forest, one of the present state-of-the-art classifiers based on ensemble learning strategy, is relatively unknown in this field. In this paper, the behavior of random forest for the intelligent diagnosis of rotating machinery is investigated with various features on two datasets. A framework for the comparison of different methods, that is, random forest, extreme learning machine, probabilistic neural network and support vector machine, is presented to find the most efficient one. Random forest has been proven to outperform the comparative classifiers in terms of recognition accuracy, stability and robustness to features, especially with a small training set. Additionally, compared with traditional methods, random forest is not easily influenced by environmental noise. Furthermore, the user-friendly parameters in random forest offer great convenience for practical engineering. These results suggest that random forest is a promising pattern recognition method for the intelligent diagnosis of rotating machinery. © 2018, © The Author(s) 2018.",Article,"Final",Scopus,2-s2.0-85028327277
"Wang J., Wu P., Wang X., Shou W.","The outlook of blockchain technology for construction engineering management",2017,"Frontiers of Engineering Management",128,,[No abstract available],,"Final",Scopus,2-s2.0-85042708142
"Fang W., Ding L., Zhong B., Love P.E.D., Luo H.","Automated detection of workers and heavy equipment on construction sites: A convolutional neural network approach",2018,"Advanced Engineering Informatics",127,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046851154&doi=10.1016%2fj.aei.2018.05.003&partnerID=40&md5=ce14178a74f67be6d345628cf64fc519","Detecting the presence of workers, plant, equipment, and materials (i.e. objects) on sites to improve safety and productivity has formed an integral part of computer vision-based research in construction. Such research has tended to focus on the use of computer vision and pattern recognition approaches that are overly reliant on the manual extraction of features and small datasets (<10k images/label), which can limit inter and intra-class variability. As a result, this hinders their ability to accurately detect objects on construction sites and generalization to different datasets. To address this limitation, an Improved Faster Regions with Convolutional Neural Network Features (IFaster R-CNN) approach is used to automatically detect the presence of objects in real-time is developed, which comprises: (1) the establishment dataset of workers and heavy equipment to train the CNN; (2) extraction of feature maps from images using deep model; (3) extraction of a region proposal from feature maps; and (4) object recognition. To validate the model's ability to detect objects in real-time, a specific dataset is established to train the IFaster R-CNN models to detect workers and plant (e.g. excavator). The results reveal that the IFaster R-CNN is able to detect the presence of workers and excavators at a high level of accuracy (91% and 95%). The accuracy of the proposed deep learning method exceeds that of current state-of-the-art descriptor methods in detecting target objects on images. © 2018 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85046851154
"Hyun K.-C., Min S., Choi H., Park J., Lee I.-M.","Risk analysis using fault-tree analysis (FTA) and analytic hierarchy process (AHP) applicable to shield TBM tunnels",2015,"Tunnelling and Underground Space Technology",127,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928335392&doi=10.1016%2fj.tust.2015.04.007&partnerID=40&md5=214f1c314ce4b68dd9f64267bcce31cf","In this paper, the potential risk of undesirable events occurring during tunneling with application of a shield tunnel boring machine (TBM) method is discussed along with the risk analysis which can systematically assess overall risk levels. Potential risks and typical scenarios pertaining to shield TBM tunnels have been investigated based on previous case histories and correspondence with experts. The relevant risks from undesirable events were categorized into four groups: cutter-related malfunction, machine blockage or hold-up, mucking problems that hinder transporting excavated materials, and segment defects. A fault-tree set was constructed by grouping risk factors (or causes) into geological, design and construction/management factors. Risk analysis was performed by adopting fault-tree analysis (FTA) and an analytic hierarchy process (AHP) with consideration of the probability and impact of the risks. In addition, the proposed method was reliably validated by comparison with field observation, and thus indicates its applicability to risk management for shield TBM tunneling. © 2015 Elsevier Ltd.",Article,"Final",Scopus,2-s2.0-84928335392
"Beskese A., Demir H.H., Ozcan H.K., Okten H.E.","Landfill site selection using fuzzy AHP and fuzzy TOPSIS: a case study for Istanbul",2015,"Environmental Earth Sciences",126,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027919839&doi=10.1007%2fs12665-014-3635-5&partnerID=40&md5=afd8616124a14b826bb0ed9b536761b9","Landfill site selection is a multi-attribute decision problem, through which factors like available land area, soil conditions, climatological conditions, and economic considerations are investigated in detail. Frequently, it is a challenge to come up with “the one” solution while tackling such complex systems. Therefore, use of tools such as fuzzy analytic hierarchy process (fuzzy AHP) and fuzzy technique for order preference by similarity to ideal solution (fuzzy TOPSIS) should be preferred in order to emphasize pros and cons for each of the studied options. In this study, three possible landfill sites for the city of Istanbul are evaluated through expert opinion and by facilitating fuzzy AHP and fuzzy TOPSIS. Initially, the landfill site selection problem is presented in the framework of a model and then the model is mathematically solved by calculating the individual criterion weights. In conclusion, considering the rapid rate of urbanization for the city of Istanbul, the possible landfill sites convey similar overall results, but differ in specific criteria. © 2014, Springer-Verlag Berlin Heidelberg.",Article,"Final",Scopus,2-s2.0-85027919839
"Giang D.T.H., Sui Pheng L.","Role of construction in economic development: Review of key concepts in the past 40 years",2011,"Habitat International",124,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956913966&doi=10.1016%2fj.habitatint.2010.06.003&partnerID=40&md5=da61f4225db587a78cd495498c6d6d7f","This paper reviews the studies completed in the past four decades which examined the role of the construction industry in economic development. Findings from these studies demonstrated the significant relationship between the construction industry and economic growth in developing countries. These findings also suggested that the relationship appears to be more complicated than originally thought. It was noted that further expansion of the construction industry beyond the adaptive capacity of the economy will only waste national resources. Little is known about the impact that the adaptive capacities of other sectors in the economy have on the construction sector. This knowledge gap requires further study in order to formulate a more effective long-term strategy for construction industry development. © 2010 Elsevier Ltd.",Article,"Final",Scopus,2-s2.0-77956913966
"Touzani S., Granderson J., Fernandes S.","Gradient boosting machine for modeling the energy consumption of commercial buildings",2018,"Energy and Buildings",122,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035809552&doi=10.1016%2fj.enbuild.2017.11.039&partnerID=40&md5=c9ad21eddd8866ae1de1e20ba74e9a14","Accurate savings estimations are important to promote energy efficiency projects and demonstrate their cost-effectiveness. The increasing presence of advanced metering infrastructure (AMI) in commercial buildings has resulted in a rising availability of high frequency interval data. These data can be used for a variety of energy efficiency applications such as demand response, fault detection and diagnosis, and heating, ventilation, and air conditioning (HVAC) optimization. This large amount of data has also opened the door to the use of advanced statistical learning models, which hold promise for providing accurate building baseline energy consumption predictions, and thus accurate saving estimations. The gradient boosting machine is a powerful machine learning algorithm that is gaining considerable traction in a wide range of data driven applications, such as ecology, computer vision, and biology. In the present work an energy consumption baseline modeling method based on a gradient boosting machine was proposed. To assess the performance of this method, a recently published testing procedure was used on a large dataset of 410 commercial buildings. The model training periods were varied and several prediction accuracy metrics were used to evaluate the model's performance. The results show that using the gradient boosting machine model improved the R‐squared prediction accuracy and the CV(RMSE) in more than 80 percent of the cases, when compared to an industry best practice model that is based on piecewise linear regression, and to a random forest algorithm. © 2017 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85035809552
"Cheng J.C.P., Wang M.","Automated detection of sewer pipe defects in closed-circuit television images using deep learning techniques",2018,"Automation in Construction",115,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052238112&doi=10.1016%2fj.autcon.2018.08.006&partnerID=40&md5=78cf325ecf330f5d8a5fda832589c477","Sanitary sewer systems are designed to collect and transport sanitary wastewater and stormwater. Pipe inspection is important in identifying both the type and location of pipe defects to maintain the normal sewer operations. Closed-circuit television (CCTV) has been commonly utilized for sewer pipe inspection. Currently, interpretation of the CCTV images is mostly conducted manually to identify the defect type and location, which is time-consuming, labor-intensive and inaccurate. Conventional computer vision techniques are explored for automated interpretation of CCTV images, but such process requires large amount of image pre-processing and the design of complex feature extractor for certain cases. In this study, an automated approach is developed for detecting sewer pipe defects based on a deep learning technique namely faster region-based convolutional neural network (faster R-CNN). The detection model is trained using 3000 images collected from CCTV inspection videos of sewer pipes. After training, the model is evaluated in terms of detection accuracy and computation cost using mean average precision (mAP), missing rate, detection speed and training time. The proposed approach is demonstrated to be applicable for detecting sewer pipe defects accurately with high accuracy and fast speed. In addition, a new model is constructed and several hyper-parameters are adjusted to study the influential factors of the proposed approach. The experiment results demonstrate that dataset size, initialization network type and training mode, and network hyper-parameters have influence on model performance. Specifically, the increase of dataset size and convolutional layers can improve the model accuracy. The adjustment of hyper-parameters such as filter dimensions or stride values contributes to higher detection accuracy, achieving an mAP of 83%. The study lays the foundation for applying deep learning techniques in sewer pipe defect detection as well as addressing similar issues for construction and facility management. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85052238112
"Atha D.J., Jahanshahi M.R.","Evaluation of deep learning approaches based on convolutional neural networks for corrosion detection",2018,"Structural Health Monitoring",115,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042103996&doi=10.1177%2f1475921717737051&partnerID=40&md5=caeeaddfff2ec2e0de82a2c51df9ac23","Corrosion is a major defect in structural systems that has a significant economic impact and can pose safety risks if left untended. Currently, an inspector visually assesses the condition of a structure to identify corrosion. This approach is time-consuming, tedious, and subjective. Robotic systems, such as unmanned aerial vehicles, paired with computer vision algorithms have the potential to perform autonomous damage detection that can significantly decrease inspection time and lead to more frequent and objective inspections. This study evaluates the use of convolutional neural networks for corrosion detection. A convolutional neural network learns the appropriate classification features that in traditional algorithms were hand-engineered. Eliminating the need for dependence on prior knowledge and human effort in designing features is a major advantage of convolutional neural networks. This article presents different convolutional neural network–based approaches for corrosion assessment on metallic surfaces. The effect of different color spaces, sliding window sizes, and convolutional neural network architectures are discussed. To this end, the performance of two pretrained state-of-the-art convolutional neural network architectures as well as two proposed convolutional neural network architectures are evaluated, and it is shown that convolutional neural networks outperform state-of-the-art vision-based corrosion detection approaches that are developed based on texture and color analysis using a simple multilayered perceptron network. Furthermore, it is shown that one of the proposed convolutional neural networks significantly improves the computational time in contrast with state-of-the-art pretrained convolutional neural networks while maintaining comparable performance for corrosion detection. © The Author(s) 2017.",Article,"Final",Scopus,2-s2.0-85042103996
"Zhang J., El-Gohary N.M.","Semantic NLP-Based Information Extraction from Construction Regulatory Documents for Automated Compliance Checking",2016,"Journal of Computing in Civil Engineering",115,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958959817&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000346&partnerID=40&md5=9061db0911d0d667e239613f7924413a","Automated regulatory compliance checking requires automated extraction of requirements from regulatory textual documents and their formalization in a computer-processable rule representation. Such information extraction (IE) is a challenging task that requires complex analysis and processing of text. Natural language processing (NLP) aims to enable computers to process natural language text in a human-like manner. This paper proposes a semantic, rule-based NLP approach for automated IE from construction regulatory documents. The proposed approach uses a set of pattern-matching-based IE rules and conflict resolution (CR) rules in IE. A variety of syntactic (syntax/grammar-related) and semantic (meaning/context-related) text features are used in the patterns of the IE and CR rules. Phrase structure grammar (PSG)-based phrasal tags and separation and sequencing of semantic information elements are proposed and used to reduce the number of needed patterns. An ontology is used to aid in the recognition of semantic text features (concepts and relations). The proposed IE algorithms were tested in extracting quantitative requirements from the 2009 International Building Code and achieved 0.969 and 0.944 precision and recall, respectively. © 2015 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84958959817
"Nhat-Duc H., Nguyen Q.-L., Tran V.-D.","Automatic recognition of asphalt pavement cracks using metaheuristic optimized edge detection algorithms and convolution neural network",2018,"Automation in Construction",114,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049789229&doi=10.1016%2fj.autcon.2018.07.008&partnerID=40&md5=e62326080c6a170efffa955599c0b41a","Crack detection is a crucial task in periodic pavement survey. This study establishes and compares the performance of two intelligent approaches for automatic recognition of pavement cracks. The first model relies on edge detection approaches of the Sobel and Canny algorithms. Since the implementation of the two edge detectors require the setting of threshold values, Differential Flower Pollination, as a metaheuristic, is employed to fine-tune the model parameters. The second model is constructed by the implementation of the Convolution Neural Network (CNN) – a deep learning algorithm. CNN has the advantage of performing the feature extraction and the prediction of crack/non-crack condition in an integrated and fully automated manner. Experimental results show that the model based on CNN achieves a good prediction performance of Classification Accuracy Rate (CAR) = 92.08%. This performance is significantly better than the method based on the edge detection algorithms (CAR = 79.99%). Accordingly, the proposed CNN based crack detection model is a promising alternative to support transportation agencies in the task of periodic pavement inspection. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85049789229
"Tixier A.J.-P., Hallowell M.R., Rajagopalan B., Bowman D.","Automated content analysis for construction safety: A natural language processing system to extract precursors and outcomes from unstructured injury reports",2016,"Automation in Construction",114,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947474989&doi=10.1016%2fj.autcon.2015.11.001&partnerID=40&md5=dc713c7d91d9d682ed44629334410191","In the United States like in many other countries throughout the globe, construction workers are more likely to be injured on the job than workers in any other industry. This poor safety performance is responsible for huge human and financial losses and has motivated extensive research. Unfortunately, safety improvement in construction has decelerated in the last decade and traditional safety programs have reached saturation. Yet major construction companies and federal agencies possess a wealth of empirical knowledge in the form of huge databases of digital construction injury reports. This knowledge could be used to better understand, predict, and prevent the occurrence of construction accidents. Unfortunately, due to the lack of a clear methodology and the high costs of manual large-scale content analysis, these valuable data have yet to be extracted and leveraged. Recently, researchers have proposed a framework allowing meaningful empirical data to be extracted from accident reports. However, the resource limitations inherent to manual content analysis still remain. The present study tested the proposition that manual content analysis of injury reports can be eliminated using natural language processing (NLP). This paper describes (1) the overall strategy and methodology used in developing the system, and specifically how key challenges with decoding unstructured reports were overcome; (2) how the system was built through an iterative process of coding and testing against manual content analysis results from a team of seven independent analysts; and (3) the implications and potential uses of the data extracted. The results indicate that the NLP system is capable of quickly and automatically scanning unstructured injury reports for 101 attributes and outcomes with over 95% accuracy. The main contribution of this research is to empower any organization to quickly obtain a large and highly reliable structured attribute and outcome data set from their databases of unstructured accident reports. Such structured data are a necessary prerequisite to the application of statistical modeling techniques, allowing the extraction of new safety knowledge and finally the amelioration of safety management. © 2015 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84947474989
"Boje C., Guerriero A., Kubicki S., Rezgui Y.","Towards a semantic Construction Digital Twin: Directions for future research",2020,"Automation in Construction",113,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082386834&doi=10.1016%2fj.autcon.2020.103179&partnerID=40&md5=914efcd6c064d6a97299f00d812bb8fc","As the Architecture, Engineering and Construction sector is embracing the digital age, the processes involved in the design, construction and operation of built assets are more and more influenced by technologies dealing with value-added monitoring of data from sensor networks, management of this data in secure and resilient storage systems underpinned by semantic models, as well as the simulation and optimisation of engineering systems. Aside from enhancing the efficiency of the value chain, such information-intensive models and associated technologies play a decisive role in minimising the lifecycle impacts of our buildings. While Building Information Modelling provides procedures, technologies and data schemas enabling a standardised semantic representation of building components and systems, the concept of a Digital Twin conveys a more holistic socio-technical and process-oriented characterisation of the complex artefacts involved by leveraging the synchronicity of the cyber-physical bi-directional data flows. Moreover, BIM lacks semantic completeness in areas such as control systems, including sensor networks, social systems, and urban artefacts beyond the scope of buildings, thus requiring a holistic, scalable semantic approach that factors in dynamic data at different levels. The paper reviews the multi-faceted applications of BIM during the construction stage and highlights limits and requirements, paving the way to the concept of a Construction Digital Twin. A definition of such a concept is then given, described in terms of underpinning research themes, while elaborating on areas for future research. © 2020 The Authors",Review,"Final",Scopus,2-s2.0-85082386834
"Kumar S.S., Cheng J.C.P.","A BIM-based automated site layout planning framework for congested construction sites",2015,"Automation in Construction",113,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941342239&doi=10.1016%2fj.autcon.2015.07.008&partnerID=40&md5=6c225300cd237a608b9890af3d49c737","Site layout planning is often performed on construction sites to find the best arrangement of temporary facilities so that transportation distances of on-site personnel and equipment are minimized. It could be achieved by creating dynamic layout models, which capture the changing requirements of construction sites. However, formulating such models is extremely tedious because it requires much manual data input and changes to design and construction plans are manually updated by layout planners. This study presents an automated framework of creating dynamic site layout models by utilizing information from BIM. The A∗algorithm is used in conjunction with genetic algorithms to develop an optimization framework that considers the actual travel paths of on-site personnel and equipment. To address the space limitation on site, our model optimizes the dimensions of facilities and also considers interior storage within buildings under construction. A case example is demonstrated to validate this framework and shows a 13.5% reduction in total travel distance compared with conventional methods. © 2015 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84941342239
"Araya D.B., Grolinger K., ElYamany H.F., Capretz M.A.M., Bitsuamlak G.","An ensemble learning framework for anomaly detection in building energy consumption",2017,"Energy and Buildings",112,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017182336&doi=10.1016%2fj.enbuild.2017.02.058&partnerID=40&md5=e942cca7578da615b7abc9715dc6bb54","During building operation, a significant amount of energy is wasted due to equipment and human-related faults. To reduce waste, today's smart buildings monitor energy usage with the aim of identifying abnormal consumption behaviour and notifying the building manager to implement appropriate energy-saving procedures. To this end, this research proposes a new pattern-based anomaly classifier, the collective contextual anomaly detection using sliding window (CCAD-SW) framework. The CCAD-SW framework identifies anomalous consumption patterns using overlapping sliding windows. To enhance the anomaly detection capacity of the CCAD-SW, this research also proposes the ensemble anomaly detection (EAD) framework. The EAD is a generic framework that combines several anomaly detection classifiers using majority voting. To ensure diversity of anomaly classifiers, the EAD is implemented by combining pattern-based (e.g., CCAD-SW) and prediction-based anomaly classifiers. The research was evaluated using real-world data provided by Powersmiths, located in Brampton, Ontario, Canada. Results show that the EAD framework improved the sensitivity of the CCAD-SW by 3.6% and reduced false alarm rate by 2.7%. © 2017 The Author(s)",Article,"Final",Scopus,2-s2.0-85017182336
"Camp C.V., Farshchin M.","Design of space trusses using modified teaching-learning based optimization",2014,"Engineering Structures",112,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893775759&doi=10.1016%2fj.engstruct.2014.01.020&partnerID=40&md5=4a2992c3ca6aaee0a85d907cb3ad18c9","A modified teaching-learning-based optimization (TLBO) algorithm is applied to fixed geometry space trusses with discrete and continuous design variables. Designs generated by the modified TLBO algorithm are compared with other popular evolutionary optimization methods. In all cases, the objective function is the total weight of the structure subjected to strength and displacement limitations. Designs are evaluated for fitness based on their penalized structural weight, which represents the actual truss weight and the degree to which the design constraints are violated. TLBO is conceptually modeled on the two types of pedagogy within a classroom: class-level learning from a teacher and individual learning between students. TLBO uses a relatively simple algorithm with no intrinsic parameters controlling its performance and can easily handle a mixture of both continuous and discrete design variables. Without introducing any additional algorithmic parameters, the modified TLBO algorithm uses a fitness-based weighted mean in the teaching phase and a refined student updating process. The computational performance of TLBO designs for several benchmark space truss structures is presented and compared with classical and evolutionary optimization methods. Optimization results indicate that the modified TLBO algorithm can generate improved designs when compared to other population-based techniques and in some cases improve the overall computational efficiency. © 2014 Elsevier Ltd.",Article,"Final",Scopus,2-s2.0-84893775759
"Li J., Zou P.X.W.","Fuzzy AHP-based risk assessment methodology for PPP projects",2011,"Journal of Construction Engineering and Management",107,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862909304&doi=10.1061%2f%28ASCE%29CO.1943-7862.0000362&partnerID=40&md5=35af4adf0c80feb5d8260e7f2734cfbb","Public Private Partnerships (PPPs) have been used globally as a method to procure infrastructure projects, such as expressways, bridges, water plants, and power plants. The risks involved in such PPP projects are unique because of the large amount of investment and long contractual concession period. This paper proposed a fuzzy analytical hierarchy process (AHP) as risk assessment technique to simulate the vagueness of human judgement and to improve the assessment accuracy. Furthermore, a comparison was made between the proposed fuzzy AHP and straight-AHP in this paper. The fuzzy AHP process was illustrated by using an actual PPP expressway project from China. The results showed that planning deficiency, low project residual value (after 30years of operation), lack of qualified bidders, design deficiency, and long project approval time were assessed as the top five risks for the project, and the feedback from the experts showed that these results reflected the actual project risk situation. © 2011 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84862909304
"Che J., Wang J.","Short-term load forecasting using a kernel-based support vector regression combination model",2014,"Applied Energy",104,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920195266&doi=10.1016%2fj.apenergy.2014.07.064&partnerID=40&md5=7b988ca01c066c4d8e6ebca57b6a62bb","Kernel-based methods, such as support vector regression (SVR), have demonstrated satisfactory performance in short-term load forecasting (STLF) application. However, the good performance of kernel-based method depends on the selection of an appropriate kernel function that fits the learning target, unsuitable kernel function or hyper-parameters setting may lead to significantly poor performance. To get the optimal kernel function of STLF problem, this paper proposes a kernel-based SVR combination model by using a novel individual model selection algorithm. Moreover, the proposed combination model provides a new way to kernel function selection of SVR model. The performance and electric load forecast accuracy of the proposed model are assessed by means of real data from the Australia and California Power Grid, respectively. The simulation results from numerical tables and figures show that the proposed combination model increases electric load forecasting accuracy compared to the best individual kernel-based SVR model. © 2014 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-84920195266
"Sacks R., Rozenfeld O., Rosenfeld Y.","Spatial and temporal exposure to safety hazards in construction",2009,"Journal of Construction Engineering and Management",104,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-67651222422&doi=10.1061%2f%28ASCE%290733-9364%282009%29135%3a8%28726%29&partnerID=40&md5=887de22e4569dad220a7236d7167176a","Given the dynamic nature of construction sites, analysis of construction activities and their related hazards is inadequate for reliable risk assessment if it does not explicitly account for the likelihood of exposure of potential victims to hazardous situations. In traditional risk level calculations for manufacturing industries, the number of victims is factored with the likelihood of an accident and the potential severity, but the victims are simply assumed to be those typically present at the accident location. In construction, exposure cannot be accounted for at a generic metaproject level: it must be assessed at the level of the activities and the physical context in which they are performed. Conceptually, accidents are ""loss-of-control events"" to which victims are exposed; without exposure, no accident is assumed to occur. A set of algorithms has been developed to demonstrate estimation of the likelihood of exposure of construction workers to loss-of-control events. The algorithms have been implemented in a prototype software application designed to predict fluctuating risk levels in construction projects. The software implements the ""construction hazard assessment with spatial and temporal exposure"" model for managing safety in construction, which empowers planners at all levels to adjust construction plans to mitigate high levels of risk or to undertake appropriate proactive measures to ensure safety when high risk levels are unavoidable. © 2009 ASCE.",Article,"Final",Scopus,2-s2.0-67651222422
"Zhang L., Wu X., Qin Y., Skibniewski M.J., Liu W.","Towards a Fuzzy Bayesian Network Based Approach for Safety Risk Analysis of Tunnel-Induced Pipeline Damage",2016,"Risk Analysis",103,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959124367&doi=10.1111%2frisa.12448&partnerID=40&md5=55924b76288c1e3a35f90c28abbad4ba","Tunneling excavation is bound to produce significant disturbances to surrounding environments, and the tunnel-induced damage to adjacent underground buried pipelines is of considerable importance for geotechnical practice. A fuzzy Bayesian networks (FBNs) based approach for safety risk analysis is developed in this article with detailed step-by-step procedures, consisting of risk mechanism analysis, the FBN model establishment, fuzzification, FBN-based inference, defuzzification, and decision making. In accordance with the failure mechanism analysis, a tunnel-induced pipeline damage model is proposed to reveal the cause-effect relationships between the pipeline damage and its influential variables. In terms of the fuzzification process, an expert confidence indicator is proposed to reveal the reliability of the data when determining the fuzzy probability of occurrence of basic events, with both the judgment ability level and the subjectivity reliability level taken into account. By means of the fuzzy Bayesian inference, the approach proposed in this article is capable of calculating the probability distribution of potential safety risks and identifying the most likely potential causes of accidents under both prior knowledge and given evidence circumstances. A case concerning the safety analysis of underground buried pipelines adjacent to the construction of the Wuhan Yangtze River Tunnel is presented. The results demonstrate the feasibility of the proposed FBN approach and its application potential. The proposed approach can be used as a decision tool to provide support for safety assurance and management in tunnel construction, and thus increase the likelihood of a successful project in a complex project environment. © 2016 Society for Risk Analysis.",Article,"Final",Scopus,2-s2.0-84959124367
"Wu X., Liu H., Zhang L., Skibniewski M.J., Deng Q., Teng J.","A dynamic Bayesian network based approach to safety decision support in tunnel construction",2015,"Reliability Engineering and System Safety",102,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910134100&doi=10.1016%2fj.ress.2014.10.021&partnerID=40&md5=2cbd1348efb86a3576c602d861318251","This paper presents a systemic decision approach with step-by-step procedures based on dynamic Bayesian network (DBN), aiming to provide guidelines for dynamic safety analysis of the tunnel-induced road surface damage over time. The proposed DBN-based approach can accurately illustrate the dynamic and updated feature of geological, design and mechanical variables as the construction progress evolves, in order to overcome deficiencies of traditional fault analysis methods. Adopting the predictive, sensitivity and diagnostic analysis techniques in the DBN inference, this approach is able to perform feed-forward, concurrent and back-forward control respectively on a quantitative basis, and provide real-time support before and after an accident. A case study in relating to dynamic safety analysis in the construction of Wuhan Yangtze Metro Tunnel in China is used to verify the feasibility of the proposed approach, as well as its application potential. The relationships between the DBN-based and BN-based approaches are further discussed according to analysis results. The proposed approach can be used as a decision tool to provide support for safety analysis in tunnel construction, and thus increase the likelihood of a successful project in a dynamic project environment. © 2014 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84910134100
"Zhang F., Fleyeh H., Wang X., Lu M.","Construction site accident analysis using text mining and natural language processing techniques",2019,"Automation in Construction",101,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058940383&doi=10.1016%2fj.autcon.2018.12.016&partnerID=40&md5=6c89d863b6d7c565d8758ea5f2734665","Workplace safety is a major concern in many countries. Among various industries, construction sector is identified as the most hazardous work place. Construction accidents not only cause human sufferings but also result in huge financial loss. To prevent reoccurrence of similar accidents in the future and make scientific risk control plans, analysis of accidents is essential. In construction industry, fatality and catastrophe investigation summary reports are available for the past accidents. In this study, text mining and natural language process (NLP) techniques are applied to analyze the construction accident reports. To be more specific, five baseline models, support vector machine (SVM), linear regression (LR), K-nearest neighbor (KNN), decision tree (DT), Naive Bayes (NB) and an ensemble model are proposed to classify the causes of the accidents. Besides, Sequential Quadratic Programming (SQP) algorithm is utilized to optimize weight of each classifier involved in the ensemble model. Experiment results show that the optimized ensemble model outperforms rest models considered in this study in terms of average weighted F1 score. The result also shows that the proposed approach is more robust to cases of low support. Moreover, an unsupervised chunking approach is proposed to extract common objects which cause the accidents based on grammar rules identified in the reports. As harmful objects are one of the major factors leading to construction accidents, identifying such objects is extremely helpful to mitigate potential risks. Certain limitations of the proposed methods are discussed and suggestions and future improvements are provided. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85058940383
"Shabbir F., Omenzetter P.","Particle swarm optimization with sequential niche technique for dynamic finite element model updating",2015,"Computer-Aided Civil and Infrastructure Engineering",101,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926486341&doi=10.1111%2fmice.12100&partnerID=40&md5=aafcc7fc78f69956d3be6488a755a223","Due to uncertainties associated with material properties, structural geometry, boundary conditions, and connectivity of structural parts as well as inherent simplifying assumptions in the development of finite element (FE) models, actual behavior of structures often differs from model predictions. FE model updating comprises a multitude of techniques that systematically calibrate FE models in order to match experimental results. Updating of structural models can be posed as an optimization problem where model parameters that minimize the errors between the responses of the model and actual structure are sought. However, due to limited number of experimental responses and measurement errors, the optimization problem may have multiple admissible solutions in the search domain. Global optimization algorithms (GOAs) are useful and efficient tools in such situations as they try to find the globally optimal solution out of many possible local minima, but are not totally immune to missing the right minimum in complex problems such as those encountered in updating. A methodology based on particle swarm optimization (PSO), a GOA, with sequential niche technique (SNT) for FE model updating is proposed and explored in this article. The combination of PSO and SNT enables a systematic search for multiple minima and considerably increases the confidence in finding the global minimum. The method is applied to FE model updating of a pedestrian cable-stayed bridge using modal data from full-scale dynamic testing. © 2014 Computer-Aided Civil and Infrastructure Engineering.",Article,"Final",Scopus,2-s2.0-84926486341
"Jetcheva J.G., Majidpour M., Chen W.-P.","Neural network model ensembles for building-level electricity load forecasts",2014,"Energy and Buildings",100,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907570987&doi=10.1016%2fj.enbuild.2014.08.004&partnerID=40&md5=c2989522d991250e8c6db4734660b3e6","The future power grid is expected to provide unprecedented flexibility in how energy is generated, distributed, and managed, which increasingly necessitates an ability to perform accurate short-term small-scale electricity load and generation forecasting, e.g., at the level of individual buildings or sites. In this paper, we present a novel building-level neural network-based ensemble model for day-ahead electricity load forecasting and show that it outperforms the previously established best performing model, SARIMA, by up to 50%, in the context of load data from half a dozen operational commercial and industrial sites. In addition, we show a straightforward, automated way to select model parameters, making our model practical for use in real deployments. © 2014 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84907570987
"Mena R., Rodríguez F., Castilla M., Arahal M.R.","A prediction model based on neural networks for the energy consumption of a bioclimatic building",2014,"Energy and Buildings",98,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905395972&doi=10.1016%2fj.enbuild.2014.06.052&partnerID=40&md5=485ce1cfd25258ad0e7dcb4405825ff0","Energy in buildings is a topic that is being widely studied due to its high impact on global energy demand. This problem involves the performance of an adequate management of the energy demand, combining both convectional and renewable sources. To this end, the use of control strategies is an important tool. These control strategies can take advantage of knowledge of variables that act as disturbances in the closed loop scheme. Thus, it is of great importance the development of predictions of such variables. The main objective of this paper is to develop and assess a short-term predictive neural network model of the electricity demand for the CIESOL bioclimatic building, located in the southeast of Spain. The performed experiments show a quick prediction with acceptable final results for real data with a short-term prediction horizon equal to 60 min and with a mean error of 11.48%. One-step ahead predictions and dynamic modeling simulations have also been evaluated. © 2014 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84905395972
"Zhou J., Sh X., Du K., Qiu X., Li X., Mitri H.S.","Feasibility of random-forest approach for prediction of ground settlements induced by the construction of a shield-driven tunnel",2017,"International Journal of Geomechanics",96,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017509463&doi=10.1061%2f%28ASCE%29GM.1943-5622.0000817&partnerID=40&md5=56ee10415bc6592f789f66723c697a5f","Ground settlements above a tunnel as a result of tunnel construction can be predicted with the help of input variables that have direct physical significance. Several empirical and artificial intelligence methods for estimating ground settlements have been established by researchers. However, these methods have some limitations because the large number of influential factors involved makes tunnel-ground interaction complicated. In this work, a random forest (RF) was developed and employed to predict ground settlements above tunnels. To achieve this goal, tunnel geometry, geological properties, and construction parameters were investigated as input variables to utilize in the RF modeling, resulting in the maximum surface settlement value (Smax) and trough width (i) as the ground surface settlement index. To demonstrate the applicability of the RF model, two data sets associated with different features, which were obtained from a detailed investigation of different tunnel projects published in literature, were utilized for model development and were applied to check the performance capacity of the developed model. A fivefold cross-validation procedure was then applied to identify the optimal parameter values during modeling, and an external testing set was employed to validate the prediction performance of the model. Two performance measures, R2 and RMS error, were employed. The relative importance of different parameters in the prediction of ground settlements was also investigated. Findings demonstrate that the RF method provides promising results and offers an alternative means in predicting ground settlements induced by tunneling. © 2016 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85017509463
"Guo H.Y., Li Z.L.","A two-stage method to identify structural damage sites and extents by using evidence theory and micro-search genetic algorithm",2009,"Mechanical Systems and Signal Processing",96,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049164201&doi=10.1016%2fj.ymssp.2008.07.008&partnerID=40&md5=293dd6bfed532aebf026fab1de35ea36","A two-stage method of determining the location and extent of multiple structural damages by using information fusion technique and genetic algorithm is presented in this paper. First the damage detection strategy is to localize the damage sites by using an evidence theory, which can perfectly integrate the damage identification information coming from both natural frequencies and mode shapes. Then, a micro-search genetic algorithm (MSGA) is proposed to determine the damage extent. A cantilever beam is analyzed as a numerical example to compare the performance of the proposed method with the multiple damage location assurance criterions (MDLAC) and the simple genetic algorithms. Simulation results show that identification results of the evidence theory are better than those both of the frequency MDLAC method and the mode shape MDLAC method, and the MSGA is also more accurate and effective than the simple genetic algorithms. Therefore, the two-stage method is very effective for the identification of multiple structural damages. © 2008 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-58049164201
"Zhong H., Wang J., Jia H., Mu Y., Lv S.","Vector field-based support vector regression for building energy consumption prediction",2019,"Applied Energy",94,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062893415&doi=10.1016%2fj.apenergy.2019.03.078&partnerID=40&md5=f9f83b58a6c0a8b74b071ddf8eb6c256","Building energy consumption prediction plays an irreplaceable role in energy planning, management, and conservation. Data-driven approaches, such as artificial neural networks, support vector regression, gradient boosting regression and extreme learning machine are the most advanced methods for building energy prediction. However, owing to the high nonlinearity between inputs and outputs of building energy consumption prediction models, the aforementioned approaches require improvement with regard to the prediction accuracy, robustness, and generalization ability. To counter these shortcomings, a novel vector field-based support vector regression method is proposed in this paper. Through multi-distortions in the sample data space or high-dimensional feature space mapped by a vector field, the optimal feature space is found, in which the high nonlinearity between inputs and outputs is approximated by linearity. Hence, the proposed method ensures a high accuracy, a generalization ability, and robustness for building energy consumption prediction. A large office building in a coastal town of China is used for a case study, and its summer hourly cooling load data are used as energy consumption data. The results indicate that the proposed method achieves better performance than commonly used methods with regard to the accuracy, robustness, and generalization ability. © 2019",Article,"Final",Scopus,2-s2.0-85062893415
"Wang Q., Kim M.-K.","Applications of 3D point cloud data in the construction industry: A fifteen-year review from 2004 to 2018",2019,"Advanced Engineering Informatics",93,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061601993&doi=10.1016%2fj.aei.2019.02.007&partnerID=40&md5=704db179024538db1a97691d817e3990","3D point cloud data obtained from laser scans, images, and videos are able to provide accurate and fast records of the 3D geometries of construction-related objects. Thus, the construction industry has been using point cloud data for a variety of purposes including 3D model reconstruction, geometry quality inspection, construction progress tracking, etc. Although a number of studies have been reported on applying point cloud data for the construction industry in the recent decades, there has not been any systematic review that summaries these applications and points out the research gaps and future research directions. This paper, therefore, aims to provide a thorough review on the applications of 3D point cloud data in the construction industry and to provide recommendations on future research directions in this area. A total of 197 research papers were collected in this study through a two-fold literature search, which were published within a fifteen-year period from 2004 to 2018. Based on the collected papers, applications of 3D point cloud data in the construction industry are reviewed according to three categories including (1) 3D model reconstruction, (2) geometry quality inspection, and (3) other applications. Following the literature review, this paper discusses on the acquisition and processing of point cloud data, particularly focusing on how to properly perform data acquisition and processing to fulfill the needs of the intended construction applications. Specifically, the determination of required point cloud data quality and the determination of data acquisition parameters are discussed with regard to data acquisition, and the extraction and utilization of semantic information and the platforms for data visualization and processing are discussed with regard to data processing. Based on the review of applications and the following discussions, research gaps and future research directions are recommended including (1) application-oriented data acquisition, (2) semantic enrichment for as-is BIM, (3) geometry quality inspection in fabrication phase, and (4) real-time visualization and processing. © 2019 Elsevier Ltd",Review,"Final",Scopus,2-s2.0-85061601993
"Leu S.-S., Chang C.-M.","Bayesian-network-based safety risk assessment for steel construction projects",2013,"Accident Analysis and Prevention",93,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879298110&doi=10.1016%2fj.aap.2013.02.019&partnerID=40&md5=7e7e5f2b235ed1c4bd456db68bb98269","There are four primary accident types at steel building construction (SC) projects: falls (tumbles), object falls, object collapse, and electrocution. Several systematic safety risk assessment approaches, such as fault tree analysis (FTA) and failure mode and effect criticality analysis (FMECA), have been used to evaluate safety risks at SC projects. However, these traditional methods ineffectively address dependencies among safety factors at various levels that fail to provide early warnings to prevent occupational accidents. To overcome the limitations of traditional approaches, this study addresses the development of a safety risk-assessment model for SC projects by establishing the Bayesian networks (BN) based on fault tree (FT) transformation. The BN-based safety risk-assessment model was validated against the safety inspection records of six SC building projects and nine projects in which site accidents occurred. The ranks of posterior probabilities from the BN model were highly consistent with the accidents that occurred at each project site. The model accurately provides site safety-management abilities by calculating the probabilities of safety risks and further analyzing the causes of accidents based on their relationships in BNs. In practice, based on the analysis of accident risks and significant safety factors, proper preventive safety management strategies can be established to reduce the occurrence of accidents on SC sites. © 2013 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84879298110
"Kaveh A., Sheikholeslami R., Talatahari S., Keshvari-Ilkhichi M.","Chaotic swarming of particles: A new method for size optimization of truss structures",2014,"Advances in Engineering Software",92,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886061270&doi=10.1016%2fj.advengsoft.2013.09.006&partnerID=40&md5=d5da2237c5a5f1ced5826a7ed836b3eb","A new combination of swarm intelligence and chaos theory is presented for optimal design of truss structures. Here the tendency to form swarms appearing in many different organisms and chaos theory has been the source of inspiration, and the algorithm is called chaotic swarming of particles (CSP). This method is a kind of multi-phase optimization technique which employs chaos theory in two phases, in the first phase it controls the parameter values of the particle swarm optimization (CPVPSO) and the second phase is utilized for local search (CLSPSO). Some truss structures are optimized using the CSP algorithm, and the results are compared to those of the other meta-heuristic algorithms showing the effectiveness of the new method. © 2013 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84886061270
"Darko A., Chan A.P.C., Adabre M.A., Edwards D.J., Hosseini M.R., Ameyaw E.E.","Artificial intelligence in the AEC industry: Scientometric analysis and visualization of research activities",2020,"Automation in Construction",91,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077800987&doi=10.1016%2fj.autcon.2020.103081&partnerID=40&md5=c1a84d3def3d92cb374ad2b4f6aaeba1","The Architecture, Engineering and Construction (AEC) industry is fraught with complex and difficult problems. Artificial intelligence (AI) represents a powerful tool to assist in addressing these problems. Therefore, over the years, researchers have been conducting research on AI in the AEC industry (AI-in-the-AECI). In this paper, the first comprehensive scientometric study appraising the state-of-the-art of research on AI-in-the-AECI is presented. The science mapping method was used to systematically and quantitatively analyze 41,827 related bibliographic records retrieved from Scopus. The results indicated that genetic algorithms, neural networks, fuzzy logic, fuzzy sets, and machine learning have been the most widely used AI methods in AEC. Optimization, simulation, uncertainty, project management, and bridges have been the most commonly addressed topics/issues using AI methods/concepts. The primary value and uniqueness of this study lies in it being the first in providing an up-to-date inclusive, big picture of the literature on AI-in-the-AECI. This study adds value to the AEC literature through visualizing and understanding trends and patterns, identifying main research interests, journals, institutions, and countries, and how these are linked within now-available studies on AI-in-the-AECI. The findings bring to light the deficiencies in the current research and provide paths for future research, where they indicated that future research opportunities lie in applying robotic automation and convolutional neural networks to AEC problems. For the world of practice, the study offers a readily-available point of reference for practitioners, policy makers, and research and development (R&D) bodies. This study therefore raises the level of awareness of AI and facilitates building the intellectual wealth of the AI area in the AEC industry. © 2020 Elsevier B.V.",Review,"Final",Scopus,2-s2.0-85077800987
"Luo L., He Q., Xie J., Yang D., Wu G.","Investigating the Relationship between Project Complexity and Success in Complex Construction Projects",2017,"Journal of Management in Engineering",91,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013127192&doi=10.1061%2f%28ASCE%29ME.1943-5479.0000471&partnerID=40&md5=b42db6a1e5816050f1390deef7d6aa6f","Although widely recognized both in literature and among practitioners, project complexity may cause poor project success, with little empirical evidence supporting this contention. Therefore, this study analyzed, for the first time, the relationship between project complexity and success in complex construction projects and investigated how project complexity affects project success. First, project complexity is hypothesized to be negatively related to project success. Second, on the basis of literature review and expert interviews, a total of 245 questionnaire surveys on project complexity and project outcomes were collected in China. Project complexity was measured as information, task, technological, organizational, environmental, and goal complexities by correlation and factor analyses. Finally, the structural-equation modeling technique was used to test the hypothesis and explore the effect of different complexities on project success. The findings of this study support the hypothesized negative relationship between the complexity and success of complex construction projects. Furthermore, information complexity and goal complexity have significant negative effects on project success. The research would have significant theoretical and practical significance for improving the theory of complex project management and achieving project success in complex construction projects for project managers. © 2016 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85013127192
"Min Q., Lu Y., Liu Z., Su C., Wang B.","Machine Learning based Digital Twin Framework for Production Optimization in Petrochemical Industry",2019,"International Journal of Information Management",90,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066307148&doi=10.1016%2fj.ijinfomgt.2019.05.020&partnerID=40&md5=5cc95ab869c2986f2aa7c98a092105ff","Digital twins, along with the internet of things (IoT), data mining, and machine learning technologies, offer great potential in the transformation of today's manufacturing paradigm toward intelligent manufacturing. Production control in petrochemical industry involves complex circumstances and a high demand for timeliness; therefore, agile and smart controls are important components of intelligent manufacturing in the petrochemical industry. This paper proposes a framework and approaches for constructing a digital twin based on the petrochemical industrial IoT, machine learning and a practice loop for information exchange between the physical factory and a virtual digital twin model to realize production control optimization. Unlike traditional production control approaches, this novel approach integrates machine learning and real-time industrial big data to train and optimize digital twin models. It can support petrochemical and other process manufacturing industries to dynamically adapt to the changing environment, respond in a timely manner to changes in the market due to production optimization, and improve economic benefits. Accounting for environmental characteristics, this paper provides concrete solutions for machine learning difficulties in the petrochemical industry, e.g., high data dimensions, time lags and alignment between time series data, and high demand for immediacy. The approaches were evaluated by applying them in the production unit of a petrochemical factory, and a model was trained via industrial IoT data and used to realize intelligent production control based on real-time data. A case study shows the effectiveness of this approach in the petrochemical industry. © 2019 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85066307148
"Dai H., Cao Z.","A Wavelet Support Vector Machine-Based Neural Network Metamodel for Structural Reliability Assessment",2017,"Computer-Aided Civil and Infrastructure Engineering",90,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014507347&doi=10.1111%2fmice.12257&partnerID=40&md5=d86ab794a38047c8865f5b5c935ce07b","Wavelet neural network (WNN) has been widely used in the field of civil engineering. However, WNN can only effectively handle problems of small dimensions as the computational cost for constructing wavelets of large dimensions is prohibitive. To expand the application of WNN to higher dimensions, this article develops a new wavelet support vector machine (SVM)-based neural network metamodel for reliability analysis. The method first develops an autocorrelation wavelet kernel SVM and then uses a set of wavelet SVMs with different resolution as the activation function of WNN. The output of network is obtained through aggregating outputs of different wavelet SVMs. The method takes advantage of the excellent capacities of SVM to handle high-dimensional problems and of the attractive properties of wavelet to represent complex functions. Four examples are given to demonstrate the application and effectiveness of the proposed method. © 2017 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85014507347
"Delgarm N., Sajadi B., Delgarm S.","Multi-objective optimization of building energy performance and indoor thermal comfort: A new method using artificial bee colony (ABC)",2016,"Energy and Buildings",87,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987947896&doi=10.1016%2fj.enbuild.2016.09.003&partnerID=40&md5=62bdb4ffc85be15bdfb27aaa81f4174d","The aim of this paper is to present a powerful simulation-based multi-objective optimization of building energy efficiency and indoor thermal comfort to obtain the optimal solutions of the comfort-energy efficient configurations of building envelope. The optimization method is developed by integrating a multi-objective artificial bee colony (MOABC) optimization algorithm implemented in MATLAB with EnergyPlus building energy simulation tool. The proposed optimization approach is applied to a single office room; and the building parameters, including the room rotation, window size, cooling and heating setpoint temperatures, glazing and wall material properties are considered as decision variables. In the present study, single-objective and multi-objective optimization analyses of the total annual building electricity consumption and the Predicted Percentage of Dissatisfied (PPD) are investigated to bring down the total energy cost as well as the thermal discomfort in four major climate regions of Iran, i.e. temperate, warm-dry, warm-humid and cold ones. In the results part, the achieved optimal solutions are presented in the form of Pareto fronts to reveal the mutual impacts of variables on the building energy consumption and the thermal discomfort. Finally, the ultimate optimum solution on the Pareto fronts are selected by TOPSIS decision-making method and the results of double-objective minimization problem are compared with the single-objective ones as well as the base design. The results of double-objective optimization problem indicate that in different climates, even though the total building electricity consumption increases a bit about 2.9–11.3%, the PPD significantly decreases about 49.1–56.8% compared to the baseline model. In addition, the comparisons of single-objective and double-objective optimization approaches clearly show that multi-objective optimization methods yield more appropriate results respect to the single ones, mainly because of the lower deviation index value from the ideal solution. © 2016 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84987947896
"Zervas E., Mpimpoudis A., Anagnostopoulos C., Sekkas O., Hadjiefthymiades S.","Multisensor data fusion for fire detection",2011,"Information Fusion",86,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951918944&doi=10.1016%2fj.inffus.2009.12.006&partnerID=40&md5=cbc8d50050556e0fc47d62908b9c0fa4","Fire is a common disastrous phenomenon that constitutes a serious threat. The SCIER (Sensor and Computing Infrastructure for Environmental Risks is partially funded by the European Community through the FP6 IST Program. The work presented in this paper expresses the ideas of the authors and not necessarily the whole SCIER consortium.) project envisages the deployment of Wireless Sensor Networks at the ""Urban-Rural-Interface"" (URI) aiming to the detection, monitoring and crisis management of such natural hazards. One of its primary objectives is the development of an advanced multisensor data fusion scheme which feeds a CUSUM sequential test used in the early detection of fires. Reasoning about the probability of fire in a geographical area covered by temperature, humidity and vision sensors is achieved through Evidential Reasoning (Dempster-Shafer theory). © 2009 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-79951918944
"Lyu H.-M., Sun W.-J., Shen S.-L., Zhou A.-N.","Risk Assessment Using a New Consulting Process in Fuzzy AHP",2020,"Journal of Construction Engineering and Management",85,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078073453&doi=10.1061%2f%28ASCE%29CO.1943-7862.0001757&partnerID=40&md5=5e4074b2188c7815c9675ff449478632","A fuzzy analytical hierarchy process (FAHP) is an effective risk assessment method in which a questionnaire is used to collect experts' responses. However, determining fuzzy numbers and establishing a consistent judgment matrix are difficult in the FAHP. This study proposes a new consulting process for solving the previously mentioned problems in the triangular FAHP. The proposed consulting process consists of a newly designed questionnaire and a new approach for determining fuzzy numbers. Experts' responses collected from the questionnaire are employed to determine fuzzy numbers and establish a consistent judgment matrix. The proposed method has been applied to the Jinan metro tunnel construction to demonstrate its validity. Both the traditional questionnaire and the new questionnaire are used to establish the judgment matrix in the case study. The results show that the judgment matrix determined from the new questionnaire can determine triangular fuzzy numbers and establish a consistent judgment matrix. Compared with the traditional questionnaire, the proposed questionnaire can be used to collect experts' opinions with greater convenience and in less time. © 2019 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85078073453
"Lu R., Hong S.H., Yu M.","Demand Response for Home Energy Management Using Reinforcement Learning and Artificial Neural Network",2019,"IEEE Transactions on Smart Grid",85,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073707145&doi=10.1109%2fTSG.2019.2909266&partnerID=40&md5=291d794bf0aa7ee802fcd91e040fdfb8","Ever-changing variables in the electricity market require energy management systems (EMSs) to make optimal real-time decisions adaptively. Demand response (DR) is the latest approach being used to accelerate the efficiency and stability of power systems. This paper proposes an hour-ahead DR algorithm for home EMSs. To deal with the uncertainty in future prices, a steady price prediction model based on artificial neural network is presented. In cooperation with forecasted future prices, multi-agent reinforcement learning is adopted to make optimal decisions for different home appliances in a decentralized manner. To verify the performance of the proposed energy management scheme, simulations are conducted with non-shiftable, shiftable, and controllable loads. Experimental results demonstrate that the proposed DR algorithm can handle energy management for multiple appliances, minimize user energy bills, and dissatisfaction costs, and help the user to significantly reduce its electricity cost compared with a benchmark without DR. © 2010-2012 IEEE.",Article,"Final",Scopus,2-s2.0-85073707145
"Garcia C.D.S., Meincheim A., Faria Junior E.R., Dallagassa M.R., Sato D.M.V., Carvalho D.R., Santos E.A.P., Scalabrin E.E.","Process mining techniques and applications – A systematic mapping study",2019,"Expert Systems with Applications",85,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065903366&doi=10.1016%2fj.eswa.2019.05.003&partnerID=40&md5=3cb4f6b9f095d847107d41b06e452d71","Process mining is a growing and promising study area focused on understanding processes and to help capture the more significant findings during real execution rather than, those methods that, only observed idealized process model. The objective of this article is to map the active research topics of process mining and their main publishers by country, periodicals, and conferences. We also extract the reported application studies and classify these by exploration domains or industry segments that are taking advantage of this technique. The applied research method was systematic mapping, which began with 3713 articles. After applying the exclusion criteria, 1278 articles were selected for review. In this article, an overview regarding process mining is presented, the main research topics are identified, followed by identification of the most applied process mining algorithms, and finally application domains among different business segments are reported on. It is possible to observe that the most active research topics are associated with the process discovery algorithms, followed by conformance checking, and architecture and tools improvements. In application domains, the segments with major case studies are healthcare followed by information and communication technology, manufacturing, education, finance, and logistics. © 2019 Elsevier Ltd",Review,"Final",Scopus,2-s2.0-85065903366
"Kim B., Cho S.","Image-based concrete crack assessment using mask and region-based convolutional neural network",2019,"Structural Control and Health Monitoring",84,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067024390&doi=10.1002%2fstc.2381&partnerID=40&md5=8876549970cd2e1aa1016994fad1a786","Recently, many countries have investigated replacing conventional visual inspection with computer-vision–based inspection to enhance the efficiency, speed, and objectivity of inspection. This paper presents a novel crack assessment framework for concrete structures that detects cracks using mask and region-based convolutional neural network (Mask R-CNN) and quantifies cracks using a few morphological operations on the detected crack masks. In this study, a Mask R-CNN is trained for crack detection using 1,102 crack regions masked on 376 concrete images. The trained Mask R-CNN model is tested on the images taken from a real concrete wall with 453 cracks whose widths range from less than 0.1 mm to 1.0 mm. The trained model successfully detects most of the cracks 0.3 mm or wider. Quantification of the cracks was then carried out using several image-processing operations on 10 randomly selected crack masks. Cracks with widths of 0.3 mm or more are quantified successfully with errors less than 0.1 mm, whereas cracks less than 0.3 mm widths show relatively larger error due to the limitation of image resolution. © 2019 John Wiley & Sons, Ltd.",Article,"Final",Scopus,2-s2.0-85067024390
"Zhang L., Wu X., Zhu H., AbouRizk S.M.","Perceiving safety risk of buildings adjacent to tunneling excavation: An information fusion approach",2017,"Automation in Construction",83,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999015117&doi=10.1016%2fj.autcon.2016.09.003&partnerID=40&md5=849cfba28907ba30462da77d914d67f9","This paper develops a novel hybrid information fusion approach that integrates cloud model (CM), Dempster–Shafer (D–S) evidence theory and Monte Carlo (MC) simulation technique to perceive safety risk of tunnel-induced building damage under uncertainty. The correlation measurement in the CM framework is used to construct basic probability assignments (BPAs) within different risk states of input factors. An improved combination rule that incorporates the Dempster' rule and the weighted mean rule is used to deal with multi-source evidence with conflicts. The MC technique is used to simulate the input observation by using probability distribution in order to describe and reduce underlying uncertainty during the characterization and measurement of input factors. A multi-layer information fusion framework is proposed for the safety risk perception, with both hard data and soft data taken into account. Four buildings adjacent to the excavation of one tunnel section in Wuhan metro system in China are utilized as a case study to demonstrate the effectiveness and applicability of the developed approach. Results indicate that the developed approach is capable of (i) synthesizing multi-source information to achieve a more accurate result for safety risk perception, and (ii) identifying global sensitivities of input factors under uncertainty. Reliability of safety risk perception results is further tested under different scenarios with different bias levels in the measurement of input factors, and the developed approach proves to have a strong robustness and fault-tolerant capacity. This approach can be used by practitioners in the industry as a decision tool to perceive and anticipate the potential safety risks in tunneling projects. © 2016 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84999015117
"Kim D., Liu M., Lee S., Kamat V.R.","Remote proximity monitoring between mobile construction resources using camera-mounted UAVs",2019,"Automation in Construction",82,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058789711&doi=10.1016%2fj.autcon.2018.12.014&partnerID=40&md5=7a9c7bfe7a3580e6d6578bf37d01bf04","Struck-by accidents have resulted in a significant number of fatal and nonfatal injuries in the construction industry. As a proactive safety measure against struck-by hazards, the authors present an Unmanned Aerial Vehicle (UAV)-assisted visual monitoring method that can automatically measure proximities among construction entities. To attain this end, this research conducts two research thrusts: (i) object localization using a deep neural network, YOLO-V3; and (ii) development of an image rectification method that allows for the measurement of actual distance from a 2D image collected from a UAV. Tests on real-site aerial videos show the promising accuracy of the proposed method; the mean absolute distance errors for estimated proximity were less than 0.9 m and the mean absolute percentage errors were around 4%. The proposed method enables the advanced detection of struck-by hazards around workers, which in turn can make timely intervention possible. This proactive intervention can ultimately promote a safer working environment for construction workers. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85058789711
"Wang Z., Wang Y., Srinivasan R.S.","A novel ensemble learning approach to support building energy use prediction",2018,"Energy and Buildings",82,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032939165&doi=10.1016%2fj.enbuild.2017.10.085&partnerID=40&md5=7324f52aa5a0b7fa7087c28fa7628fc6","Broadly speaking, building energy use prediction can be classified into two categories based on modeling approaches namely engineering and Artificial Intelligence (AI). While engineering approach requires solving physical equations representing the thermal performance of systems and components that constitute the buildings, the AI-based approach uses historical data to predict future performance. Although engineering approach estimates energy use with greater accuracy, it falls short in the overall complexity of model building and simulation in which detailed data that represent the building geometry, systems, configurations, and occupant schedule is needed. Whereas, the AI-based approach offers a rapid prediction of building energy use and, if appropriately trained and tested, may be used for quick and efficient decision-making of energy use reduction. Nevertheless, for robust integration with and to improve automated building systems management and intelligence, the need for consistent, stable, and higher prediction accuracy cannot be understated. To alleviate the instability issue, and to improve prediction accuracy, we have exploited and tested an ensemble learning technique, ‘Ensemble Bagging Trees’ (EBT), using data obtained from meteorological systems and building-level occupancy and meters.Results showed that the proposed EBT model predicted hourly electricity demand of the test building with improved accuracy of Mean Absolute Prediction Error that ranged from 2.97% to 4.63%. Additionally, results showed that proposed variable selection method could reduce the computation time of EBT by 38–41% without sacrificing the prediction accuracy. The proposed ensemble learning model that exemplifies improved prediction accuracy over other AI techniques can be used for real-time applications such as system fault detection and diagnosis. © 2017 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85032939165
"Ying Y., Garrett J.H., Oppenheim I.J., Soibelman L., Harley J.B., Shi J., Jin Y.","Toward data-driven structural health monitoring: Application of machine learning and signal processing to damage detection",2013,"Journal of Computing in Civil Engineering",82,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886500913&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000258&partnerID=40&md5=a2924e14c0cf828881bb4ed45a013bde","A multilayer data-driven framework for robust structural health monitoring based on a comprehensive application of machine learning and signal processing techniques is introduced. This paper focuses on demonstrating the effectiveness of the framework for damage detection in a steel pipe under environmental and operational variations. The pipe was instrumented with piezoelectric wafers that can generate and sense ultrasonic waves. Damage was simulated physically by a mass scatterer grease-coupled to the surface of the pipe. Benign variations included variable internal air pressure and ambient temperature over time. Ultrasonic measurements were taken on three different days with the scatterer placed at different locations on the pipe. The wave patterns are complex and difficult to interpret, and it is even more difficult to differentiate the changes produced by the scatterer from the changes produced by benign variations. The sensed data were characterized by 365 features extracted from a variety of signal-processing techniques. Automated feature selection methods were then developed using an adaptive boosting algorithm to identify the most effective features for damage detection. With the selected features, five machine-learning classifiers were formulated based on adaptive boosting and support vector machines and achieved 98.5-99.8% average accuracy during random testing and 84.2-89% average accuracy during systematic testing. In addition, other metrics for classifier evaluation generated from a confusion matrix and from a receiver operating characteristic curve are reported. © 2013 American Society of Civil Engineers.",Conference Paper,"Final",Scopus,2-s2.0-84886500913
"Ning X., Lam K.-C., Lam M.C.-K.","A decision-making system for construction site layout planning",2011,"Automation in Construction",82,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-79954595319&doi=10.1016%2fj.autcon.2010.11.014&partnerID=40&md5=ce53eebb3d56073f9c92cf1d1a9a8571","A decision-making system, which consists of input, design, evaluation and selection, and output stages, is proposed to solve dynamic, multi-objective and unequal-area construction site layout planning (CSLP) problem. In the input stage, the multiple objectives, schedule planning and site condition are determined. In the design stage, two mathematical optimization models max-min ant system (MMAS) and modified Pareto-based ant colony optimization (ACO) algorithm are employed to solve single objective optimization (SOO) and multi-objective optimization (MOO) problem respectively. In the evaluation and selection stage, the intuitionistic fuzzy TOPSIS method is used to evaluate and select the best layout plan among the generated layout alternatives from the design stage. The performance of the proposed decision-making system, which was verified by a residential building project, shall assist the practitioners in the construction industry to deliver construction projects in a more efficient and effective manner, and thus construction costs could be reduced significantly. © 2010 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-79954595319
"Nasruddin, Sholahudin, Satrio P., Mahlia T.M.I., Giannetti N., Saito K.","Optimization of HVAC system energy consumption in a building using artificial neural network and multi-objective genetic algorithm",2019,"Sustainable Energy Technologies and Assessments",81,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067884492&doi=10.1016%2fj.seta.2019.06.002&partnerID=40&md5=e42ee199ff7314d3a8ddadc1a6564a78","The optimization of heating, ventilating and air conditioning (HVAC) system operations and other building parameters intended to minimize annual energy consumption and maximize the thermal comfort is presented in this paper. The combination of artificial neural network (ANN) and multi-objective genetic algorithm (MOGA) is applied to optimize the two-chiller system operation in a building. The HVAC system installed in the building integrates radiant cooling system, variable air volume (VAV) chiller system, and dedicated outdoor air system (DOAS). Several parameters including thermostat setting, passive solar design, and chiller operation control are considered as decision variables. Subsequently, the percentage of people dissatisfied (PPD) and annual building energy consumption is chosen as objective functions. Multi-objective optimization is employed to optimize the system with two objective functions. As the result, ANN performed a good correlation between decision variables and the objective function. Moreover, MOGA successfully provides several alternative possible design variables to achieve optimum system in terms of thermal comfort and annual energy consumption. In conclusion, the optimization that considers two objectives shows the best result regarding thermal comfort and energy consumption compared to base case design. © 2019 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85067884492
"Kanan R., Elhassan O., Bensalem R.","An IoT-based autonomous system for workers’ safety in construction sites with real-time alarming, monitoring, and positioning strategies",2018,"Automation in Construction",80,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040001669&doi=10.1016%2fj.autcon.2017.12.033&partnerID=40&md5=8820a52f1f6dda22d1b75ab5993d38ef","Civil construction sites are considered as one of the riskiest environments where many potential hazards may occur. To protect construction workers and prevent accidents in such sites, this paper proposes a novel design for an autonomous system that monitors, localizes, and warns site laborers who avail within danger zones. The proposed system is user-friendly, and its architecture is based on Internet of Things (IoT). The heterogeneous components of this architecture are seamlessly integrated into a middleware backend online server. To accurately detect and identify construction workers, the proposed system employs three combined techniques. They are 1) the 868 MHz radio frequency, 2) directional antennas, and 3) the 40 kHz ultrasound waves. Vehicle's rear is secured by a sensing unit that ensures good coverage along with a wearable device for workers. The design of the wearable device includes a set of components which are a radio transceiver (transmitter/receiver), a wake-up sensor, an alarm actuator, and a GPRS module. The wearable device has a power saving scheme with a current consumption as low as 0.5 μA at 3 V supply; thanks to our RF wake-up sensor. Via proximity, this wearable device becomes hybrid (active/passive) in which it remains in deep sleep mode until the presence of a radio frequency (RF) field. Consequently, the rechargeable battery's life gets increased by up to 2 days of autonomy before recharging. Furthermore, the paper presents an implementation of wireless nodes that are powered by light energy using photovoltaic cells. These nodes adopt energy management and storage schemes for continuous operation for indoor and outdoor environments. © 2017",Review,"Final",Scopus,2-s2.0-85040001669
"Hu Z.-Z., Tian P.-L., Li S.-W., Zhang J.-P.","BIM-based integrated delivery technologies for intelligent MEP management in the operation and maintenance phase",2018,"Advances in Engineering Software",79,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028002540&doi=10.1016%2fj.advengsoft.2017.08.007&partnerID=40&md5=724b153da51d56fed643a651830f9c54","Incomplete building information in delivery and the lack of compatible tools for Operation and Maintenance (O&M) have hindered the development of the intelligent management of Mechanical, Electrical and Plumbing (MEP) systems. In fact, the information related to the O&M management of the MEP system conventionally comes from the completion documents in the forms of hard copies or unstructured digital files, making it hard to search for useful information in the “sea” of documents and drawings. Therefore, digitalization of information is an urgent task to facilitate the intelligent management of the MEP system. As a project deliverable, the as-built information model shall not only contain geometrical information and necessary construction-related data, but also built-in information useful for the intelligent O&M management. In the present study, based on the Building Information Modeling/Model (BIM) technology, a set of solutions including the automatic establishment of the logic chain for MEP systems, an equipment grouping and labeling scheme and an algorithm to transform BIM information to GIS map model, is proposed to digitalize and integrate the MEP-related information into the as-built model. Subsequently, a cross-platform O&M management system is developed using the MEP-related information in the as-built model to run routine O&M tasks and to effectively response to MEP-related emergencies. The developed system is applied to aid the O&M management of MEP engineering in a real project, showing that the developed system facilitates the intelligent O&M management and guarantees the security of the MEP system and its subsystems. © 2017 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85028002540
"Sholahudin S., Han H.","Simplified dynamic neural network model to predict heating load of a building using Taguchi method",2016,"Energy",77,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961942711&doi=10.1016%2fj.energy.2016.03.057&partnerID=40&md5=f31eda5793f153d4f8ea5d3c11ff3431","Prediction of heating and cooling loads is necessary for building design and HVAC system operation, in order to reduce energy consumption. This study intended to develop a method for the prediction of the instantaneous building energy load, depending on various combinations of input parameters using a dynamic neural network model. The heating load was calculated for a typical apartment building in Seoul for a one-month period in winter using the Energy-Plus software. The data sets obtained were used to train neural network models. The input parameters included dry-bulb temperature, dew point temperature, direct normal radiation, diffuse horizontal radiation, and wind speed. The Taguchi method was applied to investigate the effect of the individual input parameters on the heating load. It was found that the outdoor temperature and wind speed are the most influential parameters, and that the dynamic model provides better results, as compared with the static model. Optimized system parameters, such as number of tapped delay lines and number of hidden neurons, were obtained for the present application. The results of this study show that Taguchi method can successfully reduce number of input parameters. Moreover dynamic neural network model can predict precisely instantaneous heating loads using a reduced number of inputs. © 2016 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-84961942711
"Wang J., Zhang X., Shou W., Wang X., Xu B., Kim M.J., Wu P.","A BIM-based approach for automated tower crane layout planning",2015,"Automation in Construction",77,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944442108&doi=10.1016%2fj.autcon.2015.05.006&partnerID=40&md5=dcd597395b733d9d6d0241d1c799b02c","Tower crane layout design and planning within construction site is a common construction technical issue, and is regarded as a complex combinatorial problem. Previous research focused on utilising either mathematical methods or visualisation tools to find an optimal tower crane layout plan. Both these two approaches require large amounts of manual data input by the layout planners, which is time-consuming and not very practical in industry. The purpose of this paper is to develop an integrated approach which combines Building Information Modelling (BIM) and Firefly Algorithm (FA) to automatically generate an optimal tower crane layout plan. Firstly, BIM is utilised to provide inputs for the mathematical model. Then the FA is used to determine the optimal locations of tower cranes and supply points. Finally, the optimal tower crane layout scheme will be visualised and evaluated through BIM-based simulation. A practical case is selected to demonstrate the proposed approach. The final result is promising and demonstrates the practical value of this approach. © 2015 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84944442108
"Nguyen T., Kashani A., Ngo T., Bordas S.","Deep neural network with high-order neuron for the prediction of foamed concrete strength",2019,"Computer-Aided Civil and Infrastructure Engineering",76,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056629665&doi=10.1111%2fmice.12422&partnerID=40&md5=d3ae1d39cd3ad1a7e953149ead9bbea7","The article presents a deep neural network model for the prediction of the compressive strength of foamed concrete. A new, high-order neuron was developed for the deep neural network model to improve the performance of the model. Moreover, the cross-entropy cost function and rectified linear unit activation function were employed to enhance the performance of the model. The present model was then applied to predict the compressive strength of foamed concrete through a given data set, and the obtained results were compared with other machine learning methods including conventional artificial neural network (C-ANN) and second-order artificial neural network (SO-ANN). To further validate the proposed model, a new data set from the laboratory and a given data set of high-performance concrete were used to obtain a higher degree of confidence in the prediction. It is shown that the proposed model obtained a better prediction, compared to other methods. In contrast to C-ANN and SO-ANN, the proposed model can genuinely improve its performance when training a deep neural network model with multiple hidden layers. A sensitivity analysis was conducted to investigate the effects of the input variables on the compressive strength. The results indicated that the compressive strength of foamed concrete is greatly affected by density, followed by the water-to-cement and sand-to-cement ratios. By providing a reliable prediction tool, the proposed model can aid researchers and engineers in mixture design optimization of foamed concrete. © 2018 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85056629665
"Chi S., Han S.","Analyses of systems theory for construction accident prevention with specific reference to OSHA accident reports",2013,"International Journal of Project Management",75,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881616359&doi=10.1016%2fj.ijproman.2012.12.004&partnerID=40&md5=b4b453ff8771be204b117ce8c47e1462","To enhance workplace safety in the construction industry it is important to understand interrelationships among safety risk factors associated with construction accidents. This study incorporates the systems theory into Heinrich's domino theory to explore the interrelationships of risks and break the chain of accident causation. Through both empirical and statistical analyses of 9358 accidents which occurred in the U.S. construction industry between 2002 and 2011, the study investigates relationships between accidents and injury elements (e.g., injury type, part of body, injury severity) and the nature of construction injuries by accident type. The study then discusses relationships between accidents and risks, including worker behavior, injury source, and environmental condition, and identifies key risk factors and risk combinations causing accidents. The research outcomes will assist safety managers to prioritize risks according to the likelihood of accident occurrence and injury characteristics, and pay more attention to balancing significant risk relationships to prevent accidents and achieve safer working environments. © 2012 Elsevier Ltd.",Article,"Final",Scopus,2-s2.0-84881616359
"Cheng J.C.P., Chen W., Chen K., Wang Q.","Data-driven predictive maintenance planning framework for MEP components based on BIM and IoT using machine learning algorithms",2020,"Automation in Construction",74,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078707972&doi=10.1016%2fj.autcon.2020.103087&partnerID=40&md5=064c227f5e3c92afbeb91ad35da0096e","Facility managers usually conduct reactive maintenance or preventive maintenance strategies in building maintenance management. However, there are some limitations that reactive maintenance cannot prevent failure, and preventive maintenance cannot predict the future condition of MEP components and repair in advance to extend the lifetime of facilities. Therefore, this study aims to apply a predictive maintenance strategy with advanced technologies to overcome these limitations. Building information modeling (BIM) and Internet of Things (IoT) have the potential to improve the efficiency of facility maintenance management (FMM). Despite the significant efforts that have been made to apply BIM and IoT to the architecture, engineering, construction, and facility management (AEC/FM) industry, BIM and IoT integration for FMM is still at an initial stage. In order to provide a better maintenance strategy for building facilities, a data-driven predictive maintenance planning framework based on BIM and IoT technologies for FMM was developed, consisting of an information layer and an application layer. Data collection and data integration among the BIM models, FM system, and IoT network are undertaken in the information layer, while the application layer contains four modules to achieve predictive maintenance, namely: (1) condition monitoring and fault alarming module, (2) condition assessment module, (3) condition prediction module, and (4) maintenance planning module. Machine learning algorithms, ANN and SVM, are used to predict the future condition of MEP components. Furthermore, the developed framework was applied in an illustrative example to validate the feasibility of the approach. The results show that the constantly updated data obtained from the information layer together with the machine learning algorithms in the application layer can efficiently predict the future condition of MEP components for maintenance planning. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85078707972
"Pan Y., Zhang L., Li Z., Ding L.","Improved Fuzzy Bayesian Network-Based Risk Analysis with Interval-Valued Fuzzy Sets and D-S Evidence Theory",2020,"IEEE Transactions on Fuzzy Systems",71,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090906429&doi=10.1109%2fTFUZZ.2019.2929024&partnerID=40&md5=544d203fd4526d499650fea86f4fedc3","A novel risk analysis approach is developed by merging interval-valued fuzzy sets (IVFSs), improved Dempster-Shafer (D-S) evidence theory, and fuzzy Bayesian networks (BNs), acting as a systematic decision support approach for safety insurance for the entire life cycle of a complex system under uncertainty. Aiming to alleviate the problem of insufficient and imprecise data collected from the complicated environment, the expert judgment in linguistic expressions is employed to describe the risk levels for all risk factors, which are represented by IVFSs using Gaussian membership function to fully consider such fuzziness and uncertainty. In regard to interval fusion and highly conflicting data, an improved combination rule based on the D-S evidence theory is developed. Then, fuzzy prior probability for each risk factor can be generated from fused intervals and fed into a fuzzy BN model for fuzzy-based Bayesian inference, including predictive, sensitivity, and diagnosis analysis. Furthermore, a case study is used to demonstrate the feasibility of the proposed risk analysis. A comparison of risk analysis based upon the hybrid improved D-S, classical D-S, and arithmetic average method is illustrated to show the outstanding performance of the developed approach in fusing multisource information with ubiquitous uncertainty and conflicts in an efficient manner, leading to more reliable risk evaluation. It is concluded that the proposed risk analysis provides a deep insight on risk control, especially for complex project environment, which enables to not only reduce the likelihood of failure ahead of time but also mitigate risk magnitudes to some degree after the occurrence of a failure. © 1993-2012 IEEE.",Article,"Final",Scopus,2-s2.0-85090906429
"Goh Y.M., Ubeynarayana C.U.","Construction accident narrative classification: An evaluation of text mining techniques",2017,"Accident Analysis and Prevention",71,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028564740&doi=10.1016%2fj.aap.2017.08.026&partnerID=40&md5=b29a7695083edc5aca0e7bc5e4c9d753","Learning from past accidents is fundamental to accident prevention. Thus, accident and near miss reporting are encouraged by organizations and regulators. However, for organizations managing large safety databases, the time taken to accurately classify accident and near miss narratives will be very significant. This study aims to evaluate the utility of various text mining classification techniques in classifying 1000 publicly available construction accident narratives obtained from the US OSHA website. The study evaluated six machine learning algorithms, including support vector machine (SVM), linear regression (LR), random forest (RF), k-nearest neighbor (KNN), decision tree (DT) and Naive Bayes (NB), and found that SVM produced the best performance in classifying the test set of 251 cases. Further experimentation with tokenization of the processed text and non-linear SVM were also conducted. In addition, a grid search was conducted on the hyperparameters of the SVM models. It was found that the best performing classifiers were linear SVM with unigram tokenization and radial basis function (RBF) SVM with uni-gram tokenization. In view of its relative simplicity, the linear SVM is recommended. Across the 11 labels of accident causes or types, the precision of the linear SVM ranged from 0.5 to 1, recall ranged from 0.36 to 0.9 and F1 score was between 0.45 and 0.92. The reasons for misclassification were discussed and suggestions on ways to improve the performance were provided. © 2017 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85028564740
"Yet B., Constantinou A., Fenton N., Neil M., Luedeling E., Shepherd K.","A Bayesian network framework for project cost, benefit and risk analysis with an agricultural development case study",2016,"Expert Systems with Applications",71,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969753484&doi=10.1016%2fj.eswa.2016.05.005&partnerID=40&md5=723d0c402e23711dabc1cf339476bce6","Successful implementation of major projects requires careful management of uncertainty and risk. Yet such uncertainty is rarely effectively calculated when analysing project costs and benefits. This paper presents a Bayesian Network (BN) modelling framework to calculate the costs, benefits, and return on investment of a project over a specified time period, allowing for changing circumstances and trade-offs. The framework uses hybrid and dynamic BNs containing both discrete and continuous variables over multiple time stages. The BN framework calculates costs and benefits based on multiple causal factors including the effects of individual risk factors, budget deficits, and time value discounting, taking account of the parameter uncertainty of all continuous variables. The framework can serve as the basis for various project management assessments and is illustrated using a case study of an agricultural development project. © 2016 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84969753484
"Pan Y., Zhang L., Wu X., Skibniewski M.J.","Multi-classifier information fusion in risk analysis",2020,"Information Fusion",70,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081156314&doi=10.1016%2fj.inffus.2020.02.003&partnerID=40&md5=0f05307cf8a05f2efc44ef0038fded6f","This paper develops a novel multi-classifier information fusion approach that integrates the probabilistic support vector machine (SVM) and the improved Dempster-Shafer (D-S) evidence theory to support risk analysis under uncertainty. Safety levels for various risk factors can be classified separately using the probabilistic SVM. Then, these multiple classification results will be fused at the decision level to achieve an overall risk evaluation by an improved D-S evidence theory with the integration of the Dempster’ rule and the weighted average rule. The Monte Carlo simulation approach is employed to model the randomness and uncertainty underlying limited observations. A global sensitivity analysis is performed to identify the most significant factors contributing to the risk event. A realistic operational tunnel case in China is used to demonstrate the feasibility and effectiveness of the developed approach, aiming to assess the magnitude of the structural health risk. Results indicate the developed SVM-DS approach is capable of (1) Fusing multi-classifier information effectively from different SVM models with a high classification accuracy of 97.14%; (2) Performing a strong robustness to bias, which can achieve acceptable classification accuracy even under a 20% bias; and (3) Exhibiting a more outstanding classification performance (87.99% accuracy) than the single SVM model (63.84% accuracy) under a high bias (20%). Since the proposed reliable risk analysis method can efficiently fuse multi-sensory information with ubiquitous uncertainties, conflicts, and bias, it provides in-depth analysis for structural health status together with the most critical risk factors, and then proper remedial actions can be taken at an early stage. © 2020",Article,"Final",Scopus,2-s2.0-85081156314
"Islam M.S., Nepal M.P., Skitmore M., Attarzadeh M.","Current research trends and application areas of fuzzy and hybrid methods to the risk assessment of construction projects",2017,"Advanced Engineering Informatics",70,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020420365&doi=10.1016%2fj.aei.2017.06.001&partnerID=40&md5=f12a7390efbc350aa5997474be8117dd","Fuzzy and hybrid methods have been increasingly used in construction risk management research and this study aims to compile and analyse the basic concepts and methods applied in this field to date. A content analysis is made of a comprehensive literature review of publications during 2005–2017. It is found that the nature of complex projects is such that most risks are interdependent of each other. Therefore, a fuzzy structured method such as the fuzzy analytical network process (FANP) has frequently been used for different complex projects. However, the application of FANP is limited because of the tedious and lengthy calculations required for the pairwise comparisons needed and an inability to incorporate new information into the risk structure. To overcome this constraint, a fuzzy Bayesian belief network (FBBN) has been increasingly used for risk assessment. Further project-specific studies based on FBBN are recommended to justify its broader application. Beyond fuzzy methods, the Credal network – an extended form of Bayesian network- is found to have potential for risk assessment under uncertainty. © 2017",Article,"Final",Scopus,2-s2.0-85020420365
"Zhang J., El-Gohary N.M.","Integrating semantic NLP and logic reasoning into a unified system for fully-automated code checking",2017,"Automation in Construction",68,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998693262&doi=10.1016%2fj.autcon.2016.08.027&partnerID=40&md5=5da690ed8f28fc546f86d79510159bb9","Existing automated compliance checking (ACC) systems are limited in their automation; they rely on the use of hard-coded, proprietary rules for representing regulatory requirements, which requires major manual effort in extracting regulatory information from textual regulatory documents and coding these information into a rule format. To address this limitation, this paper proposes a new unified ACC system that integrates: (1) semantic natural language processing techniques and EXPRESS data-based techniques to automatically extract and transform both regulatory information (in regulatory documents) and design information [in building information models (BIMs)] for automated compliance reasoning, and (2) semantic logic-based information representation so that the reasoning could be fully automated. To test the proposed system, a BIM test case was checked for compliance with Chapter 19 of the International Building Code 2009. Comparing to a manually-developed gold standard, 98.7% recall and 87.6% precision in noncompliance detection were achieved. © 2016 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84998693262
"Mazlina Zaira M., Hadikusumo B.H.W.","Structural equation model of integrated safety intervention practices affecting the safety behaviour of workers in the construction industry",2017,"Safety Science",67,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021121154&doi=10.1016%2fj.ssci.2017.06.007&partnerID=40&md5=d2896b15cf461bda091ec6be6030fcbb","Fatality rates at workplaces in the construction industry are high compared to other industries. Tremendous effort is required to strive towards zero accidents. Managing foreign workers with different cultural backgrounds at the workplace requires appropriate safety intervention practices to improve workers’ safety behaviour. Based on the literature, the importance of safety intervention for changing unsafe to safe worker behaviour is known. For this reason, an integrated safety intervention model affecting workers’ safety behaviour was developed and tested. This study was conducted by distributing a questionnaire survey to construction companies. The survey was randomly distributed, with a total of 198 responses received. Exploratory factor analysis (EFA) was conducted to confirm the three safety intervention constructs. Structural equation modelling (SEM) was performed to identify the most significant intervention-related safety practices, which are to be the focus in handling safety management. The results indicate that technical intervention has a positive influence by management and human intervention. In addition, an improvement in workers’ safety behaviour can be achieved by focusing on the technical intervention with five important safety practices: workplace safety inspections, personal protective equipment (PPE) programmes, safety equipment availability and maintenance, safe work practices, and safety permits. These findings attempt to help construction management by identifying the appropriate selection of safety practices with specific interventions to improve workers’ safety behaviour. © 2017",Article,"Final",Scopus,2-s2.0-85021121154
"Wang Z.Z., Chen C.","Fuzzy comprehensive Bayesian network-based safety risk assessment for metro construction projects",2017,"Tunnelling and Underground Space Technology",66,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032710901&doi=10.1016%2fj.tust.2017.09.012&partnerID=40&md5=d1925a3b7848919ea957186b45379c69","This paper presents a systemic decision-support approach to safety risk analysis for metro construction projects under uncertainty using a fuzzy comprehensive Bayesian network (FCBN), which combines the fuzzy comprehensive evaluation method (FCEM) and a Bayesian network (BN). The results of the safety risk assessment based on the FCBN are composed of three aspects: risk probability, risk loss, and risk controllability. In this assessment, two of the aspects—risk loss and risk controllability—are calculated in terms of intervals or fuzzy numbers. Through the application of the FCEM, the levels of risk loss and risk controllability are then estimated. The risk probability is calculated from the BN, in which the relationships among the dependent variables are expressed in the form of a directed graph. A comprehensive safety risk assessment allows engineers to assess potential safety hazards and provides a basis for dynamic early risk warning and control ahead of metro construction, which is acquired by combining the FCEM and the BN. A case study relating to safety risk analysis in the construction of the Dalian Metro in China is used to verify the feasibility of the approach as well as its application potential. A comparison of the results with the actual construction state shows its effectiveness in estimating the risk level of a metro construction project under uncertainty. The proposed approach provides a powerful tool with which planners and engineers can systematically assess and mitigate the inherent risks associated with metro construction. © 2017 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85032710901
"Arashpour M., Wakefield R., Abbasi B., Lee E.W.M., Minas J.","Off-site construction optimization: Sequencing multiple job classes with time constraints",2016,"Automation in Construction",66,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991258587&doi=10.1016%2fj.autcon.2016.08.001&partnerID=40&md5=3aa3a7b1f9b48d06ce04ec608262f967","Off-site construction is a unique hybrid of manufacturing operations and on-site construction activities. Maximizing the production output has long been the main challenge for off-site manufacturers. Among other responses to this challenge, the use of multi-task shared resources has proved its effectiveness in improving tangible performance measures of production. However, multi-skilled resources often become bottlenecks (overloaded) when producing multiple classes of products and prevent the production network from meeting due dates. This paper analytically models the problem of defining the optimal product sequencing using optimization-based metaheuristics with the aim of minimizing changeover time, which is wasted switching from a product class to another. Production data of two Australian off-site manufacturers are used in the subsequent empirical analysis resulting in advancement of five research propositions. This research contributes to the scheduling theory by expanding the insight into dynamics of resource sharing and job sequencing. The developed models and propositions are of practical value for off-site manufacturers of building elements to maximize their production output. © 2016 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84991258587
"Nath N.D., Behzadan A.H., Paal S.G.","Deep learning for site safety: Real-time detection of personal protective equipment",2020,"Automation in Construction",65,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077950555&doi=10.1016%2fj.autcon.2020.103085&partnerID=40&md5=b23653b0f8b1d348f0a8a012e7b88098","The leading causes of construction fatalities include traumatic brain injuries (resulted from fall and electrocution) and collisions (resulted from struck by objects). As a preventive step, the U.S. Occupational Safety and Health Administration (OSHA) requires that contractors enforce and monitor appropriate usage of personal protective equipment (PPE) of workers (e.g., hard hat and vest) at all times. This paper presents three deep learning (DL) models built on You-Only-Look-Once (YOLO) architecture to verify PPE compliance of workers; i.e., if a worker is wearing hard hat, vest, or both, from image/video in real-time. In the first approach, the algorithm detects workers, hats, and vests and then, a machine learning model (e.g., neural network and decision tree) verifies if each detected worker is properly wearing hat or vest. In the second approach, the algorithm simultaneously detects individual workers and verifies PPE compliance with a single convolutional neural network (CNN) framework. In the third approach, the algorithm first detects only the workers in the input image which are then cropped and classified by CNN-based classifiers (i.e., VGG-16, ResNet-50, and Xception) according to the presence of PPE attire. All models are trained on an in-house image dataset that is created using crowd-sourcing and web-mining. The dataset, named Pictor-v3, contains ~1,500 annotated images and ~4,700 instances of workers wearing various combinations of PPE components. It is found that the second approach achieves the best performance, i.e., 72.3% mean average precision (mAP), in real-world settings, and can process 11 frames per second (FPS) on a laptop computer which makes it suitable for real-time detection, as well as a good candidate for running on light-weight mobile devices. The closest alternative in terms of performance (67.93% mAP) is the third approach where VGG-16, ResNet-50, and Xception classifiers are assembled in a Bayesian framework. However, the first approach is the fastest among all and can process 13 FPS with 63.1% mAP. The crowed-sourced Pictor-v3 dataset and all trained models are publicly available to support the design and testing of other innovative applications for monitoring safety compliance, and advancing future research in automation in construction. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85077950555
"Kim S., Lim H.","Reinforcement learning based energy management algorithm for smart energy buildings",2018,"Energies",64,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052795034&doi=10.3390%2fen11082010&partnerID=40&md5=031761ec7796bc948de5fa448afe0490","A smart grid facilitates more effective energy management of an electrical grid system. Because both energy consumption and associated building operation costs are increasing rapidly around the world, the need for flexible and cost-effective management of the energy used by buildings in a smart grid environment is increasing. In this paper, we consider an energy management system for a smart energy building connected to an external grid (utility) as well as distributed energy resources including a renewable energy source, energy storage system, and vehicle-To-grid station. First, the energy management system is modeled using a Markov decision process that completely describes the state, action, transition probability, and rewards of the system. Subsequently, a reinforcement-learning-based energy management algorithm is proposed to reduce the operation energy costs of the target smart energy building under unknown future information. The results of numerical simulation based on the data measured in real environments show that the proposed energy management algorithm gradually reduces energy costs via learning processes compared to other random and non-learning-based algorithms. © 2018 by the authors.",Article,"Final",Scopus,2-s2.0-85052795034
"Zhang L., Ding L., Wu X., Skibniewski M.J.","An improved Dempster–Shafer approach to construction safety risk perception",2017,"Knowledge-Based Systems",64,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020822112&doi=10.1016%2fj.knosys.2017.06.014&partnerID=40&md5=66eeabda2b91368f9f35d8515faf19d3","This paper proposes a novel hybrid approach that merges fuzzy matter element (FME), Monte Carlo (MC) simulation technique, and Dempster–Shafer (D–S) evidence theory to perceive the risk magnitude of tunnel-induced building damage at an early construction stage. The membership measurement in FME is used to construct basic probability assignments (BPAs) of influential factors within different risk states. An improved evidence fusion rule that integrates the Dempster’ rule and the weighted average rule is developed to synthesize multi-source conflicting evidence. A new defuzzification method, Centre of Distribution (COD), is proposed to achieve a crisp value that represents the final safety risk perception result. A confidence indicator, δ, is put forward to measure the reliability of the safety risk perception result. A comprehensive information fusion framework that incorporates 14 influential factors is proposed to perceive the risk magnitude of tunnel-induced building damage. Six existing buildings adjacent to the excavation of Wuhan Yangtze Metro Tunnel (WYMT), China, are utilized as a case study to verify the effectiveness and applicability of the proposed approach. Results indicate that the proposed approach is capable of (i) achieving a more accurate result for safety risk perception, and (ii) identifying global sensitivities of input factors throughout a series of MC simulation enabled iterations. A discussion on how to define a reasonable membership function for configuration of BPAs is further presented. The authors recommend that the constant coefficient λ that affects the shape of the defined correlation function in BPA (Basic Probability Assignment) constructs should have a value of three, and the risk perception result can thus reach up to the highest reliability level. This approach can enable a comprehensive preliminary safety risk perception during tunnel design phases, which can further substantially reduce the risk of building damage induced by tunneling excavation. © 2017 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85020822112
"Son H., Choi H., Seong H., Kim C.","Detection of construction workers under varying poses and changing background in image sequences via very deep residual networks",2019,"Automation in Construction",61,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058003134&doi=10.1016%2fj.autcon.2018.11.033&partnerID=40&md5=e8f41906139dc8ba4bc0eb17f73d9db1","Analyzing the location and behavior of construction workers using construction site images has been recognized as a means of providing useful information for safety management and productivity analysis. Although effective utilization of analyzed image data requires accurate and timely detection of workers in complex, continuously changing working environments, the previous methods that detect construction workers still require improvement because of the poor detection performance. This study proposes the use of very deep residual networks to accurately and rapidly detect construction workers under varying poses and against changing backgrounds in image sequences. The architecture of construction worker detection in this study is based on convolutional neural networks (CNNs). The proposed method is divided into two stages: extracting feature maps via very deep residual networks (ResNet-152) and bounding box regression and labeling from the original image via Faster regions with CNN features (R-CNN). The experiments were conducted at actual construction sites by acquiring 1.3-megapixel and 3.1-megapixel images from a movable digital camera to verify the proposed method for images from fixed and moving cameras. Faster R-CNN with ResNet-152 had accuracy, precision, and recall rates of 94.3%, 96.03%, and 98.13% for 3241 images, respectively. The proposed method processed 0.2 s per frame (i.e., 5 frames per second) on average. The results show that it is possible to accurately and rapidly detect multiple workers in construction site images by employing very deep residual networks without relying on limited assumptions about workers’ postures, appearance, and background. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85058003134
"Lien L.-C., Cheng M.-Y.","Particle bee algorithm for tower crane layout with material quantity supply and demand optimization",2014,"Automation in Construction",60,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901259328&doi=10.1016%2fj.autcon.2014.05.002&partnerID=40&md5=5c227c5a7894c9db7d32e45deb270bad","The tower crane layout (TCL) problem, a typical construction site layout (CSL) problem, is currently used in a wide range of construction projects and site conditions. The tower crane is a key facility used in the vertical and horizontal transportation of materials, particularly heavy prefabrication units such as steel beams, ready-mixed concrete, prefabricated elements, and large-panel formwork. Matching the location of tower cranes to material supply and engineering demands is a combinatorial optimization issue within the TCL problem that is difficult to resolve. Swarm intelligence (SI) is a popular artificial intelligence technique that is used widely to resolve complex optimization problems. Various SI-based algorithms have been developed that emulate the collective behavior of animals such as honey bees (bee algorithm, BA) and birds (particle swarm optimization, PSO). This study applies the particle bee algorithm (PBA), a hybrid swarm algorithm that integrates the respective advantages of honey bee and bird swarms, to the TCL problem. The performances of PBA, BA, and PSO are compared in terms of their effectiveness in resolving a practical TCL problem in construction engineering. Results show that the PBA performs better than both the BA and PSO algorithms. © 2014 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84901259328
"Dai B., Gu C., Zhao E., Qin X.","Statistical model optimized random forest regression model for concrete dam deformation monitoring",2018,"Structural Control and Health Monitoring",59,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046736556&doi=10.1002%2fstc.2170&partnerID=40&md5=839096f7bd80457e9288f2cfaf38df5d","The unique structures and foundations of a dam make its safety monitoring a complex task. As the most intuitive effect of dams, deformation contains important information on dam evolution. Actual response has the purpose of diagnosis and early warning compared with model prediction. Given the poor generalization ability of the conventional statistical model, establishing a dam deformation monitoring model is thus essential. The prediction of concrete dam deformation using statistical model and random forest regression (RFR) model is studied. To build an optimized RFR model, the statistical model is used to establish input variables, select the appropriate parameters Mtry and Ntree according to out-of-bag error, and extract strong explanatory variables. The model's advantage is that the influence factors can describe concrete dam deformation, and RF can serve as a sensible new data mining tool. The importance of variables for deformation prediction is measured by RF. The RFR method can extract representative influencing factors based on variable importance. The methods are applied to an actual concrete dam. Results indicate that the RFR model can be applied for analysis and prediction of other structural behavior. Copyright © 2018 John Wiley & Sons, Ltd.",Article,"Final",Scopus,2-s2.0-85046736556
"Dai H., Zhang H., Wang W.","A multiwavelet neural network-based response surface method for structural reliability analysis",2015,"Computer-Aided Civil and Infrastructure Engineering",58,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920920672&doi=10.1111%2fmice.12086&partnerID=40&md5=8bea1bc2052b1c2ff642347f87b7fb28","A new multiwavelet neural network-based response surface method is proposed for efficient structural reliability assessment. Although multiwavelet network can be used for approximating nonlinear functions, its application has been limited to small dimension problems due to computational cost. The new method expands the application of multiwavelet network to moderate dimension by introducing a series of intermediate nodes, and the number of these intermediate nodes is determined by the multiwavelet theory. Thus, a multidimensional function learning problem is transformed into a one-dimensional function learning problem. Four examples involving one stochastic finite element-based reliability problem illustrate the effectiveness of the proposed method, which indicate that the new method is more efficient up to 10 random variables than the classical multilayer perceptron-based response surface method. © 2014 Computer-Aided Civil and Infrastructure Engineering.",Article,"Final",Scopus,2-s2.0-84920920672
"Luo X., Li H., Cao D., Yu Y., Yang X., Huang T.","Towards efficient and objective work sampling: Recognizing workers’ activities in site surveillance videos with two-stream convolutional networks",2018,"Automation in Construction",57,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050276585&doi=10.1016%2fj.autcon.2018.07.011&partnerID=40&md5=bc44e3d969b0a8917cdc87d9aff93f44","Capturing the working states of workers on foot allows managers to precisely quantify and benchmark labor productivity, which in turn enables them to evaluate productivity losses and identify causes. Work sampling is a widely used method for this task, while suffers from low efficiency as only one worker is selected for each observation. Attentional selection asymmetry can also bias its uniform object selection assumption. Existing vision-based methods are primarily oriented towards recognizing single, separated activities involving few workers or equipment. In this paper, we introduce an activity recognition method, which receives surveillance videos as input and produces diverse and continuous activity labels of individual workers in the field of view. Convolutional networks are used to recognize activities, which are encoded in spatial and temporal streams. A new fusion strategy is developed to combine the recognition results of the two streams. The experimental results show that our activity recognition method has achieved an average accuracy of 80.5%, which is comparable with the state-of-the-art of activity recognition in the computer vision community, given the severe camera motion and low resolution of site surveillance videos and the marginal inter-class difference and significant intra-class variation of workers’ activities. We also demonstrate that our method can underpin the implementation of efficient and objective work sampling. The training and test datasets of the study are publicly available. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85050276585
"Perez-Ramirez C.A., Amezquita-Sanchez J.P., Valtierra-Rodriguez M., Adeli H., Dominguez-Gonzalez A., Romero-Troncoso R.J.","Recurrent neural network model with Bayesian training and mutual information for response prediction of large buildings",2019,"Engineering Structures",54,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055645005&doi=10.1016%2fj.engstruct.2018.10.065&partnerID=40&md5=ff089e1bfa01b0e3f9ec38a4b01b067b","An accurate response prediction model is of great importance in various applications such as damage detection, structural health monitoring, and vibration control. Development of such a methodology for large civil structures is challenging because of their size and complicated behavior and noise-contaminated, nonlinear, and nonstationary nature of the signals. In addition, the prediction model must have a low computational burden for real-time applications. In this article, a new methodology and a nonlinear autoregressive exogenous model (NARX)-based recurrent neural network (NN) model is presented for accurate response prediction of large structures. The methodology is based on adroit integration of three concepts: a recent signal processing concept, empirical mode decomposition (EMD), mutual information (MI) index from the information theory, and a probabilistic Bayesian-based training algorithm. The EMD method is used to remove the noise in the measured signals. An MI index is proposed to determine the optimum number of neurons in the hidden layer of the NN model with the goal of reducing the computational requirements without affecting its performance. Finally, Bayesian regularization (BR) is proposed to train the optimized NN model. The effectiveness of the proposed methodology is assessed by predicting the structural response of a 1:20-scaled 38-story highrise building structure subjected to seismic excitations and ambient vibrations, and a five-story steel frame subjected to different levels of the Kobe earthquake. © 2018",Article,"Final",Scopus,2-s2.0-85055645005
"Zhang C., Chang C.-C., Jamshidi M.","Concrete bridge surface damage detection using a single-stage detector",2020,"Computer-Aided Civil and Infrastructure Engineering",53,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073983212&doi=10.1111%2fmice.12500&partnerID=40&md5=b72d5845141f3059d562229027bbcba0","Early and timely detection of surface damages is important for maintaining the functionality, reliability, and safety of concrete bridges. Recent advancement in convolution neural network has enabled the development of deep learning-based visual inspection techniques for detecting multiple structural damages. However, most deep learning-based techniques are built on two-stage, proposal-driven detectors using less complex image data, which could be restricted for practical applications and possible integration within intelligent autonomous inspection systems. In this study, a faster, simpler single-stage detector is proposed based on a real-time object detection technique, You Only Look Once (YOLOv3), for detecting multiple concrete bridge damages. A field inspection images dataset labeled with four types of concrete damages (crack, pop-out, spalling, and exposed rebar) is used for training and testing of YOLOv3. To enhance the detection accuracy, the original YOLOv3 is further improved by introducing a novel transfer learning method with fully pretrained weights from a geometrically similar dataset. Batch renormalization and focal loss are also incorporated to increase the accuracy. Testing results show that the improved YOLOv3 has a detection accuracy of up to 80% and 47% at the Intersection-over-Union (IoU) metrics of 0.5 and 0.75, respectively. It outperforms the original YOLOv3 and the two-stage detector Faster Region-based Convolutional Neural Network (Faster R-CNN) with ResNet-101, especially for the IoU metric of 0.75. © 2019 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85073983212
"Li H., Chan N., Huang T., Guo H.L., Lu W., Skitmore M.","Optimizing construction planning schedules by virtual prototyping enabled resource analysis",2009,"Automation in Construction",53,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-67949100453&doi=10.1016%2fj.autcon.2009.04.002&partnerID=40&md5=01bb9fefa994779b12865be9de80ae4e","The inherent uncertainty and complexity of construction work make construction planning a particularly difficult task for project managers due to the need to anticipate and visualize likely future events. Conventional computer-assisted technology can help but is often limited to the constructability issues involved. Virtual prototyping, however, offers an improved method through the visualization of construction activities by computer simulation - enabling a range of 'what-if' questions to be asked and their implications on the total project to be investigated. This paper describes the use of virtual prototyping to optimize construction planning schedules by analyzing resource allocation and planning with integrated construction models, resource models, construction planning schedules and site-layout plans. A real-life case study is presented that demonstrates the use of a virtual prototyping enabled resource analysis to reallocate space, logistic on access road and arrange tower cranes to achieve a 6-day floor construction cycle. © 2009 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-67949100453
"Liu T., Tan Z., Xu C., Chen H., Li Z.","Study on deep reinforcement learning techniques for building energy consumption forecasting",2020,"Energy and Buildings",52,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076045004&doi=10.1016%2fj.enbuild.2019.109675&partnerID=40&md5=6260b96e51b1a0c4b5c2789c4383dc85","Reliable and accurate building energy consumption prediction is becoming increasingly pivotal in building energy management. Currently, data-driven approach has shown promising performances and gained lots of research attention due to its efficiency and flexibility. As a combination of reinforcement learning and deep learning, deep reinforcement learning (DRL) techniques are expected to solve nonlinear and complex issues. However, very little is known about DRL techniques in forecasting building energy consumption. Therefore, this paper presents a case study of an office building using three commonly-used DRL techniques to forecast building energy consumption, namely Asynchronous Advantage Actor-Critic (A3C), Deep Deterministic Policy Gradient (DDPG) and Recurrent Deterministic Policy Gradient (RDPG). The objective is to investigate the potential of DRL techniques in building energy consumption prediction field. A comprehensive comparison between DRL models and common supervised models is also provided. The results demonstrate that the proposed DDPG and RDPG models have obvious advantages in forecasting building energy consumption compared to common supervised models, while accounting for more computation time for model training. Their prediction performances measured by mean absolute error (MAE) can be improved by 16%-24% for single-step ahead prediction, and 19%-32% for multi-step ahead prediction. The results also indicate that A3C performs poor prediction accuracy and shows much slower convergence speed than DDPG and RDPG. However, A3C is still the most efficient technique among these three DRL methods. The findings are enlightening and the proposed DRL methodologies can be positively extended to other prediction problems, e.g., wind speed prediction and electricity load prediction. © 2019",Article,"Final",Scopus,2-s2.0-85076045004
"Fang W., Love P.E.D., Luo H., Ding L.","Computer vision for behaviour-based safety in construction: A review and future directions",2020,"Advanced Engineering Informatics",52,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074894139&doi=10.1016%2fj.aei.2019.100980&partnerID=40&md5=f36d6e7b26a0526725e5150c557d9dff","The process of identifying and bringing to the fore people's unsafe behaviour is a core function of implementing a behaviour-based safety (BBS) program in construction. This can be a labour-intensive and challenging process but is needed to enable people to reflect and learn about how their unsafe actions can jeopardise not only their safety but that of their co-workers. With advances being made in computer vision, the capability exists to automatically capture and identify unsafe behaviour and hazards in real-time from two-dimensional (2D) digital images/videos. The corollary developments in computer vision have stimulated a wealth of research in construction to examine its potential application to practice. Hindering the application of computer vision in construction has been its inability to accurately, and generalise the detection of objects. To address this shortcoming, developments in deep learning have provided computer vision with the ability to improve the accuracy, reliability and ability to generalise object detection and therefore its usage in construction. In this paper we review the developments of computer vision studies that have been used to identify unsafe behaviour from 2D images that arises on construction sites. Then, in light of advances made with deep learning, we examine and discuss its integration with computer vision to support BBS. We also suggest that future computer-vision research should aim to support BBS by being able to: (1) observe and record unsafe behaviour; (2) understand why people act unsafe behaviour; (3) learn from unsafe behaviour; and (4) predict unsafe behaviour. © 2019 Elsevier Ltd",Review,"Final",Scopus,2-s2.0-85074894139
"Winge S., Albrechtsen E.","Accident types and barrier failures in the construction industry",2018,"Safety Science",52,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042187873&doi=10.1016%2fj.ssci.2018.02.006&partnerID=40&md5=bbf44407c5134f29658d4369859eac1a","The paper identifies frequent accident types in the construction industry, characterises the accident sequence, and identifies barrier failures for the most frequent accident types. 176 accidents in the Norwegian construction industry investigated by the Norwegian Labour Inspection Authority in 2015 are analysed. The most frequent accident types include: fall from roof, floor or platform; contact with falling objects; fall from scaffold; and contact with moving parts of a machine. A comparison of the study sample to other injury samples, showed that the distribution of accident types varied regarding severity and different construction types. This can be explained by differences in work type, hazard, and energy type and energy amount. An analysis of barrier failures showed that many accidents are explained by the lack of physical barrier elements. The results indicate that there is significant potential for accident prevention in the construction industry by systematic barrier management. © 2018 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85042187873
"Lei H., Wang R., Zhang T., Liu Y., Zha Y.","A multi-objective co-evolutionary algorithm for energy-efficient scheduling on a green data center",2016,"Computers and Operations Research",51,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973293503&doi=10.1016%2fj.cor.2016.05.014&partnerID=40&md5=e868bb606d28bea18f26336aa9e5ea46","Nowadays, the environment protection and the energy crisis prompt more computing centers and data centers to use the green renewable energy in their power supply. To improve the efficiency of the renewable energy utilization and the task implementation, the computational tasks of data center should match the renewable energy supply. This paper considers a multi-objective energy-efficient task scheduling problem on a green data center partially powered by the renewable energy, where the computing nodes of the data center are DVFS-enabled. An enhanced multi-objective co-evolutionary algorithm, called OL-PICEA-g, is proposed for solving the problem, where the PICEA-g algorithm with the generalized opposition based learning is applied to search the suitable computing node, supply voltage and clock frequency for the task computation, and the smart time scheduling strategy is employed to determine the start and finish time of the task on the chosen node. In the experiments, the proposed OL-PICEA-g algorithm is compared with the PICEA-g algorithm, the smart time scheduling strategy is compared with two other scheduling strategies, i.e., Green-Oriented Scheduling Strategy and Time-Oriented Scheduling Strategy, different parameters are also tested on the randomly generated instances. Experimental results confirm the superiority and effectiveness of the proposed algorithm. © 2016 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84973293503
"Deng J., Lu Y., Lee V.C.-S.","Concrete crack detection with handwriting script interferences using faster region-based convolutional neural network",2020,"Computer-Aided Civil and Infrastructure Engineering",50,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072170902&doi=10.1111%2fmice.12497&partnerID=40&md5=49657fb9e6278415f29f781a49347dcb","The current bridge maintenance practice generally involves manual visual inspection, which is highly subjective and unreliable. A technique that can automatically detect defects, for example, surface cracks, is essential so that early warnings can be triggered to prevent disaster due to structural failure. In this study, to permit automatic identification of concrete cracks, an ad-hoc faster region-based convolutional neural network (faster R-CNN) was applied to contaminated real-world images taken from concrete bridges with complex backgrounds, including handwriting. A dataset of 5,009 cropped images was generated and labeled for two different objects, cracks and handwriting. The proposed network was then trained and tested using the generated image dataset. Four full-scale images that contained complex disturbance information were used to assess the performance of the trained network. The results of this study demonstrate that faster R-CNN can automatically locate crack from raw images, even with the presence of handwriting scripts. For comparative study, the proposed network is also compared with You Only Look Once v2 detection technique. © 2019 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85072170902
"Xue X., Zhang X., Wang L., Skitmore M., Wang Q.","Analyzing collaborative relationships among industrialized construction technology innovation organizations: A combined SNA and SEM approach",2018,"Journal of Cleaner Production",50,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009731516&doi=10.1016%2fj.jclepro.2017.01.009&partnerID=40&md5=d3eef0b5ac56a7d25415e745c1bf2d51","Industrialized construction technology (ICT) is widely used and becoming the new green construction method, but its development is being hindered by lack of innovation. To improve this, stakeholders are endeavoring to develop more innovative methods by inter-organizational collaboration. Despite its extensive use by other industries such as manufacturing, little is known of how to successfully apply collaborative innovation to ICT. This paper develops a method for studying the effects of a variety of aspects of existing collaborative relationships for ICT innovation using a combination of social network analysis (SNA) and structural equation modeling (SEM). A set of hypotheses are proposed concerning the expected influence of SNA factors of interaction frequency, emotional intensity, reciprocal exchange, network size, network density, centrality, relationship strength, network position, promotion, enterprise scale, nature and experience on collaborative innovation. Using questionnaire data obtained from a large sample of practitioners, SEM is then used to identify the key indicators involved and the extent of their effects on innovation. The paper constructs a collaborative ICT innovation relationship model in which the strengths of the interaction paths between stakeholders are obtained. With a single exception, this confirms all the hypotheses. Most of the SNA-based a priori hypotheses are shown to be well supported, which indicates the suitability of the SNA concept in developing collaborative ICT innovation. SNA is therefore confirmed as providing a suitable conceptual basis for the modeling and analysis of ICT innovation relationships. From this, a set of recommendations are provided to guide operating companies, designers and contractors in improving their collaborative innovation efforts. The results enable suggestions for enhancing collaborative ICT innovation capacity to be advanced to promote the interaction between stakeholders and the occupation of strategic positions. Although the study is carried out in the context of China's prefabricated housing construction, the methods can be adopted in the broader global community. © 2017 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85009731516
"Zhou P., El-Gohary N.","Ontology-based automated information extraction from building energy conservation codes",2017,"Automation in Construction",49,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002202500&doi=10.1016%2fj.autcon.2016.09.004&partnerID=40&md5=09c305596032efd11594ac842aa5d795","An ontology-based information extraction algorithm for automatically extracting energy requirements from energy conservation codes is proposed. The proposed algorithm aims to support fully-automated energy compliance checking in the construction domain by allowing automated extraction of the requirements from the codes instead of the status quo which relies on manual extraction of requirements from codes and manual formalization of those requirements in a computer-processable format. Automated information extraction from energy conservation codes, compared to other building codes, is a far complex task because many code provisions are long, hierarchically-complex, and with exceptions. A combination of text classification methods, domain-specific preprocessing techniques, ontology-based pattern-matching extraction techniques, sequential dependency-based extraction methods, and cascaded extraction methods is proposed to deal with such complexity in extraction. The proposed algorithm was tested in extracting energy requirements from Chapter 4 of the 2012 International Energy Conservation Code, and the results showed 97.4% recall and 98.5% precision. © 2016 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85002202500
"Purdy M., Daugherty P.","Why artificial intelligence is the future of growth",2016,"Accenture",49,,[No abstract available],,"Final",Scopus,2-s2.0-85027305052
"Plebankiewicz E., Kubek D.","Multicriteria selection of the building material supplier using AHP and fuzzy AHP",2016,"Journal of Construction Engineering and Management",48,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950161896&doi=10.1061%2f%28ASCE%29CO.1943-7862.0001033&partnerID=40&md5=42268972781faf69cfab070db8af7c6e","When selecting a building material supplier, contractors may take into consideration a large number of criteria that are often subjective and hard to measure. Including them all in the evaluation may be beneficial, yet in practice it may generate many complications. A solution is provided by one of the multicriteria analysis methods. The article describes the criteria employed in the evaluation of building material suppliers. One multicriteria analysis method, namely the analytic hierarchical process (AHP), is argued to be a useful alternative. An example of its application involving its basic and the more sophisticated variant, the fuzzy analytic hierarchical process (FAHP) with extent analysis method, is presented. As the results reveal, real decisive problems require methods resembling human reasoning, which is often characterized by uncertainty and subjectivity of evaluation. The real problem presented in the paper proves that the FAHP method may have a practical application. © 2015 American Society of Civil Engineers.",Conference Paper,"Final",Scopus,2-s2.0-84950161896
"Patel D.A., Jha K.N.","Structural Equation Modeling for Relationship-Based Determinants of Safety Performance in Construction Projects",2016,"Journal of Management in Engineering",47,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991574481&doi=10.1061%2f%28ASCE%29ME.1943-5479.0000457&partnerID=40&md5=7a191200bf905c7c5614b60ffca8b910","Safety performance in construction projects is attributed to many determinants (factors) in a safety system. This study identifies various directly or indirectly related determinants and their effects on safety performance of construction projects. Using structural equation modeling (SEM), this study empirically examines the effect of safety climate (SC), hazard management (HM), safety budget (SB), safety rules and regulations (SR), and safe work behavior (WB) of employees and workers on safety performance (SP) of projects. The unit of analysis of this study is a construction project. A questionnaire survey was conducted, and 230 responses were collected from different types of construction projects across India. The results provide evidence that safety climate, safety budget, and hazard management positively influence safe work behavior of employees and the safety performance of the project. Conversely, the SEM findings demonstrate that implementation of safety rules and regulations are positively but weakly related to safe work behavior of employees, although they positively and more strongly influence the safety performance of the project. On the basis of these empirical results, the study advocates allocating a sufficient safety budget to Indian construction projects. It also recommends considering the effects of the safety rules and regulations on safe work behavior of employees and workers while framing and revising them. © 2016 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84991574481
"Zhang J., Xiao M., Gao L., Chu S.","Probability and interval hybrid reliability analysis based on adaptive local approximation of projection outlines using support vector machine",2019,"Computer-Aided Civil and Infrastructure Engineering",46,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068523259&doi=10.1111%2fmice.12480&partnerID=40&md5=c7386a6aa326f2c35a8c1c03fdcc8109","This paper investigates structural reliability analysis with both random and interval variables, which is defined as a three-classification problem and handled by support vector machine (SVM). First, it is determined that projection outlines on the limit-state surface are crucial for describing separating hyperplanes of the three-classification problem. Compared with the whole limit-state surface, the region of projection outlines are much smaller. It will be beneficial to reduce the number of update points and the computational cost if SVM update concentrates on refining the approximate projection outlines. An adaptive local approximation method is developed to realize that the initial built SVM model is sequentially updated by adding new training samples located around the projection outlines. Using this method, the separating hyperplanes can be accurately and efficiently approximated by SVM. Finally, a new method is proposed to evaluate the failure probability interval based on Monte Carlo simulation and the refined SVM. © 2019 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85068523259
"Talatahari S., Gandomi A.H., Yang X.-S., Deb S.","Optimum design of frame structures using the Eagle Strategy with Differential Evolution",2015,"Engineering Structures",46,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924587874&doi=10.1016%2fj.engstruct.2015.02.026&partnerID=40&md5=07429e394f3e5603892c25ac2b95e5a9","Modern metaheuristic algorithms are in general suited for global optimization. This paper combines the recently developed eagle strategy algorithm with differential evolution. The new algorithm, denoted as the ES-DE, is implemented by interfacing SAP2000 structural analysis code and MATLAB mathematical software. The performance of the ES-DE is evaluated by solving four benchmark problems where the objective is to minimize the weight of steel frames. The optimized designs obtained by the proposed algorithm are better than those found by the standard differential evolution algorithm and also very competitive with literature. The overall convergence behavior is significantly enhanced by the hybrid optimization strategy. © 2015 Elsevier Ltd.",Article,"Final",Scopus,2-s2.0-84924587874
"Bureerat S., Pholdee N.","Optimal Truss Sizing Using an Adaptive Differential Evolution Algorithm",2016,"Journal of Computing in Civil Engineering",45,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959010665&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000487&partnerID=40&md5=51d23d1b71db76299ad9cd2ca9cda99b","Truss sizing optimization is one of the structural design problems that are most difficult to solve, since it may have a nonconvex feasible region in cases of statically indeterminate trusses with stress and displacement constraints. The successful use of metaheuristics to solve such a design problem, which has been found to be effective, has been studied for several decades. This paper presents a new metaheuristic for truss sizing design. The method is based on differential evolution concepts while a strategically adaptive scheme is employed. Also a new, simple, but efficient constraint handling technique is proposed so as to effectively deal with design constraints. Numerical tests show that the proposed optimizer is powerful and can be compared with the best performers found in the literature. © 2015 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84959010665
"Wang M., Cheng J.C.P.","A unified convolutional neural network integrated with conditional random field for pipe defect segmentation",2020,"Computer-Aided Civil and Infrastructure Engineering",44,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075283082&doi=10.1111%2fmice.12481&partnerID=40&md5=1146f146e1a1f6f02116ea69a2c25cff","Semantic segmentation of closed-circuit television (CCTV) images can facilitate automatic severity assessment of sewer pipe defects by assigning defect labels to each pixel on the image, from which defect types, locations, and geometric information can be obtained. In this study, a unified neural network, namely DilaSeg-CRF, is proposed by fully integrating a deep convolutional neural network (CNN) with dense conditional random field (CRF) for improving the segmentation accuracy. First, DilaSeg is constructed with dilated convolution and multiscale techniques for producing feature maps with high resolution. The steps of the dense CRF inference algorithm are converted into CNN operations, which are then formulated as recurrent neural network (RNN) layers. The DilaSeg-CRF is proposed by integrating DilaSeg with the RNN layers. Images containing three common types of sewer defects are collected from CCTV inspection videos and are annotated with ground truth labels, after which the proposed models are trained and evaluated. Experiments demonstrate that the end-to-end trainable DilaSeg-CRF can improve the segmentation significantly, with an increase of 32% and 20% in mean intersection over union (mIoU) values compared with fully convolutional network (FCN-8s) and DilaSeg, respectively. Our proposed DilaSeg-CRF also achieves faster inference speed than FCN and eliminates the manual postprocessing for refining the segmentation results. © 2019 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85075283082
"Chen C., Zhu Z., Hammad A.","Automated excavators activity recognition and productivity analysis from construction site surveillance videos",2020,"Automation in Construction",43,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076095962&doi=10.1016%2fj.autcon.2019.103045&partnerID=40&md5=7cbc3cb26b85e0e347feec26b539b19d","The productivity of construction equipment plays an important role in completing construction projects within schedule and under budget. However, the current productivity monitoring on construction sites highly depends on manually observing and recording equipment activities, which is labor-intensive and time-consuming. To address this problem, an increasing number of research studies focused on automatically identifying equipment activities from site surveillance videos. However, these studies failed to accurately conduct the activity recognition and productivity analysis, when multiple pieces of equipment are working together. This research proposes a novel framework for automatically analyzing the activity and productivity of multiple excavators. In this framework, three convolutional neural networks are designed to detect, track and recognize the activities of excavators. The results are further compiled to analyze excavator's activity time, working cycle, and productivity. The proposed framework has been tested with the videos recorded from real construction sites. The overall activity recognition has achieved 87.6% accuracy. The productivity calculation has achieved 83% accuracy, which indicates the feasibility of the proposed framework for automating the monitoring of excavator's productivity. © 2019 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85076095962
"Arashpour M., Kamat V., Bai Y., Wakefield R., Abbasi B.","Optimization modeling of multi-skilled resources in prefabrication: Theorizing cost analysis of process integration in off-site construction",2018,"Automation in Construction",43,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050980752&doi=10.1016%2fj.autcon.2018.07.027&partnerID=40&md5=ee96921bb33dd721e10588ec31db30c6","In advanced manufacturing of building elements, process integration and utilization of multi-skilled resources enhance the flexibility of production networks against variations in demand and resource availability. This research study aims to incorporate the required cost and time for cross-training multi-skilled resources into resource planning computations. Towards this aim, minimizing the cost of utilizing multi-skilled resources in off-site construction is formulated using integer and probabilistic optimization models. Production data of two prefabrication networks in Brisbane and Melbourne, Australia are used to derive computational results and validate models. The main contribution of this research study is to analyze the costeffectiveness of deploying multi-skilled resources with the aim of improving production flexibility. The modeling methodology and findings are of practical use to off-site manufacturers that experience variations in production demand and resource availability. © 2018",Article,"Final",Scopus,2-s2.0-85050980752
"Liu W., Zhao T., Zhou W., Tang J.","Safety risk factors of metro tunnel construction in China: An integrated study with EFA and SEM",2018,"Safety Science",42,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041851125&doi=10.1016%2fj.ssci.2018.01.009&partnerID=40&md5=daf8422f280cf7844f188d3e01894340","In this work, we proposed a systematic method by integrating exploratory factor analysis (EFA) and structural equation model (SEM) to examine the risk factors for the safety of metro construction. We collected 514 valid questionnaire responses from metro construction personnel in five cities, from which nine common risk factors out of 65 questionnaire items were extracted. The relationships between the individual factors were examined by SEM, and the established model was validated by hypothesis testing and goodness-of-fit tests. The influence of individual factors for the safety in metro construction was characterized by the path coefficient in the model. Real tunnel accident cases in the Wuhan Metro of China were utilized to demonstrate the feasibility and applicability of the proposed EFA-SEM approach. It was found that safety was profoundly influenced by the risks associated with the launching and arrival of tunnel boring machine (TBM) and the risks during tunnel excavation that involved special procedures and conditions. In contrast, the risks pertaining to shaft construction did not have a statistically significant impact on safety. The developed method clarified the causal relationships within a complex project and allowed finding the predominant risk factors, thus providing a guideline to improve safety management for metro construction. © 2018 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85041851125
"Chi C.-F., Lin S.-Z., Dewi R.S.","Graphical fault tree analysis for fatal falls in the construction industry",2014,"Accident Analysis and Prevention",42,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907329920&doi=10.1016%2fj.aap.2014.07.019&partnerID=40&md5=d89cf5702a3548aeb834a5aabe342455","The current study applied a fault tree analysis to represent the causal relationships among events and causes that contributed to fatal falls in the construction industry. Four hundred and eleven work-related fatalities in the Taiwanese construction industry were analyzed in terms of age, gender, experience, falling site, falling height, company size, and the causes for each fatality. Given that most fatal accidents involve multiple events, the current study coded up to a maximum of three causes for each fall fatality. After the Boolean algebra and minimal cut set analyses, accident causes associated with each falling site can be presented as a fault tree to provide an overview of the basic causes, which could trigger fall fatalities in the construction industry. Graphical icons were designed for each falling site along with the associated accident causes to illustrate the fault tree in a graphical manner. A graphical fault tree can improve inter-disciplinary discussion of risk management and the communication of accident causation to first line supervisors. © 2014 Elsevier Ltd.",Article,"Final",Scopus,2-s2.0-84907329920
"Louis J., Dunston P.S.","Integrating IoT into operational workflows for real-time and automated decision-making in repetitive construction operations",2018,"Automation in Construction",41,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050162511&doi=10.1016%2fj.autcon.2018.07.005&partnerID=40&md5=370ce59fdef4b5945bea7685c3261d31","Construction operations are typically spread across large areas and require remote collaboration between multiple disparate resources—characteristics that create logistical challenges for making and automating decisions on the worksite. This paper provides a framework for leveraging the growing ubiquity of devices that can be considered part of the internet of things (IoT) to inform real-time decision-making on the construction site. Specifically, systems and control theory concepts are implemented by first synthesizing sensor information at their point of origin into resource state, and then using this state as feedback into a process model of the operation. Decisions that are programed into the process model are then made automatically based on real-time status of the operation and relayed back to the entities on the construction site through the IoT infrastructure. The real-time decision-making capabilities enabled by the presented methodology and its associated benefits to construction performance are demonstrated through the use of a virtual experimental platform that simulates a potential implementation of IoT-enabled control on the construction worksite for an earthmoving operation. This research provides a practical and sensor-agnostic implementation of operation-level decision-making by utilizing IoT networks along with advancements in modeling and simulation tools. This paper illustrates the types of insights that can be synthesized from an operations-level IoT network that gathers and transmits information in real time from various locations of the worksite. Currently and without the use of the prescribed methodology, such actionable insight would be impractical, cost-prohibitive, and even impossible to obtain. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85050162511
"Pan Y., Ou S., Zhang L., Zhang W., Wu X., Li H.","Modeling risks in dependent systems: A Copula-Bayesian approach",2019,"Reliability Engineering and System Safety",40,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063521161&doi=10.1016%2fj.ress.2019.03.048&partnerID=40&md5=5815b033cabf32f27a957b6afb6ac739","This paper develops a hybrid Copula–Bayesian-based approach to model the structural health of an operational metro tunnel in a dependent system, where risk factors interact with each other. Aiming to rectify drawbacks of discrete Bayesian networks, the Gaussian copula and different marginal distributions are involved to build up complicated interactions among possible risk factors and structural health state more precisely and rationally. To achieve systematic and real-time decision support for safety insurance during the entire life cycle of risk-prone systems, model analytics is conducted to perform correlation analysis, forward reasoning, and backward reasoning. For demonstrating the effectiveness of the method, it is applied to a realistic cross-river tunnel, the Wuhan Yangtze Metro Tunnel in China, where all the concerning risk factors are water-related rooting in water leakage, poor construction quality, exterior load, and others. Due to the availability of vault displacement by sensors, it can herein represent the structural health to explore the impacts of risk factors. Larger vault displacement implies higher risk in the overall safety condition of the tunnel structure. This research contributes to (a) the state of knowledge by integrating Bayesian networks with copula, contributing to a more robust risk assessment by accurately modeling the complex dependence structure of risk factors; (b) the state of practice by providing guidelines of the whole-life-cycle safety control for complex systems under uncertainty and randomness, which not only prevent structural failure in advance but also control risk after accident occurrence. © 2019 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85063521161
"Qin S., Zhang Y., Zhou Y.-L., Kang J.","Dynamic model updating for bridge structures using the kriging model and PSO algorithm ensemble with higher vibration modes",2018,"Sensors (Switzerland)",40,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048333684&doi=10.3390%2fs18061879&partnerID=40&md5=e48770c0606475ee47237aff68276055","This study applied the kriging model and particle swarm optimization (PSO) algorithm for the dynamic model updating of bridge structures using the higher vibration modes under large-amplitude initial conditions. After addressing the higher mode identification theory using time-domain operational modal analysis, the kriging model is then established based on Latin hypercube sampling and regression analysis. The kriging model performs as a surrogate model for a complex finite element model in order to predict analytical responses. An objective function is established to express the relative difference between analytically predicted responses and experimentally measured ones, and the initial finite element (FE) model is hereinafter updated using the PSO algorithm. The Jalón viaduct—a concrete continuous railway bridge—is applied to verify the proposed approach. The results show that the kriging model can accurately predict the responses and reduce computational time as well. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.",Article,"Final",Scopus,2-s2.0-85048333684
"Lu Q., Parlikad A.K., Woodall P., Don Ranasinghe G., Xie X., Liang Z., Konstantinou E., Heaton J., Schooling J.","Developing a Digital Twin at Building and City Levels: Case Study of West Cambridge Campus",2020,"Journal of Management in Engineering",39,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081580153&doi=10.1061%2f%28ASCE%29ME.1943-5479.0000763&partnerID=40&md5=80fae89f7ab8ce83fa81ca1fb8ba1ed8","A digital twin (DT) refers to a digital replica of physical assets, processes, and systems. DTs integrate artificial intelligence, machine learning, and data analytics to create living digital simulation models that are able to learn and update from multiple sources as well as represent and predict the current and future conditions of physical counterparts. However, current activities related to DTs are still at an early stage with respect to buildings and other infrastructure assets from an architectural and engineering/construction point of view. Less attention has been paid to the operation and maintenance (O&M) phase, which is the longest time span in the asset life cycle. A systematic and clear architecture verified with practical use cases for constructing a DT would be the foremost step for effective operation and maintenance of buildings and cities. According to current research about multitier architectures, this paper presents a system architecture for DTs that is specifically designed at both the building and city levels. Based on this architecture, a DT demonstrator of the West Cambridge site of the University of Cambridge in the UK was developed that integrates heterogeneous data sources, supports effective data querying and analysis, supports decision-making processes in O&M management, and further bridges the gap between human relationships with buildings/cities. This paper aims at going through the whole process of developing DTs in building and city levels from the technical perspective and sharing lessons learned and challenges involved in developing DTs in real practices. Through developing this DT demonstrator, the results provide a clear roadmap and present particular DT research efforts for asset management practitioners, policymakers, and researchers to promote the implementation and development of DT at the building and city levels. © 2020 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85081580153
"Martinez P., Al-Hussein M., Ahmad R.","A scientometric analysis and critical review of computer vision applications for construction",2019,"Automation in Construction",39,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071757853&doi=10.1016%2fj.autcon.2019.102947&partnerID=40&md5=93a5c539fea26a5aa5b3149e92f58e3a","Practical interest in ‘computer vision’ has risen remarkably over the last 20 years, transforming the current state of construction-related research and attracting the worldwide attention of scholars and practitioners. This study conducts a scientometric review of the global research published between 1999 and 2019 on computer vision applications for construction, through co-author, co-citation, keyword and clustering analysis. A total of 1158 journals and conference proceedings from Scopus database were analyzed. Trends within the field are identified, as are the dominant sub-fields and their interconnections, as well as citation patterns, key publications, key research institutions, key researchers, and key journals, along with the extent to which these interact with each other in research networks. The provided results were analyzed to identify the deficiencies in current research and propose future trends. Among these is a bias in the research literature towards traditional on-site construction and a concerning gap of off-site construction research, as well as a lack of inter-relationships and collaboration between researched areas, the researchers themselves, and/or the research institutions. In the near future, computer vision will play a key role in the future development of smart construction and improvement of quality in construction projects. This study hopes to bring awareness to the industry, the journal editors, and the researchers of the need for a deeper exchange of ideas in any future research efforts. © 2019 Elsevier B.V.",Review,"Final",Scopus,2-s2.0-85071757853
"Gao Y., Kong B., Mosalam K.M.","Deep leaf-bootstrapping generative adversarial network for structural image data augmentation",2019,"Computer-Aided Civil and Infrastructure Engineering",39,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069682915&doi=10.1111%2fmice.12458&partnerID=40&md5=67d0ea96d7c569da361835b64e52c459","Employing Deep Learning (DL) technologies to solve Civil Engineering problems is an emerging topic in recent years. However, due to the lack of labeled data, it is difficult to obtain accurate results with DL. One commonly used method to tackle this issue is to use affine transformation to augment the data set, but it can only generate new images that are highly correlated with the original ones. Moreover, unlike normal natural objects, distribution of structural images is much more complex and mixed. To address these challenges, Generative Adversarial Network (GAN) can be one feasible choice. We introduce one specific generative model, namely, Deep Convolutional Generative Adversarial Network (DCGAN) and propose a Leaf-Bootstrapping (LB) method to improve the performance of this DCGAN. To effectively and quantitatively evaluate the quality of the synthetic images generated by DCGAN to complement human evaluation, Self-Inception Score (SIS) and Generalization Ability (GA) are proposed. We also propose a pipeline based on Transfer Learning (TL) using synthetic images to help enhance a weak classifier performance under the condition of low-data regime and limited computational resources. Finally, we conduct computer experiments with the proposed methods for two scenarios (scene level identification and damage state check) and one special synthetic data aggregation case. The results demonstrate the effectiveness and robustness of the proposed methods. © 2019 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85069682915
"Roy A., Manna R., Chakraborty S.","Support vector regression based metamodeling for structural reliability analysis",2019,"Probabilistic Engineering Mechanics",39,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056770436&doi=10.1016%2fj.probengmech.2018.11.001&partnerID=40&md5=b9f289d9a06f1ccd7c29de780c0fc98b","Various metamodeling approaches e.g. polynomial response surface method artificial neural network, Kriging method etc. have been emerged as an effective alternative for solving computationally challenging complex reliability analysis problems involving finite element response analysis. However, such approaches are primarily based on the principle of empirical risk minimization. The support vector machine for regression i.e. the support vector regression (SVR) which is based on structural risk minimization has revealed improved abilities of response approximation using small sample learning. The implementation of SVR model requires to optimize a loss function involving the loss function parameter, regularization parameter and also kernel function parameter(s) to tackle nonlinear problems. The success of SVR largely depends on proper choice of such parameters. A simple yet effective algorithm by solving an optimization sub-problem to minimize the mean square error value obtained by cross-validation method is investigated in the present study to construct SVR model for structural reliability analysis. The effectiveness of the algorithm is demonstrated numerically by comparing various computed statistical metrics obtained by the most accurate direct Monte Carlo Simulation (MCS) technique. The performance of SVR based metamodel to estimate the reliability is also studied by comparing the results with the direct MCS based results. © 2018 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85056770436
"Prascevic N., Prascevic Z.","Application of fuzzy AHP for ranking and selection of alternatives in construction project management",2017,"Journal of Civil Engineering and Management",37,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038807036&doi=10.3846%2f13923730.2017.1388278&partnerID=40&md5=adc619f96163ebc2156825782c42180b","The construction project management (CPM) is very important and large segment of entire project management (PM). Realisation of construction projects is usually long term process which requests significant financial, material, human and other resources to fulfil contracted obligations and achieve a good quality of works. Therefore, making good decisions with the satisfaction of various criteria is one of the main conditions to achieve planed business objectives and finish the project in contracted time with good quality. This paper proposes a new procedure for determination of the weights of criteria and alternatives in the Fuzzy analytic hierarchy process (FAHP) with trapezoidal fuzzy number using a new method for finding eigenvelues and eigenvectors of the criteria and alternatives, which is based on expected values of the fuzzy numbers and their products. Local and global fuzzy weights of the alternatives are determined using linear programming. In the paper a formula for ranking fuzzy numbers by reduced generalized fuzzy mean is also proposed, since ranking by the coefficient of variation is not always reliable. In the presented case study, applying proposed method, from imprecise input data are obtained enough accurate and useful results for rational ranking of alternatives related to the project realization. © 2017 Vilnius Gediminas Technical University (VGTU) Press.",Article,"Final",Scopus,2-s2.0-85038807036
"Zhou Q., Zhou H., Zhou Q., Yang F., Luo L., Li T.","Structural damage detection based on posteriori probability support vector machine and Dempster-Shafer evidence theory",2015,"Applied Soft Computing Journal",37,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939144627&doi=10.1016%2fj.asoc.2015.06.057&partnerID=40&md5=cbf39d42f5130ef380773ffdc9d5f7fc","An intelligent detection method is proposed in this paper to enrich the study of applying machine learning and data mining techniques to building structural damage identification. The proposed method integrates the multi-sensory data fusion and classifier ensemble to detect the location and extent of the damage. First, the wavelet package analysis is used to transform the original vibration acceleration signal into energy features. Then the posteriori probability support vector machines (PPSVM) and the Dempster-Shafer (DS) evidence theory are combined to identify the damage. Empirical study on a benchmark structure model shows that, compared with popular data mining approaches, the proposed method can provide more accurate and stable detection results. Furthermore, this paper compares the detection performance of the information fusion at different levels. The experimental analysis demonstrates that the proposed method with the fusion at the decision level can make good use of multi-sensory information and is more robust in practice. © 2015 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84939144627
"Wee Y.Y., Cheah W.P., Tan S.C., Wee K.","A method for root cause analysis with a Bayesian belief network and fuzzy cognitive map",2015,"Expert Systems with Applications",37,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906922361&doi=10.1016%2fj.eswa.2014.06.037&partnerID=40&md5=2af6a5fbcc86b08026f61df8869fdd89","People often want to know the root cause of things and events in certain application domains such as intrusion detection, medical diagnosis, and fault diagnosis. In many of these domains, a large amount of data is available. The problem is how to perform root cause analysis by leveraging the data asset at hand. Root cause analysis consists of two main functions, diagnosis of the root cause and prognosis of the effect. In this paper, a method for root cause analysis is proposed. In the first phase, a causal knowledge model is constructed by learning a Bayesian belief network (BBN) from data. BBN's backward and forward inference mechanisms are used for the diagnosis and prognosis of the root cause. Despite its powerful reasoning capability, the representation of causal strength in BBN as a set of probability values in a conditional probability table (CPT) is not intuitive at all. It is at its worst when the number of probability values needed grows exponentially with the number of variables involved. Conversely, a fuzzy cognitive map (FCM) can provide an intuitive interface as the causal strength is simply represented by a single numerical value. Hence, in the second phase of the method, an intuitive interface using FCM is generated from the BBN-based causal knowledge model, applying the migration framework proposed and formulated in this paper. © 2014 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84906922361
"Moon H., Kim H., Kamat V.R., Kang L.","BIM-based construction scheduling method using optimization theory for reducing activity overlaps",2015,"Journal of Computing in Civil Engineering",36,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928035423&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000342&partnerID=40&md5=fb28112d498cf3d9a8d00eafbfba4f52","As building information modeling (BIM) systems continue to be widely adopted, there is an increasing demand for an active construction schedule management system with more advanced decision-making capabilities. For example, if overlapping between construction activities is significant, the performance of construction operations for the corresponding activities may deteriorate. Thus, a viable construction schedule should be formulated in order to minimize overlapping of proximate construction activities. An active system can be regarded as a certain solution for this issue. The purpose of this study is to develop a systematic methodology and computer system for an optimal construction schedule simulation that minimize overlapping activities for the enhancement of a project's operational performance. This study centers on identifying overlapping activities, applying fuzzy theory, and analyzing risk levels for schedule overlap issues. In addition, genetic algorithm (GA) theory is adopted for the minimization of the overlapping of highly risky activities. Finally, an optimal construction schedule that minimizes overlapping activities is suggested. The optimal schedule is visualized in a BIM-based four-dimensional (4D) computer-aided design (CAD) environment. The 4D CAD system developed in this study includes fuzzy and GA analysis functions with a schedule simulator. A case study on an actual project is introduced to validate the effectiveness of the proposed methodology. © 2014 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84928035423
"Zhang L., Ashuri B.","BIM log mining: Discovering social networks",2018,"Automation in Construction",35,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042935815&doi=10.1016%2fj.autcon.2018.03.009&partnerID=40&md5=f83d43f62c5863488daa465eb94a0eda","This research develops a systematic methodology to deeply mine tremendous volumes of design logs (that are generated from Building Information Model (BIM) design process) to discover social networks in BIM-based collaborative design practices and examine the relationship between the characteristics of the design social network and production performance of designers. Firstly, a data extraction procedure consisting of data harvesting, parsing, and cleaning is proposed to obtain BIM design logs in a Comma Separated Values (CSV) format from several designers over the course of working on multiple projects. Secondly, a metric of working together on joint cases is proposed to build up a weighted sociogram that is consisting of performers P, relations R, and weights W. Lastly, a number of indicators are defined to measure and analyze structural characteristics of the discovered BIM-based collaborative network at macro-, meso-, and micro- levels. A dataset of design logs that involves 51 designers working on 82 projects with 620,492 lines of commands, provided by a major international design firm, is used as a case study to demonstrate the feasibility and applicability of the developed approach in this research. Results indicate that: (i) Strong positive correlations exist across all centrality measures calculated based on the discovered social network of BIM-based collaborative design where designers located in the center of the interaction map (with the greatest degree centralities), such as designers “#2” and “#24”, are generally those who provide the shortest communication channels (with highest betweenness centralities) and are most reachable for others (with highest closeness centralities); and (ii) All the node centrality measures are significantly and positively related to the production performance of designers in the BIM-based collaborative network. Particularly, the measured node degree centrality by weight is capable of explaining the greatest percentage of variations (71.13%) in the production performance of designers. This research contributes to: (a) The state of knowledge by proposing a novel methodology that is capable of capturing and modeling collaborations among designers from tremendous event logs to discover social networks; and (b) The state of practice by providing insight into a better understanding of relationships between sociological network characteristics and production performance of designers within a design firm. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85042935815
"Ardiny H., Witwicki S., Mondada F.","Construction automation with autonomous mobile robots: A review",2015,"International Conference on Robotics and Mechatronics, ICROM 2015",35,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962339712&doi=10.1109%2fICRoM.2015.7367821&partnerID=40&md5=9963f38e5f1a459c960c7a2cdfd0b6ca","In this paper, we review state-of-the-art research into automated construction by autonomous mobile robots. Today, space research agencies seek to build infrastructure without human intervention; and construction companies look to robots as having the potential to achieve improvements in construction quality, efficiency, and safety, not to mention flexibility in architectural design. This paper addresses and classifies the relevant studies in terms of applications, materials, and robotic systems. We also identify ongoing challenges and discuss about future robotic requirements for the automated construction. © 2015 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84962339712
"Salata F., Ciancio V., Dell'Olmo J., Golasi I., Palusci O., Coppi M.","Effects of local conditions on the multi-variable and multi-objective energy optimization of residential buildings using genetic algorithms",2020,"Applied Energy",34,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076002994&doi=10.1016%2fj.apenergy.2019.114289&partnerID=40&md5=9fd48d60e7b3e50068c814b7581fd310","The energy requalification of existing buildings entails the fulfillment of different, often conflicting, criteria, such as the reduction of the specific annual energy demand, the containment of the construction costs, the decrease in the annual energy operating cost and the reduction of climate-change gas emissions. Therefore, optimization methods based on the application of computational algorithms are essential to determine solutions that meet multi-objective criteria and so highly optimized to be on the Pareto frontier. In this work, a procedure for the optimization of existing buildings using genetic algorithms is presented. Building energy simulations conducted in the dynamic regime using EnergyPlus are coupled with an Active Archive Non-dominated Sorting Genetic Algorithm (aNSGA-II type). Using a residential building as a benchmark, this procedure is employed to evaluate the best retrofitting interventions for 19 European cities with different climates. The criteria taken into account in the optimization procedure are: the reduction in the annual specific energy demand, the decrease in the construction and installation costs, the reduction in the annual energy operating costs and the reduction in the greenhouse gas emissions. The results show the most advantageous energy retrofitting interventions fulfilling the criteria for the different geographical sites. © 2019 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85076002994
"Shirowzhan S., Sepasgozar S.M.E., Li H., Trinder J., Tang P.","Comparative analysis of machine learning and point-based algorithms for detecting 3D changes in buildings over time using bi-temporal lidar data",2019,"Automation in Construction",34,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066035575&doi=10.1016%2fj.autcon.2019.102841&partnerID=40&md5=a7c115e8cfcb480f4ebaf1af87281219","Building Change Detection techniques are critical for monitoring building changes and deformations, construction progress tracking, structural deflections and disaster management. However, the performance of relevant algorithms on airborne light detection and ranging (lidar) data sets have not been comparatively evaluated, when such data sets are increasingly being used for construction purposes due to their capability of providing volumetric information of objects. This study aims to suggest appropriate building change detection algorithms based on a comparative evaluation of the performance of five selected algorithms including three pixel-based algorithms, Digital Surface Model differencing (DSMd), Support Vector Machine (SVM) and Maximum Likelihood (ML), and two point-based change detection algorithms, namely Cloud to Cloud (C2C) and Multiple Model to Model Cloud Comparison (M3C2). The algorithms were applied on two-point cloud samples from the same areas, and the results of pixel-based change detection algorithms indicate that the SVM algorithm could operate satisfactorily when noise is present in the data but could not reliably quantify the magnitudes of building height changes. The DSMd algorithm can derive the magnitudes of building height change, but it produces a high level of noise in the result and influences the change detection reliability. Therefore, an integration of DSMd and SVM was applied to determine the magnitudes of change and significantly reduce the noise in the results. Among point-based algorithms, M3C2 algorithm is able to show the magnitudes of building height changes and differentiate between new and demolished objects, while C2C can not fully satisfy the evaluation criteria. The authors recommend evaluation of these algorithms using additional temporal data sets and in various urban areas. Therefore, a generalization of the findings at this stage is premature. © 2019 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85066035575
"Jin R., Zou Y., Gidado K., Ashton P., Painting N.","Scientometric analysis of BIM-based research in construction engineering and management",2019,"Engineering, Construction and Architectural Management",34,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067848624&doi=10.1108%2fECAM-08-2018-0350&partnerID=40&md5=bb093193f25d3655d6911d3b3a8e1afe","Purpose: The purpose of this paper is to summarize the latest research of BIM adoption in construction engineering and management (CEM) and propose research directions for future scholarly work. During the recent decade, building information modeling (BIM) has gained increasing applications and research interest in the construction industry. Although there have been review-based studies that summarized BIM-based research in the overall architecture, engineering and construction (AEC) area, there is limited review that evaluates the current stage of BIM-based research specifically in the CEM sub-area. Design/methodology/approach: CEM falls into the scope of AEC. It involves construction-related tasks, activities and processes (e.g. scheduling and cost estimates), issues (e.g. constructability), as well as human factors (e.g. collaboration). This study adopted a holistic literature review approach that incorporates bibliometric search and scientometric analysis. A total of 276 articles related to BIM applied in CEM were selected from Scopus as the literature sample for the scientometric analysis. Findings: Some key CEM research areas (e.g. CEM pedagogy, integrated project delivery, lean and off-site construction) were identified and evaluated. Research trends in these areas were identified, and analyses were carried out with regard to how they could be integrated with BIM. For example, BIM, as a data repository for ACE facilities, has substantial potential to be integrated with a variety of other digital technologies, project delivery methods and innovative construction techniques throughout the whole process of CEM. Practical implications: As BIM is one of the key technologies and digital platforms to improve the construction productivity and collaboration, it is important for industry practitioners to be updated of the latest movement and progress of the academic research. The industry, academics and governmental authorities should work with joint effort to fill the gap by first recognizing the current needs, limitations and trends of applying BIM in the construction industry. For example, it needs more understanding about how to address technical interoperability issues and how to introduce the integrated design and construction delivery approach for BIM implementation under the UK BIM Level 2/3 framework. Originality/value: This study contributed to the body of knowledge in BIM by proposing a framework leading to research directions including the differences of BIM effects between design-bid-build and other fast-track project delivery methods; the integration of BIM with off-site construction; and BIM pedagogy in CEM. It also addressed the need to investigate the similarities and differences between academia and industry toward perceiving the movement of BIM in construction field work. © 2019, Emerald Publishing Limited.",Review,"Final",Scopus,2-s2.0-85067848624
"Zhou P., El-Gohary N.","Ontology-based multilabel text classification of construction regulatory documents",2016,"Journal of Computing in Civil Engineering",33,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975225132&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000530&partnerID=40&md5=15e3f67fadbcbe596fb476d849fe53ab","In order to fully automate the environmental regulatory compliance checking process, rules should be automatically extracted from applicable environmental regulatory textual documents, such as energy conservation codes. In the authors' automated compliance checking (ACC) approach, prior to rule extraction, the text is first classified into predefined categories to only retrieve relevant clauses and filter out irrelevant ones, thereby improving the efficiency and accuracy of rule extraction. Machine learning (ML) techniques have been commonly used for text classification (TC). Nonontology-based, ML-based TC has, generally, performed well. However, given the need for an exceptionally high performance in TC to support high performance in ACC, further TC performance improvement is needed. To address this need, an ontology-based TC algorithm is proposed to further improve the classification performance by utilizing the semantic features of the text. A domain ontology for conceptualizing the environmental knowledge was used. The proposed ontology-based TC algorithm was tested on 25 environmental regulatory documents, evaluated using four evaluation metrics, and compared with the authors' previously utilized ML-based approach. Based on the testing data, the results show that the ontology-based approach consistently outperformed the ML-based approach, under all evaluation metrics. © 2015 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84975225132
"Dong W., Huang Y., Lehane B., Ma G.","XGBoost algorithm-based prediction of concrete electrical resistivity for structural health monitoring",2020,"Automation in Construction",32,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080988333&doi=10.1016%2fj.autcon.2020.103155&partnerID=40&md5=68693866bb376bccd28cbfc0bcce4346","For structural health monitoring, electrical resistivity measurement (ERM) method is commonly employed for the detection of concrete's durability, as indicated by the chloride permeability and the corrosion of steel reinforcement. However, according to previous experimental studies, ERM results are susceptible to significant uncertainties due to multiple influencing factors such as concrete water/cement ratio and structure curing environment as well as their complex interrelationships. The present study therefore proposes an XGBoost algorithm-based prediction model which considers all potential influential factors simultaneously. A database containing 800 experimental instances composed of 16 input attributes is constructed according to existing reported studies and utilized for training and testing the XGBoost model. Statistical scores (RMSE, MAE and R2) and the GridsearchCV feature are applied to evaluate and optimize the established model respectively. Results show that the proposed XGBoost model achieves satisfactory predictive performance as demonstrated by high coefficients of regression fitting lines (0.991 and 0.943) and comparatively low RMSE values (4.6 and 11.3 kΩ·cm) for both training and testing sets respectively. The analyses of the attribute importance ranking also reveal that curing age and cement content have the greatest influence on ERM results. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85080988333
"Guo T., Wu L., Wang C., Xu Z.","Damage detection in a novel deep-learning framework: a robust method for feature extraction",2020,"Structural Health Monitoring",32,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066839064&doi=10.1177%2f1475921719846051&partnerID=40&md5=78c285a3d0979b9d252207965df59b2e","Extracting damage features precisely while overcoming the adverse interferences of measurement noise and incomplete data is a problem demanding prompt solution in structural health monitoring (SHM). In this article, we present a deep-learning-based method that can extract the damage features from mode shapes without utilizing any hand-engineered feature or prior knowledge. To meet various requirements of the damage scenarios, we use convolutional neural network (CNN) algorithm and design a new network architecture: a multi-scale module, which helps in extracting features at various scales that can reduce the interference of contaminated data; stacked residual learning modules, which help in accelerating the network convergence; and a global average pooling layer, which helps in reducing the consumption of computing resources and obtaining a regression performance. An extensive evaluation of the proposed method is conducted by using datasets based on numerical simulations, along with two datasets based on laboratory measurements. The transferring parameter methodology is introduced to reduce retraining requirement without any decreases in precision. Furthermore, we plot the feature vectors of each layer to discuss the damage features learned at these layers and additionally provide the basis for explaining the working principle of the neural network. The results show that our proposed method has accuracy improvements of at least 10% over other network architectures. © The Author(s) 2019.",Article,"Final",Scopus,2-s2.0-85066839064
"Valero E., Bosché F., Forster A.","Automatic segmentation of 3D point clouds of rubble masonry walls, and its application to building surveying, repair and maintenance",2018,"Automation in Construction",32,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052959224&doi=10.1016%2fj.autcon.2018.08.018&partnerID=40&md5=8ae9089159e4ca9308772eb58b13f198","Changing climatic conditions are contributing to faster deterioration of building fabric. Increasing number of heavy rainfall events can particularly affect historic and Cultural Heritage (CH) buildings. These evolving and uncertain circumstances demand more frequent survey of building fabric to ensure satisfactory repair and maintenance. However, traditional fabric surveys have been shown to lack efficiency, accuracy and objectivity, hindering essential repair operations. The recent development of reality capture technologies, together with the development of algorithms to effectively process the acquired data, offers the promise of transformation of surveying methods. This paper presents an original algorithm for automatic segmentation of individual masonry units and mortar regions in digitised rubble stone constructions, using geometrical and colour data acquired by Terrestrial Laser Scanning (TLS) devices. The algorithm is based on the 2D Continuous Wavelet Transform (CWT), and uniquely it does not require the wall to be flat or plumb. This characteristic is important because historic structures, in particular, commonly present non-negligible levels of bow, waviness and out-of-verticality. The method is validated through experiments undertaken using data from two relevant and highly significant Scottish CH buildings. The value of such segmentation to building surveying and maintenance regimes is also further demonstrated with application in automated and accurate measurement of mortar recess and pinning. Overall, the results demonstrate the value of the automatic segmentation of masonry units towards more comprehensive and accurate surveys. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85052959224
"Ghanbari R., Jalili M., Yu X.","Correlation of cascade failures and centrality measures in complex networks",2018,"Future Generation Computer Systems",32,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030688696&doi=10.1016%2fj.future.2017.09.007&partnerID=40&md5=523dd67b6cb59c50d7ae4cb40e536616","In complex networks, different nodes have distinct impact on overall functionality and resiliency against failures. Hence, identifying vital nodes is crucial to limit the size of the damage during a cascade failure process, enabling us to identify the most vulnerable nodes and to take solid protection measures to deter them from failure. In this manuscript, we study the correlation between cascade depth, i.e. the number of failed nodes as a consequence of single failure in one of the nodes, and centrality measures including degree, betweenness, closeness, clustering coefficient, local rank, eigenvector centrality, lobby index and information index. Networks behave dissimilarly against cascade failure due to their different structures. Interestingly, we find that node degree is negatively correlated with the cascade depth, meaning that failing a high-degree node has less severe effect than the case when lower-degree nodes fail. Betweenness centrality and local rank show positive correlation with the cascade depth. In order to make networks more resilient against cascade failures, one can remove nodes that ranked high in terms of those centrality measures showing negative correlation with the cascade depth. © 2017 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85030688696
"Jo B.W., Lee Y.S., Kim J.H., Khan R.M.A.","Trend analysis of construction industrial accidents in Korea from 2011 to 2015",2017,"Sustainability (Switzerland)",32,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026460678&doi=10.3390%2fsu9081297&partnerID=40&md5=15b6cd2d909f45c0ffc4d50a095e56cb","The purpose of this study is to analyze the results of construction accidents occurred from 2011 to 2015 in Korea. The annual reports from the Ministry of Employment and Labor, Korea (MOEL), and the annual reports from the Statistics Korea were used for the analysis in this study. The gender, age, company size and accident types were chosen as a category to analyze the trend of various occupational accidents. In order to analyze the characteristics of construction accidents, incidence rates (IRs) and mortality rates (MRs) were calculated. Further, T-tests and ANOVA analysis were performed to discover the relationships among IRs, MRs, and chosen categories. Male workers' IRs and MRs were significantly higher than those of female workers. Construction workers over 40 years of age suffered the most from occupational injuries. In terms of company size, as company size increases, both IRs and MRs tended to decrease. Occupational injuries caused by falls were higher than other accident types each year. This paper will be able to provide information on occupational accidents for establishing strategies to reduce the accident rate in construction sectors of Korea. © 2017 by the authors.",Article,"Final",Scopus,2-s2.0-85026460678
"El-Abbasy M.S., Elazouni A., Zayed T.","Generic Scheduling Optimization Model for Multiple Construction Projects",2017,"Journal of Computing in Civil Engineering",32,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018784724&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000659&partnerID=40&md5=b985149250c7d89eedf2658ff8619c45","In the construction industry, contractors usually manage and execute multiple projects simultaneously. Typically, this situation involves sharing different types of resources, including cash, equipment, and manpower. The management of resources becomes a major challenge in these problems. In this situation, contractors are concerned with optimizing a number of different objectives which often conflict with one another. These objectives include duration, total cost, financing cost, required cash, profit, and resource fluctuations. This paper presents the development of a multiobjective scheduling optimization model for multiple construction projects using the fast elitist nondominated sorting genetic algorithm (NSGA-II). The purpose of the proposed model is to obtain optimal trade-offs between different projects' objectives. The scheduling optimization model comprises submodels of project scheduling, resource allocation and leveling, and cash flow forecasting. The optimization model was successfully implemented and tested using different case studies of multiple projects of different sizes. The developed model is expected to help construction companies in solving the problems of prioritizing projects under resource-conflict conditions, allocating limited resources, and optimizing all the projects' multiple objectives under certain funding limits. © 2017 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85018784724
"Sharif M.-M., Nahangi M., Haas C., West J.","Automated Model-Based Finding of 3D Objects in Cluttered Construction Point Cloud Models",2017,"Computer-Aided Civil and Infrastructure Engineering",32,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029210189&doi=10.1111%2fmice.12306&partnerID=40&md5=32096b6e05eabc7ca96164b8a09f95b3","Finding construction components in cluttered point clouds is a critical pre-processing task that requires intensive and manual operations. Accurate isolation of an object from point clouds is a key for further processing steps such as positive identification, scan-to-building information modeling (BIM), and robotic manipulation. Manual isolaton is tedious, time consuming, and disconnected from the automated tasks involved in the process. This article adapts and examines a method for finding objects within 3D point clouds robustly, quickly, and automatically. A local feature on a pair of points is employed for representing 3D shapes. The method has three steps: (1) offline model library generation, (2) online searching and matching, and (3) match refinement and isolation. Experimental tests are carried out for finding industrial (curvilinear) and structural (rectilinear) elements. The method is verified under various circumstances in order to measure its performance toward addressing the major challenges involved in 3D object finding. Results show that the method is sufficiently quick and robust to be integrated with automated process control frameworks. © 2017 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85029210189
"Elbeltagi E., Ammar M., Sanad H., Kassab M.","Overall multiobjective optimization of construction projects scheduling using particle swarm",2016,"Engineering, Construction and Architectural Management",32,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966480715&doi=10.1108%2fECAM-11-2014-0135&partnerID=40&md5=5386a92ce857537790b7742e0b880cee","Purpose-Developing an optimized project schedule that considers all decision criteria represents a challenge for project managers. The purpose of this paper is to provide a multi-objectives overall optimization model for project scheduling considering time, cost, resources, and cash flow. This development aims to overcome the limitations of optimizing each objective at once resulting of non-overall optimized schedule. Design/methodology/approach-In this paper, a multi-objectives overall optimization model for project scheduling is developed using particle swarm optimization with a new evolutionary strategy based on the compromise solution of the Pareto-front. This model optimizes the most important decisions that affect a given project including: Time, cost, resources, and cash flow. The study assumes each activity has different execution methods accompanied by different time, cost, cost distribution pattern, and multiple resource utilization schemes. Findings-Applying the developed model to schedule a real-life case study project proves that the proposed model is valid in modeling real-life construction projects and gives important results for schedulers and project managers. The proposed model is expected to help construction managers and decision makers in successfully completing the project on time and reduced budget by utilizing the available information and resources. Originality/value-The paper presented a novel model that has four main characteristics: it produces an optimized schedule considering time, cost, resources, and cash flow simultaneously; it incorporates a powerful particle swarm optimization technique to search for the optimum schedule; it applies multi-objectives optimization rather than single-objective and it uses a unique Pareto-compromise solution to drive the fitness calculations of the evolutionary process.",Article,"Final",Scopus,2-s2.0-84966480715
"Pan Y., Zhang L.","Data-driven estimation of building energy consumption with multi-source heterogeneous data",2020,"Applied Energy",31,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083337705&doi=10.1016%2fj.apenergy.2020.114965&partnerID=40&md5=c0288ef65f6ea0cfb17ad0d9671785e0","For better energy evaluation and management, a categorical boosting (CatBoost)-based predictive method is presented to accurately estimate building energy consumption by learning large volumes of multi-source heterogeneous data collected from buildings. To be specific, the newly-developed CatBoost model belonging to the ensemble learning has superiority in handling categorical variables and producing reliable results. As a case study, our proposed method is validated in a multi-dimensional dataset about Seattle's building energy performance provided by the city's government, aiming to estimate the weather normalized site energy use intensity of buildings and characterize its non-linear relationship with other 12 possible influential features. Results from the 5-fold cross-validation demonstrate that the model exhibits a strong ability in predicting the exact value of energy intensity precisely, which can even outperform popular machine learning algorithms including random forest and gradient boosting decision tree under R2 of 0.897. Based on a defined threshold, these predicted values can be classified as the normal or abnormal energy consumption reaching an accuracy of 99.32% for outlier detection, which is helpful in alarming potential risks at an early stage and developing strategies to enhance the energy efficiency. Moreover, results from the established model can be interpreted objectively, suggesting that features concerning the physical and energy characteristics contribute more to energy estimation than environmental features. Since such results understand the building energy consumption and efficiency in a data-driven manner, they can eventually serve as guidance for building owners and designers in designing and renovating buildings to achieve better energy-conserving performance. © 2020 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85083337705
"Balado J., Díaz-Vilariño L., Arias P., Soilán M.","Automatic building accessibility diagnosis from point clouds",2017,"Automation in Construction",31,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025480279&doi=10.1016%2fj.autcon.2017.06.026&partnerID=40&md5=867e1cd30be811f1bb01c6cc8b64fcbc","Building accessibility diagnosis is of high interest especially in case of people with reduced mobility. This paper proposes a methodology for automated detection of inaccessible steps in building façade entrances from MLS (mobile laser scanner) data. Our approach uses the MLS trajectory to automatically subdivide urban point clouds into regular stretches. From each stretch, the lower zone of façade is isolated and selected as region of interest. Points belonging to vertical elements are projected onto a 2D image and steps are detected and classified as inaccessible areas according to the comparison of geometrical features such as height jump, proximity to ground and width, with regulation. The methodology has been tested in four real datasets, which constitute > 400 m of different urban scenarios. Results exhibit a robust performance under urban scenes with a high variability of façade geometry due to the presence of different entrance types to shops and dwellings. Results have been quantitatively evaluated and they show global F1 value around 93%. Moreover, the methodology is very fast since 100 m are processed in < 2 min. © 2017 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85025480279
"Zhang L., Liu Q., Wu X., Skibniewski M.J.","Perceiving interactions on construction safety behaviors: Workers' perspective",2016,"Journal of Management in Engineering",31,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982272493&doi=10.1061%2f%28ASCE%29ME.1943-5479.0000454&partnerID=40&md5=acb30bf6c0432b01a0b5dbb4ed0520e4","This paper presents a systematic approach that incorporates structural equation modeling (SEM) and exploratory factor analysis (EFA) to perceive and verify causal-relationships and interactions between enablers and goals of construction workers' safety behaviors (CWSB). A sample of 450 questionnaire surveys regarding CWSB was collected from construction workers in several Chinese construction companies. EFA was used to extract eight common factors in order to identify the model structure among 28 questionnaire items. Then, SEM was employed to investigate the interrelationships among variables in the hypothesized safety behavior model. The built causal model was verified in terms of the hypothesis test and goodness-of-fit test. The impact of the path coefficient on CWSB was investigated and analyzed in detail. Results indicate that management-oriented supervision and system (F3) and leadership (F8) exert obvious positive impacts on CWSB in accordance with the path coefficients analysis, whereas psychological workers' condition (F5) and workplace conditions (F6) exert obvious negative influences. Individual differences among workers (F2) do not perform statistically significantly with workers' safety behaviors. The developed approach is capable of revealing causal-relationships, testing hypothesized models, and determining leading factors in complex project environments. This research provides insights into cause-effect relationships among the workers' perceived influential factors and goals, and the results can be used to understand the factors that the construction workers perceive as important factors in safety behaviors. This can further provide decision support on the improvement of construction safety performance in the context of the Chinese construction industry. © 2016 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84982272493
"Fiore A., Marano G.C., Greco R., Mastromarino E.","Structural optimization of hollow-section steel trusses by differential evolution algorithm",2016,"International Journal of Steel Structures",31,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978256862&doi=10.1007%2fs13296-016-6013-1&partnerID=40&md5=f53f0173104cd5811f052b456130b92f","This paper deals with the weight minimization of planar steel trusses by adopting a differential evolution-based algorithm. Square hollow sections are considered. The design optimization refers to size, shape and topology. The design variables are represented by the geometrical dimensions of the cross sections of the different components of the truss, directly involving the size of the structure, and by some geometrical parameters affecting the outer shape of the truss. The topology is included in the optimization search in a particular way, since the designer at different runs of the algorithm can change the number of bays keeping constant the total length of the truss, to successively choose the best optimal solution. The minimum weight optimum design is posed as a single-objective optimization problem subject to constraints formulated in accordance with the current Eurocode 3. The optimal solution is obtained by a Differential Evolutionary (DE) algorithm. In the DE algorithm, a particular combination of mutation and crossover operators is adopted in order to achieve the best solutions and a specific way for dealing with constraints is introduced. The effectiveness of the proposed approach is shown with reference to two case-studies. The analysis results prove the versatility of the optimizer algorithm with regard to the three optimization categories of sizing, shape, topology as well as its high computational performances and its efficacy for practical applications. In particular useful practical indications concerning the geometrical dimensions of the various involved structural elements can be deduced by the optimal solutions: in a truss girder the cross section of the top chord should be bigger than the one of the bottom chord as well as diagonals should be characterized by smaller cross sections with respect to the top and bottom chords in order to simultaneously optimize the weight and ensure an optimal structural behaviour. © 2016, Korean Society of Steel Construction and Springer-Verlag Berlin Heidelberg.",Article,"Final",Scopus,2-s2.0-84978256862
"Maeda H., Kashiyama T., Sekimoto Y., Seto T., Omata H.","Generative adversarial network for road damage detection",2021,"Computer-Aided Civil and Infrastructure Engineering",30,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085704675&doi=10.1111%2fmice.12561&partnerID=40&md5=d1a64e433371d30ed4379d6e4799b797","Machine learning can produce promising results when sufficient training data are available; however, infrastructure inspections typically do not provide sufficient training data for road damage. Given the differences in the environment, the type of road damage and the degree of its progress can vary from structure to structure. The use of generative models, such as a generative adversarial network (GAN) or a variational autoencoder, makes it possible to generate a pseudoimage that cannot be distinguished from a real one. Combining a progressive growing GAN along with Poisson blending artificially generates road damage images that can be used as new training data to improve the accuracy of road damage detection. The addition of a synthesized road damage image to the training data improves the F-measure by 5% and 2% when the number of original images is small and relatively large, respectively. All of the results and the new Road Damage Dataset 2019 are publicly available (https://github.com/sekilab/RoadDamageDetector). © 2020 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85085704675
"Marucci-Wellman H.R., Corns H.L., Lehto M.R.","Classifying injury narratives of large administrative databases for surveillance—A practical approach combining machine learning ensembles and human review",2017,"Accident Analysis and Prevention",29,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995615058&doi=10.1016%2fj.aap.2016.10.014&partnerID=40&md5=8996678efcb6d342d03357253c573924","Injury narratives are now available real time and include useful information for injury surveillance and prevention. However, manual classification of the cause or events leading to injury found in large batches of narratives, such as workers compensation claims databases, can be prohibitive. In this study we compare the utility of four machine learning algorithms (Naïve Bayes, Single word and Bi-gram models, Support Vector Machine and Logistic Regression) for classifying narratives into Bureau of Labor Statistics Occupational Injury and Illness event leading to injury classifications for a large workers compensation database. These algorithms are known to do well classifying narrative text and are fairly easy to implement with off-the-shelf software packages such as Python. We propose human-machine learning ensemble approaches which maximize the power and accuracy of the algorithms for machine-assigned codes and allow for strategic filtering of rare, emerging or ambiguous narratives for manual review. We compare human-machine approaches based on filtering on the prediction strength of the classifier vs. agreement between algorithms. Regularized Logistic Regression (LR) was the best performing algorithm alone. Using this algorithm and filtering out the bottom 30% of predictions for manual review resulted in high accuracy (overall sensitivity/positive predictive value of 0.89) of the final machine-human coded dataset. The best pairings of algorithms included Naïve Bayes with Support Vector Machine whereby the triple ensemble NBSW = NBBI-GRAM = SVM had very high performance (0.93 overall sensitivity/positive predictive value and high accuracy (i.e. high sensitivity and positive predictive values)) across both large and small categories leaving 41% of the narratives for manual review. Integrating LR into this ensemble mix improved performance only slightly. For large administrative datasets we propose incorporation of methods based on human-machine pairings such as we have done here, utilizing readily-available off-the-shelf machine learning techniques and resulting in only a fraction of narratives that require manual review. Human-machine ensemble methods are likely to improve performance over total manual coding. © 2016 The Authors",Article,"Final",Scopus,2-s2.0-84995615058
"Gholizadeh S., Baghchevan A.","Multi-objective seismic design optimization of steel frames by a chaotic meta-heuristic algorithm",2017,"Engineering with Computers",28,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017185040&doi=10.1007%2fs00366-017-0515-0&partnerID=40&md5=d055ecaa06ed3550ef634349588a07e1","In this study, multi-objective optimization is applied to implement performance-based design of steel moment-resisting frame (SMRF) structures. In order to efficiently achieve this purpose, a chaotic multi-objective firefly algorithm (CMOFA) is proposed to find the Pareto optimal front for the multi-objective performance-based optimum design (MO-PBOD) problem of SMRFs. The structural weight and the maximum inter-story drift at performance levels are taken as the conflicting objective functions of the MO-PBOD problem which should be optimized simultaneously subject to serviceability and ultimate limit-state constraints. In order to illustrate the efficiency of the proposed CMOFA meta-heuristic, two benchmark truss examples and three MO-PBOD examples of SMRFs are presented. The numerical results demonstrate the better computational performance of the proposed CMOFA meta-heuristic in comparison with some existing multi-objective algorithms. © 2017, Springer-Verlag London.",Article,"Final",Scopus,2-s2.0-85017185040
"Liu T., Xu C., Guo Y., Chen H.","A novel deep reinforcement learning based methodology for short-term HVAC system energy consumption prediction [Simulation multi-physique de refroidisseurs de gaz au CO2 à l'aide de la modélisation des équivalences]",2019,"International Journal of Refrigeration",27,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072586699&doi=10.1016%2fj.ijrefrig.2019.07.018&partnerID=40&md5=c92f2c27a9bfb59f474b93510d9a05cd","Short-term energy consumption prediction has fundamental importance in many HVAC system management tasks, such as demand-side management, short-term maintenance, etc. Currently, the prevailing data-driven techniques, especially supervised machine learning methods, are widely applied for short-term energy consumption prediction. Deep reinforcement learning (DRL), as the state-of-the-art machine learning techniques, have been applied for HVAC system control, but rarely for energy consumption prediction. In this paper, a DRL algorithm, namely Deep Deterministic Policy Gradient (DDPG), is firstly introduced for short-term HVAC system energy consumption prediction. Moreover, Autoencoder (AE), which is powerful in processing data in their raw form, is incorporated into DDPG method to extract the high-level features of state space and optimize the prediction model. The operation data of the ground source heat pump (GSHP) system of an office building in Henan province, China is used to train and assess the proposed models. The results demonstrate that the proposed DDPG based models can achieve better prediction performance than common supervised models like BP Neural Network and Support Vector Machine. This study is an enlightening work which may inspire other researchers to tap the potential of DRL algorithms in this field. © 2019 Elsevier Ltd and IIR",Article,"Final",Scopus,2-s2.0-85072586699
"Chokor A., Naganathan H., Chong W.K., Asmar M.E.","Analyzing Arizona OSHA Injury Reports Using Unsupervised Machine Learning",2016,"Procedia Engineering",27,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999622572&doi=10.1016%2fj.proeng.2016.04.200&partnerID=40&md5=9b06d9ff3ef0bbabee4421895d791a11","As the construction continue to be a leading industry in the number of injuries and fatalities annually, several organizations and agencies are working avidly to ensure the number of injuries and fatalities is minimized. The Occupational Safety and Health Administration (OSHA) is one such effort to assure safe and healthful working conditions for working men and women by setting and enforcing standards and by providing training, outreach, education and assistance. Given the large databases of OSHA historical events and reports, a manual analysis of the fatality and catastrophe investigations content is a time consuming and expensive process. This paper aims to evaluate the strength of unsupervised machine learning and Natural Language Processing (NLP) in supporting safety inspections and reorganizing accidents database on a state level. After collecting construction accident reports from the OSHA Arizona office, the methodology consists of preprocessing the accident reports and weighting terms in order to apply a data-driven unsupervised K-Means-based clustering approach. The proposed method classifies the collected reports in four clusters, each reporting a type of accident. The results show the construction accidents in the state of Arizona to be caused by falls (42.9%), struck by objects (34.3%), electrocutions (12.5%), and trenches collapse (10.3%). The findings of this research empower state and local agencies with a customized presentation of the accidents fitting their regulations and weather conditions. What is applicable to one climate might not be suitable for another; therefore, such rearrangement of the accidents database on a state based level is a necessary prerequisite to enhance the local safety applications and standards. © 2016 The Authors.",Conference Paper,"Final",Scopus,2-s2.0-84999622572
"Yao L., Dong Q., Jiang J., Ni F.","Deep reinforcement learning for long-term pavement maintenance planning",2020,"Computer-Aided Civil and Infrastructure Engineering",26,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084995854&doi=10.1111%2fmice.12558&partnerID=40&md5=1ce36615b5d8e2647eec45d042e899d8","Inappropriate maintenance and rehabilitation strategies cause many problems such as maintenance budget waste, ineffective pavement distress treatments, and so forth. A method based on a machine learning algorithm called deep reinforcement learning (DRL) was developed in this presented research in order to learn better maintenance strategies that maximize the long-term cost-effectiveness in maintenance decision-making through trial and error. In this method, each single-lane pavement segment can have different treatments, and the long-term maintenance cost-effectiveness of the entire section is treated as the optimization goal. In the DRL algorithm, states are embodied by 42 parameters involving the pavement structures and materials, traffic loads, maintenance records, pavement conditions, and so forth. Specific treatments as well as do-nothing are the actions. The reward is defined as the increased or decreased cost-effectiveness after taking corresponding actions. Two expressways, the Ningchang and Zhenli expressways, were selected for a case study. The results show that the DRL model is capable of learning a better strategy to improve the long-term maintenance cost-effectiveness. By implementing the optimized maintenance strategies produced by the developed model, the pavement conditions can be controlled in an acceptable range. © 2020 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85084995854
"Salhi L., Silverston T., Yamazaki T., Miyoshi T.","Early Detection System for Gas Leakage and Fire in Smart Home Using Machine Learning",2019,"2019 IEEE International Conference on Consumer Electronics, ICCE 2019",26,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063810989&doi=10.1109%2fICCE.2019.8661990&partnerID=40&md5=5d703b768f3bcdaea0e990cefdf4c059","Making houses more inclusive, safer, resilient and sustainable is an important requirement that must be achieved in every society. Gas leakage and fires in smart houses are serious issues that are causing people's death and properties losses. Currently, preventing and alerting systems are widely available. However, they are generally individual units having elementary functions without adequate capabilities of multi-sensing and interaction with the existing Machine-to-Machine (M2M) home network along with the outside networks such as Internet. Indeed, this communication paradigm will be clearly the most dominant in the near future for M2M home networks. In this paper, we are proposing an efficient system model to integrate the gas leakage and fire detection system into a centralized M2M home network using low cost devices. Then, through machine learning approach, we are involving a data mining method with the sensed information and detect the abnormal air state changes in hidden patterns for early prediction of the risk incidences. This work will help to enhance safety and protect property in smart houses. © 2019 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85063810989
"Liang C., Luo A., Zhong Z.","Knowledge mapping of medication literacy study: a visualized analysis using CiteSpace",2018,"SAGE Open Med",26,,[No abstract available],,"Final",Scopus,2-s2.0-85064566373
"Al Hattab M., Hamzeh F.","Simulating the dynamics of social agents and information flows in BIM-based design",2018,"Automation in Construction",25,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044470786&doi=10.1016%2fj.autcon.2018.03.024&partnerID=40&md5=0238045bae8059bd18fd8c3b469cb286","Design work entails collaboration that increasingly requires dynamic and complex information exchanges among multi-disciplinary teams. Although Building Information Modelling (BIM) is frequently advocated as a solution to myriad issues, poor workflow still plagues the design process resulting in rework, delays, cost overruns, and errors which are detrimental to the project. This can be attributed to a lack of consideration of inherent problems in communication and behaviours of design teams when adopting BIM. This study aims to examine whether BIM adoption can improve design workflow by concurrently considering social interaction mechanisms and information flow dynamics. Accordingly, the research method adopts agent-based modelling and social network analysis to analyse and measure information flow in BIM-based design. Cross-analyses of results from a case study indicate that using BIM as production tool does not explicitly improve workflow or achieve the full potential unless fundamental conditions are present, namely collaboration and changes in traditional mindsets. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85044470786
"Irani Z., Kamal M.M.","Intelligent systems research in the construction industry",2014,"Expert Systems with Applications",25,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888308524&doi=10.1016%2fj.eswa.2013.06.061&partnerID=40&md5=fd26ace91bd92cc6cdb4111e28b71b68","With the increasing complexity of problems in the construction industry, researchers are investigating computationally rigorous intelligent systems with the aim of seeking intelligent solutions. The purpose of this paper is therefore to analyse the research published on 'intelligent systems in the construction industry' over the past two decades. This is achieved to observe and understand the historical trends and current patterns in the use of different types of intelligent systems and to exhibit potential directions of further research. Thus, to trace the applications of intelligent systems to research in the construction industry, a profiling approach is employed to analyse 514 publications extracted from the Scopus database. The prime value and uniqueness of this paper lies in analysing and compiling the existing published material by examining variables (such as yearly publications, geographic location of each publication, etc.). This has been achieved by synthesising existing publications using 14 keywords2 'Intelligent Systems', 'Artificial Intelligence', 'Expert Systems', 'Fuzzy Systems', 'Genetic Algorithms', 'Knowledge-Based Systems', 'Neural Networks', 'Context Aware Applications', 'Embedded Systems', 'Human-Machine Interface', 'Sensing and Multiple Sensor Fusion', 'Ubiquitous and Physical Computing', 'Case-based Reasoning' and 'Construction Industry'. The prime contributions of this research are identified by associating (a) yearly publication and geographic location, (b) yearly publication and the type of intelligent systems employed/discussed, (c) geographic location and the type of research methods employed, and (d) geographic location and the types of intelligent systems employed. These contributions provide a comparison between the two decades and offer insights into the trends in using different intelligent systems types in the construction industry. The analysis presented in this paper has identified intelligent systems studies that have contributed to the development and accumulation of intellectual wealth to the intelligent systems area in the construction industry. This research has implications for researchers, journal editors, practitioners, universities and research institutions. Moreover, it is likely to form the basis and motivation for profiling other database resources and specific types of intelligent systems journals in this area. © 2013 Published by Elsevier Ltd.",Article,"Final",Scopus,2-s2.0-84888308524
"Pholdee N., Bureerat S.","Performance enhancement of multiobjective evolutionary optimisers for truss design using an approximate gradient",2012,"Computers and Structures",25,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863791561&doi=10.1016%2fj.compstruc.2012.04.015&partnerID=40&md5=39cc307c2c8a8378030d87e3ac13a3bc","This paper proposes hybridisation of evolutionary algorithms (EAs) and an efficient search strategy for truss optimisation. During an optimisation process, function gradients are approximated using already explored design solutions. The approximate gradient is then employed as a local search direction. The approximate gradient operator is integrated into the main search procedure of three multiobjective evolutionary algorithms (MOEAs) leading to three hybrid optimisers. The proposed hybrid strategies along with their original MOEAs are implemented on multiobjective design of truss structures. From the comparative results, it is found that the approximate gradient operator can greatly improve the search performance of MOEAs. © 2012 Elsevier Ltd. All rights reserved.",Article,"Final",Scopus,2-s2.0-84863791561
"Pan Y., Zhang G., Zhang L.","A spatial-channel hierarchical deep learning network for pixel-level automated crack detection",2020,"Automation in Construction",24,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088541317&doi=10.1016%2fj.autcon.2020.103357&partnerID=40&md5=95ed73f35f217a3a9680669cbd89bd87","This research develops a novel computer vision approach named a spatial-channel hierarchical network (SCHNet), which is feasible to support the automated and reliable concrete crack segmentation at the pixel level. Specifically, SCHNet with a base net Visual Geometry Group 19 (VGG19) contains a self-attention mechanism, which is realized by three parallel modules, including the feature pyramid attention module, the spatial attention module, and the channel attention module. It can not only consider the semantic interdependencies in spatial and channel dimensions, but also adaptively integrate local features into their global dependencies. The segmentation performance is evaluated by a metric named Mean Intersection over Union (IoU) in a public dataset containing 11,000 cracked and non-cracked images with a unified resolution at 256 × 256 pixels (px). The experimental results confirm the effectiveness of the three attention modules, since they can individually increase Mean IoU by 1.62% (74.16%–72.54%), 5.15% (79.31%–74.16%), and 5.76% (79.92%–74.16%), respectively. With the help of new strategies like the data augmentation and multi-grid method, SCHNet can boost Mean IoU to 85.31%. In a comparison of the state-of-the-art models (i.e. U-net, DeepLab-v2, PSPNet, Ding, Dilated FCN) on the test dataset, SCHNet can outperform others with an improvement of at least 7.51% in Mean IoU. Moreover, SCHNet is robust to noises with a better generalization ability under various conditions, including shadows, roughness surfaces, and holes. Overall, this research contributes to developing SCHNet to integrate spatial and channel information in feature extraction, resulting in a more accurate and efficient crack detection process. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85088541317
"Abotaleb I., Nassar K., Hosny O.","Layout optimization of construction site facilities with dynamic freeform geometric representations",2016,"Automation in Construction",24,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960121513&doi=10.1016%2fj.autcon.2016.02.007&partnerID=40&md5=852b6bc66b96537ee26a09babb990d7c","Traditional approaches to the construction site layout problem have been focused mainly on rectilinear and simple interpolated static geometrical shapes for modeling site facilities. Moreover, they have used proximity measures based on Cartesian distances between the centroids of the facilities. This is a fair abstraction of the problem; however it ignores the fact that many facilities on the construction sites assume non-rectilinear shapes that allow for better compaction within congested sites. The main focus of this research is to develop a new approach of modeling site facilities to overcome limitations and inefficiencies of previous models and to ensure a more realistic approach to construction site layout problems. A site layout optimization model was developed through a series of new algorithms for modeling regular and irregular freeform shapes of site facilities. The model mimics the ""dynamic"" behavior of the geometries of site facilities; where the geometrical shapes automatically modify their forms to fit in congested areas. Moreover, new proximity measures and distance measurement techniques were introduced. Furthermore, the research introduced the concept of selective zoning that significantly enhances optimization efficiency by minimizing the number of solutions through selection of pre-determined movement zones on site. At the end, a real site layout planning problem was solved using the developed model and the results were compared to two past models from the literature. The model has shown to be superior to the past models in optimizing congested and geometrically-complex site layouts. © 2016 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84960121513
"Zhao X., Li M., Song G., Xu J.","Hierarchical ensemble-based data fusion for structural health monitoring",2010,"Smart Materials and Structures",24,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949898504&doi=10.1088%2f0964-1726%2f19%2f4%2f045009&partnerID=40&md5=dc06abd878065709429f6f39833afdbf","In structural health monitoring, damage detection results always have uncertainty because of three factors: measurement noise, modeling error and environment changes. Data fusion can lead to the improved accuracy of a classification decision as compared to a decision based on any individual data source alone. Ensemble approaches constitute a relatively new breed of algorithms used for data fusion. In this paper, we introduced a hierarchical ensemble scheme to the data fusion field. The hierarchical ensemble scheme was based on the Dempster-Shafer (DS) theory and the Rotation Forest (RF) method, it was called a hierarchical ensemble because the RF method itself was an ensemble method. The DS theory was used to combine the output of RF based on different data sources. The validation accuracy of the RF model was considered in the improvement of the performance of the hierarchical ensemble. Health monitoring of a small-scale two-story frame structure with different damages subject to shaking table tests was used as an example to validate the efficiency of the proposed scheme. The experimental results indicated that the proposed scheme will improve the identification accuracy and increase the reliability of identification. © IOP Publishing Ltd.",Article,"Final",Scopus,2-s2.0-77949898504
"Cheng M.-Y., Kusoemo D., Gosno R.A.","Text mining-based construction site accident classification using hybrid supervised machine learning",2020,"Automation in Construction",23,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085244072&doi=10.1016%2fj.autcon.2020.103265&partnerID=40&md5=fa1b7074df831c76f35eff9bcda7fdf6","Safety is one key consideration in the monitoring of construction projects by engineers. Accidents in the project can potentially cause issues, such as workers' injury and progress delay, which lead to financial losses. Generally, accident narratives store all summaries and causes of the related events. Since documentations rapidly use large quantities of resources, the implementation of Artificial Intelligence (AI) begins to seek attention. Nevertheless, in current models, there are still drawbacks, such as weak learning performance and substantial error rate. In this regard, this study develops a hybrid model incorporating Gated Recurrent Unit (GRU) and Symbiotic Organisms Search (SOS), named Symbiotic Gated Recurrent Unit (SGRU). SOS searches the best parameters of GRU to ensure optimal performance. Furthermore, Natural Language Processing is applied to pre-process the text data prior classification process. The experimental result in this study showcases SGRU as the best classification model among other AI models. Therefore, SGRU shares the capability to aid the safety assessments of construction projects. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85085244072
"Du J., Zhu Q., Shi Y., Wang Q., Lin Y., Zhao D.","Cognition Digital Twins for Personalized Information Systems of Smart Cities: Proof of Concept",2020,"Journal of Management in Engineering",23,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077031409&doi=10.1061%2f%28ASCE%29ME.1943-5479.0000740&partnerID=40&md5=e29bdb69b109ad501d24e348f0b84d4d","Amid the rapid development of information communication technologies (ICTs), residents of future smart cities are expected to be exposed to unprecedented amounts of real-Time information on a daily basis. The cognitive overload driven by an excess of complex information has become a potential issue. Nonetheless, standardized information systems are still widely used, despite individual differences in information intake. To set a foundation for the intelligent information systems of smart cities, this paper introduces methods and tools for a cognition-driven, personalized information system, which acknowledges individual differences in information preference and helps reduce the cognitive load in daily lives and at work. The proposed method includes the use of virtual reality (VR) to simulate complex tasks paired with the digital twin modeling of workers' cognitive reactions to different information formats and contents in VR simulation. Collected data are then used to build a personal digital twins model of information-driven cognition, or Cog-DT. A human subject experiment was performed with a simulated industrial facility shutdown maintenance task as a proof of concept of Cog-DT. The latest neuroimaging technology and analysis methods were applied to model unique cognitive processes pertaining to information processing. Results indicate that cognitive activities driven by different information stimuli in the work context are distinguishable and modelable with Cog-DT methods and tools. This study is expected to contribute to digital twin literature by testing a human-centered, individual-level digital twin modeling method of cognitive activities. It also sets a preliminary foundation for developing personalized information systems for the smart cities of the future. © 2019 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85077031409
"Ding Q., Peng Z., Liu T., Tong Q.","Multi-sensor building fire alarm system with information fusion technology based on D-S evidence theory",2014,"Algorithms",23,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920261326&doi=10.3390%2fa7040523&partnerID=40&md5=56ae3f949961e36d7b68116d63e9ea2d","Multi-sensor and information fusion technology based on Dempster-Shafer evidence theory is applied in the system of a building fire alarm to realize early detecting and alarming. By using a multi-sensor to monitor the parameters of the fire process, such as light, smoke, temperature, gas and moisture, the range of fire monitoring in space and time is expanded compared with a single-sensor system. Then, the D-S evidence theory is applied to fuse the information from the multi-sensor with the specific fire model, and the fire alarm is more accurate and timely. The proposed method can avoid the failure of the monitoring data effectively, deal with the conflicting evidence from the multi-sensor robustly and improve the reliability of fire warning significantly. © 2014 by the authors.",Article,"Final",Scopus,2-s2.0-84920261326
"Wei S., Bao Y., Li H.","Optimal policy for structure maintenance: A deep reinforcement learning framework",2020,"Structural Safety",22,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074992181&doi=10.1016%2fj.strusafe.2019.101906&partnerID=40&md5=afdb7ae237fef711074699b91ea5bfd1","The cost-effective management of aged infrastructure is an issue of worldwide concern. Markov decision process (MDP) models have been used in developing structural maintenance policies. Recent advances in the artificial intelligence (AI) community have shown that deep reinforcement learning (DRL) has the potential to solve large MDP optimization tasks. This paper proposes a novel automated DRL framework to obtain an optimized structural maintenance policy. The DRL framework contains a decision maker (AI agent) and the structure that needs to be maintained (AI task environment). The agent outputs maintenance policies and chooses maintenance actions, and the task environment determines the state transition of the structure and returns rewards to the agent under given maintenance actions. The advantages of the DRL framework include: (1) a deep neural network (DNN) is employed to learn the state-action Q value (defined as the predicted discounted expectation of the return for consequences under a given state-action pair), either based on simulations or historical data, and the policy is then obtained from the Q value; (2) optimization of the learning process is sample-based so that it can learn directly from real historical data collected from multiple bridges (i.e., big data from a large number of bridges); and (3) a general framework is used for different structure maintenance tasks with minimal changes to the neural network architecture. Case studies for a simple bridge deck with seven components and a long-span cable-stayed bridge with 263 components are performed to demonstrate the proposed procedure. The results show that the DRL is efficient at finding the optimal policy for maintenance tasks for both simple and complex structures. © 2019 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85074992181
"Zhang L., Chettupuzha A.J.A., Chen H., Wu X., AbouRizk S.M.","Fuzzy cognitive maps enabled root cause analysis in complex projects",2017,"Applied Soft Computing Journal",22,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018520045&doi=10.1016%2fj.asoc.2017.04.020&partnerID=40&md5=78d9f73a339d2bc2419be45c0ce9c9c3","This paper presents a Fuzzy Cognitive Maps (FCM) enabled Root Cause Analysis (RCA) approach to assessing the TBM performance in tunnel construction. Fuzzy logic is used to capture and utilize construction experience and knowledge from domain experts, and a cause-effect model consisting of nine concepts is established for simulating the TBM performance within the FCM framework. A tunnel case in the Wuhan metro system in China is used to demonstrate the applicability of the developed approach. Results indicate that (i) C4 (Soil Density) displays a strongest negative correlation with the concept CT (TBM Advance Rate); while C8 (Grouting Speed) displays a strongest positive correlation with CT; (ii) TBM performance is very sensitive to the change of operational conditions, where the values of operational parameters can be adjusted to go up (or down) in case the TBM performance negatively (or positively) reduces; and (iii) we can identify the magnitude of the adjustment scope of operational variables when the TBM operational performance suffers a reduction. The novelty of the proposed approach is that it is verified to be capable of modeling dynamics of system behaviors over time and performing many kinds of what-if scenario analysis, including predictive, diagnostic, and hybrid RCA, which turns out to be a more competitive solution that deals with uncertainty, dynamics, and interactions in the approximate reasoning process, compared to other traditional approximate methods (i.e. Fault Tree Analysis (FTA), Rule-Based Reasoning (RBR), and Case-Based Reasoning (CBR)). The proposed approach can be used as a decision support tool for ensuring the satisfactory performance of TBMs, and thus, increases the efficiency of tunnel construction projects. © 2017 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85018520045
"Kim K., Walewski J., Cho Y.K.","Multiobjective Construction Schedule Optimization Using Modified Niched Pareto Genetic Algorithm",2016,"Journal of Management in Engineering",22,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958592722&doi=10.1061%2f%28ASCE%29ME.1943-5479.0000374&partnerID=40&md5=b53d380f7267237d5ce63a669aaff11a","A construction schedule must satisfy multiple project objectives that often conflict with each other. While several earlier approaches attempted to generate optimal schedules in terms of several criteria, most of their optimization processes were segmented into multiple steps. Owing to such a lack of simultaneous optimization, limited alternative solutions could be searched and some trade-offs between goals could not be identified. This paper presents an optimization approach that enables a simultaneous search for an optimal construction schedule in terms of three objectives: minimization of construction duration, cost, and resource fluctuation. A multiobjective optimization (MOO) approach was adopted to generate scheduling solutions considering all those objectives. To enable a simultaneous optimization, we propose a new data structure that can compute the performances of solutions in terms of all the objectives at the same time. A Niched Pareto Genetic Algorithm (NPGA) is modified to facilitate the optimization procedure. Then the proposed optimization approach is implemented in an existing case study. The result indicates that the proposed approach has the capability to explore and generate a greater range of solutions compared to existing models. Trade-offs between all three objectives are identified, limitations and further research needs are discussed. © 2015 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84958592722
"Zhang L., Wen M., Ashuri B.","BIM Log Mining: Measuring Design Productivity",2018,"Journal of Computing in Civil Engineering",21,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032629269&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000721&partnerID=40&md5=11205660a5d20cd767e7cea104417f96","There has been a long debate on how to measure design productivity. Compared to construction productivity, design productivity is much more difficult to measure because design is an iterative and innovative process. Today, with rapid extension of building information modeling (BIM) applications, tremendous volumes of design logs have been generated by design software systems, such as Autodesk Revit. A systematic approach composed of a detailed step-by-step procedure is developed to deeply mine design logs in order to monitor and measure the productivity of the design process. A pattern retrieval algorithm is proposed to identify the most frequent design sequential patterns in building design projects. A novel metric for measuring design productivity based on the discovered sequential patterns is put forward. A large data set of design logs, provided by a large international design firm, is used as a case study to demonstrate the feasibility and applicability of the developed approach. Results indicate that: (1) typically, each designer executes specific commands more than any other commands; for instance, it is shown for a designer that the accumulative frequency of three commands can reach up to 56.15% of the entire number of commands executed by the designer; (2) a particular sequential pattern of design commands (\""pick lines →\""trim/extend two lines or walls to make a corner→ \""finish sketch"") has been executed 2,219 times, accounting for 46.75% of instances associated with the top five discovered sequential patterns of design commands; (3) the identified sequential patterns can be used as a project control mean to detect outlier performers that may require additional attention from project leaders; and (4) productivity performance within the discovered sequential patterns varies significantly among different designers; for instance, one of the designers (designer #6 in the case study) is identified as the most productive designer in executing both Patterns I and II, whereas another designer (Designer #1) is found to be the most productive designer in executing both Patterns III and IV. It is also uncovered that designers, on average, spend less time running the most observed sequential patterns of design commands as they gain more experience. This research contributes: (1) to the body of knowledge by providing a novel approach to monitoring, measuring, and analyzing design productivity; and (2) to the state of practice by providing new insights into what additional design process information can be retrieved from Revit journal files. © 2017 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85032629269
"Yarmohammadi S., Pourabolghasem R., Castro-Lacouture D.","Mining implicit 3D modeling patterns from unstructured temporal BIM log text data",2017,"Automation in Construction",21,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019461492&doi=10.1016%2fj.autcon.2017.04.012&partnerID=40&md5=6ce524313333e6dec5ce9e2b2a559e78","Building information modeling is instrumental in documenting design, enhancing customer experience, and improving product functionality in capital projects. However, good building models do not happen by accident, but rather as a result of a managed process that involves several participants from different disciplines and backgrounds. Effective management of this process requires an ability to closely monitor the modeling process and correctly measure modelers' performance. Nevertheless, existing methods of performance monitoring in building design practices lack an objective measurement system to quantify modeling progress. The widespread utilization of Building Information Modeling (BIM) tools presents a unique opportunity to retrieve granular design process data and conduct accurate performance measurements. As a building's 3D model is gradually developed, model generation software packages, such as Autodesk Revit, automatically create log files that record design activities. This paper investigates what information these log files contain and how one can extract and further analyze the information to provide insight into the design modeling process. The specific objectives of this study were to: (1) investigate the presence of implicit patterns in 3-D design log files; and (2) to empirically characterize the performance of modelers based on the time it takes them to execute similar modeling tasks. To fulfill these objectives, design log files provided by an international architecture and design firm were analyzed. Using a tailored text file parser, user-model interaction data including modeler characteristics, command type, and command time were extracted from the journal files. To identify implicit command execution patterns, a sequence mining algorithm based on Generalized Suffix Trees (GST) was implemented. It was shown that there is a statistically significant difference between the average time it takes modelers to execute each command sequence. This study extends the existing knowledge by proposing a novel methodology to extract meaningful patterns from time-stamped unstructured design log data. This research contributes to the state of practice by providing a better understanding of information embedded in design log files. © 2017 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85019461492
"Chua D.K.H., Hossain M.A.","A simulation model to study the impact of early information on design duration and redesign",2011,"International Journal of Project Management",21,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-79651475204&doi=10.1016%2fj.ijproman.2010.02.012&partnerID=40&md5=f93df4caf1ea5ad45a34d28f873a0ecd","In the design process, it is common to utilize early information from precedent activities to shorten the project duration instead of having to wait for the confirmed parameter values to arrive after full analysis. However, the estimated preliminary parameter might be different from that obtained after the full analysis. Consequently, redesign may be needed in downstream activities to correct this discrepancy. Total amount of induced redesign may adversely impact loss of productivity and overall design completion. Furthermore, redesign requires additional resources which may exaggerate the project completion for a project with limited resources. This study presents a simulation model to describe the effect of utilizing early information on redesign and total design duration. The paper characterizes the reduction in project duration while accounting for the impact of redesign through sensitivity studies of the parameters of the simulation model. The sensitivity studies would provide valuable insight that project managers can take into account when utilizing early information in design. © 2010 International Project Management Association.",Article,"Final",Scopus,2-s2.0-79651475204
"Pan Y., Zhang L.","BIM log mining: Learning and predicting design commands",2020,"Automation in Construction",20,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079126973&doi=10.1016%2fj.autcon.2020.103107&partnerID=40&md5=ad55b5c74c6a6a244f7172926a6ae9b1","This paper develops a framework to learn and predict design commands based upon building information modeling (BIM) event log data stored in Autodesk Revit journal files, which has the potential to improve the modeling efficiency. BIM design logs, which automatically keep detailed records on the modeling process, are the basis of data acquisition and data mining. Long Short-Term Memory Neural Network (LSTM NN), as a probabilistic deep learning model for learning sequential data with varying lengths from logs, is established to provide designers with predictions about the possible design command class in the next step. To demonstrate the feasibility of this method, a case study runs at large design logs over 4 GB from an international design firm for command class prediction. To begin with, useful data retrieved from logs is cleaned and saved in a 320 MB Comma Separated Values (CSV) file with totally 352,056 lines of commands over 289 projects. Subsequently, various design commands are categorized into 14 classes according to their effects and given numerical labels, which are then fed into LSTM NN for training and testing. As a result, the overall accuracy of this particular case study can reach 70.5% in the test set, which outperforms some classical machine learning methods, like k nearest neighbor, random forest and support vector machine. This research contributes to applying a probabilistic LSTM NN with optimal parameters to learn features from designers' subjective behaviors effectively and predict the next possible design command class intelligently towards automation of the design process. Moreover, the three most possible command classes will be offered as the recommendations under the assumption that the correct class tends to appear owning the top three highest probabilities, which can possibly enhance the reliability of predictions. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85079126973
"Zhang J., Zhang W., Xu P., Chen N.","Applicability of accident analysis methods to Chinese construction accidents",2019,"Journal of Safety Research",20,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060294352&doi=10.1016%2fj.jsr.2018.11.006&partnerID=40&md5=db9a5e27801654aa9520651712121484","Introduction: It is necessary to clearly understand construction accidents for preventing a rise in Chinese construction accidents and deaths. Better analysis methods are required for Chinese construction sector accidents. Methods: Choosing and analyzing a typical construction accident based on four popular contemporary accident causation models: STAMP, AcciMap, HFACS, and the 2-4 Model. Then we evaluated the models' applicability to construction accidents, including their usability, reliability, and validity. Results: STAMP addressed how complexity within the accident system influenced the accident development, and its output makes the responsibilities clearer for the accident. AcciMap described the entire system's failure, the entire accident's trajectory, and the relationship between them. AcciMap showed that the accident was a dynamic developing process, and this method has a high usability. The taxonomic nature of HFACS is an important feature that provides it with a high reliability. In the accident reviewed here, we found that poor management was a critical factor rather than the individual factor in the accident. The 2-4 Model provided detailed causes of the accident and established the relationship among the accident causes, the safety management system, and the safety culture. It also avoided capturing all of the complexity in the large sociotechnical system and revealed a dynamic analysis and developing process. We confirmed that it has a high usability and validity. Therefore, the 2-4Model is recommended for future Chinese construction accident analysis efforts. Practical Applications: The study provides a useful, reliable, and effective analysis method for Chinese construction accidents. © 2018 Elsevier Ltd and National Safety Council",Article,"Final",Scopus,2-s2.0-85060294352
"Khanzadi M., Nasirzadeh F., Dashti M.S.","Fuzzy Cognitive Map Approach to Analyze Causes of Change Orders in Construction Projects",2018,"Journal of Construction Engineering and Management",20,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038387901&doi=10.1061%2f%28ASCE%29CO.1943-7862.0001430&partnerID=40&md5=89aab4a96d7de0c9203b59ff40c56970","The negative impacts of change orders on construction projects are well documented in the literature. Effective management of change orders requires a comprehensive approach to identify and analyze their causes. A change order in construction projects is usually an outcome of combining several interrelated causes, rather than a single cause. Most of the previous studies have considered the causes of change orders as independent causes. However, the causes of change orders have a complicated causal structure, which makes it difficult to independently analyze and prioritize them. Therefore, this study contributes to the body of knowledge in change order management by proposing a fuzzy cognitive map (FCM) approach, which has the capability to analyze the causes of change orders considering their entire causal interactions. The root causes of change orders, as well as the direct ones, can be identified and prioritized by the proposed approach. The manageability of the causes can also be analyzed by the FCM approach. The performance of the proposed approach is evaluated by implementing it in a real construction project. A modeling-validating approach is used to construct and validate the FCM model. It is believed that the proposed FCM approach presents a powerful tool for analyzing the causes of change orders. In addition, this research contributes to knowledge in the area of FCMs by proposing a new inference law. © 2017 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85038387901
"Zhang L., Chen H., Li H., Wu X., Skibniewski M.J.","Perceiving interactions and dynamics of safety leadership in construction projects",2018,"Safety Science",19,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043382090&doi=10.1016%2fj.ssci.2018.03.007&partnerID=40&md5=05cdc76e6b0a78a58b2724d1e3914a24","This paper develops a Structural Equation Model (SEM) based approach to identify roles of leadership in managing construction safety performance in a changing project environment. A model consisting of 5 latent variables and 26 observed variables is established to reveal relationships between different stakeholders’ leaderships and construction safety performance according to a survey of 464 valid respondents. The built model is verified through several tests, including common method bias test, hypothesis test, multiple group invariance test, and goodness-of-fit tests. Impacts of path coefficient, stakeholder participation, and construction process dynamics on construction safety performance are investigated and analyzed in detail. Results indicate that: (i) At the pre-construction phase, the owner party has a strongest total effect on managing construction safety performance; (ii) At the construction phase, the contractor party plays a dominant role in managing construction safety performance associated with a highest value in both total and direct effects; and (iii) The role of the indirect effect that participating stakeholders play on construction safety performance becomes weakened as the project gradually steps from pre-construction into construction phase. The novelty of the developed approach lies in its capabilities in (a) perceiving causal relationships among stakeholders from survey data, (b) identifying leading roles on managing construction safety performance, and (c) revealing the transfer of duty and responsibility within different stakeholders as the construction advances. The research findings can assist to allocate the duty on construction safety management among different stakeholders and further facilitate the enhancement of safety performance in the construction industry. © 2018 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85043382090
"Shoar S., Banaitis A.","Application of fuzzy fault tree analysis to identify factors influencing construction labor productivity: A high-rise building case study",2018,"Journal of Civil Engineering and Management",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064461427&doi=10.3846%2fjcem.2019.7785&partnerID=40&md5=6a9f70e5994ded72775c644923aac156","The aim of this research is to develop a systematic approach to identify and prioritize the most influencing factors on labor productivity in a construction project, with respect to their interrelations, and also investigate different scenarios which can affect it. In the first step, factors influencing construction labor productivity were identified through reviewing previous researches. Applying a group of experts, the most important factors were then determined using their relative importance index in the second step. In the third step, the interrelations among factors were determined through several sessions and interviewing those experts. Finally, the efficiency of the proposed methodology is proved by implementing in a real high rise building construction project. In this step, the selected factors from previous steps were used subsequently for analyzing their impact on labor productivity through fuzzy fault tree analysis. The probability of occurrence of events was determined according to the opinions of four members of the project management team who involved in that project. The most critical causes were also identified using importance analysis. It is believed that using the proposed methodology, appropriate response strategies could be adopted against the identified critical events to enhance the overall productivity of a construction project. © 2019 The Author(s). Published by VGTU Press.",Article,"Final",Scopus,2-s2.0-85064461427
"Guo T., Xu Z.","Data fusion of multi-scale representations for structural damage detection",2018,"Mechanical Systems and Signal Processing",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032213951&doi=10.1016%2fj.ymssp.2017.05.045&partnerID=40&md5=fc1ca768cd58dfaf0b37dbd6730b12fa","Despite extensive researches into structural health monitoring (SHM) in the past decades, there are few methods that can detect multiple slight damage in noisy environments. Here, we introduce a new hybrid method that utilizes multi-scale space theory and data fusion approach for multiple damage detection in beams and plates. A cascade filtering approach provides multi-scale space for noisy mode shapes and filters the fluctuations caused by measurement noise. In multi-scale space, a series of amplification and data fusion algorithms are utilized to search the damage features across all possible scales. We verify the effectiveness of the method by numerical simulation using damaged beams and plates with various types of boundary conditions. Monte Carlo simulations are conducted to illustrate the effectiveness and noise immunity of the proposed method. The applicability is further validated via laboratory cases studies focusing on different damage scenarios. Both results demonstrate that the proposed method has a superior noise tolerant ability, as well as damage sensitivity, without knowing material properties or boundary conditions. © 2017 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85032213951
"Florez L.","Crew Allocation System for the Masonry Industry",2017,"Computer-Aided Civil and Infrastructure Engineering",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029011122&doi=10.1111%2fmice.12301&partnerID=40&md5=3c6ee62a6ff96f11777677f806accfc8","Masonry construction is labor-intensive. Processes require a large number of crews made up of masons with diverse skills, capabilities, and personalities. Often crews are reassembled and the superintendent in the site is responsible for allocating crews to balance between the complexity of the job and the need for quality and high production rates. However, the masonry industry still faces increased time and low productivity rates that result from inefficiencies in crew allocation. This article presents a system for efficient crew allocation in the masonry industry formulated as a mixed-integer program. The system takes into consideration characteristics of masons and site conditions and how to relate these to determine the right crew for the right wall to increase productivity. With the system, superintendents are not only able to identify working patterns for each of the masons but also optimal crew formation, completion times, and labor costs. To validate the model, data from a real project in the United States is used to compare the crew allocation completed by the superintendent onsite with the one proposed by the system. The results showed that relating characteristics of workers with site conditions had a substantial impact on reducing the completion time to build the walls, maximizing the utilization of masons, and outlining opportunities for concurrent work. © 2017 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85029011122
"Ailenei I., Rozinat A., Eckert A., Van Der Aalst W.M.P.","Definition and validation of process mining use cases",2012,"Lecture Notes in Business Information Processing",17,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856564868&doi=10.1007%2f978-3-642-28108-2_7&partnerID=40&md5=c7edb99153c93a02d47563947946ea78","Process mining is an emerging topic in the BPM marketplace. Recently, several (commercial) software solutions have become available. Due to the lack of an evaluation framework, it is very difficult for potential users to assess the strengths and weaknesses of these process mining tools. As the first step towards such an evaluation framework, we developed a set of process mining use cases and validated these use cases by means of expert interviews and a survey. We present the list of use cases and discuss the insights from our empirical validation. These use cases will then form the basis for a detailed evaluation of current process mining tools on the market. © 2012 Springer-Verlag.",Conference Paper,"Final",Scopus,2-s2.0-84856564868
"Gulgec N.S., Takáč M., Pakzad S.N.","Structural sensing with deep learning: Strain estimation from acceleration data for fatigue assessment",2020,"Computer-Aided Civil and Infrastructure Engineering",16,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085010123&doi=10.1111%2fmice.12565&partnerID=40&md5=ce318c22072fcc49695a9cc19b725f4c","Many of the civil structures experience significant vibrations and repeated stress cycles during their life span. These conditions are the bases for fatigue analysis to accurately establish the remaining fatigue life of the structures that ideally requires a full-field strain assessment of the structures over years of data collection. Traditional inspection methods collect strain measurements by using strain gauges for a short time span and extrapolate the measurements in time; nevertheless, large-scale deployment of strain gauges is expensive and laborious as more spatial information is desired. This paper introduces a deep learning-based approach to replace this high cost by employing inexpensive data coming from acceleration sensors. The proposed approach utilizes collected acceleration responses as inputs to a multistage deep neural network based on long short-term memory and fully connected layers to estimate the strain responses. The memory requirement of training long acceleration sequences is reduced by proposing a novel training strategy. In the evaluation of the method, a laboratory-scale horizontally curved girder subjected to various loading scenarios is tested. © 2020 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85085010123
"Fayek A.R.","Fuzzy Logic and Fuzzy Hybrid Techniques for Construction Engineering and Management",2020,"Journal of Construction Engineering and Management",16,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084187918&doi=10.1061%2f%28ASCE%29CO.1943-7862.0001854&partnerID=40&md5=a0e2bc2c88ea9895d436ec0928a277dc","Construction engineering and management are vital for successful project execution, and both researchers and practitioners continually seek ways to improve construction processes. Fuzzy logic plays an important role in many construction engineering and management applications, which are reviewed in this paper. This paper discusses the limitations of fuzzy logic and how this theory has been combined with other modeling techniques to develop fuzzy hybrid techniques, and describes the aspects of construction problems and decision making that are most effectively modeled using these techniques. Fuzzy hybrid techniques that are most common in construction are presented and examples from construction literature and the author's research program are provided. The author shares her vision of future research in this area, which is based on her expertise and experiences collaborating with construction industry partners, who have helped shape her research program and its impact on industry. Finally, the author presents her thoughts on the challenges construction researchers face in translating research to practice and measuring its impact, and she discusses some potential solutions from her research program. This paper is based on the 2019 Peurifoy Construction Advancement Address, which the author presented in Montreal, Canada, in June 2019. © 2020 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85084187918
"Hu Y., Castro-Lacouture D.","Clash Relevance Prediction Based on Machine Learning",2019,"Journal of Computing in Civil Engineering",16,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057625719&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000810&partnerID=40&md5=1c4ee5152caf061fc81fa5d9df4c0148","Building information modeling (BIM) has been widely used for clash detection, which has greatly improved the coordination efficiency among multiple disciplines in construction projects. However, the accuracy of BIM-enabled clash detection has been questioned because its outcome includes many irrelevant clashes that have no substantial influence on a project or that can be solved in the subsequent design or construction phases. To improve the quality of clash detection, this paper uses supervised machine learning algorithms to automatically distinguish relevant and irrelevant clashes. This paper selects six kinds of algorithms: J48-based decision tree, random forest, Jrip-based rule methods, binary logistic regression, naïve Bayes, and Bayesian network. The Kruskal-Wallis test was used to compare their performance, and the results found that the Jrip method outperforms the other methods. Finally, a method is provided to identify irrelevant clashes and demonstrate how the clash management process can be improved through learning from historical data. © 2018 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85057625719
"Yan H., Yang N., Peng Y., Ren Y.","Data mining in the construction industry: Present status, opportunities, and future trends",2020,"Automation in Construction",15,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087202900&doi=10.1016%2fj.autcon.2020.103331&partnerID=40&md5=cb5ec083ebf89f1dfa2e99ef9dfdebef","The construction industry is experiencing remarkable growth in the data generation. Data mining (DM) from considerable amount of data in the construction industry has emerged as an important tool for knowledge discovery. Despite the remarkable growth of DM applications to the construction industry, a systematic review on DM applications in this field is still lacking. Therefore, this paper attempts to provide a comprehensive literature review of DM application articles published between 2001 and 2019 with the specificity of construction industry. The popularity of DM applications in the construction industry is increasing, especially after 2016, with a plurality emanating from China. The main data sources, DM functions, and frequently used DM techniques in the construction industry are discussed in detail. Nine major application fields are identified, with the primary research interests focusing on multiple dimensions of energy, safety management, building occupancy and occupant behavior, material performance, and textual knowledge discovery. Four major challenges and four future research directions are proposed by drawing on the research findings. This study provides academics and practitioners with a more comprehensive understanding of the state-of-the-art of DM applications and heuristic implications for future studies. © 2020 Elsevier B.V.",Review,"Final",Scopus,2-s2.0-85087202900
"Pan Y., Zhang L.","BIM log mining: Exploring design productivity characteristics",2020,"Automation in Construction",15,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074657553&doi=10.1016%2fj.autcon.2019.102997&partnerID=40&md5=358c8c269860a09acc76a189078a1801","A clustering-based building information modeling (BIM) log mining method is developed in this research to provide a data-driven knowledge discovery about the design productivity characteristics from a huge amount of BIM design log data. Since design behaviors are non-deterministic and subjective, a novel clustering algorithm named efficient fuzzy Kohonen clustering network (EFKCN) is utilized to produce informative clusters of different features. First, datasets are pulled out from the raw design logs and transformed into understandable forms for computers. Then, EFKCN clustering algorithm is performed in datasets at both individual and team level. Finally, analysis and prediction methods, like time analysis, regression and others, will further investigate the extracted clusters, which help managers to figure out the design preference and productivity of different designers. A case study is conducted in the real BIM design logs from an international architecture design firm with 853,520 records to illustrate the effectiveness of the proposed method. From a view of individuals, the personal design behaviors hidden in different clusters are served to arrange proper design work rationally during particular time periods. From a team perspective, the design productivity of different designers can be approximately evaluated as high, medium, and low levels in an objective and efficient manner. In the comparison of EFKCN with other popular clustering methods, EFKCN takes less time and iterations to complete the clustering process, and its clustering results achieve great compactness and separation according to the value of cluster validity indices (CVIs). Hence, this research contributes to performing the novel clustering-based BIM log mining, which acts as a powerful decision-making tool in evaluating design productivity and drawing up personalized work arrangements for a more efficient modeling process. © 2019 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85074657553
"Shojaei A., Wang J., Fenner A.","Exploring the feasibility of blockchain technology as an infrastructure for improving built asset sustainability",2020,"Built Environment Project and Asset Management",14,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075037090&doi=10.1108%2fBEPAM-11-2018-0142&partnerID=40&md5=9cbdb2940121cd62b22abe259c2bc52f","Purpose: The purpose of this paper is to show the feasibility of blockchain technology to perform as an infrastructure for improving built asset sustainability by providing all the necessary information for better decision making at all the stages of its life cycle. Design/methodology/approach: Blockchain technology can be used as a tool to build a reliable and secure decentralized information system to capture and disseminate all the data required for different sustainability assessment models. A model is designed and tested through a synthetic scenario to substantiate the research objective with empirical work. Findings: It is shown that blockchain can revolutionize the current state of knowledge for long-term sustainability thinking and provide necessary information in different stages of the life cycle of a built asset. With the proposed decentralized, transparent and comprehensive database using blockchain, the life cycle assessment methods can become much more inclusive and reliable. The new holistic analysis of the built asset sustainability enables better decision making in design, build, operation and demolition of each asset. Originality/value: This paper proposes and tests a model for using blockchain as an infrastructure to support built asset sustainability. Practitioners from different backgrounds at different stages of a built asset life cycle can use such a network to make better decisions and better assess the sustainability of their built assets. © 2019, Emerald Publishing Limited.",Article,"Final",Scopus,2-s2.0-85075037090
"Alavipour S.M.R., Arditi D.","Time-cost tradeoff analysis with minimized project financing cost",2019,"Automation in Construction",14,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057279025&doi=10.1016%2fj.autcon.2018.09.009&partnerID=40&md5=8ef2e7fda7d76ff4903bf0c38a1e336a","Time-cost tradeoff analysis allows a contractor to build a project using an optimal schedule that leads to minimum cost. The financing cost can be minimized if the financing decision considers different financing alternatives such as short-term and long-term loans and lines of credit. Financing optimization should be integrated into time-cost tradeoff analysis to minimize total cost and maximize profit. This study proposes an integrated model that performs time-cost tradeoff analysis and financing optimization. A hybrid GALP algorithm is introduced to solve the optimization by combining genetic algorithms (GA) and linear programming (LP). The proposed model is tested using small and large networks: (1) to prove that optimal results are obtained in terms of the financing cost and profit if the proposed integrated model is used, (2) to validate the performance and structure of each model, and (3) to confirm the practicality of the proposed models in large networks. © 2018 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85057279025
"Faghihi V., Reinschmidt K.F., Kang J.H.","Objective-driven and Pareto Front analysis: Optimizing time, cost, and job-site movements",2016,"Automation in Construction",14,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973520106&doi=10.1016%2fj.autcon.2016.06.003&partnerID=40&md5=6a923158e4701f6a70753f2430844b8c","Finding the optimized trade-off relationship between cost and time, two important objectives of construction projects, helps project managers and their teams select a more suitable schedule for a given project. This trade-off relationship can roughly be estimated using past and cumulative knowledge, but since the early 1970s, researchers have been working on a systematic and mathematical solution to define this relationship more accurately. These researchers have used different optimization techniques such as the genetic algorithm (GA), ant colony, and fuzzy logic to further explore the relationship. In the present paper, the authors have used their previously introduced construction schedule generator algorithm to present graphical relationships between pre-defined objectives of schedule optimizations. The process starts with developing construction schedules from the project's Building Information Model (BIM) as part of the input along with resource data. Then the process continues with optimization of all developed construction schedules according to the two mentioned objectives along with the introduced job-site movement objective, which mathematically helps the sequence of installation be more logical and practical. Finally generation of a 3D space for all the created and calculated construction schedules in the form of a 3D solution cloud point. These 3D construction schedules show solution cloud points and three Pareto Fronts for the given project. © 2016 Elsevier B.V. All rights reserved.",Article,"Final",Scopus,2-s2.0-84973520106
"Aziz R.F., Hafez S.M., Abuel-Magd Y.R.","Smart optimization for mega construction projects using artificial intelligence",2014,"Alexandria Engineering Journal",14,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948709915&doi=10.1016%2fj.aej.2014.05.003&partnerID=40&md5=004bde5ecb5eb42b3a4e763a70f447d0","During practicing the planning process, scheduling and controlling mega construction projects, there are varieties of procedures and methods that should be taken into consideration during project life cycle. Accordingly, it is important to consider the different modes that may be selected for an activity in the scheduling, for controlling mega construction projects. Critical Path Method ""CPM"" is useful for scheduling, controlling and improving mega construction projects; hence this paper presents the development of a model which incorporates the basic concepts of Critical Path Method ""CPM"" with a multi-objective Genetic Algorithm ""GA"" simultaneously. The main objective of this model is to suggest a practical support for compound horizontally and vertically mega construction planners who need to optimize resource utilization in order to minimize project duration and its cost with maximizing its quality simultaneously. Proposed software is named Smart Critical Path Method System, ""SCPMS"" which uses features of Critical Path Method ""CPM"" and multi-objective Genetic Algorithms ""GAs"". The main inputs and outputs of the proposed software are demonstrated and outlined; also the main subroutines and the inference wizards are detailed. The application of this research is focused on planning and scheduling mega construction projects that hold a good promise to: (1) Increase resource use efficiency; (2) Reduce construction total time; (3) Minimize construction total cost; and (4) Measure and improve construction total quality. In addition, the verification and validation of the proposed software are tested using a real case study. © 2014 Production and hosting by Elsevier B.V.",Article,"Final",Scopus,2-s2.0-84948709915
"Zhong B., Pan X., Love P.E.D., Sun J., Tao C.","Hazard analysis: A deep learning and text mining framework for accident prevention",2020,"Advanced Engineering Informatics",13,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090042501&doi=10.1016%2fj.aei.2020.101152&partnerID=40&md5=ad4fe2965126f1dbb09c6bcd220589a7","Learning from past accidents is pivotal for improving safety in construction. However, hazard records are typically documented and stored as unstructured or semi-structured free-text rendering the ability to analyse such data a difficult task. The research presented in this study presents a novel and robust framework that combines deep learning and text mining technologies that provide the ability to analyse hazard records automatically. The framework comprises four-step modelling approach: (1) identification of hazard topics using a Latent Dirichlet Allocation algorithm (LDA) model; (2) automatic classification of hazards using a Convolution Neural Network (CNN) algorithm; (3) the production of a Word Co-occurrence Network (WCN) to determine the interrelations between hazards; and (4) quantitative analysis by Word Cloud (WC) technology of keywords to provide a visual overview of hazard records. The proposed framework is validated by analysing hazard records collected from a large-scale transport infrastructure project. It is envisaged that the use of the framework can provide managers with new insights and knowledge to better ensure positive safety outcomes in projects. The contributions of this research are threefold: (1) it is demonstrated that the process of analysing hazard records can be automated by combining deep learning and text learning; (2) hazards are able to be visualized using a systematic and data-driven process; and (3) the automatic generation of hazard topics and their classification over specific time periods enabling managers to understand their patterns of manifestation and therefore put in place strategies to prevent them from reoccurring. © 2020 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85090042501
"Kouhestani S., Nik-Bakht M.","IFC-based process mining for design authoring",2020,"Automation in Construction",13,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077803423&doi=10.1016%2fj.autcon.2019.103069&partnerID=40&md5=561947d0af20d909f1ad8be490f98844","Building Information Modelling (BIM) is defined as the process of creation and management of digital replica for building products in a collaborative design set-up. On this basis, BIM as a digital collaboration platform in AECO (Architecture, Engineering, Construction, and Operation) industry, can be upgraded to assist monitoring, control and improvement of the business processes related to planning, design, construction and operation of building facilities. The main problem in this regard, is the wastage of data related to activities completed by different actors during the project; and subsequently, the lack of analytics to discover latent patterns in collaboration and execution of such processes. The present study aims to enable BIM to capture digital footprints of project actors and create event logs for design authoring phase of building projects. This is done using files in IFC (Industry Foundation Classes) format, archived during the design process. We have developed algorithms to create event logs from such archives, and analyzed the event logs using process mining (i.e. process discovery, conformance checking and bottleneck analysis), to identify measures derived from as-happened processes. BIM managers can implement such measures in monitoring, controlling and re-engineering work processes related to design authoring. Two case studies were completed to validate and verify the products and findings of the research. Our results show that process models discovered/fine-tuned at various resolutions and from different perspectives (including ‘actor-centric’ and ‘phase-centric’ views) can provide a realistic view of the BIM project execution. This includes understanding the structure of collaboration and hand-over of work; evaluation of compliance with the BIM execution plan; and detection of bottlenecks and re-works. While the scope of the study has been limited to design authoring processes, this mindset can be extended to other BIM uses, and other phases (such as construction and operation) of building projects. Given the growing efforts on upgrading BIM to capture and formalize the lifecycle data on the products, processes and actors, this study can strongly support BIM managers with documentation and evaluation of the business processes and workflows in their project teams. © 2019",Article,"Final",Scopus,2-s2.0-85077803423
"Saeed F., Paul A., Karthigaikumar P., Nayyar A.","Convolutional neural network based early fire detection",2020,"Multimedia Tools and Applications",13,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068149097&doi=10.1007%2fs11042-019-07785-w&partnerID=40&md5=33740bf5db717ed63226e62c95934061","The detection of manmade disasters particularly fire is valuable because it causes many damages in terms of human lives. Research on fire detection using wireless sensor network and video-based methods is a very hot research topic. However, the WSN based detection model need fire happens and a lot of smoke and fire for detection. Similarly, video-based models also have some drawbacks because conventional algorithms need feature vectors and high rule-based models for detection. In this paper, we proposed a fire detection method which is based on powerful machine learning and deep learning algorithms. We used both sensors data as well as images data for fire prevention. Our proposed model has three main deep neural networks i.e. a hybrid model which consists of Adaboost and many MLP neural networks, Adaboost-LBP model and finally convolutional neural network. We used Adaboost-MLP model to predict the fire. After the prediction, we proposed two neural networks i.e. Adaboost-LBP model and convolutional neural network for detection of fire using the videos and images taken from the cameras installed for the surveillance. Adaboost-LBP model is to generate the ROIs from the image where emergencies exist Our proposed model results are quite good, and the accuracy is almost 99%. The false alarming rate is very low and can be reduced more using further training. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.",Article,"Final",Scopus,2-s2.0-85068149097
"Wang Q.","Automatic checks from 3D point cloud data for safety regulation compliance for scaffold work platforms",2019,"Automation in Construction",13,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064123391&doi=10.1016%2fj.autcon.2019.04.008&partnerID=40&md5=b671ba95e457ae1b0040e12e4ec6fcb0","Fall from scaffolds is one of the leading causes for injuries and fatalities in the construction industry. To prevent fall from scaffolds, toe-boards and guard-rails must be installed on scaffold work platforms according to relevant safety regulations. Traditionally, the checking of safety regulation conformity relies on manual observation, which is inefficient and inaccurate. To address the limitations of manual checking, this study proposes a technique to automatically check whether scaffold work platforms conform to the safety regulations based on 3D point cloud data. The proposed technique first detects the location of scaffolds from the point cloud data by finding the vertical scaffold components, known as uprights. Then, scaffold work platforms, which are planar and horizontal components, are detected based on the histogram of the Z values of the point cloud data. Once the work platforms are extracted, the toe-boards and guard-rails are detected along all the four sides of each work platform. Then, the detected toe-boards and guard-rails are checked to identify any violation of safety regulations. Validation experiments were conducted on a point cloud dataset acquired from a construction site in Singapore. The experimental results show that the proposed technique could successfully detect scaffolds and work platforms from point cloud data, and extract toe-boards and guard-rails for safety regulation checking. All the violations of safety regulations in the point cloud data were successfully identified using the proposed technique. © 2019",Article,"Final",Scopus,2-s2.0-85064123391
"Chikahiro Y., Ario I., Pawlowski P., Graczykowski C., Holnicki-Szulc J.","Optimization of reinforcement layout of scissor-type bridge using differential evolution algorithm",2019,"Computer-Aided Civil and Infrastructure Engineering",13,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061938171&doi=10.1111%2fmice.12432&partnerID=40&md5=0fc2d4257522709b97cb73d30f06b406","Scissors mechanisms are commonly used in safety engineering during the construction of temporary structures, owing to their inherent advantages of foldability, transformability, and reusability. We effectively utilized these scissors mechanism features to develop a lightweight, deployable emergency Mobile Bridge (MB) based on optimization, and control of the folding structure. Here, we discuss the problems of optimal reinforcement layout for the MB by formulating and solving three optimization problems, namely: (a) the load capacity maximization problem, (b) the weight minimization problem, and (c) coupling the load capacity maximization problem and the weight minimization problem. The potential benefits resulting from the application of reinforcement were evaluated using a combination of finite element analysis and an optimization algorithm based on the differential evolution method. The results demonstrate the significant positive influence of the additional reinforcing members. In particular, the limit load was increased by over 10 times, while the weight was decreased to approximately half. The proposed methodology enabled the development of a substantially improved version of the MB characterized by a higher load capacity and lower weight in comparison to the initial bridge design. © 2019 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85061938171
"Memarzadeh M., Pozzi M.","Model-free reinforcement learning with model-based safe exploration: Optimizing adaptive recovery process of infrastructure systems",2019,"Structural Safety",12,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065237144&doi=10.1016%2fj.strusafe.2019.04.003&partnerID=40&md5=0ac44289ff030dd264d42495b6be4821","Extreme events represent not only some of the most damaging events in our society and environment, but also the most difficult to predict. Model-based predictions of the disruptions induced by extreme events on urban infrastructure systems are often unreliable, as these events are unlikely by their very definition. Specifically, characterizing the effect of such disruptions to the urban infrastructure using a parameterized model is a difficult task. On the other hand, model-free approaches based on recent advancements in reinforcement learning can model the complex dynamics of urban society and infrastructure under the risk of extreme events explicitly without relying on any specific physics-based mechanism. However, these approaches usually require performing random exploration of the effects of management actions on the system (typically in the post-event situation)to allow for an acceptable approximation to the optimal management policy. When dealing with costly infrastructure systems and important communities, this random exploration can be unacceptable and risky. In this paper, we propose a method called Safe Q-learning, which is a model-free reinforcement learning approach with addition of a model-based safe exploration for near-optimal management of infrastructure system pre-event and their recovery post-event. Our method requires the decision-maker to model the structure of the state space of the problem, and a suitable equilibrium of the system (optimum functionality pre-event). This information is usually available for urban systems, as they spend long time in optimum equilibrium before the occurrence of such events. We show on several examples of infrastructure management how the proposed approach is able to achieve near-optimal performance without the risk due to random exploration. © 2019",Article,"Final",Scopus,2-s2.0-85065237144
"Amiri R., Sardroud J.M., Soto B.G.D.","BIM-based Applications of Metaheuristic Algorithms to Support the Decision-making Process: Uses in the Planning of Construction Site Layout",2017,"Procedia Engineering",12,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030308819&doi=10.1016%2fj.proeng.2017.08.030&partnerID=40&md5=ce6fa1af1e266bf6606674ed4a2600e0","The use of Building Information Modeling (BIM) is affecting the way in which construction projects are planned, designed, executed and operated. One of the main goals of BIM is to provide, based on a 3D model, an accurate information model in a digital format to give different project participants better tools when evaluating different options to support their decisions about the project at a given phase. With this in mind, BIM provides a suitable framework to support the decision-makings process by aggregating the necessary information at the right time, and clarifying details and existing conditions; however, the different elements required to make an optimized decision need additional consideration. To address that, this paper explores the value of metaheuristic algorithms for reaching an optimized solution. The use of metaheuristic algorithms is well known in various aspects of knowledge optimization. This paper provides an overall review of the applications of metaheuristic algorithms in BIM-based optimized decisions in the construction industry and focuses on applications to the planning of construction site layout. Based on the findings from this paper, research gaps in this area have been identified and suggestions for future research to address those gaps are suggested. © 2017 The Authors.",Conference Paper,"Final",Scopus,2-s2.0-85030308819
"Kaveh A., Vazirinia Y.","Construction Site Layout Planning Problem Using Metaheuristic Algorithms: A Comparative Study",2019,"Iranian Journal of Science and Technology - Transactions of Civil Engineering",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065129209&doi=10.1007%2fs40996-018-0148-6&partnerID=40&md5=b650676c478b45812b0cc17563a4bbbc","Material handling is one of the essential activities in the construction industry. Suitable location of facilities in the construction site can affect the costs and duration of the construction material handling process. The construction site layout planning to supply material and engineering demands within the minimum transportation distance is a quadratic assignment problem. Metaheuristics are widely used to solve construction site layout planning problems. In this article, the performance of four metaheuristic algorithms called charged system search, whale optimization algorithm, vibrating particles system, and enhanced vibrating particles system (EVPS) are compared in terms of their effectiveness in resolving a practical construction site layout problem. Results show that EVPS performs better than the other three methods. © 2018, Shiraz University.",Article,"Final",Scopus,2-s2.0-85065129209
"Song J., Kim J., Lee J.-K.","NLP and deep learning-based analysis of building regulations to support automated rule checking system",2018,"ISARC 2018 - 35th International Symposium on Automation and Robotics in Construction and International AEC/FM Hackathon: The Future of Building Things",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053895840&partnerID=40&md5=4bf618da7b91f5c8c1f0ca2b5e00a85a","This paper aims to describe a natural language processing (NLP) and deep learning-based approach for supporting automated rule checking system. Automated rule checking has been developed in various ways and enhanced the efficiency of building design review process. Converting human-readable building regulations to computer-readable format is, however, still time-consuming and error-prone due to the nature of human languages. Several domain-independent efforts have been made for NLP, and this paper focuses on how computers can be able to understand semantic meaning of building regulations to intelligently automate rule interpretation process. This paper proposes a semantic analysis process of regulatory sentences and its utilization for rule checking system. The proposed process is composed of following steps: 1) learning semantics of words and sentences, 2) utilization of semantic analysis. For semantic analysis, we use word embedding technique which converts meaning of words in numerical values. By using those values, computers can extract related words and classify the topic of sentences. The results of the semantic analysis can elaborate the interpretation with domain-specific knowledge. This paper also shows a demonstration of the proposed approach. © ISARC 2018 - 35th International Symposium on Automation and Robotics in Construction and International AEC/FM Hackathon: The Future of Building Things. All rights reserved.",Conference Paper,"Final",Scopus,2-s2.0-85053895840
"Lv X., El-Gohary N.","Text Analytics for Supporting Stakeholder Opinion Mining for Large-scale Highway Projects",2016,"Procedia Engineering",11,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999836129&doi=10.1016%2fj.proeng.2016.04.039&partnerID=40&md5=5c5f3d80aafab0c8eaf45d7a2346bb3f","For large-scale highway projects, late identification of stakeholder concerns often leads to design changes and duplication of effort, which may cause major project delays. This paper proposes a stakeholder opinion mining approach for helping transportation practitioners better identify the types of concerns in the early project stage. The proposed approach includes two major components: (1) stakeholder concern extraction, and (2) stakeholder concern classification. This paper focuses on presenting the proposed methodology and experimental results for stakeholder concern extraction, which extracts the words and phrases that describe stakeholder concerns from stakeholder comments on large-scale highway projects. In developing the proposed stakeholder concern extraction methodology, several supervised machine learning (ML) algorithms were tested and evaluated, and the effect of using a predefined name list as feature was also investigated. All the algorithms were tested on a testing data set of 200 comment sentences, which were selected from a comment collection including 1,849 stakeholder comments on five large-scale highway projects. © 2016 The Authors.",Conference Paper,"Final",Scopus,2-s2.0-84999836129
"Afzal F., Yunfei S., Nazir M., Bhatti S.M.","A review of artificial intelligence based risk assessment methods for capturing complexity-risk interdependencies: Cost overrun in construction projects",2021,"International Journal of Managing Projects in Business",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073940600&doi=10.1108%2fIJMPB-02-2019-0047&partnerID=40&md5=c58acc28babdeb59c01e371bd967ca4c","Purpose: In the past decades, artificial intelligence (AI)-based hybrid methods have been increasingly applied in construction risk management practices. The purpose of this paper is to review and compile the current AI methods used for cost-risk assessment in the construction management domain in order to capture complexity and risk interdependencies under high uncertainty. Design/methodology/approach: This paper makes a content analysis, based on a comprehensive literature review of articles published in high-quality journals from the years 2008 to 2018. Fuzzy hybrid methods, such as fuzzy-analytical network processing, fuzzy-artificial neural network and fuzzy-simulation, have been widely used and dominated in the literature due to their ability to measure the complexity and uncertainty of the system. Findings: The findings of this review article suggest that due to the limitation of subjective risk data and complex computation, the applications of these AI methods are limited in order to address cost overrun issues under high uncertainty. It is suggested that a hybrid approach of fuzzy logic and extended form of Bayesian belief network (BBN) can be applied in cost-risk assessment to better capture complexity-risk interdependencies under uncertainty. Research limitations/implications: This study only focuses on the subjective risk assessment methods applied in construction management to overcome cost overrun problem. Therefore, future research can be extended to interpret the input data required to deal with uncertainties, rather than relying solely on subjective judgments in risk assessment analysis. Practical implications: These results may assist in the management of cost overrun while addressing complexity and uncertainty to avoid chaos in a project. In addition, project managers, experts and practitioners should address the interrelationship between key complexity and risk factors in order to plan risk impact on project cost. The proposed hybrid method of fuzzy logic and BBN can better support the management implications in recent construction risk management practice. Originality/value: This study addresses the applications of AI-based methods in complex construction projects. A proposed hybrid approach could better address the complexity-risk interdependencies which increase cost uncertainty in project. © 2019, Emerald Publishing Limited.",Review,"Final",Scopus,2-s2.0-85073940600
"Pan Y., Zhang L., Skibniewski M.J.","Clustering of designers based on building information modeling event logs",2020,"Computer-Aided Civil and Infrastructure Engineering",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083789150&doi=10.1111%2fmice.12551&partnerID=40&md5=d49e99f21ab8efcf8bb3542c0a7a22cb","A network-enabled event log mining approach is proposed for a deep understanding of the Building Information Modeling (BIM)-based collaborative design work. It proposes a novel algorithm termed node2vec-GMM combining a graph embedding algorithm named node2vec and a clustering method named Gaussian mixture model (GMM) to cluster designers within a network into several subgroups, and then makes cluster analysis. Its superiority lies in the efficient feature learning ability to preserve network structure and the powerful clustering ability to tackle uncertainty and visualize results, which can directly return the cluster embedding. As a case study, a directional network with 68 nodes (designers) and 436 ties (design task transmissions) is constructed based on retrieved data from 4GB real BIM event logs. The node2vec learns and projects the network feature representation into a 128-dimensional vector, which is learned by GMM to discover three possible clusters owning 15, 26, and 27 closely linked designers. Analysis of each cluster is performed from node importance measurement and link prediction to identify information spreading and designers’ roles within clusters. Our new algorithm node2vec-GMM is proven to better improve clustering quality than other state-of-the-art methods by at least 6.0% Adjusted Rand Index and 13.4% Adjusted Mutual Information. Overall, the designer clustering process provides managers with data-driven support in both monitoring the whole course of the BIM-based design and making reliable decisions to increase collaboration opportunities. © 2020 Computer-Aided Civil and Infrastructure Engineering",Article,"Final",Scopus,2-s2.0-85083789150
"Nowakowski W., Ciszewski T., Młyńczak J., Łukasik Z.","Failure Evaluation of the Level Crossing Protection System Based on Fault Tree Analysis",2018,"Lecture Notes in Networks and Systems",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055521631&doi=10.1007%2f978-3-319-64084-6_10&partnerID=40&md5=babf2c99ff442df537298134540fdc4b","An intersection where railway line crosses a road at the same level is called level crossing. The development of the automotive industry has resulted in an increase in the number of vehicles. Thus the traffic on the level crossings has been raised and this, in turn, has resulted in an increase requirements in terms of level crossings safety. For this purpose, the Level Crossing Protection Systems (LCPS), that help to protect these road users, are built. LCPS systems, due to the need to ensure the efficient operating of the railway, should be developed taking into account the detailed analyses. It is necessary to include in these analyses the growing needs and expectations of users in terms of system functionality. However, the requirements for ensuring the reliability and safety of systems should be taken into consideration above all. One of the methods to identify and analyse the factors which may cause adverse events is the Fault Tree Analysis (FTA). The authors of this article using the FTA method carried out a qualitative analysis of the safety of B class level crossings. Traffic safety related requirements for LCPS system were described. Then this analysis was used to identify top and intermediate events and build necessary fault trees. Conducted analysis may be helpful in the process of designing new LCPS systems. © 2018, Springer International Publishing AG.",Book Chapter,"Final",Scopus,2-s2.0-85055521631
"Liang Y.-H., Tian W.-M.","Multi-sensor fusion approach for fire alarm using BP neural network",2016,"Proceedings - 2016 International Conference on Intelligent Networking and Collaborative Systems, IEEE INCoS 2016",10,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998799697&doi=10.1109%2fINCoS.2016.38&partnerID=40&md5=3aeefc96bef5e2072fdbaea2aab425b9","Multi-sensor information fusion algorithm based on BP neural network is applied in the system of fire alarm to realize early detecting and alarming. The fire detection method based on neural network was developed using detection information for temperature, smoke density, and CO concentration to determine the probability of three representative fire conditions. The method overcomes the drawbacks of the fire alarm system using single sensor information. Results show that the proposed method can provide fire warning more accurate and timely and can effectively reduce leak-check rates and false alarms, reaching the desired purpose. © 2016 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-84998799697
"Ahmadisheykhsarmast S., Sonmez R.","Smart contracts in construction industry",2018,"5th International Project & Construction Management Conference",9,,[No abstract available],,"Final",Scopus,2-s2.0-85075674194
"Mo Y., Zhao D., Du J., Syal M., Aziz A., Li H.","Automated staff assignment for building maintenance using natural language processing",2020,"Automation in Construction",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080045516&doi=10.1016%2fj.autcon.2020.103150&partnerID=40&md5=19cdc791acca9993b0ce408c0e8fbb7a","Staff assignment is the decision-making to determine appropriate workforce with required skills to perform a specific task. Staff assignment is critical to success of construction projects, especially when responding to routine requests such as the change order and building service. However, the effectiveness is low due to manual processing by the management personnel. To improve the productivity of staff assignment, this paper creates a machine learning model that reads service request texts and automatically assigns workforce and priority through the technique of natural language processing (NLP). The dataset used for modeling in this study contains 82,106 building maintenance records for a 3-year period from over 60 buildings on a university campus. The results show a 77% accuracy for predicting workforce and an 88% accuracy for predicting priority, indicating a considerably high performance for multiclass and binary classifications. Different from existing studies, the NLP model highlights the value of stop-words and punctuation in learning service request texts. The NLP model presented in this study provides a solution for staff assignment and offers a piece of the puzzle to the information system automation in the construction industry. This study has an immediate implication for building maintenance; and, in the long term, contributes to human-building interactions in smart buildings by connecting human feedback to building control systems. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85080045516
"Ji W., Li Y., AbouRizk S.M.","Integrated data-driven approach for analyzing pipe welding operator-quality performance",2019,"Automation in Construction",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066931268&doi=10.1016%2fj.autcon.2019.04.009&partnerID=40&md5=4f6203516a2ca90c47c4547f613f7e8f","This paper proposes an integrated, data-driven approach for quantifying and comparing pipe-welding operator quality performance for industrial construction projects using a Metropolis-Hastings algorithm-based fraction nonconforming estimation and an A/B testing algorithm. Existing quality-management and engineering-design data from a pipe fabrication company in Alberta, Canada are processed and analyzed to demonstrate the feasibility and applicability of the proposed approach. Through the use of a specialized Metropolis-Hastings algorithm, operator welding performances are quantified as Bayesian posterior distributions to account for uncertainty. Using an A/B testing algorithm, probabilistic differences between operator-quality performance distributions are computed to quantitatively compare their quality performance. Both visualized and quantitative decision metrics are provided for practitioners to (1) infer operator welding-quality performance for a particular weld type; (2) identify operators with exceptional quality performance; and (3) quantitatively measure differences in quality performance between operators. Implemented applications of the research findings are also discussed from the perspectives of production planning, employee training, and strategic recruiting. © 2019 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85066931268
"Zhang F.","A hybrid structured deep neural network with Word2Vec for construction accident causes classification",2019,"International Journal of Construction Management",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075085414&doi=10.1080%2f15623599.2019.1683692&partnerID=40&md5=1a03add9d03087ae077f537e648e47d5","According to the latest fatal work injury rates reported by the Bureau of Labors Statistics, construction sites remain the most hazardous workplaces. In the construction sector, fatality investigation summary reports are available for past accidents and by investigating such reports, valuable insights can be gained. In this study, text mining algorithms are explored for automatic construction accident causes classification. To be more specific, Word2Vec skip-gram model is utilized to learn word embedding from a domain-specific corpus and a hybrid structured deep neural network is proposed by incorporating the learned word embedding for accident reports classification. Dataset from Occupational Safety and Health Administration (OSHA) is employed in the experiment to evaluate the performance of the proposed approach. Besides, five baseline models: support vector machine (SVM), linear regression (LR), K-nearest neighbor (KNN), decision tree (DT), Naive Bayes (NB) are employed to compare with the proposed approach. Experiment results show that the proposed model achieves the highest average weighted F1 score among all models considered in this study. The result also proves the effectiveness of applying Word2Vec skip-gram algorithm for semantic information augmentation. As a result, robustness of the model is improved when classifying cases of low support values. © 2019, © 2019 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",Article,"Article in Press",Scopus,2-s2.0-85075085414
"Ogidan E.T., Dimililer K., Ever Y.K.","Machine Learning for Expert Systems in Data Analysis",2018,"ISMSIT 2018 - 2nd International Symposium on Multidisciplinary Studies and Innovative Technologies, Proceedings",8,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060791688&doi=10.1109%2fISMSIT.2018.8567251&partnerID=40&md5=3d864a2e43f0ded7fb2396db5662beb5","Imagine a system that automates the job of data science in such a way that if given sales data of a store nationwide can analyze the rate of sales of a product relative to its supply and demand and other necessary variables and is able to decide on the best places for the company to open new stores and help them to decide on the best possible ways to distribute their products. Data Science is an interdisciplinary field that is very much like data mining and Knowledge Discovery in Databases (KDD), involving the analysis of data to make useful inferences and deduction. However, taking into consideration the information overload of this age, it has become a pressing need to automate the process of analyzing this data. At the point of this need is where data science meets machine learning. Machine learning being a powerful tool for automation can be merged with data science and analysis to make for a more effective faster way to analyze data. In this paper, an application of expert systems for data analysis would be discussed as a case study. © 2018 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-85060791688
"Pan Y., Zhang L., Li Z.","Mining event logs for knowledge discovery based on adaptive efficient fuzzy Kohonen clustering network",2020,"Knowledge-Based Systems",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092044717&doi=10.1016%2fj.knosys.2020.106482&partnerID=40&md5=8be795b3d9777773e3e164a1e9aaf629","As a digital representation of building projects, Building Information Modeling (BIM) can accumulate large volumes of log data containing hidden knowledge for deep exploration. However, such ever-increasing logs are likely to suffer from high complexity, inaccuracy, and uncertainty, which will inevitably raise challenges in uncovering latent and meaningful patterns. In order to yield satisfactory clustering quality and efficiency for better design process management, a novel clustering-based BIM event log mining approach is put forward in this paper. For one thing, a hybrid clustering algorithm named adaptive efficient fuzzy Kohonen clustering network (AEFKCN) is developed with a modified learning rate to accelerate the convergence. For another, a new clustering validity index (CVI) only relying on boundary points is designed to reduce computational complexity. An experiment is conducted in a 4 GB realistic BIM design event log dataset to validate the effectiveness of the proposed method. It begins from extracting a set of features associated with designers’ engagement and efficiency and ends up retrieving inherent insights into the person's design behavioral patterns. Moreover, the cluster analysis can significantly distinguish the design productivity at different time periods into the high, medium, and low level, which presents a unique opportunity in understanding and assessing design productivity objectively. Practically, our method can support data-driven decision making for managers to strategically schedule personalized work for different designers, aiming to boost design efficiency and smooth the design process. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85092044717
"Chen H., Zhang L., Wu X.","Performance risk assessment in public–private partnership projects based on adaptive fuzzy cognitive map",2020,"Applied Soft Computing Journal",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084939514&doi=10.1016%2fj.asoc.2020.106413&partnerID=40&md5=48ae74431b76433eaee541797642816f","High complexity exists underlying public–private partnership (PPP) projects due to their huge scale, large investment, and long-term relationships among various participants, leading to difficulty in managing PPP project performance risk. A robust model that integrates the structural equation model (SEM) and fuzzy cognitive map (FCM) is proposed to perceive and assess the performance risk in PPP projects. SEM is used to learn causal relationships among critical factors representing PPP project performance from the data given. Based on the well-verified SEM, an adaptive FCM model consisting of 14 observed variables and 5 latent variables is built. The proposed approach is capable of performing predictive, diagnostic, and hybrid analysis in various scenarios. Results indicate that variables, including project characteristics (A), project participants (B), project input (C), and project progress (D), all display positive correlations with the target performance (T). Particularly, variables C and D are identified to be more sensitive in ensuring the project satisfactory performance than variables A and B. The optimal risk mitigation strategy can be discovered when the project performance is under an unsatisfactory level. It is found that upgrading the variable with a higher priority would be more efficient to improve the target performance than the variable with a lower priority, which is helpful in both generic and specific situations. The novelty of this research lies in the development of an adaptive FCM model that is capable of learning casual relationships from observed data and assessing risk subjected to uncertainty, subjectivity, and interdependence. The developed model can be used to provide insights into a better understanding of risk mitigation strategies through what-if scenario analysis, enabling to enhance the likelihood of success in PPP projects. © 2020 Elsevier B.V.",Article,"Final",Scopus,2-s2.0-85084939514
"Pan Y., Zhang L., Koh J., Deng Y.","An adaptive decision making method with copula Bayesian network for location selection",2021,"Information Sciences",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088924410&doi=10.1016%2fj.ins.2020.07.063&partnerID=40&md5=2c7a6c3213b9d1fe0c39316901c542ee","A novel multi-criteria decision making approach based on an adaptive copula Bayesian network (CBN) model is proposed to effectively handle complex dependence problems under uncertainty. Specifically, the Bayesian network is used to merge various criteria in a model and graphically describe cause-effect relationships. The copula is incorporated to construct joint distributions of variables by specifying marginal distributions and copula functions separately. Regarding the practical value, the constructed model can adjust to changeable conditions to provide adaptive suggestions in view of diverse disciplines. The effectiveness of the proposed approach is verified in a case study about choosing the most suitable location of the pedestrian overhead bridge (POB) to install lift facilities in Singapore. Firstly, three criteria and ten relevant influential factors concerning the sustainable aspect are derived from a combination of expert knowledge and statistical data. Then, a proper CBN model is developed under the consideration of these determined criteria and factors, aiming to predict the constructability index for alternative locations statistically. Finally, the correlation analysis and CBN inference are performed to evaluate and identify the ideal location in a data-driven manner. Furthermore, results from the proposed CBN-based approach are compared against the traditional Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) to illustrate its advantages in representing dependency, modeling uncertainty, fusing information, and reducing subjectivity. © 2020 Elsevier Inc.",Article,"Final",Scopus,2-s2.0-85088924410
"Zhang G., Pan Y., Zhang L., Tiong R.L.K.","Cross-scale generative adversarial network for crowd density estimation from images",2020,"Engineering Applications of Artificial Intelligence",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087931129&doi=10.1016%2fj.engappai.2020.103777&partnerID=40&md5=2280b5686a6ffb79ffe4d069681f60d4","This research develops a cross-scale convolutional spatial generative adversarial network (CSGAN), in order to estimate the crowd density from images accurately. It consists of two similar generators, one for the whole feature extraction, and the other for patch scale feature extraction. An encoder–decoder structure is employed to generate density maps from input images or patches. Additionally, a new objective function for crowd counting called cross-scale consistency pursuit containing an adversarial loss, L2 loss, perceptual loss, and consistency loss, is developed to make the generated density maps more realistic and closer to the ground truth. The effectiveness of the proposed CSGAN is verified in two public datasets. Results indicate that the new objective function is able to reach the most satisfying value of evaluation metrics in both the low-density and high-density crowd scenes when it is compared with other state-of-the-art methods on the test datasets. Moreover, the proposed CSGAN is more practical and flexible due to the smaller computational complexity. Its estimation capability will be significantly improved even in a small size of training data. Overall, this research contributes to the development of a novel computer vision approach together with a new objective function to generate density maps from cross-scale crowd images, enabling the counting process more accurately and efficiently. © 2020 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85087931129
"Bailey B., Raich A.M.","Modeling of user design preferences in multiobjective optimization of roof trusses",2012,"Journal of Computing in Civil Engineering",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878358761&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000145&partnerID=40&md5=29b6a88324dd6411172e99a49fbe3920","Many conceptual design programs determine optimality by relying on quantifiable design objectives such as minimizing weight and deflection. Qualitative design criteria related to architectural or constructability requirements, however, are not typically considered. This paper presents a preference-prediction model that evaluates user preference as an explicit design objective in the topology and geometry optimization of roof trusses. During optimization, each truss design is characterized by using a set of nine quantifiable features. A trained neural network inputs the characteristic truss feature values for each proposed design and outputs an integer value that indicates the user's preference for that design. To reduce the number of user interactions required to collect the required neural network training data, a Kohonen self-organizing map clusters designs into groups on the basis of feature similarities. Clustering allows users to indicate preferences for groups of similar trusses instead of for individual trusses. A rough-set reduct technique removes outliers from the user-preferred truss groups before the feature information and user preference assignments are used to train the predictive back-propagation neural network. The preference-prediction model is implemented in an existing multiobjective optimization program to determine the benefits of including satisfaction of user preferences as a design objective. Trial results indicate that more Pareto-optimal designs are identified, which increases the extent of the front, when user preferences are stated. Also, the Pareto-optimal set includes designs that have features reflecting the imposed user preferences and features that are structurally optimal. © 2012 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-84878358761
"Luo L., Zhang L., He Q.","Linking project complexity to project success: a hybrid SEM–FCM method",2020,"Engineering, Construction and Architectural Management",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085120536&doi=10.1108%2fECAM-05-2019-0241&partnerID=40&md5=f5b45c99753cb849b09311468769eaad","Purpose: The purpose of this study is to develop a novel hybrid approach that incorporates the structural equation model (SEM) and fuzzy cognitive map (FCM) to investigate the impacts of the variation in project complexity on project success. Design/methodology/approach: This study adopts SEM to identify and validate a correlation between project complexity variables and PS. Standardized causal coefficients estimated in SEM are used to construct an FCM model to illustrate the effect of complexity on PS with linkage direction and weights. Predictive and diagnostic analyses are performed to dynamically model the variation in project complexity on the evolution of PS. Findings: Results indicate that (1) the hybrid SEM–FCM approach is capable of modeling the dynamic interactions between project complexity and PS; (2) information, goal and environmental complexities are negatively correlated with PS, and technological, task and organizational complexities are positively correlated with PS and (3) the recommendations of complexity management for construction projects are put forward under the guideline of success monitoring. Originality/value: This research contributes to (1) the state of knowledge by proposing a hybrid methodology that can model the dynamic interactions between project complexity and PS and (2) the state of practice by providing a new perspective of PS evaluation to enhance the probability of success in complex construction projects. © 2020, Emerald Publishing Limited.",Article,"Final",Scopus,2-s2.0-85085120536
"Hatami M., Flood I., Franz B., Zhang X.","State-of-the-Art Review on the Applicability of AI Methods to Automated Construction Manufacturing",2019,"Computing in Civil Engineering 2019: Data, Sensing, and Analytics - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2019",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083450774&partnerID=40&md5=6fe633f204e3a721f55ab7988597b829","Productivity in the U.S. construction industry has stagnated over the past 50 years, whereas manufacturing industries have about doubled productivity levels. Adoption of smart manufacturing with construction has challenges to achieving efficiency in a factory environment. Construction projects are one-off designs with little replication in the configuration of components. The ability to reconfigure factory production and network optimization performance help smart manufacturing systems. Artificial intelligence (AI) is well suited to this problem. This paper provides an in-depth review of AI methods and how the technology may be applied to automated construction manufacturing systems. This starts with a state-of-the-practice review of AI applications within construction manufacturing. This is followed by an identification of the AI needs of construction manufacturing systems. Lastly, the paper reviews the state-of-the-art of artificial neural networks (ANNs) (e.g. deep learning and transfer learning) from the domains of manufacturing and industrial engineering, and discusses the potential for application to construction manufacturing. The objective of the paper is to help identify the direction for future research and development in this field. © 2019 American Society of Civil Engineers.",Conference Paper,"Final",Scopus,2-s2.0-85083450774
"Wang J., Razavi S.","Spatiotemporal Network-Based Model for Dynamic Risk Analysis on Struck-by-Equipment Hazard",2018,"Journal of Computing in Civil Engineering",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040076585&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000732&partnerID=40&md5=a9091aeaab56d35550b3df015a784676","Having an approach that can analyze and identify safety risks in the dynamic and hazardous construction environment is one of the key steps to the success of health and safety plans. Struck-by-equipment hazard is one of the leading causes of construction injuries and fatalities. Therefore, the primary objective of this paper is to investigate and provide an effective method of safety risk analysis on struck-by-equipment hazard. A spatiotemporal network-based model is developed in this paper which performs dynamic risk analysis on the struck-by-equipment hazard at both entity and network levels. The developed model performs safety risk analysis in a real-time and proactive manner by considering the spatiotemporal interactions among all construction entities (equipment and workers on foot) across the jobsite. Three risk factors of struck-by-equipment hazards were selected, including proximity, blind spots, and velocity. The interactions of the selected factors between entities are quantified and used to generate the network. Three safety leading indicators - degree centrality, eigenvector centrality, and relative risk score - are adopted to represent the risk levels of individual entities and jobsites. The implementation and evaluation of the network-based model with the three leading indicators are conducted and illustrated based on four simulated jobsites. Accordingly, the derived practical applications for risk analysis and hazard identification and prevention are described. The work presented in this paper enables the quantification and analysis of struck-by-equipment risk for both individual entities and jobsites from multiple perspectives. Further insight into the temporal aspects of risk and the safety performance of entities, as well as jobsites, is gained to proactively identify and prevent hazards. © 2017 American Society of Civil Engineers.",Article,"Final",Scopus,2-s2.0-85040076585
"Xie Y., Liu J.","Analysis of early-warning threshold for metro construction collapse risk based on D-S evidence theory and rough set",2017,"Wuhan University Journal of Natural Sciences",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033698360&doi=10.1007%2fs11859-017-1281-y&partnerID=40&md5=b74247ec5491a22754e3365cb09268d3","The existing early-warning system in metro construction are generally based on traditional single-sensor data and simple analytic model, which makes it difficult to deal with the complex and comprehensive environment in metro construction. In this paper, the framework of early-warning threshold for metro construction collapse risk based on D-S evidence theory and rough set is built. By combining the primary data fusion collected based on rough set with the secondary data fusion which is based on D-S evidence theory, the integration of multiple information in metro construction is realized and the risk assessment methods are optimized. A case trial based on Hangzhou metro construction collapse accident is also carried out to exemplify the framework. The empirical analysis guarantees the completeness and independence of the prediction information, and realizes the dynamic prediction of the variation trend of metro construction collapse risk. © 2017, Wuhan University and Springer-Verlag GmbH Germany, part of Springer Nature.",Article,"Final",Scopus,2-s2.0-85033698360
"Guo Q., Dai J., Wang J.","Study on fire detection model based on fuzzy neural network",2010,"Proceedings - 2010 2nd International Workshop on Intelligent Systems and Applications, ISA 2010",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954414452&doi=10.1109%2fIWISA.2010.5473248&partnerID=40&md5=7fa6b585343526bb4b08f94f45cb589a","The fire signal detection is a non-structural problem and difficult to be precise described by mathematical model, which increase the difficulty of fire detection. According to the special type of signal detection technique such as fire signal detection, a fire detection model based on fuzzy-neural network is presented. This paper described the design method of the model, as well as its learning algorithm. In standard fire test rooms, simulation experiments were carried out for smoldering fire SH1 and flaming fire SH3 of the china national standard test fires, the model can make right judgment. Theory analysis and simulation study show that the model combines the advantages of fuzzy system and neural network, and improves the intelligence of fire detection, has a stronger ability to adapt the environment. It effectively solves the problems of mistake and failure in the fire alarm, and improves the sensibility of fire detection. ©2010 IEEE.",Conference Paper,"Final",Scopus,2-s2.0-77954414452
"Tsiapoki S., Bahrami O., Häckell M.W., Lynch J.P., Rolfes R.","Combination of damage feature decisions with adaptive boosting for improving the detection performance of a structural health monitoring framework: Validation on an operating wind turbine",2021,"Structural Health Monitoring",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082106889&doi=10.1177%2f1475921720909379&partnerID=40&md5=aa8e4975848d0cb1a4e8a64c74297129","This article proposes the deployment of adaptive boosting (AdaBoost) for combining damage feature decisions and improving the detection accuracy of structural health monitoring algorithms. In structural health monitoring applications, damage-sensitive features are combined with classifiers to define decision boundaries and provide information about the structural state. Boosting algorithms combine multiple classifiers aiming at the improvement of their performance. In this study, AdaBoost is deployed on the realizations of a modular structural health monitoring framework, which consists of three tiers: data normalization based on environmental and operational conditions; extraction of damage features, also referred to as condition parameters; and hypothesis testing. Each condition parameter–hypothesis testing pair composes a classifier which is used in AdaBoost as a weak classifier. The integration of AdaBoost with the structural health monitoring framework is validated using experimental data of a 3-kW wind turbine located at the Los Alamos National Laboratory and data generated from a mechanical model of the same structure. The AdaBoost classifier is evaluated with respect to the error rate as well as the true positive and false positive rates, which are typically used in receiver operating characteristic curves. The AdaBoost classifier outperforms the framework classifiers in many cases, improving drastically the detection performance. However, it is shown that the boosting performance depends on the relative location of the condition parameter values on the condition parameter space. The overlaps between the condition parameter values to be combined are quantified using the Bhattacharyya coefficient, which provides a metric for assessing the boosting potential. Finally, omitting condition parameter values corresponding to specific environmental and operational conditions from the boosting process is proposed for obtaining optimum boosting results. © The Author(s) 2020.",Review,"Final",Scopus,2-s2.0-85082106889
"Shahinmoghaddam M., Nazari A., Zandieh M.","CA-FCM: Towards a formal representation of expert's causal judgements over construction project changes",2018,"Advanced Engineering Informatics",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054301306&doi=10.1016%2fj.aei.2018.09.006&partnerID=40&md5=0dbf12a1d6b5c2035eebaaf1863ce121","Aimed at improving the proactive benefits of Fuzzy Cognitive Mapping (FCM) for predicting construction project changes, this paper presents CA-FCM: a Context-aware Fuzzy Cognitive Mapping approach. CA-FCM's main functionality is to imitate the intuitive causal judgements of project experts over change causation in different contextual settings. Invoking the logical inference capabilities of semantic web tools, a hybrid inference mechanism is embedded within the proposed framework which enables establishing contextual connections between prospective causal factors through a semi-automated process of generating relevant causal statements. Hence, CA-FCM can assist decision-makers with (1) a shared sense-making of the domain concepts which would significantly facilitate the manual construction of FCM scenarios, (2) providing contextualized recommendations of causal information required for developing FCM scenarios, (3) dynamic modelling of causal inferences, imitating expert reasoning on change causation and propagation. Towards providing a detailed delineation of CA-FCM's effectiveness on providing assistance in planning for project changes, a partial implementation of the proposed framework was conducted within a real case scenario. © 2018 Elsevier Ltd",Article,"Final",Scopus,2-s2.0-85054301306
"Hsu P.-Y., Aurisicchio M., Angeloudis P., Whyte J.","Understanding and visualizing schedule deviations in construction projects using fault tree analysis",2020,"Engineering, Construction and Architectural Management",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085077629&doi=10.1108%2fECAM-01-2020-0058&partnerID=40&md5=e376774b91f2ac26561ff14f1a51e73f","Purpose: Delays in construction projects are both disruptive and expensive. Thus, potential causes of schedule deviation need to be identified and mitigated. In previous research, delay factors were predominantly identified through surveys administered to stakeholders in construction projects. Such delay factors are typically considered individually and presented at the same level without explicitly examining their sequence of occurrence and inter-relationships. In reality, owing to the complex structure of construction projects and long execution time, non-conformance to schedule occurs by a chain of cascading events. An understanding of these linkages is important not only for minimising the delays but also for revealing the liability of stakeholders. To explicitly illustrate the cause–effect and logical relationship between delay factors and further identify the primary factors which possess the highest significance toward the overall project schedule delay, the fault tree analysis (FTA) method, a widely implemented approach to root cause problems in safety-critical systems, has been systematically and rigorously executed. Design/methodology/approach: Using a case study, the in-depth analysis for identifying the most fundamental delay factors has been fulfilled through FTA's tree structure. The logical deduction for mapping and visualising the chronological and cause–effect relationships between various delay factors has been conducted through the logical gate functions of FTA based on the data collected from the site event log, pre-fabricated structural component manufacturing log and face-to-face interview with project stakeholders. Findings: The analysis identified multiple delay factors and showed how they are linked logically and chronologically from the primary causes to the ultimate undesired event in a rigorous manner. A comparison was performed between the proposed FTA model and the conventional investigation method for revealing the responsibility employed in the construction industry, consisting of event logs and problem reports. The results indicate that the FTA model provides richer information and a clearer picture of the network of delay factors. Importantly, the ability of FTA in revealing the causal connection between the events leading to the undesired delays and in comprehending their prominence in the real-world construction project has been clearly displayed. Originality/ value: This study demonstrates a new application of FTA in the construction sector allowing the delay factors to be understood and visualised from a new perspective. The new approach has practical use in finding and removing root causes of the delay, as well as clarifying the attribution of responsibility that causes the delay. © 2020, Emerald Publishing Limited.",Article,"Final",Scopus,2-s2.0-85085077629
"Kouhestani S.","Integration of Building Information Modeling (BIM) and Process Mining for Design Authoring Processes",2019,,1,,[No abstract available],,"Final",Scopus,2-s2.0-85097898881
